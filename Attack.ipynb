{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit"
  },
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Attack Code Testing"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Imports"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from adversary import *\n",
    "from net import Net\n",
    "import numpy as np\n",
    "from torch.optim import Optimizer\n",
    "import torch\n",
    "from training import training, testing, accuracy\n",
    "from optimizer import MiniBatchOptimizer\n",
    "import matplotlib.pyplot as plt\n",
    "from data_utils import get_mnist, build_data_loaders"
   ]
  },
  {
   "source": [
    "## Setup of a Testing Net with Minibatch"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies_naive_fgsm = []\n",
    "accuracies_naive_proj = []\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "epochs = 10\n",
    "batch_size = 100\n",
    "learning_rate = 0.01\n",
    "decreasing_lr = False\n",
    "use_cuda = True # GPU seems to raise erros on my side\n",
    "device = torch.device('cuda' if use_cuda and torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "net_naive = Net().to(device)\n",
    "train_dataset, test_dataset = get_mnist(normalize=True)\n",
    "train_loader, test_loader = build_data_loaders(train_dataset, test_dataset, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilons = np.arange(0, 0.5, 0.05)"
   ]
  },
  {
   "source": [
    "## Train Naive Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Launching training on cuda batch 100\tloss = 1.666\tacc = 0.73\n",
      "batch 200\tloss = 0.6291\tacc = 0.82\n",
      "batch 300\tloss = 0.6094\tacc = 0.81\n",
      "batch 400\tloss = 0.3901\tacc = 0.92\n",
      "batch 500\tloss = 0.2852\tacc = 0.93\n",
      "batch 600\tloss = 0.3494\tacc = 0.92\n",
      "epoch 0\tavg epoch loss = 0.7691\tavg epoch acc = 0.8143\n",
      "batch 100\tloss = 0.1683\tacc = 0.97\n",
      "batch 200\tloss = 0.1808\tacc = 0.95\n",
      "batch 300\tloss = 0.3013\tacc = 0.87\n",
      "batch 400\tloss = 0.2257\tacc = 0.92\n",
      "batch 500\tloss = 0.1399\tacc = 0.96\n",
      "batch 600\tloss = 0.2965\tacc = 0.96\n",
      "epoch 1\tavg epoch loss = 0.2069\tavg epoch acc = 0.9389\n",
      "batch 100\tloss = 0.1007\tacc = 0.97\n",
      "batch 200\tloss = 0.1095\tacc = 0.97\n",
      "batch 300\tloss = 0.1785\tacc = 0.94\n",
      "batch 400\tloss = 0.1427\tacc = 0.96\n",
      "batch 500\tloss = 0.08739\tacc = 0.98\n",
      "batch 600\tloss = 0.2777\tacc = 0.97\n",
      "epoch 2\tavg epoch loss = 0.1416\tavg epoch acc = 0.9588\n",
      "batch 100\tloss = 0.06902\tacc = 0.98\n",
      "batch 200\tloss = 0.07592\tacc = 0.97\n",
      "batch 300\tloss = 0.1175\tacc = 0.97\n",
      "batch 400\tloss = 0.1002\tacc = 0.96\n",
      "batch 500\tloss = 0.06249\tacc = 1.0\n",
      "batch 600\tloss = 0.2687\tacc = 0.97\n",
      "epoch 3\tavg epoch loss = 0.109\tavg epoch acc = 0.9681\n",
      "batch 100\tloss = 0.05178\tacc = 0.98\n",
      "batch 200\tloss = 0.05987\tacc = 0.98\n",
      "batch 300\tloss = 0.08096\tacc = 0.98\n",
      "batch 400\tloss = 0.07677\tacc = 0.98\n",
      "batch 500\tloss = 0.0491\tacc = 1.0\n",
      "batch 600\tloss = 0.263\tacc = 0.98\n",
      "epoch 4\tavg epoch loss = 0.08969\tavg epoch acc = 0.9737\n",
      "batch 100\tloss = 0.0401\tacc = 0.99\n",
      "batch 200\tloss = 0.05072\tacc = 0.98\n",
      "batch 300\tloss = 0.05957\tacc = 0.99\n",
      "batch 400\tloss = 0.06311\tacc = 0.98\n",
      "batch 500\tloss = 0.04076\tacc = 1.0\n",
      "batch 600\tloss = 0.2582\tacc = 0.98\n",
      "epoch 5\tavg epoch loss = 0.07686\tavg epoch acc = 0.9774\n",
      "batch 100\tloss = 0.03205\tacc = 1.0\n",
      "batch 200\tloss = 0.04525\tacc = 0.99\n",
      "batch 300\tloss = 0.0474\tacc = 0.99\n",
      "batch 400\tloss = 0.0545\tacc = 0.98\n",
      "batch 500\tloss = 0.03488\tacc = 1.0\n",
      "batch 600\tloss = 0.2529\tacc = 0.98\n",
      "epoch 6\tavg epoch loss = 0.06758\tavg epoch acc = 0.9798\n",
      "batch 100\tloss = 0.02632\tacc = 1.0\n",
      "batch 200\tloss = 0.04082\tacc = 0.99\n",
      "batch 300\tloss = 0.03938\tacc = 1.0\n",
      "batch 400\tloss = 0.04767\tacc = 0.98\n",
      "batch 500\tloss = 0.0304\tacc = 1.0\n",
      "batch 600\tloss = 0.2471\tacc = 0.98\n",
      "epoch 7\tavg epoch loss = 0.06047\tavg epoch acc = 0.9819\n",
      "batch 100\tloss = 0.02172\tacc = 1.0\n",
      "batch 200\tloss = 0.03705\tacc = 0.99\n",
      "batch 300\tloss = 0.03396\tacc = 1.0\n",
      "batch 400\tloss = 0.04139\tacc = 0.99\n",
      "batch 500\tloss = 0.02673\tacc = 1.0\n",
      "batch 600\tloss = 0.2408\tacc = 0.98\n",
      "epoch 8\tavg epoch loss = 0.05478\tavg epoch acc = 0.9837\n",
      "batch 100\tloss = 0.01833\tacc = 1.0\n",
      "batch 200\tloss = 0.03515\tacc = 0.99\n",
      "batch 300\tloss = 0.03045\tacc = 1.0\n",
      "batch 400\tloss = 0.03609\tacc = 0.99\n",
      "batch 500\tloss = 0.02389\tacc = 1.0\n",
      "batch 600\tloss = 0.2347\tacc = 0.98\n",
      "epoch 9\tavg epoch loss = 0.05012\tavg epoch acc = 0.9848\n",
      "training took 25.21 s\n",
      "Avg test loss = 0.0516\tAvg test acc = 0.983\n"
     ]
    }
   ],
   "source": [
    "mini_opt = MiniBatchOptimizer(net_naive.parameters(), lr=learning_rate, decreasing_lr=decreasing_lr)\n",
    "losses, acc = training(net_naive, train_loader, mini_opt, criterion, accuracy, epochs=epochs, device=device)\n",
    "losses, acc = testing(net_naive, test_loader, criterion, accuracy, device=device)\n"
   ]
  },
  {
   "source": [
    "## Attack Naive Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Standard FGSM"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epsilon: 0.00\tTest Accuracy = 0.900\nNaive Net:  0.9004999999999999\n"
     ]
    }
   ],
   "source": [
    "losses, acc = attack(net_naive, criterion, accuracy, test_loader, epsilon=0.0, device=device)\n",
    "print(\"Naive Net: \", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for eps in epsilons:\n",
    "    loss_attack, acc_attack  = attack(net_naive, criterion, accuracy, test_loader, epsilon=eps, device=device)\n",
    "    accuracies_naive_fgsm.append(acc_attack)"
   ]
  },
  {
   "source": [
    "Projected Gradient Descent"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilons_proj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epsilon: 0.00\tTest Accuracy = 0.983\n",
      "Epsilon: 0.05\tTest Accuracy = 0.962\n",
      "Epsilon: 0.10\tTest Accuracy = 0.919\n",
      "Epsilon: 0.15\tTest Accuracy = 0.835\n",
      "Epsilon: 0.20\tTest Accuracy = 0.692\n",
      "Epsilon: 0.25\tTest Accuracy = 0.498\n",
      "Epsilon: 0.30\tTest Accuracy = 0.302\n",
      "Epsilon: 0.35\tTest Accuracy = 0.172\n",
      "Epsilon: 0.40\tTest Accuracy = 0.094\n",
      "Epsilon: 0.45\tTest Accuracy = 0.044\n"
     ]
    }
   ],
   "source": [
    "for eps in epsilons:\n",
    "    loss_attack, acc_attack  = projected_attack(net_naive, criterion, accuracy, test_loader, epsilon=eps, alpha=0.1, num_iter=40, device=device)\n",
    "    accuracies_naive_proj.append(acc_attack)\n"
   ]
  },
  {
   "source": [
    "## Train Robust Models Version"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "robust_net = Net().to(device)\n",
    "protect_epochs = 10\n",
    "protect_lr = 0.01\n",
    "protect_bz = 32\n",
    "protect_dec_lr = False\n",
    "\n",
    "prot_train_loader, prot_test_loader = build_data_loaders(train_dataset, test_dataset, protect_bz)\n",
    "mini_opt_proc = MiniBatchOptimizer(robust_net.parameters(), lr=protect_lr, decreasing_lr=protect_dec_lr)\n",
    "\n",
    "accuracies_robust_fgsm = []\n",
    "accuracies_robust_proj = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-34c21682ca94>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mloss_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprotected_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrobust_net\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprot_train_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmini_opt_proc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprotect_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mloss_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtesting\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrobust_net\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/storage/Semester 2/Opt. ML/Project/REPO/optml_project/adversary.py\u001b[0m in \u001b[0;36mprotected_training\u001b[0;34m(model, dataset, optim, loss_fun, metric_fun, epochs, device, batch_log_interval)\u001b[0m\n\u001b[1;32m    155\u001b[0m             \u001b[0myhat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myhat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m   1045\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1047\u001b[0;31m         return F.cross_entropy(input, target, weight=self.weight,\n\u001b[0m\u001b[1;32m   1048\u001b[0m                                ignore_index=self.ignore_index, reduction=self.reduction)\n\u001b[1;32m   1049\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   2691\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2692\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2693\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2694\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2695\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mnll_loss\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   2386\u001b[0m         )\n\u001b[1;32m   2387\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2388\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2389\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2390\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "loss_train, acc_train = protected_training(robust_net, prot_train_loader, mini_opt_proc, criterion, accuracy, epochs=protect_epochs, device=device)\n",
    "loss_test, acc_test = testing(robust_net, test_loader, criterion, accuracy, device=device)"
   ]
  },
  {
   "source": [
    "## Attack Robust Model Version"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Standard FGSM"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for eps in epsilons_fgsm:\n",
    "    loss_attack, acc_attack  = attack(robust_net, criterion, accuracy, test_loader, epsilon=eps, device=device)\n",
    "    accuracies_robust_fgsm.append(acc_attack)"
   ]
  },
  {
   "source": [
    "Projected Gradient Descent"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for eps in epsilons_proj:\n",
    "    loss_attack, acc_attack  = projected_attack(robust_net, criterion, accuracy, test_loader, epsilon=eps, alpha=1e-2, num_iter=40, device=device)\n",
    "    accuracies_robust_proj.append(acc_attack)\n"
   ]
  },
  {
   "source": [
    "## Comparative Analysis"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilons_it = np.arange(0, len(epsilons_pgd), 1)\n"
   ]
  },
  {
   "source": [
    "### Naive Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,5))\n",
    "plt.plot(epsilons_it, accuracies_naive_fgsm, \"*-\", c='blue', label='Std. FGSM')\n",
    "plt.plot(epsilons_it, accuracies_naive_proj, \"*-\", c='orange', label='PGD')\n",
    "\n",
    "plt.yticks(np.arange(0, 1.1, step=0.1))\n",
    "plt.xticks(epsilons_it)\n",
    "\n",
    "plt.title(\"Naive Model\")\n",
    "plt.xlabel(\"Epsilon Choices\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend();"
   ]
  },
  {
   "source": [
    "### Robust Mode"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,5))\n",
    "plt.plot(epsilons_it, accuracies_robust_fgsm, \"*-\", c='blue', label='Std. FGSM')\n",
    "plt.plot(epsilons_it, accuracies_robust_proj, \"*-\", c='orange', label='PGD')\n",
    "\n",
    "plt.yticks(np.arange(0, 1.1, step=0.1))\n",
    "plt.xticks(epsilons_it)\n",
    "\n",
    "plt.title(\"Robust Model\")\n",
    "plt.xlabel(\"Epsilon Choices\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend();"
   ]
  },
  {
   "source": [
    "## File output"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"********************************\")\n",
    "for entry in  accuracies_naive_fgsm:\n",
    "    print(entry)\n",
    "print(\"********************************\")\n",
    "for entry in  accuracies_naive_proj:\n",
    "    print(entry)\n",
    "print(\"********************************\")\n",
    "for entry in  accuracies_robust_fgsm:\n",
    "    print(entry)\n",
    "print(\"********************************\")\n",
    "for entry in  accuracies_robust_proj:\n",
    "    print(entry)"
   ]
  }
 ]
}