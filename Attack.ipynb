{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Attack Code Testing"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Imports"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from adversary import *\n",
    "from net import Net\n",
    "import numpy as np\n",
    "from torch.optim import Optimizer\n",
    "import torch\n",
    "from training import training, testing, accuracy\n",
    "from optimizer import MiniBatchOptimizer\n",
    "import matplotlib.pyplot as plt\n",
    "from data_utils import get_mnist, build_data_loaders"
   ]
  },
  {
   "source": [
    "## Setup of a Testing Net with Minibatch"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies_naive_fgsm = []\n",
    "accuracies_naive_proj = []\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "epochs = 10\n",
    "batch_size = 100\n",
    "learning_rate = 0.01\n",
    "decreasing_lr = False\n",
    "use_cuda = True # GPU seems to raise erros on my side\n",
    "device = torch.device('cuda' if use_cuda and torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "net_naive = Net().to(device)\n",
    "train_dataset, test_dataset = get_mnist(normalize=True)\n",
    "train_loader, test_loader = build_data_loaders(train_dataset, test_dataset, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilons_fgsm = np.arange(0, 0.5, 0.05)\n",
    "\n",
    "epsilons_proj = []\n",
    "\n",
    "n = 784 # Thus n is the dimension of each image, which we need to scale the L2 norm for Projected Gradient Descent\n",
    "\n",
    "# From source https://adversarial-ml-tutorial.org/adversarial_examples/ for L2 PGD\n",
    "scaler = np.sqrt(2*n)/(np.sqrt(np.pi*np.exp(1)))\n",
    "for eps in epsilons_fgsm:\n",
    "    new_eps = eps*scaler\n",
    "    epsilons_proj.append(new_eps)"
   ]
  },
  {
   "source": [
    "## Train Naive Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Launching training on cuda\n",
      "batch 100\tloss = 1.956\tacc = 0.62\n",
      "batch 200\tloss = 0.9253\tacc = 0.76\n",
      "batch 300\tloss = 0.7016\tacc = 0.76\n",
      "batch 400\tloss = 0.408\tacc = 0.9\n",
      "batch 500\tloss = 0.3013\tacc = 0.94\n",
      "batch 600\tloss = 0.3604\tacc = 0.9\n",
      "epoch 0\tavg epoch loss = 0.8829\tavg epoch acc = 0.7646\n",
      "batch 100\tloss = 0.1768\tacc = 0.95\n",
      "batch 200\tloss = 0.1664\tacc = 0.95\n",
      "batch 300\tloss = 0.3008\tacc = 0.9\n",
      "batch 400\tloss = 0.2275\tacc = 0.93\n",
      "batch 500\tloss = 0.1244\tacc = 0.97\n",
      "batch 600\tloss = 0.2869\tacc = 0.96\n",
      "epoch 1\tavg epoch loss = 0.207\tavg epoch acc = 0.9404\n",
      "batch 100\tloss = 0.1056\tacc = 0.97\n",
      "batch 200\tloss = 0.09397\tacc = 0.96\n",
      "batch 300\tloss = 0.1809\tacc = 0.94\n",
      "batch 400\tloss = 0.1422\tacc = 0.94\n",
      "batch 500\tloss = 0.07289\tacc = 0.99\n",
      "batch 600\tloss = 0.2617\tacc = 0.98\n",
      "epoch 2\tavg epoch loss = 0.1393\tavg epoch acc = 0.9593\n",
      "batch 100\tloss = 0.07156\tacc = 0.98\n",
      "batch 200\tloss = 0.06446\tacc = 0.97\n",
      "batch 300\tloss = 0.123\tacc = 0.97\n",
      "batch 400\tloss = 0.09504\tacc = 0.97\n",
      "batch 500\tloss = 0.05393\tacc = 1.0\n",
      "batch 600\tloss = 0.2468\tacc = 0.98\n",
      "epoch 3\tavg epoch loss = 0.1084\tavg epoch acc = 0.9682\n",
      "batch 100\tloss = 0.05321\tacc = 0.98\n",
      "batch 200\tloss = 0.04829\tacc = 0.98\n",
      "batch 300\tloss = 0.0861\tacc = 0.97\n",
      "batch 400\tloss = 0.0731\tacc = 0.97\n",
      "batch 500\tloss = 0.0454\tacc = 1.0\n",
      "batch 600\tloss = 0.2353\tacc = 0.98\n",
      "epoch 4\tavg epoch loss = 0.08998\tavg epoch acc = 0.9732\n",
      "batch 100\tloss = 0.04221\tacc = 0.99\n",
      "batch 200\tloss = 0.03967\tacc = 0.99\n",
      "batch 300\tloss = 0.063\tacc = 0.99\n",
      "batch 400\tloss = 0.06127\tacc = 0.98\n",
      "batch 500\tloss = 0.04006\tacc = 1.0\n",
      "batch 600\tloss = 0.2249\tacc = 0.98\n",
      "epoch 5\tavg epoch loss = 0.07747\tavg epoch acc = 0.9767\n",
      "batch 100\tloss = 0.03472\tacc = 0.99\n",
      "batch 200\tloss = 0.0347\tacc = 0.99\n",
      "batch 300\tloss = 0.04786\tacc = 1.0\n",
      "batch 400\tloss = 0.05404\tacc = 0.98\n",
      "batch 500\tloss = 0.03617\tacc = 1.0\n",
      "batch 600\tloss = 0.2154\tacc = 0.98\n",
      "epoch 6\tavg epoch loss = 0.06837\tavg epoch acc = 0.9796\n",
      "batch 100\tloss = 0.02931\tacc = 0.99\n",
      "batch 200\tloss = 0.03189\tacc = 0.99\n",
      "batch 300\tloss = 0.0385\tacc = 1.0\n",
      "batch 400\tloss = 0.04774\tacc = 0.99\n",
      "batch 500\tloss = 0.03341\tacc = 1.0\n",
      "batch 600\tloss = 0.2073\tacc = 0.98\n",
      "epoch 7\tavg epoch loss = 0.0614\tavg epoch acc = 0.9816\n",
      "batch 100\tloss = 0.02498\tacc = 1.0\n",
      "batch 200\tloss = 0.02964\tacc = 0.99\n",
      "batch 300\tloss = 0.03246\tacc = 1.0\n",
      "batch 400\tloss = 0.04206\tacc = 0.99\n",
      "batch 500\tloss = 0.03105\tacc = 1.0\n",
      "batch 600\tloss = 0.2\tacc = 0.99\n",
      "epoch 8\tavg epoch loss = 0.05587\tavg epoch acc = 0.9832\n",
      "batch 100\tloss = 0.02154\tacc = 1.0\n",
      "batch 200\tloss = 0.02823\tacc = 0.99\n",
      "batch 300\tloss = 0.02797\tacc = 1.0\n",
      "batch 400\tloss = 0.03711\tacc = 0.99\n",
      "batch 500\tloss = 0.02927\tacc = 1.0\n",
      "batch 600\tloss = 0.1935\tacc = 0.99\n",
      "epoch 9\tavg epoch loss = 0.05134\tavg epoch acc = 0.9845\n",
      "training took 26.14 s\n",
      "Avg test loss = 0.0545\tAvg test acc = 0.982\n"
     ]
    }
   ],
   "source": [
    "mini_opt = MiniBatchOptimizer(net_naive.parameters(), lr=learning_rate, decreasing_lr=decreasing_lr)\n",
    "losses, acc = training(net_naive, train_loader, mini_opt, criterion, accuracy, epochs=epochs, device=device)\n",
    "losses, acc = testing(net_naive, test_loader, criterion, accuracy, device=device)\n"
   ]
  },
  {
   "source": [
    "## Attack Naive Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Standard FGSM"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epsilon: 0.10\tTest Accuracy = 0.873\nNaive Net:  0.8725000000000003\n"
     ]
    }
   ],
   "source": [
    "losses, acc = attack(net_naive, criterion, accuracy, test_loader, epsilon=0.1, device=device)\n",
    "print(\"Naive Net: \", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epsilon: 0.00\tTest Accuracy = 0.902\n",
      "Epsilon: 0.05\tTest Accuracy = 0.889\n",
      "Epsilon: 0.10\tTest Accuracy = 0.873\n",
      "Epsilon: 0.15\tTest Accuracy = 0.850\n",
      "Epsilon: 0.20\tTest Accuracy = 0.823\n",
      "Epsilon: 0.25\tTest Accuracy = 0.785\n",
      "Epsilon: 0.30\tTest Accuracy = 0.735\n",
      "Epsilon: 0.35\tTest Accuracy = 0.670\n",
      "Epsilon: 0.40\tTest Accuracy = 0.590\n",
      "Epsilon: 0.45\tTest Accuracy = 0.500\n"
     ]
    }
   ],
   "source": [
    "for eps in epsilons_fgsm:\n",
    "    loss_attack, acc_attack  = attack(net_naive, criterion, accuracy, test_loader, epsilon=eps, device=device)\n",
    "    accuracies_naive_fgsm.append(acc_attack)"
   ]
  },
  {
   "source": [
    "Projected Gradient Descent"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[0.0,\n",
       " 0.6775180286536014,\n",
       " 1.355036057307203,\n",
       " 2.0325540859608044,\n",
       " 2.710072114614406,\n",
       " 3.387590143268007,\n",
       " 4.065108171921609,\n",
       " 4.74262620057521,\n",
       " 5.420144229228812,\n",
       " 6.097662257882413]"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "epsilons_proj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epsilon: 0.00\tTest Accuracy = 0.982\n",
      "Epsilon: 0.68\tTest Accuracy = 0.982\n",
      "Epsilon: 1.36\tTest Accuracy = 0.982\n",
      "Epsilon: 2.03\tTest Accuracy = 0.982\n",
      "Epsilon: 2.71\tTest Accuracy = 0.982\n",
      "Epsilon: 3.39\tTest Accuracy = 0.982\n",
      "Epsilon: 4.07\tTest Accuracy = 0.981\n",
      "Epsilon: 4.74\tTest Accuracy = 0.981\n",
      "Epsilon: 5.42\tTest Accuracy = 0.981\n",
      "Epsilon: 6.10\tTest Accuracy = 0.981\n"
     ]
    }
   ],
   "source": [
    "for eps in epsilons_proj:\n",
    "    loss_attack, acc_attack  = projected_attack(net_naive, criterion, accuracy, test_loader, epsilon=eps, alpha=0.1, num_iter=40, device=device)\n",
    "    accuracies_naive_proj.append(acc_attack)\n"
   ]
  },
  {
   "source": [
    "## Train Robust Models Version"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "robust_net = Net().to(device)\n",
    "protect_epochs = 10\n",
    "protect_lr = 0.01\n",
    "protect_bz = 32\n",
    "protect_dec_lr = False\n",
    "\n",
    "prot_train_loader, prot_test_loader = build_data_loaders(train_dataset, test_dataset, protect_bz)\n",
    "mini_opt_proc = MiniBatchOptimizer(robust_net.parameters(), lr=protect_lr, decreasing_lr=protect_dec_lr)\n",
    "\n",
    "accuracies_robust_fgsm = []\n",
    "accuracies_robust_proj = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_train, acc_train = protected_training(robust_net, prot_train_loader, mini_opt_proc, criterion, accuracy, epochs=protect_epochs, device=device)\n",
    "loss_test, acc_test = testing(robust_net, test_loader, criterion, accuracy, device=device)"
   ]
  },
  {
   "source": [
    "## Attack Robust Model Version"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Standard FGSM"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for eps in epsilons_fgsm:\n",
    "    loss_attack, acc_attack  = attack(robust_net, criterion, accuracy, test_loader, epsilon=eps, device=device)\n",
    "    accuracies_robust_fgsm.append(acc_attack)"
   ]
  },
  {
   "source": [
    "Projected Gradient Descent"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for eps in epsilons_proj:\n",
    "    loss_attack, acc_attack  = projected_attack(robust_net, criterion, accuracy, test_loader, epsilon=eps, alpha=1e-2, num_iter=40, device=device)\n",
    "    accuracies_robust_proj.append(acc_attack)\n"
   ]
  },
  {
   "source": [
    "## Comparative Analysis"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilons_it = np.arange(0, len(epsilons_pgd), 1)\n"
   ]
  },
  {
   "source": [
    "### Naive Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,5))\n",
    "plt.plot(epsilons_it, accuracies_naive_fgsm, \"*-\", c='blue', label='Std. FGSM')\n",
    "plt.plot(epsilons_it, accuracies_naive_proj, \"*-\", c='orange', label='PGD')\n",
    "\n",
    "plt.yticks(np.arange(0, 1.1, step=0.1))\n",
    "plt.xticks(epsilons_it)\n",
    "\n",
    "plt.title(\"Naive Model\")\n",
    "plt.xlabel(\"Epsilon Choices\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend();"
   ]
  },
  {
   "source": [
    "### Robust Mode"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,5))\n",
    "plt.plot(epsilons_it, accuracies_robust_fgsm, \"*-\", c='blue', label='Std. FGSM')\n",
    "plt.plot(epsilons_it, accuracies_robust_proj, \"*-\", c='orange', label='PGD')\n",
    "\n",
    "plt.yticks(np.arange(0, 1.1, step=0.1))\n",
    "plt.xticks(epsilons_it)\n",
    "\n",
    "plt.title(\"Robust Model\")\n",
    "plt.xlabel(\"Epsilon Choices\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend();"
   ]
  },
  {
   "source": [
    "## File output"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"********************************\")\n",
    "for entry in  accuracies_naive_fgsm:\n",
    "    print(entry)\n",
    "print(\"********************************\")\n",
    "for entry in  accuracies_naive_proj:\n",
    "    print(entry)\n",
    "print(\"********************************\")\n",
    "for entry in  accuracies_robust_fgsm:\n",
    "    print(entry)\n",
    "print(\"********************************\")\n",
    "for entry in  accuracies_robust_proj:\n",
    "    print(entry)"
   ]
  }
 ]
}