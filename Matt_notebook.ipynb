{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Mini-Batch GD and How Adverserial Examples affects its Performance"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Overview of this Notebook: <br>\n",
    "#### 1. Import of Python libraries and the dataset<br>\n",
    "#### 2. Tuning of the Hyperparameters of the Mini-Batch Optimiser<br>\n",
    "#### 3. Training a Naive Model<br>\n",
    "#### 4. Evaluate the Attack against the Naive Model<br>\n",
    "#### 5. Training a Robust Model <br>\n",
    "#### 6. Evaluate the Attack against the Robust Model <br>\n",
    "#### 7. Comparision of the two performances <br>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Begin by importing the relevant libraries"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from adversary import attack, protect\n",
    "from net import Net\n",
    "import numpy as np\n",
    "from torch.optim import Optimizer\n",
    "import torch\n",
    "from training import training, testing, accuracy, tune_optimizer\n",
    "from minibatch import MiniBatchOptimizer\n",
    "import matplotlib.pyplot as plt\n",
    "from data_utils import get_mnist, build_data_loaders\n",
    "import json\n",
    "from pathlib import Path\n",
    "import random\n"
   ]
  },
  {
   "source": [
    "## Get Data and Setup"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = True # GPU seems to raise erros on my side\n",
    "device = torch.device('cuda' if use_cuda and torch.cuda.is_available() else 'cpu')\n",
    "train_dataset, test_dataset = get_mnist(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilons = np.arange(0, 0.5, 0.05)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "epochs = 10\n",
    "batch_size = 16"
   ]
  },
  {
   "source": [
    "## Hyperparameter Tuning"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Train the Naive Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "decreasing_lr = False"
   ]
  },
  {
   "source": [
    "### Create Data Loaders with the set Batch Size and the Model\n",
    "#### The layer setup is in the net.py file"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_naive = Net().to(device)\n",
    "train_loader, test_loader = build_data_loaders(train_dataset, test_dataset, batch_size)"
   ]
  },
  {
   "source": [
    "### Train and Test"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mini_opt_naive = MiniBatchOptimizer(net_naive.parameters(), lr=learning_rate, decreasing_lr=decreasing_lr)\n",
    "loss_train, acc_train = training(net_naive, train_loader, mini_opt_naive, criterion, accuracy, epochs=epochs, device=device)\n",
    "loss_test, acc_test = testing(net_naive, test_loader, criterion, accuracy, device=device)"
   ]
  },
  {
   "source": [
    "## Attack Naive Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_naive= []\n",
    "losses_naive= []\n",
    "\n",
    "for eps in epsilons:\n",
    "    loss_attack, acc_attack  = attack(net_naive, criterion, test_loader, epsilon=eps, device=device)\n",
    "    accuracy_naive.append(acc_attack)\n",
    "    losses_naive.append(loss_attack)"
   ]
  },
  {
   "source": [
    "## Train the Robust Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "robust_net = Net().to(device)\n",
    "protect_epochs = epochs\n",
    "protect_lr = learning_rate\n",
    "protect_bz = batch_size\n",
    "protect_dec_lr = decreasing_lr\n",
    "prot_train_loader, prot_test_loader = build_data_loaders(train_dataset, test_dataset, protect_bz)\n",
    "mini_opt_proc = MiniBatchOptimizer(robust_net.parameters(), lr=protect_lr, decreasing_lr=protect_dec_lr)"
   ]
  },
  {
   "source": [
    "### Call the protect function to make the model robust"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "robust_net = protect(robust_net, mini_opt_proc, criterion, prot_train_loader, prot_test_loader, device=device, epochs=protect_epochs)"
   ]
  },
  {
   "source": [
    "## Attack the Robust Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_robust = []\n",
    "losses_robust = []\n",
    "\n",
    "for eps in epsilons:\n",
    "    loss_attack, acc_attack = attack(robust_net, criterion, prot_train_loader, eps, device=device)\n",
    "    accuracy_robust.append(acc_attack)\n",
    "    losses_robust.append(loss_attack)"
   ]
  },
  {
   "source": [
    "## Comparative Analysis of the Two Models"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,5))\n",
    "plt.plot(epsilons, accuracy_naive, \"*-\", c='blue', label='Naive Model')\n",
    "plt.plot(epsilons, accuracy_robust, \"*-\", c='orange', label='Robust Model')\n",
    "\n",
    "plt.yticks(np.arange(0, 1.1, step=0.1))\n",
    "plt.xticks(np.arange(0, 5, step=0.05))\n",
    "\n",
    "plt.title(\"Accuracy vs Epsilon\")\n",
    "plt.xlabel(\"Epsilon\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend();"
   ]
  }
 ]
}