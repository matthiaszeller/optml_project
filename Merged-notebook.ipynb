{"nbformat":4,"nbformat_minor":5,"metadata":{"kernelspec":{"name":"python391jvsc74a57bd0fe366cf0acf0ec4657f8e8dacfa2befd1e22c17f5ab271a2cdab9201ebd0edfa","display_name":"Python 3.9.1 64-bit ('DL': conda)"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.1"},"metadata":{"interpreter":{"hash":"aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"}},"colab":{"name":"Merged-notebook.ipynb","provenance":[],"collapsed_sections":["9kL7lW6RTC5B","xOu0V6AjTC5F","R6vqeaYzTC5I","iQc7A5jETC5I","tcc0rN-VTC5I","treK0pzuTC5I"],"toc_visible":true},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"UJ_a9gfoTC4y"},"source":["# guidelines\n","\n","TODO : import whenever needed, not centralized"],"id":"UJ_a9gfoTC4y"},{"cell_type":"markdown","metadata":{"id":"qm2EKZTHTC41"},"source":["states https://pytorch.org/tutorials/beginner/saving_loading_models.html"],"id":"qm2EKZTHTC41"},{"cell_type":"markdown","metadata":{"id":"NsH47FguTC41"},"source":["# Introduction "],"id":"NsH47FguTC41"},{"cell_type":"markdown","metadata":{"id":"clL0GDWjTC42"},"source":["## Aim"],"id":"clL0GDWjTC42"},{"cell_type":"markdown","metadata":{"id":"_cM5-hWaTC42"},"source":["## Data"],"id":"_cM5-hWaTC42"},{"cell_type":"markdown","metadata":{"id":"8XnMM2bBTC43"},"source":["First load the dataset:"],"id":"8XnMM2bBTC43"},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UkmF8OX2YVg6","executionInfo":{"status":"ok","timestamp":1623417477037,"user_tz":-120,"elapsed":620,"user":{"displayName":"Baris Sevilmis","photoUrl":"","userId":"05631870087761794056"}},"outputId":"1f7e2157-d50e-4c8b-b572-1af211aa8fdc"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"id":"UkmF8OX2YVg6","execution_count":29,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wvXzTwJKYoAq","executionInfo":{"status":"ok","timestamp":1623417478026,"user_tz":-120,"elapsed":8,"user":{"displayName":"Baris Sevilmis","photoUrl":"","userId":"05631870087761794056"}},"outputId":"d0d4d62a-0d99-4cee-e1d8-3e4653d516d6"},"source":["#%cd drive/MyDrive/\n","#%cd Colab\\ Notebooks\n","#%cd CS439/optml_project/\n","!ls"],"id":"wvXzTwJKYoAq","execution_count":30,"outputs":[{"output_type":"stream","text":[" adversary.py\t        data_utils.py\t\t  Nesterov.ipynb   res\n"," adv_test.py\t        Hyperparam-tuning.ipynb   net.py\t   Research\n"," alt_adv_test.py        Matt_notebook.ipynb\t  optimizer.py\t   test.py\n"," Baris_Notebook.ipynb   Merged-notebook.ipynb\t  __pycache__\t   training.py\n"," data\t\t       'MF Notebook.ipynb'\t  README.md\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"W_KxujBATC43","executionInfo":{"status":"ok","timestamp":1623415140709,"user_tz":-120,"elapsed":17982,"user":{"displayName":"Baris Sevilmis","photoUrl":"","userId":"05631870087761794056"}}},"source":["from data_utils import get_mnist\n","\n","train_dataset, test_dataset = get_mnist(normalize=True)"],"id":"W_KxujBATC43","execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nid4IHn6TC44"},"source":["# Import (Remove section later on)"],"id":"nid4IHn6TC44"},{"cell_type":"code","metadata":{"id":"ydlgk0IATC45","executionInfo":{"status":"ok","timestamp":1623415140712,"user_tz":-120,"elapsed":20,"user":{"displayName":"Baris Sevilmis","photoUrl":"","userId":"05631870087761794056"}}},"source":["import numpy as np\n","import torch\n","import matplotlib.pyplot as plt\n","import pandas as pd"],"id":"ydlgk0IATC45","execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"N2coYXcoTC45","executionInfo":{"status":"ok","timestamp":1623415143597,"user_tz":-120,"elapsed":2903,"user":{"displayName":"Baris Sevilmis","photoUrl":"","userId":"05631870087761794056"}}},"source":["from adversary import attack, protected_training\n","from net import Net\n","from torch.optim import Optimizer\n","from training import training, testing, tune_optimizer\n","from pathlib import Path\n","from data_utils import build_data_loaders\n","import random"],"id":"N2coYXcoTC45","execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JOCvUKD4TC45"},"source":["## Setup"],"id":"JOCvUKD4TC45"},{"cell_type":"markdown","metadata":{"id":"Jo1zcsgCTC46"},"source":["Below one can find flags that will setup the notebook:"],"id":"Jo1zcsgCTC46"},{"cell_type":"code","metadata":{"id":"FIDMg4EQTC46","executionInfo":{"status":"ok","timestamp":1623415143598,"user_tz":-120,"elapsed":26,"user":{"displayName":"Baris Sevilmis","photoUrl":"","userId":"05631870087761794056"}}},"source":["# Whether to tune the hyperparameters in this notebook\n","# Note that this might take a long time (especially for Adam)\n","hyperparameter_tune = False\n","prot_hyperparameter_tune = True"],"id":"FIDMg4EQTC46","execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yU6gHibuTC46","executionInfo":{"status":"ok","timestamp":1623415143598,"user_tz":-120,"elapsed":23,"user":{"displayName":"Baris Sevilmis","photoUrl":"","userId":"05631870087761794056"}},"outputId":"32368551-2360-42c8-fbab-aedcacabddbc"},"source":["# Whether to use the GPU, if it's not available, this will be ignored\n","use_cuda = True\n","\n","device = torch.device('cuda' if use_cuda and torch.cuda.is_available() else 'cpu')\n","print(\"Device chosen is {}\".format(device))"],"id":"yU6gHibuTC46","execution_count":7,"outputs":[{"output_type":"stream","text":["Device chosen is cuda\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"x9yEXbkCTC47"},"source":["We setup the training parameters that we will use all along the notebook, in order to improve readability in downstream code:"],"id":"x9yEXbkCTC47"},{"cell_type":"markdown","metadata":{"id":"mwSjghI5TC47"},"source":["Note that we will use a model with a 10-dimensional output, where each output is passed through softmax. When receiving an output \n","\n","$$Z = \\begin{bmatrix} \\mathbf z_1 & \\dots & \\mathbf z_B \\end{bmatrix}^\\top \\in \\mathbb R^{B \\times 10}$$\n","\n","with $B$ the batch size, we first retrieve the maximal component of each $\\mathbf z_i$:\n","\n","$$\\hat y_i = \\text{argmax}_{k = 1, \\ldots, 10} \\; z_{ik}, \\quad i = 1, \\ldots, B$$\n","\n","and then compute the accuracy:\n","\n","$$\\text{acc} = \\frac 1 B \\sum_{i=1}^B I\\left\\{ \\hat y_i = y_i \\right\\} $$\n","\n","with $I$ the indicator function and $y_i \\in \\{1, \\ldots, 10\\}$ the true target. "],"id":"mwSjghI5TC47"},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-k633Z4qTC48","executionInfo":{"status":"ok","timestamp":1623415143600,"user_tz":-120,"elapsed":14,"user":{"displayName":"Baris Sevilmis","photoUrl":"","userId":"05631870087761794056"}},"outputId":"dce0e836-cace-43f4-920f-b985977ada45"},"source":["from training import accuracy\n","\n","training_config = {\n","    # Loss function\n","    'loss_fun': torch.nn.CrossEntropyLoss(),\n","    # Performance evaluation function\n","    'metric_fun': accuracy,\n","    # The device to train on\n","    'device': device,\n","    # Number of epochs\n","    'epochs': 10,\n","}\n","\n","test_config = training_config.copy()\n","test_config.pop('epochs')"],"id":"-k633Z4qTC48","execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["10"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"code","metadata":{"id":"duD86o_VTC48","executionInfo":{"status":"ok","timestamp":1623415144568,"user_tz":-120,"elapsed":977,"user":{"displayName":"Baris Sevilmis","photoUrl":"","userId":"05631870087761794056"}}},"source":["# View the source code\n","??accuracy"],"id":"duD86o_VTC48","execution_count":9,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eLHWxZnwTC48"},"source":["# Model"],"id":"eLHWxZnwTC48"},{"cell_type":"markdown","metadata":{"id":"ShHEMS_2TC49"},"source":["We use a simple standard model for the MNIST dataset (can be found [here](https://github.com/floydhub/mnist/blob/master/ConvNet.py))."],"id":"ShHEMS_2TC49"},{"cell_type":"code","metadata":{"id":"xQPq9DYgTC49","executionInfo":{"status":"ok","timestamp":1623415144840,"user_tz":-120,"elapsed":276,"user":{"displayName":"Baris Sevilmis","photoUrl":"","userId":"05631870087761794056"}}},"source":["from net import Net"],"id":"xQPq9DYgTC49","execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"37yE7eiYTC49","executionInfo":{"status":"ok","timestamp":1623415146140,"user_tz":-120,"elapsed":1576,"user":{"displayName":"Baris Sevilmis","photoUrl":"","userId":"05631870087761794056"}}},"source":["??Net"],"id":"37yE7eiYTC49","execution_count":11,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Wi6r1BeyTC4-"},"source":["# Hyperparameter tuning"],"id":"Wi6r1BeyTC4-"},{"cell_type":"code","metadata":{"id":"lJkShBNlTC4-","executionInfo":{"status":"ok","timestamp":1623415146263,"user_tz":-120,"elapsed":136,"user":{"displayName":"Baris Sevilmis","photoUrl":"","userId":"05631870087761794056"}}},"source":["from training import tune_optimizer\n","from optimizer import AdamOptimizer, NesterovOptimizer, MiniBatchOptimizer\n","from data_utils import get_best_hyperparams"],"id":"lJkShBNlTC4-","execution_count":12,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qVEQ7Sq9TC4-"},"source":["If the `hyperparameter_tune` flag was set to `True` above, the following code will run hyperparameter tuning on all optimizers. Note that one can either run KFold cross validation (by providing `n_folds`) or use a simple train/test split (by providing `train_ratio`)."],"id":"qVEQ7Sq9TC4-"},{"cell_type":"markdown","metadata":{"id":"ZudQ63PlTC4-"},"source":["If the flag is set to `False`, the cell below will simply set up the hyperparameters that we carefully cross-validated:"],"id":"ZudQ63PlTC4-"},{"cell_type":"code","metadata":{"id":"2s-KL5tQTC4-","executionInfo":{"status":"ok","timestamp":1623415177355,"user_tz":-120,"elapsed":2731,"user":{"displayName":"Baris Sevilmis","photoUrl":"","userId":"05631870087761794056"}}},"source":["optimizers = {\n","    AdamOptimizer: get_best_hyperparams('./res/adam_tuning_round3.json'),\n","    NesterovOptimizer: get_best_hyperparams('./res/nesterov_tuning_round2.json'),\n","    MiniBatchOptimizer: get_best_hyperparams('./res/minibatch_tuning_round2.json')\n","}"],"id":"2s-KL5tQTC4-","execution_count":13,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"n0IP8shlTC4_"},"source":["## Adam"],"id":"n0IP8shlTC4_"},{"cell_type":"code","metadata":{"id":"CGoUXfziTC4_","executionInfo":{"status":"ok","timestamp":1623415177355,"user_tz":-120,"elapsed":4,"user":{"displayName":"Baris Sevilmis","photoUrl":"","userId":"05631870087761794056"}}},"source":["search_grid_adam = {\n","        'lr': np.linspace(0.00001, 0.01, 5),\n","        'beta1':  np.linspace(0.1, 0.9, 5),\n","        'beta2': np.linspace(0.5, 0.999, 5),\n","        'batch_size': [32, 64, 128],\n","        'weight_decay': np.linspace(0.0001, 0.1, 3),\n","        'epsilon': np.linspace(1e-10, 1e-8, 3),\n","    }\n","\n","if hyperparameter_tune:\n","    results_adam = tune_optimizer(\n","        model=Net().to(device),\n","        optim_fun=AdamOptimizer,\n","        xtrain=train_dataset.data,\n","        ytrain=train_dataset.targets,\n","        search_grid=search_grid_adam,\n","        nfolds=5,\n","        **training_config)\n","\n","else:\n","    results_adam = optimizers[AdamOptimizer]"],"id":"CGoUXfziTC4_","execution_count":14,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zID5R12xTC4_"},"source":["## Nesterov"],"id":"zID5R12xTC4_"},{"cell_type":"code","metadata":{"id":"GngpxuJ3TC4_","executionInfo":{"status":"ok","timestamp":1623415179116,"user_tz":-120,"elapsed":3,"user":{"displayName":"Baris Sevilmis","photoUrl":"","userId":"05631870087761794056"}}},"source":["search_grid_nesterov = {\n","    'lr': np.logspace(0, 1),\n","    'batch_size': [32, 64, 128]\n","}\n","\n","if hyperparameter_tune:\n","    results_nesterov = tune_optimizer(\n","        model=Net().to(device),\n","        optim_fun=NesterovOptimizer,\n","        xtrain=train_dataset.data,\n","        ytrain=train_dataset.targets,\n","        search_grid=search_grid_nesterov,\n","        nfolds=5,\n","        **training_config\n","    )\n","\n","else:\n","    results_nesterov = optimizers[NesterovOptimizer]"],"id":"GngpxuJ3TC4_","execution_count":15,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QdZrv5wMTC5A"},"source":["## Minibatch"],"id":"QdZrv5wMTC5A"},{"cell_type":"code","metadata":{"id":"Nqw3LTmHTC5A","executionInfo":{"status":"ok","timestamp":1623415180824,"user_tz":-120,"elapsed":3,"user":{"displayName":"Baris Sevilmis","photoUrl":"","userId":"05631870087761794056"}}},"source":["dec_lr_set =  [0]*1 + [1]*1\n","random.shuffle(dec_lr_set)\n","search_grid_mini  = {\n","        'lr': np.linspace(0.00001, 0.01, 5),\n","        'batch_size': [32, 64, 128],\n","        'decreasing_lr': dec_lr_set,\n","    }\n","if hyperparameter_tune:\n","    results_mini = tune_optimizer(\n","        model=Net().to(device),\n","        optim_fun=MiniBatchOptimizer,\n","        xtrain=train_dataset.data,\n","        ytrain=train_dataset.targets,\n","        search_grid=search_grid_mini,\n","        nfolds=5,\n","        **training_config\n","    )\n","\n","else:\n","    results_mini = optimizers[MiniBatchOptimizer]"],"id":"Nqw3LTmHTC5A","execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"E9kdzeK9lQGo","executionInfo":{"status":"ok","timestamp":1623415182847,"user_tz":-120,"elapsed":3,"user":{"displayName":"Baris Sevilmis","photoUrl":"","userId":"05631870087761794056"}},"outputId":"4faa8d57-5731-4a64-a9ff-c0902d0b43d7"},"source":["print(np.mean(results_adam['metric_train']))\n","print(np.std(np.mean(results_adam['metric_train'],axis=1)))"],"id":"E9kdzeK9lQGo","execution_count":17,"outputs":[{"output_type":"stream","text":["0.9530608333339999\n","0.0003547553908674052\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":232},"id":"5qHNhl3sTC5A","executionInfo":{"status":"error","timestamp":1623415183734,"user_tz":-120,"elapsed":7,"user":{"displayName":"Baris Sevilmis","photoUrl":"","userId":"05631870087761794056"}},"outputId":"a6d0bd5c-7307-46c9-83ce-a51f8b50f7f2"},"source":["df_analysis = pd.DataFrame(results)\n","best_acc = 0.0\n","for index, row in df_analysis.iterrows():    \n","        trial_acc = row[\"metric_test\"]\n","        if trial_acc > best_acc:\n","            best_acc = trial_acc\n","            learning_rate = round(row[\"lr\"], 6)\n","            decreasing_lr = row[\"decreasing_lr\"]\n","\n","print(\"Best Accuracy was {}% with Learning Rate {} and Decreasing LR: {}\".format(100*best_acc, learning_rate, decreasing_lr))\n"],"id":"5qHNhl3sTC5A","execution_count":18,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-18-f5671cdedc76>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_analysis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mbest_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf_analysis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mtrial_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"metric_test\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtrial_acc\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbest_acc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'results' is not defined"]}]},{"cell_type":"markdown","metadata":{"id":"9kL7lW6RTC5B"},"source":["## Comparison"],"id":"9kL7lW6RTC5B"},{"cell_type":"markdown","metadata":{"id":"jZSmvLRTTC5B"},"source":["# Attack on naive model\n","\n"],"id":"jZSmvLRTTC5B"},{"cell_type":"code","metadata":{"id":"GQiIUAR8TC5B","executionInfo":{"status":"ok","timestamp":1623415211452,"user_tz":-120,"elapsed":803,"user":{"displayName":"Baris Sevilmis","photoUrl":"","userId":"05631870087761794056"}}},"source":["from data_utils import build_data_loaders\n","from training import training, testing"],"id":"GQiIUAR8TC5B","execution_count":24,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bwA_rKY9TC5B"},"source":["## Train naive models"],"id":"bwA_rKY9TC5B"},{"cell_type":"markdown","metadata":{"id":"TwbOM_NuTC5C"},"source":["### Adam"],"id":"TwbOM_NuTC5C"},{"cell_type":"code","metadata":{"id":"d-XosMjITC5C","executionInfo":{"status":"ok","timestamp":1623415221799,"user_tz":-120,"elapsed":8356,"user":{"displayName":"Baris Sevilmis","photoUrl":"","userId":"05631870087761794056"}}},"source":["net_naive_adam = Net().to(device)\n","train_loader, test_loader = build_data_loaders(train_dataset, test_dataset, results_adam['batch_size'])"],"id":"d-XosMjITC5C","execution_count":25,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2Eaql9dQTC5C","executionInfo":{"status":"ok","timestamp":1623415288652,"user_tz":-120,"elapsed":45981,"user":{"displayName":"Baris Sevilmis","photoUrl":"","userId":"05631870087761794056"}},"outputId":"ae99bdac-7bd8-4f7b-edb8-3cb42fd34c33"},"source":["adam_opt_naive = AdamOptimizer(net_naive_adam.parameters(), lr=results_adam['lr'], beta1=results_adam['beta1'],beta2=results_adam['beta2'],weight_decay=results_adam['weight_decay'],epsilon=results_adam['epsilon'])\n","loss_train, acc_train = training(net_naive_adam, train_loader, adam_opt_naive, training_config['loss_fun'], training_config['metric_fun'], epochs=training_config['epochs'], device=device)\n","loss_test, acc_test = testing(net_naive_adam, test_loader, training_config['loss_fun'], training_config['metric_fun'], device=device)"],"id":"2Eaql9dQTC5C","execution_count":28,"outputs":[{"output_type":"stream","text":["Launching training on cuda\n","batch 100\tloss = 2.266\tacc = 0.25\n","batch 200\tloss = 2.089\tacc = 0.4531\n","batch 300\tloss = 1.376\tacc = 0.6719\n","batch 400\tloss = 0.5344\tacc = 0.875\n","batch 500\tloss = 0.3246\tacc = 0.9062\n","batch 600\tloss = 0.3789\tacc = 0.8906\n","batch 700\tloss = 0.2879\tacc = 0.8906\n","batch 800\tloss = 0.3578\tacc = 0.8594\n","batch 900\tloss = 0.1543\tacc = 0.9531\n","epoch 0\tavg epoch loss = 0.925\tavg epoch acc = 0.7355\n","batch 100\tloss = 0.09071\tacc = 0.9688\n","batch 200\tloss = 0.2134\tacc = 0.9219\n","batch 300\tloss = 0.09425\tacc = 1.0\n","batch 400\tloss = 0.2278\tacc = 0.9688\n","batch 500\tloss = 0.1188\tacc = 0.9688\n","batch 600\tloss = 0.1556\tacc = 0.9531\n","batch 700\tloss = 0.1063\tacc = 0.9688\n","batch 800\tloss = 0.08588\tacc = 0.9688\n","batch 900\tloss = 0.05556\tacc = 0.9844\n","epoch 1\tavg epoch loss = 0.122\tavg epoch acc = 0.9637\n","batch 100\tloss = 0.06475\tacc = 0.9844\n","batch 200\tloss = 0.07802\tacc = 0.9531\n","batch 300\tloss = 0.04139\tacc = 1.0\n","batch 400\tloss = 0.1989\tacc = 0.9688\n","batch 500\tloss = 0.07916\tacc = 0.9688\n","batch 600\tloss = 0.1154\tacc = 0.9375\n","batch 700\tloss = 0.08335\tacc = 0.9531\n","batch 800\tloss = 0.03901\tacc = 0.9844\n","batch 900\tloss = 0.0367\tacc = 0.9844\n","epoch 2\tavg epoch loss = 0.07394\tavg epoch acc = 0.9781\n","batch 100\tloss = 0.05165\tacc = 0.9844\n","batch 200\tloss = 0.04778\tacc = 0.9844\n","batch 300\tloss = 0.02633\tacc = 1.0\n","batch 400\tloss = 0.1777\tacc = 0.9688\n","batch 500\tloss = 0.06181\tacc = 0.9688\n","batch 600\tloss = 0.09926\tacc = 0.9531\n","batch 700\tloss = 0.0729\tacc = 0.9688\n","batch 800\tloss = 0.02596\tacc = 1.0\n","batch 900\tloss = 0.02994\tacc = 0.9844\n","epoch 3\tavg epoch loss = 0.05715\tavg epoch acc = 0.9833\n","batch 100\tloss = 0.04205\tacc = 0.9844\n","batch 200\tloss = 0.03628\tacc = 0.9844\n","batch 300\tloss = 0.02244\tacc = 1.0\n","batch 400\tloss = 0.1659\tacc = 0.9688\n","batch 500\tloss = 0.05287\tacc = 0.9844\n","batch 600\tloss = 0.08876\tacc = 0.9531\n","batch 700\tloss = 0.05869\tacc = 0.9688\n","batch 800\tloss = 0.01722\tacc = 1.0\n","batch 900\tloss = 0.0252\tacc = 0.9844\n","epoch 4\tavg epoch loss = 0.04828\tavg epoch acc = 0.9859\n","batch 100\tloss = 0.03486\tacc = 0.9844\n","batch 200\tloss = 0.02886\tacc = 0.9844\n","batch 300\tloss = 0.01795\tacc = 1.0\n","batch 400\tloss = 0.1595\tacc = 0.9688\n","batch 500\tloss = 0.04608\tacc = 0.9844\n","batch 600\tloss = 0.08533\tacc = 0.9531\n","batch 700\tloss = 0.04635\tacc = 0.9844\n","batch 800\tloss = 0.01319\tacc = 1.0\n","batch 900\tloss = 0.02152\tacc = 1.0\n","epoch 5\tavg epoch loss = 0.04218\tavg epoch acc = 0.9876\n","batch 100\tloss = 0.0293\tacc = 0.9844\n","batch 200\tloss = 0.02481\tacc = 0.9844\n","batch 300\tloss = 0.01511\tacc = 1.0\n","batch 400\tloss = 0.1506\tacc = 0.9688\n","batch 500\tloss = 0.04007\tacc = 0.9844\n","batch 600\tloss = 0.07932\tacc = 0.9531\n","batch 700\tloss = 0.03157\tacc = 1.0\n","batch 800\tloss = 0.01092\tacc = 1.0\n","batch 900\tloss = 0.01747\tacc = 1.0\n","epoch 6\tavg epoch loss = 0.03764\tavg epoch acc = 0.9891\n","batch 100\tloss = 0.02469\tacc = 0.9844\n","batch 200\tloss = 0.02164\tacc = 0.9844\n","batch 300\tloss = 0.01271\tacc = 1.0\n","batch 400\tloss = 0.1441\tacc = 0.9688\n","batch 500\tloss = 0.03738\tacc = 0.9844\n","batch 600\tloss = 0.07612\tacc = 0.9531\n","batch 700\tloss = 0.02425\tacc = 1.0\n","batch 800\tloss = 0.008404\tacc = 1.0\n","batch 900\tloss = 0.01331\tacc = 1.0\n","epoch 7\tavg epoch loss = 0.03412\tavg epoch acc = 0.9904\n","batch 100\tloss = 0.02091\tacc = 1.0\n","batch 200\tloss = 0.01988\tacc = 0.9844\n","batch 300\tloss = 0.01088\tacc = 1.0\n","batch 400\tloss = 0.1381\tacc = 0.9688\n","batch 500\tloss = 0.03444\tacc = 0.9844\n","batch 600\tloss = 0.07604\tacc = 0.9531\n","batch 700\tloss = 0.01949\tacc = 1.0\n","batch 800\tloss = 0.006818\tacc = 1.0\n","batch 900\tloss = 0.01218\tacc = 1.0\n","epoch 8\tavg epoch loss = 0.03123\tavg epoch acc = 0.9915\n","batch 100\tloss = 0.01798\tacc = 1.0\n","batch 200\tloss = 0.01819\tacc = 1.0\n","batch 300\tloss = 0.01045\tacc = 1.0\n","batch 400\tloss = 0.1319\tacc = 0.9688\n","batch 500\tloss = 0.03214\tacc = 0.9844\n","batch 600\tloss = 0.07043\tacc = 0.9531\n","batch 700\tloss = 0.01475\tacc = 1.0\n","batch 800\tloss = 0.00599\tacc = 1.0\n","batch 900\tloss = 0.01109\tacc = 1.0\n","epoch 9\tavg epoch loss = 0.02896\tavg epoch acc = 0.9924\n","training took 45.62 s\n","Avg test loss = 0.0333\tAvg test acc = 0.989\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"PRHfeJn0TC5C"},"source":["### Nesterov\n","\n"],"id":"PRHfeJn0TC5C"},{"cell_type":"code","metadata":{"id":"3oAvdXjwTC5C","colab":{"base_uri":"https://localhost:8080/","height":249},"executionInfo":{"status":"error","timestamp":1623375051509,"user_tz":-120,"elapsed":29,"user":{"displayName":"Baris Sevilmis","photoUrl":"","userId":"05631870087761794056"}},"outputId":"15bb70d6-563b-40fe-c1e7-331753cf811d"},"source":["naive_networks = dict()\n","data_naive = list()\n","batch_log_interval = 0\n","\n","for optimizer, optimizer_params in optimizers.items():\n","    print(f'--- {optimizer}')\n","    optimizer_params = optimizer_params.copy()\n","    \n","    net = Net().to(device)\n","    # Instantiate data loaders with selected batch size\n","    batch_size = optimizer_params.pop('batch_size')\n","    train_loader, test_loader = build_data_loaders(train_dataset, test_dataset, batch_size)\n","    # Instantiate optimizer\n","    optimizer_instance = optimizer(net.parameters(), **optimizer_params)\n","    # Train\n","    loss_train, acc_train = training(\n","        model=net, \n","        dataset=train_loader, \n","        optim=optimizer_instance,\n","        batch_log_interval=batch_log_interval,\n","        **training_config\n","    )\n","    # Test\n","    loss_test, acc_test = testing(\n","        model=net,\n","        dataset=test_loader,\n","        **test_config\n","    )\n","    # Log\n","    data_naive.append({\n","        'optimizer': str(optimizer),\n","        'loss_train': loss_train,\n","        'acc_train': acc_train,\n","        'loss_test': loss_test,\n","        'acc_test': acc_test\n","    })\n","    # Save naive model\n","    naive_networks[optimizer] = net"],"id":"3oAvdXjwTC5C","execution_count":28,"outputs":[{"output_type":"stream","text":["--- <class 'optimizer.AdamOptimizer'>\n"],"name":"stdout"},{"output_type":"error","ename":"TypeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-28-70fb781770c5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_data_loaders\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;31m# Instantiate optimizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0moptimizer_instance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptimizer_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0;31m# Train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     loss_train, acc_train = training(\n","\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'loss_train'"]}]},{"cell_type":"markdown","metadata":{"id":"xCXPQZVwTC5B"},"source":["### Minibatch (for now, loop later)"],"id":"xCXPQZVwTC5B"},{"cell_type":"code","metadata":{"id":"PtrqA0NwTC5B","executionInfo":{"status":"ok","timestamp":1623417489257,"user_tz":-120,"elapsed":329,"user":{"displayName":"Baris Sevilmis","photoUrl":"","userId":"05631870087761794056"}}},"source":["net_naive_mini = Net().to(device)\n","train_loader, test_loader = build_data_loaders(train_dataset, test_dataset, results_mini['batch_size'])"],"id":"PtrqA0NwTC5B","execution_count":31,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BqDCrck6TC5C","executionInfo":{"status":"ok","timestamp":1623417534294,"user_tz":-120,"elapsed":32156,"user":{"displayName":"Baris Sevilmis","photoUrl":"","userId":"05631870087761794056"}},"outputId":"6cc678e1-06bc-40c0-bb63-d71d70de0e15"},"source":["mini_opt_naive = MiniBatchOptimizer(net_naive_mini.parameters(), lr=results_mini['lr'], decreasing_lr=results_mini['decreasing_lr'])\n","loss_train, acc_train = training(net_naive_mini, train_loader, mini_opt_naive, training_config['loss_fun'], training_config['metric_fun'], epochs=training_config['epochs'], device=device)\n","loss_test, acc_test = testing(net_naive_mini, test_loader,training_config['loss_fun'], training_config['metric_fun'], device=device)"],"id":"BqDCrck6TC5C","execution_count":33,"outputs":[{"output_type":"stream","text":["Launching training on cuda\n","batch 100\tloss = 0.2284\tacc = 0.9219\n","batch 200\tloss = 0.179\tacc = 0.9688\n","batch 300\tloss = 0.08645\tacc = 0.9609\n","batch 400\tloss = 0.02451\tacc = 0.9922\n","epoch 0\tavg epoch loss = 0.2309\tavg epoch acc = 0.9287\n","batch 100\tloss = 0.04506\tacc = 0.9766\n","batch 200\tloss = 0.1311\tacc = 0.9766\n","batch 300\tloss = 0.07145\tacc = 0.9688\n","batch 400\tloss = 0.007264\tacc = 1.0\n","epoch 1\tavg epoch loss = 0.05266\tavg epoch acc = 0.9836\n","batch 100\tloss = 0.01591\tacc = 0.9922\n","batch 200\tloss = 0.1019\tacc = 0.9844\n","batch 300\tloss = 0.05305\tacc = 0.9844\n","batch 400\tloss = 0.003513\tacc = 1.0\n","epoch 2\tavg epoch loss = 0.035\tavg epoch acc = 0.9896\n","batch 100\tloss = 0.007727\tacc = 1.0\n","batch 200\tloss = 0.09252\tacc = 0.9844\n","batch 300\tloss = 0.04272\tacc = 0.9844\n","batch 400\tloss = 0.001961\tacc = 1.0\n","epoch 3\tavg epoch loss = 0.02539\tavg epoch acc = 0.993\n","batch 100\tloss = 0.005133\tacc = 1.0\n","batch 200\tloss = 0.08512\tacc = 0.9844\n","batch 300\tloss = 0.03906\tacc = 0.9844\n","batch 400\tloss = 0.0009479\tacc = 1.0\n","epoch 4\tavg epoch loss = 0.01891\tavg epoch acc = 0.9951\n","batch 100\tloss = 0.00714\tacc = 1.0\n","batch 200\tloss = 0.07446\tacc = 0.9766\n","batch 300\tloss = 0.03779\tacc = 0.9844\n","batch 400\tloss = 0.0006002\tacc = 1.0\n","epoch 5\tavg epoch loss = 0.0143\tavg epoch acc = 0.9965\n","batch 100\tloss = 0.009895\tacc = 0.9922\n","batch 200\tloss = 0.05734\tacc = 0.9766\n","batch 300\tloss = 0.03151\tacc = 0.9922\n","batch 400\tloss = 0.0004469\tacc = 1.0\n","epoch 6\tavg epoch loss = 0.01078\tavg epoch acc = 0.9975\n","batch 100\tloss = 0.005225\tacc = 1.0\n","batch 200\tloss = 0.03953\tacc = 0.9844\n","batch 300\tloss = 0.02859\tacc = 0.9922\n","batch 400\tloss = 0.0004339\tacc = 1.0\n","epoch 7\tavg epoch loss = 0.008231\tavg epoch acc = 0.9983\n","batch 100\tloss = 0.003214\tacc = 1.0\n","batch 200\tloss = 0.02672\tacc = 0.9844\n","batch 300\tloss = 0.02658\tacc = 0.9922\n","batch 400\tloss = 0.0005066\tacc = 1.0\n","epoch 8\tavg epoch loss = 0.006462\tavg epoch acc = 0.9988\n","batch 100\tloss = 0.002544\tacc = 1.0\n","batch 200\tloss = 0.01601\tacc = 0.9922\n","batch 300\tloss = 0.02957\tacc = 0.9844\n","batch 400\tloss = 0.0005203\tacc = 1.0\n","epoch 9\tavg epoch loss = 0.004923\tavg epoch acc = 0.999\n","training took 31.58 s\n","Avg test loss = 0.0409\tAvg test acc = 0.988\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"PM2opkkMTC5D"},"source":["## Attack naive models"],"id":"PM2opkkMTC5D"},{"cell_type":"code","metadata":{"id":"B6wX6BPXTC5D","executionInfo":{"status":"ok","timestamp":1623417566569,"user_tz":-120,"elapsed":486,"user":{"displayName":"Baris Sevilmis","photoUrl":"","userId":"05631870087761794056"}}},"source":["from adversary import attack"],"id":"B6wX6BPXTC5D","execution_count":37,"outputs":[]},{"cell_type":"code","metadata":{"id":"MrOvET6zTC5D","executionInfo":{"status":"ok","timestamp":1623417567044,"user_tz":-120,"elapsed":7,"user":{"displayName":"Baris Sevilmis","photoUrl":"","userId":"05631870087761794056"}}},"source":["epsilons = np.arange(0, 0.5, 0.05)"],"id":"MrOvET6zTC5D","execution_count":38,"outputs":[]},{"cell_type":"code","metadata":{"id":"xMPRU4x6TC5D","executionInfo":{"status":"ok","timestamp":1623417567045,"user_tz":-120,"elapsed":7,"user":{"displayName":"Baris Sevilmis","photoUrl":"","userId":"05631870087761794056"}}},"source":["# use the lst_optimizer\n","# Only one optimizer used in this part?"],"id":"xMPRU4x6TC5D","execution_count":39,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Pf2OYPFsTC5E"},"source":["### Adam"],"id":"Pf2OYPFsTC5E"},{"cell_type":"code","metadata":{"id":"Hu7pNd_HTC5E","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623417574986,"user_tz":-120,"elapsed":6386,"user":{"displayName":"Baris Sevilmis","photoUrl":"","userId":"05631870087761794056"}},"outputId":"24a33bbb-c350-4811-9aaa-2d70f449bcfc"},"source":["accuracy_naive_adam= []\n","losses_naive_adam= []\n","\n","for eps in epsilons:\n","    loss_attack, acc_attack  = attack(net_naive_adam, training_config['loss_fun'],training_config['metric_fun'], test_loader, epsilon=eps, device=device)\n","    accuracy_naive_adam.append(acc_attack)\n","    losses_naive_adam.append(loss_attack)"],"id":"Hu7pNd_HTC5E","execution_count":40,"outputs":[{"output_type":"stream","text":["Epsilon: 0.00\tTest Accuracy = 0.973\n","Epsilon: 0.05\tTest Accuracy = 0.967\n","Epsilon: 0.10\tTest Accuracy = 0.960\n","Epsilon: 0.15\tTest Accuracy = 0.951\n","Epsilon: 0.20\tTest Accuracy = 0.936\n","Epsilon: 0.25\tTest Accuracy = 0.920\n","Epsilon: 0.30\tTest Accuracy = 0.896\n","Epsilon: 0.35\tTest Accuracy = 0.866\n","Epsilon: 0.40\tTest Accuracy = 0.823\n","Epsilon: 0.45\tTest Accuracy = 0.760\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"bpjf-wgDTC5E"},"source":["### Nesterov"],"id":"bpjf-wgDTC5E"},{"cell_type":"code","metadata":{"id":"dPVWZPnSTC5E","outputId":"df266647-f7d8-4b17-98c9-de039ee0be44"},"source":["data_naive = list()\n","\n","for optimizer, network in naive_networks.items():\n","    print(f'--- {optimizer}')\n","    \n","    for eps in epsilons:\n","        loss_attack, acc_attack = attack(\n","            model=network, \n","            loss_fun=training_config['loss_fun'],\n","            test_loader=test_loader, \n","            epsilon=eps, \n","            device=training_config['loss_fun']\n","        )\n","        # Log\n","        data_naive.append({\n","            'optimizer': str(optimizer),\n","            'epsilon': eps,\n","            'loss': loss_attack,\n","            'acc': acc_attack\n","        })"],"id":"dPVWZPnSTC5E","execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'naive_networks' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-24-4483485418d3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnetwork\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnaive_networks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'--- {optimizer}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     loss_attack, acc_attack  = attack(\n\u001b[1;32m      4\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mloss_fun\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss_fun'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'naive_networks' is not defined"]}]},{"cell_type":"markdown","metadata":{"id":"JmX-0IG4TC5E"},"source":["### Minibatch (for now, loop later)"],"id":"JmX-0IG4TC5E"},{"cell_type":"code","metadata":{"id":"ypKAQIMETC5E","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623417591877,"user_tz":-120,"elapsed":6816,"user":{"displayName":"Baris Sevilmis","photoUrl":"","userId":"05631870087761794056"}},"outputId":"fc87975a-9e82-4357-9a98-42097ce0d4f3"},"source":["accuracy_naive= []\n","losses_naive= []\n","\n","for eps in epsilons:\n","    loss_attack, acc_attack  = attack(net_naive_mini,  training_config['loss_fun'],training_config['metric_fun'], test_loader, epsilon=eps, device=device)\n","    accuracy_naive.append(acc_attack)\n","    losses_naive.append(loss_attack)"],"id":"ypKAQIMETC5E","execution_count":42,"outputs":[{"output_type":"stream","text":["Epsilon: 0.00\tTest Accuracy = 0.964\n","Epsilon: 0.05\tTest Accuracy = 0.957\n","Epsilon: 0.10\tTest Accuracy = 0.948\n","Epsilon: 0.15\tTest Accuracy = 0.937\n","Epsilon: 0.20\tTest Accuracy = 0.919\n","Epsilon: 0.25\tTest Accuracy = 0.897\n","Epsilon: 0.30\tTest Accuracy = 0.866\n","Epsilon: 0.35\tTest Accuracy = 0.822\n","Epsilon: 0.40\tTest Accuracy = 0.761\n","Epsilon: 0.45\tTest Accuracy = 0.685\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"xOu0V6AjTC5F"},"source":["## Comparison"],"id":"xOu0V6AjTC5F"},{"cell_type":"markdown","metadata":{"id":"eQCOdFFQTC5F"},"source":["# Attack on robust model"],"id":"eQCOdFFQTC5F"},{"cell_type":"markdown","metadata":{"id":"La4ABLV5gCOd"},"source":["## Hyperparameter optimization on robust models\n","\n","- Set hyperparameter tuning for robust models:\n","-- True, in case you want to get tuned hyperparameters.\n","-- False, by default. If you want to tryout, we have already processed it and got the same results out.\n"],"id":"La4ABLV5gCOd"},{"cell_type":"code","metadata":{"id":"DkqBVJufgg-z"},"source":["prot_hyperparameter_tune = True\n","prot_optimizers = {\n","    AdamOptimizer: get_best_hyperparams('./res/prot_adam_tuning.json'),\n","    NesterovOptimizer: get_best_hyperparams('./res/prot_nesterov_tuning.json'),\n","    MiniBatchOptimizer: get_best_hyperparams('./res/prot_minibatch_tuning.json')\n","}"],"id":"DkqBVJufgg-z","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"B-JYd7t8oyOt"},"source":["###Adam"],"id":"B-JYd7t8oyOt"},{"cell_type":"code","metadata":{"id":"1-LkqzEzgBbH","colab":{"base_uri":"https://localhost:8080/"},"outputId":"d23b210e-9872-4e87-e5f4-75084de4e165"},"source":["search_grid_adam = {\n","        'lr': np.linspace(0.00001, 0.01, 5),\n","        'beta1':  np.linspace(0.1, 0.9, 5),\n","        'beta2': np.linspace(0.5, 0.999, 5),\n","        'batch_size': [32, 64, 128],\n","        'weight_decay': np.linspace(0.0001, 0.1, 3),\n","        'epsilon': np.linspace(1e-10, 1e-8, 3),\n","    }\n","\n","if prot_hyperparameter_tune:\n","    results_adam_prot = tune_optimizer(\n","        model=Net().to(device),\n","        optim_fun=AdamOptimizer,\n","        xtrain=train_dataset.data,\n","        ytrain=train_dataset.targets,\n","        search_grid=search_grid_adam,\n","        nfolds=5,\n","        func=protected_training,\n","        **training_config)\n","\n","else:\n","    results_adam_prot = optimizers[AdamOptimizer]"],"id":"1-LkqzEzgBbH","execution_count":null,"outputs":[{"output_type":"stream","text":["Launching hyperparameter tuning:\n","\tlr = [1.0000e-05 2.5075e-03 5.0050e-03 7.5025e-03 1.0000e-02]\n","\tbeta1 = [0.1 0.3 0.5 0.7 0.9]\n","\tbeta2 = [0.5     0.62475 0.7495  0.87425 0.999  ]\n","\tbatch_size = [32, 64, 128]\n","\tweight_decay = [0.0001  0.05005 0.1    ]\n","\tepsilon = [1.00e-10 5.05e-09 1.00e-08]\n","{'lr': 1e-05, 'beta1': 0.1, 'beta2': 0.5, 'batch_size': 32, 'weight_decay': 0.0001, 'epsilon': 1e-10}\n","Epoch 0\tavg epoch Loss = 1.961\tavg epoch acc = 0.5912\n","Epoch 1\tavg epoch Loss = 0.9866\tavg epoch acc = 0.7529\n","Epoch 2\tavg epoch Loss = 0.6678\tavg epoch acc = 0.8072\n","Epoch 3\tavg epoch Loss = 0.5561\tavg epoch acc = 0.8293\n","Epoch 4\tavg epoch Loss = 0.4828\tavg epoch acc = 0.8411\n","Epoch 5\tavg epoch Loss = 0.4271\tavg epoch acc = 0.8494\n","Epoch 6\tavg epoch Loss = 0.3834\tavg epoch acc = 0.8564\n","Epoch 7\tavg epoch Loss = 0.3484\tavg epoch acc = 0.8628\n","Epoch 8\tavg epoch Loss = 0.3199\tavg epoch acc = 0.869\n","Epoch 9\tavg epoch Loss = 0.2964\tavg epoch acc = 0.8751\n","training took 113.2 s\n","Avg test loss = 0.62\tAvg test acc = 0.878\n","Epoch 0\tavg epoch Loss = 1.961\tavg epoch acc = 0.6021\n","Epoch 1\tavg epoch Loss = 0.9854\tavg epoch acc = 0.7543\n","Epoch 2\tavg epoch Loss = 0.6697\tavg epoch acc = 0.8072\n","Epoch 3\tavg epoch Loss = 0.5592\tavg epoch acc = 0.8257\n","Epoch 4\tavg epoch Loss = 0.4861\tavg epoch acc = 0.8375\n","Epoch 5\tavg epoch Loss = 0.4302\tavg epoch acc = 0.8461\n","Epoch 6\tavg epoch Loss = 0.386\tavg epoch acc = 0.8535\n","Epoch 7\tavg epoch Loss = 0.3507\tavg epoch acc = 0.8599\n","Epoch 8\tavg epoch Loss = 0.3217\tavg epoch acc = 0.8668\n","Epoch 9\tavg epoch Loss = 0.2978\tavg epoch acc = 0.8729\n","training took 112.3 s\n","Avg test loss = 0.652\tAvg test acc = 0.87\n","Epoch 0\tavg epoch Loss = 1.961\tavg epoch acc = 0.5963\n","Epoch 1\tavg epoch Loss = 0.9865\tavg epoch acc = 0.7518\n","Epoch 2\tavg epoch Loss = 0.6686\tavg epoch acc = 0.8061\n","Epoch 3\tavg epoch Loss = 0.558\tavg epoch acc = 0.8273\n","Epoch 4\tavg epoch Loss = 0.4857\tavg epoch acc = 0.8386\n","Epoch 5\tavg epoch Loss = 0.4307\tavg epoch acc = 0.8468\n","Epoch 6\tavg epoch Loss = 0.3872\tavg epoch acc = 0.8544\n","Epoch 7\tavg epoch Loss = 0.3523\tavg epoch acc = 0.8608\n","Epoch 8\tavg epoch Loss = 0.3241\tavg epoch acc = 0.867\n","Epoch 9\tavg epoch Loss = 0.3008\tavg epoch acc = 0.873\n","training took 112.8 s\n","Avg test loss = 0.637\tAvg test acc = 0.873\n","Epoch 0\tavg epoch Loss = 1.959\tavg epoch acc = 0.5999\n","Epoch 1\tavg epoch Loss = 0.9832\tavg epoch acc = 0.7533\n","Epoch 2\tavg epoch Loss = 0.6665\tavg epoch acc = 0.8056\n","Epoch 3\tavg epoch Loss = 0.5561\tavg epoch acc = 0.8256\n","Epoch 4\tavg epoch Loss = 0.4837\tavg epoch acc = 0.837\n","Epoch 5\tavg epoch Loss = 0.4288\tavg epoch acc = 0.8461\n","Epoch 6\tavg epoch Loss = 0.3851\tavg epoch acc = 0.8538\n","Epoch 7\tavg epoch Loss = 0.3503\tavg epoch acc = 0.8597\n","Epoch 8\tavg epoch Loss = 0.322\tavg epoch acc = 0.8654\n","Epoch 9\tavg epoch Loss = 0.2985\tavg epoch acc = 0.8711\n","training took 112.4 s\n","Avg test loss = 0.655\tAvg test acc = 0.872\n","Epoch 0\tavg epoch Loss = 1.957\tavg epoch acc = 0.5936\n","Epoch 1\tavg epoch Loss = 0.9793\tavg epoch acc = 0.7535\n","Epoch 2\tavg epoch Loss = 0.6665\tavg epoch acc = 0.8055\n","Epoch 3\tavg epoch Loss = 0.5567\tavg epoch acc = 0.8254\n","Epoch 4\tavg epoch Loss = 0.4842\tavg epoch acc = 0.8369\n","Epoch 5\tavg epoch Loss = 0.429\tavg epoch acc = 0.8445\n","Epoch 6\tavg epoch Loss = 0.3856\tavg epoch acc = 0.8516\n","Epoch 7\tavg epoch Loss = 0.3508\tavg epoch acc = 0.8576\n","Epoch 8\tavg epoch Loss = 0.3225\tavg epoch acc = 0.8631\n","Epoch 9\tavg epoch Loss = 0.2993\tavg epoch acc = 0.868\n","training took 112.6 s\n","Avg test loss = 0.641\tAvg test acc = 0.871\n","{'lr': 1e-05, 'beta1': 0.1, 'beta2': 0.5, 'batch_size': 32, 'weight_decay': 0.0001, 'epsilon': 5.0500000000000006e-09}\n","Epoch 0\tavg epoch Loss = 1.961\tavg epoch acc = 0.5966\n","Epoch 1\tavg epoch Loss = 0.9854\tavg epoch acc = 0.753\n","Epoch 2\tavg epoch Loss = 0.6667\tavg epoch acc = 0.8058\n","Epoch 3\tavg epoch Loss = 0.5561\tavg epoch acc = 0.8265\n","Epoch 4\tavg epoch Loss = 0.4833\tavg epoch acc = 0.8382\n","Epoch 5\tavg epoch Loss = 0.4283\tavg epoch acc = 0.8465\n","Epoch 6\tavg epoch Loss = 0.3847\tavg epoch acc = 0.853\n","Epoch 7\tavg epoch Loss = 0.3498\tavg epoch acc = 0.8588\n","Epoch 8\tavg epoch Loss = 0.3213\tavg epoch acc = 0.8645\n","Epoch 9\tavg epoch Loss = 0.2978\tavg epoch acc = 0.8698\n","training took 113.4 s\n","Avg test loss = 0.66\tAvg test acc = 0.869\n","Epoch 0\tavg epoch Loss = 1.961\tavg epoch acc = 0.5976\n","Epoch 1\tavg epoch Loss = 0.9857\tavg epoch acc = 0.7514\n","Epoch 2\tavg epoch Loss = 0.6677\tavg epoch acc = 0.8052\n","Epoch 3\tavg epoch Loss = 0.5566\tavg epoch acc = 0.8262\n","Epoch 4\tavg epoch Loss = 0.4838\tavg epoch acc = 0.8368\n","Epoch 5\tavg epoch Loss = 0.4287\tavg epoch acc = 0.8458\n","Epoch 6\tavg epoch Loss = 0.3854\tavg epoch acc = 0.853\n","Epoch 7\tavg epoch Loss = 0.3505\tavg epoch acc = 0.8593\n","Epoch 8\tavg epoch Loss = 0.3221\tavg epoch acc = 0.866\n","Epoch 9\tavg epoch Loss = 0.2984\tavg epoch acc = 0.8718\n","training took 113.5 s\n","Avg test loss = 0.633\tAvg test acc = 0.877\n","Epoch 0\tavg epoch Loss = 1.962\tavg epoch acc = 0.5931\n","Epoch 1\tavg epoch Loss = 0.9863\tavg epoch acc = 0.754\n","Epoch 2\tavg epoch Loss = 0.6693\tavg epoch acc = 0.8081\n","Epoch 3\tavg epoch Loss = 0.5581\tavg epoch acc = 0.8288\n","Epoch 4\tavg epoch Loss = 0.4849\tavg epoch acc = 0.8408\n","Epoch 5\tavg epoch Loss = 0.4294\tavg epoch acc = 0.8502\n","Epoch 6\tavg epoch Loss = 0.3856\tavg epoch acc = 0.8576\n","Epoch 7\tavg epoch Loss = 0.3506\tavg epoch acc = 0.8638\n","Epoch 8\tavg epoch Loss = 0.322\tavg epoch acc = 0.8703\n","Epoch 9\tavg epoch Loss = 0.2986\tavg epoch acc = 0.8758\n","training took 114.0 s\n","Avg test loss = 0.614\tAvg test acc = 0.877\n","Epoch 0\tavg epoch Loss = 1.957\tavg epoch acc = 0.5945\n","Epoch 1\tavg epoch Loss = 0.9816\tavg epoch acc = 0.7546\n","Epoch 2\tavg epoch Loss = 0.6682\tavg epoch acc = 0.8064\n","Epoch 3\tavg epoch Loss = 0.5581\tavg epoch acc = 0.8264\n","Epoch 4\tavg epoch Loss = 0.4855\tavg epoch acc = 0.8379\n","Epoch 5\tavg epoch Loss = 0.4302\tavg epoch acc = 0.8457\n","Epoch 6\tavg epoch Loss = 0.3866\tavg epoch acc = 0.8532\n","Epoch 7\tavg epoch Loss = 0.3514\tavg epoch acc = 0.8587\n","Epoch 8\tavg epoch Loss = 0.3227\tavg epoch acc = 0.8651\n","Epoch 9\tavg epoch Loss = 0.2992\tavg epoch acc = 0.8715\n","training took 112.6 s\n","Avg test loss = 0.634\tAvg test acc = 0.877\n","Epoch 0\tavg epoch Loss = 1.959\tavg epoch acc = 0.5984\n","Epoch 1\tavg epoch Loss = 0.9845\tavg epoch acc = 0.7536\n","Epoch 2\tavg epoch Loss = 0.6685\tavg epoch acc = 0.8071\n","Epoch 3\tavg epoch Loss = 0.5582\tavg epoch acc = 0.8264\n","Epoch 4\tavg epoch Loss = 0.4857\tavg epoch acc = 0.8384\n","Epoch 5\tavg epoch Loss = 0.4305\tavg epoch acc = 0.8472\n","Epoch 6\tavg epoch Loss = 0.3869\tavg epoch acc = 0.8551\n","Epoch 7\tavg epoch Loss = 0.3519\tavg epoch acc = 0.8611\n","Epoch 8\tavg epoch Loss = 0.3235\tavg epoch acc = 0.8669\n","Epoch 9\tavg epoch Loss = 0.3\tavg epoch acc = 0.8722\n","training took 112.2 s\n","Avg test loss = 0.647\tAvg test acc = 0.866\n","{'lr': 1e-05, 'beta1': 0.1, 'beta2': 0.5, 'batch_size': 32, 'weight_decay': 0.0001, 'epsilon': 1e-08}\n","Epoch 0\tavg epoch Loss = 1.96\tavg epoch acc = 0.5955\n","Epoch 1\tavg epoch Loss = 0.9862\tavg epoch acc = 0.753\n","Epoch 2\tavg epoch Loss = 0.6694\tavg epoch acc = 0.806\n","Epoch 3\tavg epoch Loss = 0.5583\tavg epoch acc = 0.8264\n","Epoch 4\tavg epoch Loss = 0.4852\tavg epoch acc = 0.8377\n","Epoch 5\tavg epoch Loss = 0.4298\tavg epoch acc = 0.8461\n","Epoch 6\tavg epoch Loss = 0.386\tavg epoch acc = 0.8533\n","Epoch 7\tavg epoch Loss = 0.3508\tavg epoch acc = 0.8586\n","Epoch 8\tavg epoch Loss = 0.3221\tavg epoch acc = 0.8644\n","Epoch 9\tavg epoch Loss = 0.2984\tavg epoch acc = 0.8697\n","training took 112.4 s\n","Avg test loss = 0.621\tAvg test acc = 0.875\n","Epoch 0\tavg epoch Loss = 1.959\tavg epoch acc = 0.5949\n","Epoch 1\tavg epoch Loss = 0.9842\tavg epoch acc = 0.7537\n","Epoch 2\tavg epoch Loss = 0.669\tavg epoch acc = 0.8069\n","Epoch 3\tavg epoch Loss = 0.5584\tavg epoch acc = 0.8271\n","Epoch 4\tavg epoch Loss = 0.4855\tavg epoch acc = 0.8383\n","Epoch 5\tavg epoch Loss = 0.4302\tavg epoch acc = 0.8466\n","Epoch 6\tavg epoch Loss = 0.3865\tavg epoch acc = 0.854\n","Epoch 7\tavg epoch Loss = 0.3516\tavg epoch acc = 0.8591\n","Epoch 8\tavg epoch Loss = 0.3233\tavg epoch acc = 0.8651\n","Epoch 9\tavg epoch Loss = 0.3\tavg epoch acc = 0.8708\n","training took 112.2 s\n","Avg test loss = 0.618\tAvg test acc = 0.876\n","Epoch 0\tavg epoch Loss = 1.957\tavg epoch acc = 0.5939\n","Epoch 1\tavg epoch Loss = 0.9794\tavg epoch acc = 0.7543\n","Epoch 2\tavg epoch Loss = 0.6634\tavg epoch acc = 0.8086\n","Epoch 3\tavg epoch Loss = 0.5533\tavg epoch acc = 0.8288\n","Epoch 4\tavg epoch Loss = 0.4806\tavg epoch acc = 0.8408\n","Epoch 5\tavg epoch Loss = 0.4254\tavg epoch acc = 0.8497\n","Epoch 6\tavg epoch Loss = 0.3822\tavg epoch acc = 0.8575\n","Epoch 7\tavg epoch Loss = 0.3477\tavg epoch acc = 0.8629\n","Epoch 8\tavg epoch Loss = 0.3194\tavg epoch acc = 0.8688\n","Epoch 9\tavg epoch Loss = 0.296\tavg epoch acc = 0.8743\n","training took 112.9 s\n","Avg test loss = 0.671\tAvg test acc = 0.864\n","Epoch 0\tavg epoch Loss = 1.962\tavg epoch acc = 0.5997\n","Epoch 1\tavg epoch Loss = 0.9882\tavg epoch acc = 0.7523\n","Epoch 2\tavg epoch Loss = 0.6712\tavg epoch acc = 0.807\n","Epoch 3\tavg epoch Loss = 0.5597\tavg epoch acc = 0.8263\n","Epoch 4\tavg epoch Loss = 0.4864\tavg epoch acc = 0.8376\n","Epoch 5\tavg epoch Loss = 0.4307\tavg epoch acc = 0.8463\n","Epoch 6\tavg epoch Loss = 0.3867\tavg epoch acc = 0.8531\n","Epoch 7\tavg epoch Loss = 0.3514\tavg epoch acc = 0.8593\n","Epoch 8\tavg epoch Loss = 0.3227\tavg epoch acc = 0.8657\n","Epoch 9\tavg epoch Loss = 0.2991\tavg epoch acc = 0.8716\n","training took 112.4 s\n","Avg test loss = 0.645\tAvg test acc = 0.875\n","Epoch 0\tavg epoch Loss = 1.96\tavg epoch acc = 0.5958\n","Epoch 1\tavg epoch Loss = 0.9852\tavg epoch acc = 0.7519\n","Epoch 2\tavg epoch Loss = 0.6683\tavg epoch acc = 0.8037\n","Epoch 3\tavg epoch Loss = 0.5577\tavg epoch acc = 0.8232\n","Epoch 4\tavg epoch Loss = 0.4853\tavg epoch acc = 0.8356\n","Epoch 5\tavg epoch Loss = 0.4305\tavg epoch acc = 0.8436\n","Epoch 6\tavg epoch Loss = 0.3871\tavg epoch acc = 0.8512\n","Epoch 7\tavg epoch Loss = 0.352\tavg epoch acc = 0.8579\n","Epoch 8\tavg epoch Loss = 0.3234\tavg epoch acc = 0.8648\n","Epoch 9\tavg epoch Loss = 0.2995\tavg epoch acc = 0.8708\n","training took 112.4 s\n","Avg test loss = 0.672\tAvg test acc = 0.873\n","{'lr': 1e-05, 'beta1': 0.1, 'beta2': 0.5, 'batch_size': 32, 'weight_decay': 0.050050000000000004, 'epsilon': 1e-10}\n","Epoch 0\tavg epoch Loss = 1.962\tavg epoch acc = 0.5991\n","Epoch 1\tavg epoch Loss = 0.9886\tavg epoch acc = 0.7537\n","Epoch 2\tavg epoch Loss = 0.6707\tavg epoch acc = 0.8065\n","Epoch 3\tavg epoch Loss = 0.5593\tavg epoch acc = 0.8267\n","Epoch 4\tavg epoch Loss = 0.4859\tavg epoch acc = 0.8384\n","Epoch 5\tavg epoch Loss = 0.4305\tavg epoch acc = 0.8466\n","Epoch 6\tavg epoch Loss = 0.3869\tavg epoch acc = 0.8534\n","Epoch 7\tavg epoch Loss = 0.352\tavg epoch acc = 0.8595\n","Epoch 8\tavg epoch Loss = 0.3236\tavg epoch acc = 0.865\n","Epoch 9\tavg epoch Loss = 0.3\tavg epoch acc = 0.8708\n","training took 112.0 s\n","Avg test loss = 0.638\tAvg test acc = 0.873\n","Epoch 0\tavg epoch Loss = 1.96\tavg epoch acc = 0.5925\n","Epoch 1\tavg epoch Loss = 0.9839\tavg epoch acc = 0.7537\n","Epoch 2\tavg epoch Loss = 0.6672\tavg epoch acc = 0.8086\n","Epoch 3\tavg epoch Loss = 0.5566\tavg epoch acc = 0.8288\n","Epoch 4\tavg epoch Loss = 0.484\tavg epoch acc = 0.8404\n","Epoch 5\tavg epoch Loss = 0.4286\tavg epoch acc = 0.8486\n","Epoch 6\tavg epoch Loss = 0.3849\tavg epoch acc = 0.8556\n","Epoch 7\tavg epoch Loss = 0.3499\tavg epoch acc = 0.8615\n","Epoch 8\tavg epoch Loss = 0.3212\tavg epoch acc = 0.8676\n","Epoch 9\tavg epoch Loss = 0.2976\tavg epoch acc = 0.873\n","training took 112.5 s\n","Avg test loss = 0.635\tAvg test acc = 0.871\n","Epoch 0\tavg epoch Loss = 1.961\tavg epoch acc = 0.5946\n","Epoch 1\tavg epoch Loss = 0.9851\tavg epoch acc = 0.7534\n","Epoch 2\tavg epoch Loss = 0.6671\tavg epoch acc = 0.8067\n","Epoch 3\tavg epoch Loss = 0.5562\tavg epoch acc = 0.8261\n","Epoch 4\tavg epoch Loss = 0.4833\tavg epoch acc = 0.8377\n","Epoch 5\tavg epoch Loss = 0.4285\tavg epoch acc = 0.8471\n","Epoch 6\tavg epoch Loss = 0.3852\tavg epoch acc = 0.8547\n","Epoch 7\tavg epoch Loss = 0.3506\tavg epoch acc = 0.86\n","Epoch 8\tavg epoch Loss = 0.3224\tavg epoch acc = 0.8654\n","Epoch 9\tavg epoch Loss = 0.2993\tavg epoch acc = 0.8716\n","training took 112.1 s\n","Avg test loss = 0.64\tAvg test acc = 0.872\n","Epoch 0\tavg epoch Loss = 1.961\tavg epoch acc = 0.594\n","Epoch 1\tavg epoch Loss = 0.9891\tavg epoch acc = 0.7512\n","Epoch 2\tavg epoch Loss = 0.6718\tavg epoch acc = 0.805\n","Epoch 3\tavg epoch Loss = 0.5614\tavg epoch acc = 0.8251\n","Epoch 4\tavg epoch Loss = 0.4888\tavg epoch acc = 0.838\n","Epoch 5\tavg epoch Loss = 0.4333\tavg epoch acc = 0.846\n","Epoch 6\tavg epoch Loss = 0.3892\tavg epoch acc = 0.853\n","Epoch 7\tavg epoch Loss = 0.3537\tavg epoch acc = 0.8588\n","Epoch 8\tavg epoch Loss = 0.3247\tavg epoch acc = 0.8656\n","Epoch 9\tavg epoch Loss = 0.3007\tavg epoch acc = 0.8713\n","training took 111.7 s\n","Avg test loss = 0.62\tAvg test acc = 0.879\n","Epoch 0\tavg epoch Loss = 1.96\tavg epoch acc = 0.5984\n","Epoch 1\tavg epoch Loss = 0.9862\tavg epoch acc = 0.7521\n","Epoch 2\tavg epoch Loss = 0.6701\tavg epoch acc = 0.8045\n","Epoch 3\tavg epoch Loss = 0.5591\tavg epoch acc = 0.8246\n","Epoch 4\tavg epoch Loss = 0.4858\tavg epoch acc = 0.837\n","Epoch 5\tavg epoch Loss = 0.4302\tavg epoch acc = 0.845\n","Epoch 6\tavg epoch Loss = 0.3863\tavg epoch acc = 0.8523\n","Epoch 7\tavg epoch Loss = 0.3512\tavg epoch acc = 0.8586\n","Epoch 8\tavg epoch Loss = 0.3228\tavg epoch acc = 0.8646\n","Epoch 9\tavg epoch Loss = 0.2995\tavg epoch acc = 0.8705\n","training took 112.5 s\n","Avg test loss = 0.648\tAvg test acc = 0.871\n","{'lr': 1e-05, 'beta1': 0.1, 'beta2': 0.5, 'batch_size': 32, 'weight_decay': 0.050050000000000004, 'epsilon': 5.0500000000000006e-09}\n","Epoch 0\tavg epoch Loss = 1.959\tavg epoch acc = 0.595\n","Epoch 1\tavg epoch Loss = 0.9839\tavg epoch acc = 0.7544\n","Epoch 2\tavg epoch Loss = 0.6675\tavg epoch acc = 0.8076\n","Epoch 3\tavg epoch Loss = 0.557\tavg epoch acc = 0.8275\n","Epoch 4\tavg epoch Loss = 0.4845\tavg epoch acc = 0.8391\n","Epoch 5\tavg epoch Loss = 0.4297\tavg epoch acc = 0.8474\n","Epoch 6\tavg epoch Loss = 0.3862\tavg epoch acc = 0.8552\n","Epoch 7\tavg epoch Loss = 0.3515\tavg epoch acc = 0.8613\n","Epoch 8\tavg epoch Loss = 0.3231\tavg epoch acc = 0.8674\n","Epoch 9\tavg epoch Loss = 0.2997\tavg epoch acc = 0.8731\n","training took 112.7 s\n","Avg test loss = 0.662\tAvg test acc = 0.866\n","Epoch 0\tavg epoch Loss = 1.962\tavg epoch acc = 0.5977\n","Epoch 1\tavg epoch Loss = 0.9889\tavg epoch acc = 0.7518\n","Epoch 2\tavg epoch Loss = 0.6733\tavg epoch acc = 0.8049\n","Epoch 3\tavg epoch Loss = 0.5629\tavg epoch acc = 0.8254\n","Epoch 4\tavg epoch Loss = 0.4901\tavg epoch acc = 0.8381\n","Epoch 5\tavg epoch Loss = 0.4345\tavg epoch acc = 0.8464\n","Epoch 6\tavg epoch Loss = 0.3906\tavg epoch acc = 0.8536\n","Epoch 7\tavg epoch Loss = 0.3554\tavg epoch acc = 0.8593\n","Epoch 8\tavg epoch Loss = 0.3266\tavg epoch acc = 0.8662\n","Epoch 9\tavg epoch Loss = 0.3026\tavg epoch acc = 0.8724\n","training took 113.5 s\n","Avg test loss = 0.599\tAvg test acc = 0.879\n","Epoch 0\tavg epoch Loss = 1.96\tavg epoch acc = 0.6012\n","Epoch 1\tavg epoch Loss = 0.9852\tavg epoch acc = 0.7542\n","Epoch 2\tavg epoch Loss = 0.6683\tavg epoch acc = 0.8065\n","Epoch 3\tavg epoch Loss = 0.5575\tavg epoch acc = 0.8274\n","Epoch 4\tavg epoch Loss = 0.4849\tavg epoch acc = 0.8395\n","Epoch 5\tavg epoch Loss = 0.4294\tavg epoch acc = 0.8476\n","Epoch 6\tavg epoch Loss = 0.3857\tavg epoch acc = 0.8549\n","Epoch 7\tavg epoch Loss = 0.3508\tavg epoch acc = 0.8609\n","Epoch 8\tavg epoch Loss = 0.3223\tavg epoch acc = 0.8671\n","Epoch 9\tavg epoch Loss = 0.2988\tavg epoch acc = 0.8735\n","training took 113.3 s\n","Avg test loss = 0.615\tAvg test acc = 0.878\n","Epoch 0\tavg epoch Loss = 1.962\tavg epoch acc = 0.5914\n","Epoch 1\tavg epoch Loss = 0.9898\tavg epoch acc = 0.7525\n","Epoch 2\tavg epoch Loss = 0.6702\tavg epoch acc = 0.8069\n","Epoch 3\tavg epoch Loss = 0.5582\tavg epoch acc = 0.8273\n","Epoch 4\tavg epoch Loss = 0.4848\tavg epoch acc = 0.8396\n","Epoch 5\tavg epoch Loss = 0.4289\tavg epoch acc = 0.8471\n","Epoch 6\tavg epoch Loss = 0.3849\tavg epoch acc = 0.8547\n","Epoch 7\tavg epoch Loss = 0.3497\tavg epoch acc = 0.86\n","Epoch 8\tavg epoch Loss = 0.3212\tavg epoch acc = 0.8658\n","Epoch 9\tavg epoch Loss = 0.298\tavg epoch acc = 0.8711\n","training took 113.6 s\n","Avg test loss = 0.644\tAvg test acc = 0.873\n","Epoch 0\tavg epoch Loss = 1.965\tavg epoch acc = 0.5939\n","Epoch 1\tavg epoch Loss = 0.9909\tavg epoch acc = 0.7511\n","Epoch 2\tavg epoch Loss = 0.6689\tavg epoch acc = 0.8058\n","Epoch 3\tavg epoch Loss = 0.557\tavg epoch acc = 0.8255\n","Epoch 4\tavg epoch Loss = 0.4841\tavg epoch acc = 0.837\n","Epoch 5\tavg epoch Loss = 0.4291\tavg epoch acc = 0.8455\n","Epoch 6\tavg epoch Loss = 0.3854\tavg epoch acc = 0.8531\n","Epoch 7\tavg epoch Loss = 0.3503\tavg epoch acc = 0.8591\n","Epoch 8\tavg epoch Loss = 0.3219\tavg epoch acc = 0.8653\n","Epoch 9\tavg epoch Loss = 0.2986\tavg epoch acc = 0.8715\n","training took 112.9 s\n","Avg test loss = 0.641\tAvg test acc = 0.872\n","{'lr': 1e-05, 'beta1': 0.1, 'beta2': 0.5, 'batch_size': 32, 'weight_decay': 0.050050000000000004, 'epsilon': 1e-08}\n","Epoch 0\tavg epoch Loss = 1.962\tavg epoch acc = 0.5987\n","Epoch 1\tavg epoch Loss = 0.9845\tavg epoch acc = 0.7551\n","Epoch 2\tavg epoch Loss = 0.668\tavg epoch acc = 0.8081\n","Epoch 3\tavg epoch Loss = 0.5574\tavg epoch acc = 0.8273\n","Epoch 4\tavg epoch Loss = 0.4842\tavg epoch acc = 0.8386\n","Epoch 5\tavg epoch Loss = 0.4287\tavg epoch acc = 0.8472\n","Epoch 6\tavg epoch Loss = 0.3851\tavg epoch acc = 0.8545\n","Epoch 7\tavg epoch Loss = 0.3505\tavg epoch acc = 0.86\n","Epoch 8\tavg epoch Loss = 0.3224\tavg epoch acc = 0.8657\n","Epoch 9\tavg epoch Loss = 0.2991\tavg epoch acc = 0.8711\n","training took 113.6 s\n","Avg test loss = 0.636\tAvg test acc = 0.874\n","Epoch 0\tavg epoch Loss = 1.962\tavg epoch acc = 0.5858\n","Epoch 1\tavg epoch Loss = 0.9897\tavg epoch acc = 0.7513\n","Epoch 2\tavg epoch Loss = 0.6723\tavg epoch acc = 0.8048\n","Epoch 3\tavg epoch Loss = 0.5608\tavg epoch acc = 0.8252\n","Epoch 4\tavg epoch Loss = 0.4869\tavg epoch acc = 0.8372\n","Epoch 5\tavg epoch Loss = 0.431\tavg epoch acc = 0.8451\n","Epoch 6\tavg epoch Loss = 0.387\tavg epoch acc = 0.852\n","Epoch 7\tavg epoch Loss = 0.3515\tavg epoch acc = 0.8573\n","Epoch 8\tavg epoch Loss = 0.3228\tavg epoch acc = 0.863\n","Epoch 9\tavg epoch Loss = 0.2992\tavg epoch acc = 0.8684\n","training took 113.1 s\n","Avg test loss = 0.669\tAvg test acc = 0.867\n","Epoch 0\tavg epoch Loss = 1.959\tavg epoch acc = 0.592\n","Epoch 1\tavg epoch Loss = 0.9863\tavg epoch acc = 0.7516\n","Epoch 2\tavg epoch Loss = 0.666\tavg epoch acc = 0.8048\n","Epoch 3\tavg epoch Loss = 0.5545\tavg epoch acc = 0.8251\n","Epoch 4\tavg epoch Loss = 0.4814\tavg epoch acc = 0.8375\n","Epoch 5\tavg epoch Loss = 0.4263\tavg epoch acc = 0.8459\n","Epoch 6\tavg epoch Loss = 0.3827\tavg epoch acc = 0.8526\n","Epoch 7\tavg epoch Loss = 0.3478\tavg epoch acc = 0.8584\n","Epoch 8\tavg epoch Loss = 0.3195\tavg epoch acc = 0.8641\n","Epoch 9\tavg epoch Loss = 0.2961\tavg epoch acc = 0.8698\n","training took 113.7 s\n","Avg test loss = 0.667\tAvg test acc = 0.869\n","Epoch 0\tavg epoch Loss = 1.958\tavg epoch acc = 0.6039\n","Epoch 1\tavg epoch Loss = 0.9819\tavg epoch acc = 0.7551\n","Epoch 2\tavg epoch Loss = 0.6685\tavg epoch acc = 0.8058\n","Epoch 3\tavg epoch Loss = 0.559\tavg epoch acc = 0.827\n","Epoch 4\tavg epoch Loss = 0.4873\tavg epoch acc = 0.839\n","Epoch 5\tavg epoch Loss = 0.4326\tavg epoch acc = 0.8475\n","Epoch 6\tavg epoch Loss = 0.3891\tavg epoch acc = 0.8554\n","Epoch 7\tavg epoch Loss = 0.3545\tavg epoch acc = 0.8614\n","Epoch 8\tavg epoch Loss = 0.3262\tavg epoch acc = 0.8679\n","Epoch 9\tavg epoch Loss = 0.3028\tavg epoch acc = 0.874\n","training took 113.1 s\n","Avg test loss = 0.601\tAvg test acc = 0.877\n","Epoch 0\tavg epoch Loss = 1.961\tavg epoch acc = 0.6032\n","Epoch 1\tavg epoch Loss = 0.9866\tavg epoch acc = 0.7539\n","Epoch 2\tavg epoch Loss = 0.6694\tavg epoch acc = 0.8082\n","Epoch 3\tavg epoch Loss = 0.5584\tavg epoch acc = 0.8287\n","Epoch 4\tavg epoch Loss = 0.4851\tavg epoch acc = 0.8406\n","Epoch 5\tavg epoch Loss = 0.4298\tavg epoch acc = 0.8495\n","Epoch 6\tavg epoch Loss = 0.3864\tavg epoch acc = 0.8568\n","Epoch 7\tavg epoch Loss = 0.3514\tavg epoch acc = 0.8635\n","Epoch 8\tavg epoch Loss = 0.3229\tavg epoch acc = 0.87\n","Epoch 9\tavg epoch Loss = 0.2995\tavg epoch acc = 0.8761\n","training took 113.6 s\n","Avg test loss = 0.606\tAvg test acc = 0.877\n","{'lr': 1e-05, 'beta1': 0.1, 'beta2': 0.5, 'batch_size': 32, 'weight_decay': 0.1, 'epsilon': 1e-10}\n","Epoch 0\tavg epoch Loss = 1.96\tavg epoch acc = 0.5961\n","Epoch 1\tavg epoch Loss = 0.9869\tavg epoch acc = 0.7538\n","Epoch 2\tavg epoch Loss = 0.671\tavg epoch acc = 0.8071\n","Epoch 3\tavg epoch Loss = 0.5602\tavg epoch acc = 0.8276\n","Epoch 4\tavg epoch Loss = 0.4875\tavg epoch acc = 0.8391\n","Epoch 5\tavg epoch Loss = 0.4326\tavg epoch acc = 0.8479\n","Epoch 6\tavg epoch Loss = 0.3891\tavg epoch acc = 0.8553\n","Epoch 7\tavg epoch Loss = 0.3541\tavg epoch acc = 0.8612\n","Epoch 8\tavg epoch Loss = 0.3254\tavg epoch acc = 0.8678\n","Epoch 9\tavg epoch Loss = 0.3018\tavg epoch acc = 0.8741\n","training took 113.2 s\n","Avg test loss = 0.624\tAvg test acc = 0.876\n","Epoch 0\tavg epoch Loss = 1.959\tavg epoch acc = 0.5989\n","Epoch 1\tavg epoch Loss = 0.9861\tavg epoch acc = 0.7519\n","Epoch 2\tavg epoch Loss = 0.6688\tavg epoch acc = 0.8048\n","Epoch 3\tavg epoch Loss = 0.5581\tavg epoch acc = 0.8251\n","Epoch 4\tavg epoch Loss = 0.4856\tavg epoch acc = 0.8366\n","Epoch 5\tavg epoch Loss = 0.4304\tavg epoch acc = 0.8445\n","Epoch 6\tavg epoch Loss = 0.3867\tavg epoch acc = 0.8511\n","Epoch 7\tavg epoch Loss = 0.3517\tavg epoch acc = 0.8569\n","Epoch 8\tavg epoch Loss = 0.3232\tavg epoch acc = 0.8625\n","Epoch 9\tavg epoch Loss = 0.2998\tavg epoch acc = 0.8683\n","training took 112.6 s\n","Avg test loss = 0.678\tAvg test acc = 0.868\n","Epoch 0\tavg epoch Loss = 1.96\tavg epoch acc = 0.592\n","Epoch 1\tavg epoch Loss = 0.9839\tavg epoch acc = 0.7532\n","Epoch 2\tavg epoch Loss = 0.6663\tavg epoch acc = 0.8069\n","Epoch 3\tavg epoch Loss = 0.5552\tavg epoch acc = 0.8279\n","Epoch 4\tavg epoch Loss = 0.4825\tavg epoch acc = 0.8395\n","Epoch 5\tavg epoch Loss = 0.4274\tavg epoch acc = 0.8484\n","Epoch 6\tavg epoch Loss = 0.3838\tavg epoch acc = 0.856\n","Epoch 7\tavg epoch Loss = 0.3492\tavg epoch acc = 0.8619\n","Epoch 8\tavg epoch Loss = 0.3211\tavg epoch acc = 0.8679\n","Epoch 9\tavg epoch Loss = 0.2979\tavg epoch acc = 0.8735\n","training took 113.2 s\n","Avg test loss = 0.609\tAvg test acc = 0.877\n","Epoch 0\tavg epoch Loss = 1.963\tavg epoch acc = 0.5962\n","Epoch 1\tavg epoch Loss = 0.9905\tavg epoch acc = 0.7512\n","Epoch 2\tavg epoch Loss = 0.6709\tavg epoch acc = 0.8039\n","Epoch 3\tavg epoch Loss = 0.5598\tavg epoch acc = 0.8245\n","Epoch 4\tavg epoch Loss = 0.4872\tavg epoch acc = 0.837\n","Epoch 5\tavg epoch Loss = 0.4322\tavg epoch acc = 0.8455\n","Epoch 6\tavg epoch Loss = 0.3887\tavg epoch acc = 0.8529\n","Epoch 7\tavg epoch Loss = 0.3539\tavg epoch acc = 0.8589\n","Epoch 8\tavg epoch Loss = 0.3256\tavg epoch acc = 0.8646\n","Epoch 9\tavg epoch Loss = 0.3023\tavg epoch acc = 0.8705\n","training took 113.2 s\n","Avg test loss = 0.631\tAvg test acc = 0.869\n","Epoch 0\tavg epoch Loss = 1.96\tavg epoch acc = 0.5968\n","Epoch 1\tavg epoch Loss = 0.9872\tavg epoch acc = 0.7545\n","Epoch 2\tavg epoch Loss = 0.6705\tavg epoch acc = 0.8082\n","Epoch 3\tavg epoch Loss = 0.5599\tavg epoch acc = 0.8273\n","Epoch 4\tavg epoch Loss = 0.4872\tavg epoch acc = 0.8384\n","Epoch 5\tavg epoch Loss = 0.4319\tavg epoch acc = 0.847\n","Epoch 6\tavg epoch Loss = 0.3881\tavg epoch acc = 0.8542\n","Epoch 7\tavg epoch Loss = 0.3528\tavg epoch acc = 0.8602\n","Epoch 8\tavg epoch Loss = 0.3242\tavg epoch acc = 0.8655\n","Epoch 9\tavg epoch Loss = 0.3005\tavg epoch acc = 0.8702\n","training took 113.4 s\n","Avg test loss = 0.628\tAvg test acc = 0.872\n","{'lr': 1e-05, 'beta1': 0.1, 'beta2': 0.5, 'batch_size': 32, 'weight_decay': 0.1, 'epsilon': 5.0500000000000006e-09}\n","Epoch 0\tavg epoch Loss = 1.962\tavg epoch acc = 0.5938\n","Epoch 1\tavg epoch Loss = 0.9882\tavg epoch acc = 0.751\n","Epoch 2\tavg epoch Loss = 0.67\tavg epoch acc = 0.8053\n","Epoch 3\tavg epoch Loss = 0.5591\tavg epoch acc = 0.8264\n","Epoch 4\tavg epoch Loss = 0.4865\tavg epoch acc = 0.8384\n","Epoch 5\tavg epoch Loss = 0.431\tavg epoch acc = 0.8464\n","Epoch 6\tavg epoch Loss = 0.387\tavg epoch acc = 0.8529\n","Epoch 7\tavg epoch Loss = 0.3518\tavg epoch acc = 0.859\n","Epoch 8\tavg epoch Loss = 0.3232\tavg epoch acc = 0.8649\n","Epoch 9\tavg epoch Loss = 0.2995\tavg epoch acc = 0.8703\n","training took 112.4 s\n","Avg test loss = 0.662\tAvg test acc = 0.869\n","Epoch 0\tavg epoch Loss = 1.96\tavg epoch acc = 0.6032\n","Epoch 1\tavg epoch Loss = 0.9829\tavg epoch acc = 0.7549\n","Epoch 2\tavg epoch Loss = 0.6646\tavg epoch acc = 0.8065\n","Epoch 3\tavg epoch Loss = 0.5533\tavg epoch acc = 0.8272\n","Epoch 4\tavg epoch Loss = 0.4805\tavg epoch acc = 0.8383\n","Epoch 5\tavg epoch Loss = 0.4255\tavg epoch acc = 0.8467\n","Epoch 6\tavg epoch Loss = 0.3819\tavg epoch acc = 0.854\n","Epoch 7\tavg epoch Loss = 0.347\tavg epoch acc = 0.8594\n","Epoch 8\tavg epoch Loss = 0.3188\tavg epoch acc = 0.8646\n","Epoch 9\tavg epoch Loss = 0.2956\tavg epoch acc = 0.8703\n","training took 112.1 s\n","Avg test loss = 0.653\tAvg test acc = 0.87\n","Epoch 0\tavg epoch Loss = 1.96\tavg epoch acc = 0.6011\n","Epoch 1\tavg epoch Loss = 0.9841\tavg epoch acc = 0.7538\n","Epoch 2\tavg epoch Loss = 0.6673\tavg epoch acc = 0.8067\n","Epoch 3\tavg epoch Loss = 0.5567\tavg epoch acc = 0.8264\n","Epoch 4\tavg epoch Loss = 0.4843\tavg epoch acc = 0.8383\n","Epoch 5\tavg epoch Loss = 0.4297\tavg epoch acc = 0.847\n","Epoch 6\tavg epoch Loss = 0.3863\tavg epoch acc = 0.8549\n","Epoch 7\tavg epoch Loss = 0.3517\tavg epoch acc = 0.8612\n","Epoch 8\tavg epoch Loss = 0.3236\tavg epoch acc = 0.8669\n","Epoch 9\tavg epoch Loss = 0.3005\tavg epoch acc = 0.873\n","training took 112.1 s\n","Avg test loss = 0.649\tAvg test acc = 0.874\n","Epoch 0\tavg epoch Loss = 1.961\tavg epoch acc = 0.5909\n","Epoch 1\tavg epoch Loss = 0.9908\tavg epoch acc = 0.7524\n","Epoch 2\tavg epoch Loss = 0.6735\tavg epoch acc = 0.8059\n","Epoch 3\tavg epoch Loss = 0.563\tavg epoch acc = 0.8269\n","Epoch 4\tavg epoch Loss = 0.4901\tavg epoch acc = 0.8382\n","Epoch 5\tavg epoch Loss = 0.4347\tavg epoch acc = 0.8465\n","Epoch 6\tavg epoch Loss = 0.3909\tavg epoch acc = 0.8544\n","Epoch 7\tavg epoch Loss = 0.3556\tavg epoch acc = 0.8602\n","Epoch 8\tavg epoch Loss = 0.327\tavg epoch acc = 0.8666\n","Epoch 9\tavg epoch Loss = 0.3035\tavg epoch acc = 0.8724\n","training took 112.3 s\n","Avg test loss = 0.606\tAvg test acc = 0.87\n","Epoch 0\tavg epoch Loss = 1.961\tavg epoch acc = 0.592\n","Epoch 1\tavg epoch Loss = 0.9876\tavg epoch acc = 0.7523\n","Epoch 2\tavg epoch Loss = 0.6711\tavg epoch acc = 0.8046\n","Epoch 3\tavg epoch Loss = 0.5611\tavg epoch acc = 0.8249\n","Epoch 4\tavg epoch Loss = 0.4887\tavg epoch acc = 0.8361\n","Epoch 5\tavg epoch Loss = 0.4337\tavg epoch acc = 0.8445\n","Epoch 6\tavg epoch Loss = 0.3899\tavg epoch acc = 0.8522\n","Epoch 7\tavg epoch Loss = 0.3547\tavg epoch acc = 0.858\n","Epoch 8\tavg epoch Loss = 0.326\tavg epoch acc = 0.8632\n","Epoch 9\tavg epoch Loss = 0.3024\tavg epoch acc = 0.8694\n","training took 111.9 s\n","Avg test loss = 0.611\tAvg test acc = 0.875\n","{'lr': 1e-05, 'beta1': 0.1, 'beta2': 0.5, 'batch_size': 32, 'weight_decay': 0.1, 'epsilon': 1e-08}\n","Epoch 0\tavg epoch Loss = 1.963\tavg epoch acc = 0.5924\n","Epoch 1\tavg epoch Loss = 0.9889\tavg epoch acc = 0.7524\n","Epoch 2\tavg epoch Loss = 0.6699\tavg epoch acc = 0.8069\n","Epoch 3\tavg epoch Loss = 0.5596\tavg epoch acc = 0.8274\n","Epoch 4\tavg epoch Loss = 0.4868\tavg epoch acc = 0.8385\n","Epoch 5\tavg epoch Loss = 0.4311\tavg epoch acc = 0.8463\n","Epoch 6\tavg epoch Loss = 0.3871\tavg epoch acc = 0.8528\n","Epoch 7\tavg epoch Loss = 0.3518\tavg epoch acc = 0.8586\n","Epoch 8\tavg epoch Loss = 0.3232\tavg epoch acc = 0.8641\n","Epoch 9\tavg epoch Loss = 0.2997\tavg epoch acc = 0.87\n","training took 112.5 s\n","Avg test loss = 0.663\tAvg test acc = 0.869\n","Epoch 0\tavg epoch Loss = 1.961\tavg epoch acc = 0.5994\n","Epoch 1\tavg epoch Loss = 0.9884\tavg epoch acc = 0.7531\n","Epoch 2\tavg epoch Loss = 0.6717\tavg epoch acc = 0.8058\n","Epoch 3\tavg epoch Loss = 0.5602\tavg epoch acc = 0.8264\n","Epoch 4\tavg epoch Loss = 0.487\tavg epoch acc = 0.8388\n","Epoch 5\tavg epoch Loss = 0.4316\tavg epoch acc = 0.8478\n","Epoch 6\tavg epoch Loss = 0.3879\tavg epoch acc = 0.8545\n","Epoch 7\tavg epoch Loss = 0.3527\tavg epoch acc = 0.861\n","Epoch 8\tavg epoch Loss = 0.3241\tavg epoch acc = 0.8676\n","Epoch 9\tavg epoch Loss = 0.3006\tavg epoch acc = 0.8737\n","training took 112.1 s\n","Avg test loss = 0.633\tAvg test acc = 0.874\n","Epoch 0\tavg epoch Loss = 1.96\tavg epoch acc = 0.6015\n","Epoch 1\tavg epoch Loss = 0.9853\tavg epoch acc = 0.7542\n","Epoch 2\tavg epoch Loss = 0.6687\tavg epoch acc = 0.8062\n","Epoch 3\tavg epoch Loss = 0.5586\tavg epoch acc = 0.8264\n","Epoch 4\tavg epoch Loss = 0.4863\tavg epoch acc = 0.8378\n","Epoch 5\tavg epoch Loss = 0.4318\tavg epoch acc = 0.8469\n","Epoch 6\tavg epoch Loss = 0.3884\tavg epoch acc = 0.8541\n","Epoch 7\tavg epoch Loss = 0.3536\tavg epoch acc = 0.8607\n","Epoch 8\tavg epoch Loss = 0.325\tavg epoch acc = 0.8675\n","Epoch 9\tavg epoch Loss = 0.3014\tavg epoch acc = 0.8741\n","training took 111.9 s\n","Avg test loss = 0.62\tAvg test acc = 0.87\n","Epoch 0\tavg epoch Loss = 1.96\tavg epoch acc = 0.5941\n","Epoch 1\tavg epoch Loss = 0.9873\tavg epoch acc = 0.7517\n","Epoch 2\tavg epoch Loss = 0.6716\tavg epoch acc = 0.8046\n","Epoch 3\tavg epoch Loss = 0.5613\tavg epoch acc = 0.8243\n","Epoch 4\tavg epoch Loss = 0.4884\tavg epoch acc = 0.837\n","Epoch 5\tavg epoch Loss = 0.433\tavg epoch acc = 0.8448\n","Epoch 6\tavg epoch Loss = 0.3889\tavg epoch acc = 0.8521\n","Epoch 7\tavg epoch Loss = 0.3535\tavg epoch acc = 0.8588\n","Epoch 8\tavg epoch Loss = 0.3247\tavg epoch acc = 0.865\n","Epoch 9\tavg epoch Loss = 0.301\tavg epoch acc = 0.8706\n","training took 112.1 s\n","Avg test loss = 0.604\tAvg test acc = 0.878\n","Epoch 0\tavg epoch Loss = 1.962\tavg epoch acc = 0.5997\n","Epoch 1\tavg epoch Loss = 0.9869\tavg epoch acc = 0.7522\n","Epoch 2\tavg epoch Loss = 0.6679\tavg epoch acc = 0.8052\n","Epoch 3\tavg epoch Loss = 0.5562\tavg epoch acc = 0.8257\n","Epoch 4\tavg epoch Loss = 0.4836\tavg epoch acc = 0.8372\n","Epoch 5\tavg epoch Loss = 0.4288\tavg epoch acc = 0.8451\n","Epoch 6\tavg epoch Loss = 0.3856\tavg epoch acc = 0.8526\n","Epoch 7\tavg epoch Loss = 0.3511\tavg epoch acc = 0.8585\n","Epoch 8\tavg epoch Loss = 0.3231\tavg epoch acc = 0.8633\n","Epoch 9\tavg epoch Loss = 0.2999\tavg epoch acc = 0.8691\n","training took 112.0 s\n","Avg test loss = 0.649\tAvg test acc = 0.874\n","{'lr': 1e-05, 'beta1': 0.1, 'beta2': 0.5, 'batch_size': 64, 'weight_decay': 0.0001, 'epsilon': 1e-10}\n","Epoch 0\tavg epoch Loss = 2.156\tavg epoch acc = 0.5486\n","Epoch 1\tavg epoch Loss = 1.519\tavg epoch acc = 0.6884\n","Epoch 2\tavg epoch Loss = 0.9465\tavg epoch acc = 0.7623\n","Epoch 3\tavg epoch Loss = 0.723\tavg epoch acc = 0.8002\n","Epoch 4\tavg epoch Loss = 0.6222\tavg epoch acc = 0.8195\n","Epoch 5\tavg epoch Loss = 0.556\tavg epoch acc = 0.831\n","Epoch 6\tavg epoch Loss = 0.5047\tavg epoch acc = 0.839\n","Epoch 7\tavg epoch Loss = 0.4625\tavg epoch acc = 0.8461\n","Epoch 8\tavg epoch Loss = 0.4265\tavg epoch acc = 0.8517\n","Epoch 9\tavg epoch Loss = 0.3958\tavg epoch acc = 0.8563\n","training took 59.68 s\n","Avg test loss = 0.611\tAvg test acc = 0.862\n","Epoch 0\tavg epoch Loss = 2.154\tavg epoch acc = 0.5652\n","Epoch 1\tavg epoch Loss = 1.504\tavg epoch acc = 0.692\n","Epoch 2\tavg epoch Loss = 0.9343\tavg epoch acc = 0.7637\n","Epoch 3\tavg epoch Loss = 0.7162\tavg epoch acc = 0.8007\n","Epoch 4\tavg epoch Loss = 0.6172\tavg epoch acc = 0.8193\n","Epoch 5\tavg epoch Loss = 0.552\tavg epoch acc = 0.8303\n","Epoch 6\tavg epoch Loss = 0.5016\tavg epoch acc = 0.8388\n","Epoch 7\tavg epoch Loss = 0.4601\tavg epoch acc = 0.8455\n","Epoch 8\tavg epoch Loss = 0.4249\tavg epoch acc = 0.8518\n","Epoch 9\tavg epoch Loss = 0.3946\tavg epoch acc = 0.8564\n","training took 60.04 s\n","Avg test loss = 0.646\tAvg test acc = 0.855\n","Epoch 0\tavg epoch Loss = 2.155\tavg epoch acc = 0.5625\n","Epoch 1\tavg epoch Loss = 1.516\tavg epoch acc = 0.6909\n","Epoch 2\tavg epoch Loss = 0.9448\tavg epoch acc = 0.7618\n","Epoch 3\tavg epoch Loss = 0.7215\tavg epoch acc = 0.7997\n","Epoch 4\tavg epoch Loss = 0.6206\tavg epoch acc = 0.819\n","Epoch 5\tavg epoch Loss = 0.5545\tavg epoch acc = 0.8298\n","Epoch 6\tavg epoch Loss = 0.5031\tavg epoch acc = 0.8376\n","Epoch 7\tavg epoch Loss = 0.4608\tavg epoch acc = 0.8445\n","Epoch 8\tavg epoch Loss = 0.4252\tavg epoch acc = 0.85\n","Epoch 9\tavg epoch Loss = 0.3944\tavg epoch acc = 0.8543\n","training took 59.8 s\n","Avg test loss = 0.668\tAvg test acc = 0.855\n","Epoch 0\tavg epoch Loss = 2.155\tavg epoch acc = 0.5475\n","Epoch 1\tavg epoch Loss = 1.512\tavg epoch acc = 0.6903\n","Epoch 2\tavg epoch Loss = 0.9413\tavg epoch acc = 0.7612\n","Epoch 3\tavg epoch Loss = 0.7211\tavg epoch acc = 0.7974\n","Epoch 4\tavg epoch Loss = 0.622\tavg epoch acc = 0.8179\n","Epoch 5\tavg epoch Loss = 0.5568\tavg epoch acc = 0.8295\n","Epoch 6\tavg epoch Loss = 0.5061\tavg epoch acc = 0.8378\n","Epoch 7\tavg epoch Loss = 0.4643\tavg epoch acc = 0.844\n","Epoch 8\tavg epoch Loss = 0.4288\tavg epoch acc = 0.85\n","Epoch 9\tavg epoch Loss = 0.3984\tavg epoch acc = 0.8558\n","training took 59.78 s\n","Avg test loss = 0.662\tAvg test acc = 0.855\n","Epoch 0\tavg epoch Loss = 2.155\tavg epoch acc = 0.5557\n","Epoch 1\tavg epoch Loss = 1.508\tavg epoch acc = 0.6882\n","Epoch 2\tavg epoch Loss = 0.9364\tavg epoch acc = 0.7611\n","Epoch 3\tavg epoch Loss = 0.7178\tavg epoch acc = 0.7988\n","Epoch 4\tavg epoch Loss = 0.6193\tavg epoch acc = 0.8178\n","Epoch 5\tavg epoch Loss = 0.5543\tavg epoch acc = 0.8284\n","Epoch 6\tavg epoch Loss = 0.5037\tavg epoch acc = 0.8369\n","Epoch 7\tavg epoch Loss = 0.4619\tavg epoch acc = 0.8433\n","Epoch 8\tavg epoch Loss = 0.4266\tavg epoch acc = 0.8485\n","Epoch 9\tavg epoch Loss = 0.396\tavg epoch acc = 0.8535\n","training took 59.82 s\n","Avg test loss = 0.637\tAvg test acc = 0.86\n","{'lr': 1e-05, 'beta1': 0.1, 'beta2': 0.5, 'batch_size': 64, 'weight_decay': 0.0001, 'epsilon': 5.0500000000000006e-09}\n","Epoch 0\tavg epoch Loss = 2.155\tavg epoch acc = 0.5638\n","Epoch 1\tavg epoch Loss = 1.511\tavg epoch acc = 0.6923\n","Epoch 2\tavg epoch Loss = 0.9393\tavg epoch acc = 0.7635\n","Epoch 3\tavg epoch Loss = 0.7198\tavg epoch acc = 0.7993\n","Epoch 4\tavg epoch Loss = 0.6205\tavg epoch acc = 0.8186\n","Epoch 5\tavg epoch Loss = 0.5552\tavg epoch acc = 0.8295\n","Epoch 6\tavg epoch Loss = 0.5046\tavg epoch acc = 0.8378\n","Epoch 7\tavg epoch Loss = 0.4629\tavg epoch acc = 0.844\n","Epoch 8\tavg epoch Loss = 0.4276\tavg epoch acc = 0.8496\n","Epoch 9\tavg epoch Loss = 0.3971\tavg epoch acc = 0.8546\n","training took 59.69 s\n","Avg test loss = 0.683\tAvg test acc = 0.852\n","Epoch 0\tavg epoch Loss = 2.156\tavg epoch acc = 0.5482\n","Epoch 1\tavg epoch Loss = 1.516\tavg epoch acc = 0.69\n","Epoch 2\tavg epoch Loss = 0.9433\tavg epoch acc = 0.762\n","Epoch 3\tavg epoch Loss = 0.7214\tavg epoch acc = 0.8001\n","Epoch 4\tavg epoch Loss = 0.6213\tavg epoch acc = 0.8188\n","Epoch 5\tavg epoch Loss = 0.5556\tavg epoch acc = 0.83\n","Epoch 6\tavg epoch Loss = 0.5046\tavg epoch acc = 0.838\n","Epoch 7\tavg epoch Loss = 0.4626\tavg epoch acc = 0.8449\n","Epoch 8\tavg epoch Loss = 0.427\tavg epoch acc = 0.8505\n","Epoch 9\tavg epoch Loss = 0.3965\tavg epoch acc = 0.8553\n","training took 59.91 s\n","Avg test loss = 0.656\tAvg test acc = 0.859\n","Epoch 0\tavg epoch Loss = 2.154\tavg epoch acc = 0.5602\n","Epoch 1\tavg epoch Loss = 1.509\tavg epoch acc = 0.6909\n","Epoch 2\tavg epoch Loss = 0.9396\tavg epoch acc = 0.7614\n","Epoch 3\tavg epoch Loss = 0.7202\tavg epoch acc = 0.7993\n","Epoch 4\tavg epoch Loss = 0.6212\tavg epoch acc = 0.8186\n","Epoch 5\tavg epoch Loss = 0.5558\tavg epoch acc = 0.8305\n","Epoch 6\tavg epoch Loss = 0.5049\tavg epoch acc = 0.8394\n","Epoch 7\tavg epoch Loss = 0.4628\tavg epoch acc = 0.8455\n","Epoch 8\tavg epoch Loss = 0.4272\tavg epoch acc = 0.8517\n","Epoch 9\tavg epoch Loss = 0.3966\tavg epoch acc = 0.8564\n","training took 60.07 s\n","Avg test loss = 0.599\tAvg test acc = 0.864\n","Epoch 0\tavg epoch Loss = 2.155\tavg epoch acc = 0.5557\n","Epoch 1\tavg epoch Loss = 1.51\tavg epoch acc = 0.6908\n","Epoch 2\tavg epoch Loss = 0.9382\tavg epoch acc = 0.763\n","Epoch 3\tavg epoch Loss = 0.7176\tavg epoch acc = 0.8003\n","Epoch 4\tavg epoch Loss = 0.618\tavg epoch acc = 0.8198\n","Epoch 5\tavg epoch Loss = 0.5522\tavg epoch acc = 0.8307\n","Epoch 6\tavg epoch Loss = 0.5012\tavg epoch acc = 0.8394\n","Epoch 7\tavg epoch Loss = 0.4592\tavg epoch acc = 0.8458\n","Epoch 8\tavg epoch Loss = 0.4236\tavg epoch acc = 0.852\n","Epoch 9\tavg epoch Loss = 0.3929\tavg epoch acc = 0.8572\n","training took 59.66 s\n","Avg test loss = 0.658\tAvg test acc = 0.854\n","Epoch 0\tavg epoch Loss = 2.155\tavg epoch acc = 0.5576\n","Epoch 1\tavg epoch Loss = 1.512\tavg epoch acc = 0.6847\n","Epoch 2\tavg epoch Loss = 0.9432\tavg epoch acc = 0.7599\n","Epoch 3\tavg epoch Loss = 0.7224\tavg epoch acc = 0.7972\n","Epoch 4\tavg epoch Loss = 0.6228\tavg epoch acc = 0.8164\n","Epoch 5\tavg epoch Loss = 0.5572\tavg epoch acc = 0.8285\n","Epoch 6\tavg epoch Loss = 0.5062\tavg epoch acc = 0.837\n","Epoch 7\tavg epoch Loss = 0.4641\tavg epoch acc = 0.8436\n","Epoch 8\tavg epoch Loss = 0.4286\tavg epoch acc = 0.8498\n","Epoch 9\tavg epoch Loss = 0.398\tavg epoch acc = 0.855\n","training took 59.7 s\n","Avg test loss = 0.628\tAvg test acc = 0.858\n","{'lr': 1e-05, 'beta1': 0.1, 'beta2': 0.5, 'batch_size': 64, 'weight_decay': 0.0001, 'epsilon': 1e-08}\n","Epoch 0\tavg epoch Loss = 2.155\tavg epoch acc = 0.5568\n","Epoch 1\tavg epoch Loss = 1.509\tavg epoch acc = 0.6901\n","Epoch 2\tavg epoch Loss = 0.9381\tavg epoch acc = 0.7618\n","Epoch 3\tavg epoch Loss = 0.7196\tavg epoch acc = 0.7994\n","Epoch 4\tavg epoch Loss = 0.6209\tavg epoch acc = 0.8184\n","Epoch 5\tavg epoch Loss = 0.5557\tavg epoch acc = 0.8291\n","Epoch 6\tavg epoch Loss = 0.5051\tavg epoch acc = 0.8377\n","Epoch 7\tavg epoch Loss = 0.4634\tavg epoch acc = 0.8442\n","Epoch 8\tavg epoch Loss = 0.4277\tavg epoch acc = 0.85\n","Epoch 9\tavg epoch Loss = 0.397\tavg epoch acc = 0.8551\n","training took 59.67 s\n","Avg test loss = 0.645\tAvg test acc = 0.857\n","Epoch 0\tavg epoch Loss = 2.155\tavg epoch acc = 0.558\n","Epoch 1\tavg epoch Loss = 1.512\tavg epoch acc = 0.6874\n","Epoch 2\tavg epoch Loss = 0.9388\tavg epoch acc = 0.7602\n","Epoch 3\tavg epoch Loss = 0.7155\tavg epoch acc = 0.7987\n","Epoch 4\tavg epoch Loss = 0.6149\tavg epoch acc = 0.818\n","Epoch 5\tavg epoch Loss = 0.5489\tavg epoch acc = 0.8302\n","Epoch 6\tavg epoch Loss = 0.4975\tavg epoch acc = 0.8385\n","Epoch 7\tavg epoch Loss = 0.4556\tavg epoch acc = 0.8445\n","Epoch 8\tavg epoch Loss = 0.4204\tavg epoch acc = 0.8507\n","Epoch 9\tavg epoch Loss = 0.3904\tavg epoch acc = 0.8555\n","training took 59.62 s\n","Avg test loss = 0.657\tAvg test acc = 0.857\n","Epoch 0\tavg epoch Loss = 2.155\tavg epoch acc = 0.5623\n","Epoch 1\tavg epoch Loss = 1.508\tavg epoch acc = 0.6895\n","Epoch 2\tavg epoch Loss = 0.9358\tavg epoch acc = 0.7626\n","Epoch 3\tavg epoch Loss = 0.7176\tavg epoch acc = 0.7991\n","Epoch 4\tavg epoch Loss = 0.6198\tavg epoch acc = 0.8181\n","Epoch 5\tavg epoch Loss = 0.5554\tavg epoch acc = 0.8292\n","Epoch 6\tavg epoch Loss = 0.5054\tavg epoch acc = 0.8379\n","Epoch 7\tavg epoch Loss = 0.4639\tavg epoch acc = 0.8442\n","Epoch 8\tavg epoch Loss = 0.4284\tavg epoch acc = 0.8493\n","Epoch 9\tavg epoch Loss = 0.398\tavg epoch acc = 0.8543\n","training took 59.81 s\n","Avg test loss = 0.682\tAvg test acc = 0.852\n","Epoch 0\tavg epoch Loss = 2.157\tavg epoch acc = 0.5487\n","Epoch 1\tavg epoch Loss = 1.519\tavg epoch acc = 0.6906\n","Epoch 2\tavg epoch Loss = 0.9489\tavg epoch acc = 0.7627\n","Epoch 3\tavg epoch Loss = 0.7263\tavg epoch acc = 0.8004\n","Epoch 4\tavg epoch Loss = 0.6255\tavg epoch acc = 0.8192\n","Epoch 5\tavg epoch Loss = 0.5591\tavg epoch acc = 0.831\n","Epoch 6\tavg epoch Loss = 0.5074\tavg epoch acc = 0.8388\n","Epoch 7\tavg epoch Loss = 0.4647\tavg epoch acc = 0.8449\n","Epoch 8\tavg epoch Loss = 0.4287\tavg epoch acc = 0.8516\n","Epoch 9\tavg epoch Loss = 0.3979\tavg epoch acc = 0.8572\n","training took 59.22 s\n","Avg test loss = 0.605\tAvg test acc = 0.862\n","Epoch 0\tavg epoch Loss = 2.156\tavg epoch acc = 0.5624\n","Epoch 1\tavg epoch Loss = 1.513\tavg epoch acc = 0.6898\n","Epoch 2\tavg epoch Loss = 0.9408\tavg epoch acc = 0.7621\n","Epoch 3\tavg epoch Loss = 0.7198\tavg epoch acc = 0.7981\n","Epoch 4\tavg epoch Loss = 0.6202\tavg epoch acc = 0.8171\n","Epoch 5\tavg epoch Loss = 0.555\tavg epoch acc = 0.8286\n","Epoch 6\tavg epoch Loss = 0.5043\tavg epoch acc = 0.8366\n","Epoch 7\tavg epoch Loss = 0.4626\tavg epoch acc = 0.8431\n","Epoch 8\tavg epoch Loss = 0.4273\tavg epoch acc = 0.8486\n","Epoch 9\tavg epoch Loss = 0.3969\tavg epoch acc = 0.8531\n","training took 59.64 s\n","Avg test loss = 0.641\tAvg test acc = 0.859\n","{'lr': 1e-05, 'beta1': 0.1, 'beta2': 0.5, 'batch_size': 64, 'weight_decay': 0.050050000000000004, 'epsilon': 1e-10}\n","Epoch 0\tavg epoch Loss = 2.156\tavg epoch acc = 0.564\n","Epoch 1\tavg epoch Loss = 1.514\tavg epoch acc = 0.6891\n","Epoch 2\tavg epoch Loss = 0.9426\tavg epoch acc = 0.7628\n","Epoch 3\tavg epoch Loss = 0.722\tavg epoch acc = 0.7988\n","Epoch 4\tavg epoch Loss = 0.6223\tavg epoch acc = 0.8172\n","Epoch 5\tavg epoch Loss = 0.5567\tavg epoch acc = 0.8285\n","Epoch 6\tavg epoch Loss = 0.506\tavg epoch acc = 0.8365\n","Epoch 7\tavg epoch Loss = 0.464\tavg epoch acc = 0.8429\n","Epoch 8\tavg epoch Loss = 0.4286\tavg epoch acc = 0.848\n","Epoch 9\tavg epoch Loss = 0.3982\tavg epoch acc = 0.8533\n","training took 59.57 s\n","Avg test loss = 0.62\tAvg test acc = 0.863\n","Epoch 0\tavg epoch Loss = 2.156\tavg epoch acc = 0.5563\n","Epoch 1\tavg epoch Loss = 1.516\tavg epoch acc = 0.6883\n","Epoch 2\tavg epoch Loss = 0.9448\tavg epoch acc = 0.7611\n","Epoch 3\tavg epoch Loss = 0.722\tavg epoch acc = 0.7995\n","Epoch 4\tavg epoch Loss = 0.6217\tavg epoch acc = 0.8196\n","Epoch 5\tavg epoch Loss = 0.5559\tavg epoch acc = 0.8315\n","Epoch 6\tavg epoch Loss = 0.5051\tavg epoch acc = 0.8403\n","Epoch 7\tavg epoch Loss = 0.4631\tavg epoch acc = 0.8474\n","Epoch 8\tavg epoch Loss = 0.4277\tavg epoch acc = 0.8533\n","Epoch 9\tavg epoch Loss = 0.3973\tavg epoch acc = 0.8585\n","training took 59.54 s\n","Avg test loss = 0.645\tAvg test acc = 0.855\n","Epoch 0\tavg epoch Loss = 2.153\tavg epoch acc = 0.5529\n","Epoch 1\tavg epoch Loss = 1.506\tavg epoch acc = 0.6905\n","Epoch 2\tavg epoch Loss = 0.9368\tavg epoch acc = 0.7628\n","Epoch 3\tavg epoch Loss = 0.7181\tavg epoch acc = 0.8002\n","Epoch 4\tavg epoch Loss = 0.6194\tavg epoch acc = 0.8197\n","Epoch 5\tavg epoch Loss = 0.5546\tavg epoch acc = 0.831\n","Epoch 6\tavg epoch Loss = 0.5043\tavg epoch acc = 0.8394\n","Epoch 7\tavg epoch Loss = 0.4628\tavg epoch acc = 0.846\n","Epoch 8\tavg epoch Loss = 0.4277\tavg epoch acc = 0.852\n","Epoch 9\tavg epoch Loss = 0.3975\tavg epoch acc = 0.8572\n","training took 59.79 s\n","Avg test loss = 0.648\tAvg test acc = 0.854\n","Epoch 0\tavg epoch Loss = 2.155\tavg epoch acc = 0.557\n","Epoch 1\tavg epoch Loss = 1.513\tavg epoch acc = 0.6889\n","Epoch 2\tavg epoch Loss = 0.9429\tavg epoch acc = 0.7602\n","Epoch 3\tavg epoch Loss = 0.7231\tavg epoch acc = 0.7978\n","Epoch 4\tavg epoch Loss = 0.6235\tavg epoch acc = 0.8159\n","Epoch 5\tavg epoch Loss = 0.5577\tavg epoch acc = 0.8271\n","Epoch 6\tavg epoch Loss = 0.5066\tavg epoch acc = 0.8356\n","Epoch 7\tavg epoch Loss = 0.4641\tavg epoch acc = 0.8424\n","Epoch 8\tavg epoch Loss = 0.4279\tavg epoch acc = 0.8492\n","Epoch 9\tavg epoch Loss = 0.3969\tavg epoch acc = 0.8546\n","training took 59.99 s\n","Avg test loss = 0.642\tAvg test acc = 0.855\n","Epoch 0\tavg epoch Loss = 2.154\tavg epoch acc = 0.5522\n","Epoch 1\tavg epoch Loss = 1.508\tavg epoch acc = 0.689\n","Epoch 2\tavg epoch Loss = 0.9368\tavg epoch acc = 0.7609\n","Epoch 3\tavg epoch Loss = 0.7182\tavg epoch acc = 0.799\n","Epoch 4\tavg epoch Loss = 0.6194\tavg epoch acc = 0.8181\n","Epoch 5\tavg epoch Loss = 0.5542\tavg epoch acc = 0.829\n","Epoch 6\tavg epoch Loss = 0.5035\tavg epoch acc = 0.8373\n","Epoch 7\tavg epoch Loss = 0.4618\tavg epoch acc = 0.8435\n","Epoch 8\tavg epoch Loss = 0.4264\tavg epoch acc = 0.8493\n","Epoch 9\tavg epoch Loss = 0.3961\tavg epoch acc = 0.854\n","training took 59.94 s\n","Avg test loss = 0.668\tAvg test acc = 0.858\n","{'lr': 1e-05, 'beta1': 0.1, 'beta2': 0.5, 'batch_size': 64, 'weight_decay': 0.050050000000000004, 'epsilon': 5.0500000000000006e-09}\n","Epoch 0\tavg epoch Loss = 2.155\tavg epoch acc = 0.551\n","Epoch 1\tavg epoch Loss = 1.513\tavg epoch acc = 0.6892\n","Epoch 2\tavg epoch Loss = 0.9415\tavg epoch acc = 0.7627\n","Epoch 3\tavg epoch Loss = 0.72\tavg epoch acc = 0.7997\n","Epoch 4\tavg epoch Loss = 0.62\tavg epoch acc = 0.8178\n","Epoch 5\tavg epoch Loss = 0.5545\tavg epoch acc = 0.8297\n","Epoch 6\tavg epoch Loss = 0.504\tavg epoch acc = 0.8376\n","Epoch 7\tavg epoch Loss = 0.4624\tavg epoch acc = 0.8439\n","Epoch 8\tavg epoch Loss = 0.4269\tavg epoch acc = 0.8486\n","Epoch 9\tavg epoch Loss = 0.3965\tavg epoch acc = 0.8535\n","training took 59.85 s\n","Avg test loss = 0.659\tAvg test acc = 0.856\n","Epoch 0\tavg epoch Loss = 2.156\tavg epoch acc = 0.56\n","Epoch 1\tavg epoch Loss = 1.517\tavg epoch acc = 0.6897\n","Epoch 2\tavg epoch Loss = 0.9455\tavg epoch acc = 0.7613\n","Epoch 3\tavg epoch Loss = 0.7228\tavg epoch acc = 0.7976\n","Epoch 4\tavg epoch Loss = 0.6222\tavg epoch acc = 0.8173\n","Epoch 5\tavg epoch Loss = 0.5556\tavg epoch acc = 0.8287\n","Epoch 6\tavg epoch Loss = 0.5043\tavg epoch acc = 0.8378\n","Epoch 7\tavg epoch Loss = 0.4618\tavg epoch acc = 0.8445\n","Epoch 8\tavg epoch Loss = 0.4256\tavg epoch acc = 0.8509\n","Epoch 9\tavg epoch Loss = 0.3947\tavg epoch acc = 0.8555\n","training took 60.15 s\n","Avg test loss = 0.635\tAvg test acc = 0.858\n","Epoch 0\tavg epoch Loss = 2.154\tavg epoch acc = 0.554\n","Epoch 1\tavg epoch Loss = 1.51\tavg epoch acc = 0.6872\n","Epoch 2\tavg epoch Loss = 0.9404\tavg epoch acc = 0.7619\n","Epoch 3\tavg epoch Loss = 0.7209\tavg epoch acc = 0.8007\n","Epoch 4\tavg epoch Loss = 0.6218\tavg epoch acc = 0.8194\n","Epoch 5\tavg epoch Loss = 0.5565\tavg epoch acc = 0.8309\n","Epoch 6\tavg epoch Loss = 0.5058\tavg epoch acc = 0.8393\n","Epoch 7\tavg epoch Loss = 0.4639\tavg epoch acc = 0.8459\n","Epoch 8\tavg epoch Loss = 0.4281\tavg epoch acc = 0.8515\n","Epoch 9\tavg epoch Loss = 0.3973\tavg epoch acc = 0.8566\n","training took 60.01 s\n","Avg test loss = 0.642\tAvg test acc = 0.857\n","Epoch 0\tavg epoch Loss = 2.157\tavg epoch acc = 0.5656\n","Epoch 1\tavg epoch Loss = 1.518\tavg epoch acc = 0.6912\n","Epoch 2\tavg epoch Loss = 0.9448\tavg epoch acc = 0.7618\n","Epoch 3\tavg epoch Loss = 0.7221\tavg epoch acc = 0.7995\n","Epoch 4\tavg epoch Loss = 0.6218\tavg epoch acc = 0.819\n","Epoch 5\tavg epoch Loss = 0.5556\tavg epoch acc = 0.8299\n","Epoch 6\tavg epoch Loss = 0.5044\tavg epoch acc = 0.8383\n","Epoch 7\tavg epoch Loss = 0.4623\tavg epoch acc = 0.8448\n","Epoch 8\tavg epoch Loss = 0.4267\tavg epoch acc = 0.8503\n","Epoch 9\tavg epoch Loss = 0.3962\tavg epoch acc = 0.8549\n","training took 59.87 s\n","Avg test loss = 0.67\tAvg test acc = 0.85\n","Epoch 0\tavg epoch Loss = 2.157\tavg epoch acc = 0.5559\n","Epoch 1\tavg epoch Loss = 1.518\tavg epoch acc = 0.6892\n","Epoch 2\tavg epoch Loss = 0.9471\tavg epoch acc = 0.7608\n","Epoch 3\tavg epoch Loss = 0.7251\tavg epoch acc = 0.7991\n","Epoch 4\tavg epoch Loss = 0.6248\tavg epoch acc = 0.8178\n","Epoch 5\tavg epoch Loss = 0.5591\tavg epoch acc = 0.8293\n","Epoch 6\tavg epoch Loss = 0.5085\tavg epoch acc = 0.837\n","Epoch 7\tavg epoch Loss = 0.4665\tavg epoch acc = 0.8441\n","Epoch 8\tavg epoch Loss = 0.431\tavg epoch acc = 0.8501\n","Epoch 9\tavg epoch Loss = 0.4005\tavg epoch acc = 0.855\n","training took 59.99 s\n","Avg test loss = 0.605\tAvg test acc = 0.867\n","{'lr': 1e-05, 'beta1': 0.1, 'beta2': 0.5, 'batch_size': 64, 'weight_decay': 0.050050000000000004, 'epsilon': 1e-08}\n","Epoch 0\tavg epoch Loss = 2.156\tavg epoch acc = 0.5607\n","Epoch 1\tavg epoch Loss = 1.518\tavg epoch acc = 0.6889\n","Epoch 2\tavg epoch Loss = 0.9466\tavg epoch acc = 0.7613\n","Epoch 3\tavg epoch Loss = 0.7249\tavg epoch acc = 0.7991\n","Epoch 4\tavg epoch Loss = 0.6248\tavg epoch acc = 0.8179\n","Epoch 5\tavg epoch Loss = 0.559\tavg epoch acc = 0.829\n","Epoch 6\tavg epoch Loss = 0.508\tavg epoch acc = 0.8375\n","Epoch 7\tavg epoch Loss = 0.466\tavg epoch acc = 0.8436\n","Epoch 8\tavg epoch Loss = 0.4304\tavg epoch acc = 0.849\n","Epoch 9\tavg epoch Loss = 0.3999\tavg epoch acc = 0.8534\n","training took 60.14 s\n","Avg test loss = 0.649\tAvg test acc = 0.853\n","Epoch 0\tavg epoch Loss = 2.157\tavg epoch acc = 0.5483\n","Epoch 1\tavg epoch Loss = 1.521\tavg epoch acc = 0.6878\n","Epoch 2\tavg epoch Loss = 0.9456\tavg epoch acc = 0.7603\n","Epoch 3\tavg epoch Loss = 0.7216\tavg epoch acc = 0.799\n","Epoch 4\tavg epoch Loss = 0.6215\tavg epoch acc = 0.8192\n","Epoch 5\tavg epoch Loss = 0.5557\tavg epoch acc = 0.8307\n","Epoch 6\tavg epoch Loss = 0.505\tavg epoch acc = 0.8391\n","Epoch 7\tavg epoch Loss = 0.463\tavg epoch acc = 0.8455\n","Epoch 8\tavg epoch Loss = 0.4271\tavg epoch acc = 0.8514\n","Epoch 9\tavg epoch Loss = 0.3962\tavg epoch acc = 0.8565\n","training took 59.85 s\n","Avg test loss = 0.634\tAvg test acc = 0.862\n","Epoch 0\tavg epoch Loss = 2.154\tavg epoch acc = 0.5586\n","Epoch 1\tavg epoch Loss = 1.506\tavg epoch acc = 0.6918\n","Epoch 2\tavg epoch Loss = 0.9369\tavg epoch acc = 0.762\n","Epoch 3\tavg epoch Loss = 0.7195\tavg epoch acc = 0.7993\n","Epoch 4\tavg epoch Loss = 0.6209\tavg epoch acc = 0.8181\n","Epoch 5\tavg epoch Loss = 0.5557\tavg epoch acc = 0.8288\n","Epoch 6\tavg epoch Loss = 0.5053\tavg epoch acc = 0.8375\n","Epoch 7\tavg epoch Loss = 0.4636\tavg epoch acc = 0.8444\n","Epoch 8\tavg epoch Loss = 0.4279\tavg epoch acc = 0.8506\n","Epoch 9\tavg epoch Loss = 0.3973\tavg epoch acc = 0.8558\n","training took 59.86 s\n","Avg test loss = 0.631\tAvg test acc = 0.859\n","Epoch 0\tavg epoch Loss = 2.155\tavg epoch acc = 0.5645\n","Epoch 1\tavg epoch Loss = 1.511\tavg epoch acc = 0.6862\n","Epoch 2\tavg epoch Loss = 0.9414\tavg epoch acc = 0.762\n","Epoch 3\tavg epoch Loss = 0.7213\tavg epoch acc = 0.7985\n","Epoch 4\tavg epoch Loss = 0.6211\tavg epoch acc = 0.8181\n","Epoch 5\tavg epoch Loss = 0.5552\tavg epoch acc = 0.8291\n","Epoch 6\tavg epoch Loss = 0.5042\tavg epoch acc = 0.8374\n","Epoch 7\tavg epoch Loss = 0.4618\tavg epoch acc = 0.8438\n","Epoch 8\tavg epoch Loss = 0.4258\tavg epoch acc = 0.8496\n","Epoch 9\tavg epoch Loss = 0.395\tavg epoch acc = 0.8546\n","training took 60.03 s\n","Avg test loss = 0.64\tAvg test acc = 0.855\n","Epoch 0\tavg epoch Loss = 2.157\tavg epoch acc = 0.5531\n","Epoch 1\tavg epoch Loss = 1.522\tavg epoch acc = 0.688\n","Epoch 2\tavg epoch Loss = 0.9486\tavg epoch acc = 0.7609\n","Epoch 3\tavg epoch Loss = 0.7238\tavg epoch acc = 0.7992\n","Epoch 4\tavg epoch Loss = 0.6225\tavg epoch acc = 0.8185\n","Epoch 5\tavg epoch Loss = 0.5558\tavg epoch acc = 0.8302\n","Epoch 6\tavg epoch Loss = 0.5048\tavg epoch acc = 0.8388\n","Epoch 7\tavg epoch Loss = 0.4627\tavg epoch acc = 0.8461\n","Epoch 8\tavg epoch Loss = 0.427\tavg epoch acc = 0.8519\n","Epoch 9\tavg epoch Loss = 0.3964\tavg epoch acc = 0.8569\n","training took 59.94 s\n","Avg test loss = 0.652\tAvg test acc = 0.859\n","{'lr': 1e-05, 'beta1': 0.1, 'beta2': 0.5, 'batch_size': 64, 'weight_decay': 0.1, 'epsilon': 1e-10}\n","Epoch 0\tavg epoch Loss = 2.157\tavg epoch acc = 0.5605\n","Epoch 1\tavg epoch Loss = 1.52\tavg epoch acc = 0.6905\n","Epoch 2\tavg epoch Loss = 0.9483\tavg epoch acc = 0.7597\n","Epoch 3\tavg epoch Loss = 0.726\tavg epoch acc = 0.7974\n","Epoch 4\tavg epoch Loss = 0.6262\tavg epoch acc = 0.8167\n","Epoch 5\tavg epoch Loss = 0.5605\tavg epoch acc = 0.8284\n","Epoch 6\tavg epoch Loss = 0.5095\tavg epoch acc = 0.8368\n","Epoch 7\tavg epoch Loss = 0.4672\tavg epoch acc = 0.8437\n","Epoch 8\tavg epoch Loss = 0.4315\tavg epoch acc = 0.8492\n","Epoch 9\tavg epoch Loss = 0.4008\tavg epoch acc = 0.8541\n","training took 59.79 s\n","Avg test loss = 0.609\tAvg test acc = 0.86\n","Epoch 0\tavg epoch Loss = 2.155\tavg epoch acc = 0.5556\n","Epoch 1\tavg epoch Loss = 1.511\tavg epoch acc = 0.6893\n","Epoch 2\tavg epoch Loss = 0.9393\tavg epoch acc = 0.7611\n","Epoch 3\tavg epoch Loss = 0.7182\tavg epoch acc = 0.8002\n","Epoch 4\tavg epoch Loss = 0.6185\tavg epoch acc = 0.8196\n","Epoch 5\tavg epoch Loss = 0.5531\tavg epoch acc = 0.8314\n","Epoch 6\tavg epoch Loss = 0.5026\tavg epoch acc = 0.8404\n","Epoch 7\tavg epoch Loss = 0.4608\tavg epoch acc = 0.8469\n","Epoch 8\tavg epoch Loss = 0.4254\tavg epoch acc = 0.8529\n","Epoch 9\tavg epoch Loss = 0.3952\tavg epoch acc = 0.858\n","training took 59.62 s\n","Avg test loss = 0.675\tAvg test acc = 0.852\n","Epoch 0\tavg epoch Loss = 2.156\tavg epoch acc = 0.5593\n","Epoch 1\tavg epoch Loss = 1.513\tavg epoch acc = 0.6864\n","Epoch 2\tavg epoch Loss = 0.9414\tavg epoch acc = 0.7601\n","Epoch 3\tavg epoch Loss = 0.7199\tavg epoch acc = 0.7961\n","Epoch 4\tavg epoch Loss = 0.6198\tavg epoch acc = 0.8148\n","Epoch 5\tavg epoch Loss = 0.554\tavg epoch acc = 0.8268\n","Epoch 6\tavg epoch Loss = 0.5031\tavg epoch acc = 0.8353\n","Epoch 7\tavg epoch Loss = 0.461\tavg epoch acc = 0.8422\n","Epoch 8\tavg epoch Loss = 0.4254\tavg epoch acc = 0.8481\n","Epoch 9\tavg epoch Loss = 0.3948\tavg epoch acc = 0.8535\n","training took 59.59 s\n","Avg test loss = 0.648\tAvg test acc = 0.859\n","Epoch 0\tavg epoch Loss = 2.157\tavg epoch acc = 0.5594\n","Epoch 1\tavg epoch Loss = 1.52\tavg epoch acc = 0.6882\n","Epoch 2\tavg epoch Loss = 0.9475\tavg epoch acc = 0.7613\n","Epoch 3\tavg epoch Loss = 0.7249\tavg epoch acc = 0.7988\n","Epoch 4\tavg epoch Loss = 0.6247\tavg epoch acc = 0.8182\n","Epoch 5\tavg epoch Loss = 0.5586\tavg epoch acc = 0.8291\n","Epoch 6\tavg epoch Loss = 0.5077\tavg epoch acc = 0.8374\n","Epoch 7\tavg epoch Loss = 0.4659\tavg epoch acc = 0.8438\n","Epoch 8\tavg epoch Loss = 0.4304\tavg epoch acc = 0.8497\n","Epoch 9\tavg epoch Loss = 0.4\tavg epoch acc = 0.8545\n","training took 59.55 s\n","Avg test loss = 0.633\tAvg test acc = 0.857\n","Epoch 0\tavg epoch Loss = 2.156\tavg epoch acc = 0.5536\n","Epoch 1\tavg epoch Loss = 1.516\tavg epoch acc = 0.6907\n","Epoch 2\tavg epoch Loss = 0.9456\tavg epoch acc = 0.7629\n","Epoch 3\tavg epoch Loss = 0.7235\tavg epoch acc = 0.8\n","Epoch 4\tavg epoch Loss = 0.6228\tavg epoch acc = 0.8182\n","Epoch 5\tavg epoch Loss = 0.5564\tavg epoch acc = 0.8304\n","Epoch 6\tavg epoch Loss = 0.505\tavg epoch acc = 0.8382\n","Epoch 7\tavg epoch Loss = 0.4626\tavg epoch acc = 0.8452\n","Epoch 8\tavg epoch Loss = 0.4269\tavg epoch acc = 0.8507\n","Epoch 9\tavg epoch Loss = 0.3964\tavg epoch acc = 0.8558\n","training took 59.51 s\n","Avg test loss = 0.647\tAvg test acc = 0.858\n","{'lr': 1e-05, 'beta1': 0.1, 'beta2': 0.5, 'batch_size': 64, 'weight_decay': 0.1, 'epsilon': 5.0500000000000006e-09}\n","Epoch 0\tavg epoch Loss = 2.157\tavg epoch acc = 0.5671\n","Epoch 1\tavg epoch Loss = 1.517\tavg epoch acc = 0.6901\n","Epoch 2\tavg epoch Loss = 0.9453\tavg epoch acc = 0.76\n","Epoch 3\tavg epoch Loss = 0.723\tavg epoch acc = 0.797\n","Epoch 4\tavg epoch Loss = 0.6226\tavg epoch acc = 0.8157\n","Epoch 5\tavg epoch Loss = 0.5564\tavg epoch acc = 0.8279\n","Epoch 6\tavg epoch Loss = 0.5051\tavg epoch acc = 0.8364\n","Epoch 7\tavg epoch Loss = 0.4629\tavg epoch acc = 0.8432\n","Epoch 8\tavg epoch Loss = 0.4272\tavg epoch acc = 0.8492\n","Epoch 9\tavg epoch Loss = 0.3966\tavg epoch acc = 0.8547\n","training took 59.6 s\n","Avg test loss = 0.656\tAvg test acc = 0.857\n","Epoch 0\tavg epoch Loss = 2.155\tavg epoch acc = 0.5659\n","Epoch 1\tavg epoch Loss = 1.514\tavg epoch acc = 0.6889\n","Epoch 2\tavg epoch Loss = 0.9423\tavg epoch acc = 0.7612\n","Epoch 3\tavg epoch Loss = 0.7219\tavg epoch acc = 0.7987\n","Epoch 4\tavg epoch Loss = 0.6228\tavg epoch acc = 0.8176\n","Epoch 5\tavg epoch Loss = 0.5572\tavg epoch acc = 0.8289\n","Epoch 6\tavg epoch Loss = 0.5064\tavg epoch acc = 0.8372\n","Epoch 7\tavg epoch Loss = 0.4645\tavg epoch acc = 0.8433\n","Epoch 8\tavg epoch Loss = 0.4286\tavg epoch acc = 0.8485\n","Epoch 9\tavg epoch Loss = 0.3979\tavg epoch acc = 0.8535\n","training took 59.49 s\n","Avg test loss = 0.659\tAvg test acc = 0.858\n","Epoch 0\tavg epoch Loss = 2.156\tavg epoch acc = 0.5421\n","Epoch 1\tavg epoch Loss = 1.515\tavg epoch acc = 0.6903\n","Epoch 2\tavg epoch Loss = 0.9419\tavg epoch acc = 0.7622\n","Epoch 3\tavg epoch Loss = 0.7196\tavg epoch acc = 0.7988\n","Epoch 4\tavg epoch Loss = 0.6192\tavg epoch acc = 0.8181\n","Epoch 5\tavg epoch Loss = 0.5532\tavg epoch acc = 0.8285\n","Epoch 6\tavg epoch Loss = 0.5026\tavg epoch acc = 0.8372\n","Epoch 7\tavg epoch Loss = 0.4608\tavg epoch acc = 0.8439\n","Epoch 8\tavg epoch Loss = 0.4255\tavg epoch acc = 0.8493\n","Epoch 9\tavg epoch Loss = 0.395\tavg epoch acc = 0.8542\n","training took 59.39 s\n","Avg test loss = 0.654\tAvg test acc = 0.856\n","Epoch 0\tavg epoch Loss = 2.155\tavg epoch acc = 0.5549\n","Epoch 1\tavg epoch Loss = 1.511\tavg epoch acc = 0.6881\n","Epoch 2\tavg epoch Loss = 0.9401\tavg epoch acc = 0.7624\n","Epoch 3\tavg epoch Loss = 0.7202\tavg epoch acc = 0.8001\n","Epoch 4\tavg epoch Loss = 0.621\tavg epoch acc = 0.8191\n","Epoch 5\tavg epoch Loss = 0.5558\tavg epoch acc = 0.8307\n","Epoch 6\tavg epoch Loss = 0.5052\tavg epoch acc = 0.8394\n","Epoch 7\tavg epoch Loss = 0.4634\tavg epoch acc = 0.8459\n","Epoch 8\tavg epoch Loss = 0.4281\tavg epoch acc = 0.8517\n","Epoch 9\tavg epoch Loss = 0.3977\tavg epoch acc = 0.8567\n","training took 59.52 s\n","Avg test loss = 0.633\tAvg test acc = 0.859\n","Epoch 0\tavg epoch Loss = 2.154\tavg epoch acc = 0.5606\n","Epoch 1\tavg epoch Loss = 1.511\tavg epoch acc = 0.6897\n","Epoch 2\tavg epoch Loss = 0.9419\tavg epoch acc = 0.7628\n","Epoch 3\tavg epoch Loss = 0.722\tavg epoch acc = 0.8004\n","Epoch 4\tavg epoch Loss = 0.6223\tavg epoch acc = 0.8199\n","Epoch 5\tavg epoch Loss = 0.5569\tavg epoch acc = 0.8308\n","Epoch 6\tavg epoch Loss = 0.5064\tavg epoch acc = 0.8392\n","Epoch 7\tavg epoch Loss = 0.4648\tavg epoch acc = 0.8458\n","Epoch 8\tavg epoch Loss = 0.4295\tavg epoch acc = 0.8512\n","Epoch 9\tavg epoch Loss = 0.3992\tavg epoch acc = 0.8565\n","training took 59.49 s\n","Avg test loss = 0.616\tAvg test acc = 0.856\n","{'lr': 1e-05, 'beta1': 0.1, 'beta2': 0.5, 'batch_size': 64, 'weight_decay': 0.1, 'epsilon': 1e-08}\n","Epoch 0\tavg epoch Loss = 2.157\tavg epoch acc = 0.5578\n","Epoch 1\tavg epoch Loss = 1.519\tavg epoch acc = 0.6905\n","Epoch 2\tavg epoch Loss = 0.9464\tavg epoch acc = 0.7607\n","Epoch 3\tavg epoch Loss = 0.7244\tavg epoch acc = 0.799\n","Epoch 4\tavg epoch Loss = 0.6245\tavg epoch acc = 0.8185\n","Epoch 5\tavg epoch Loss = 0.5587\tavg epoch acc = 0.8296\n","Epoch 6\tavg epoch Loss = 0.5076\tavg epoch acc = 0.8381\n","Epoch 7\tavg epoch Loss = 0.4654\tavg epoch acc = 0.8451\n","Epoch 8\tavg epoch Loss = 0.4294\tavg epoch acc = 0.8515\n","Epoch 9\tavg epoch Loss = 0.3987\tavg epoch acc = 0.8567\n","training took 59.5 s\n","Avg test loss = 0.633\tAvg test acc = 0.861\n","Epoch 0\tavg epoch Loss = 2.153\tavg epoch acc = 0.5597\n","Epoch 1\tavg epoch Loss = 1.503\tavg epoch acc = 0.69\n","Epoch 2\tavg epoch Loss = 0.9346\tavg epoch acc = 0.7629\n","Epoch 3\tavg epoch Loss = 0.7172\tavg epoch acc = 0.8\n","Epoch 4\tavg epoch Loss = 0.6183\tavg epoch acc = 0.819\n","Epoch 5\tavg epoch Loss = 0.5529\tavg epoch acc = 0.8307\n","Epoch 6\tavg epoch Loss = 0.502\tavg epoch acc = 0.8385\n","Epoch 7\tavg epoch Loss = 0.4599\tavg epoch acc = 0.8447\n","Epoch 8\tavg epoch Loss = 0.4245\tavg epoch acc = 0.8508\n","Epoch 9\tavg epoch Loss = 0.3943\tavg epoch acc = 0.8557\n","training took 59.6 s\n","Avg test loss = 0.627\tAvg test acc = 0.854\n","Epoch 0\tavg epoch Loss = 2.155\tavg epoch acc = 0.5591\n","Epoch 1\tavg epoch Loss = 1.512\tavg epoch acc = 0.6858\n","Epoch 2\tavg epoch Loss = 0.9422\tavg epoch acc = 0.7602\n","Epoch 3\tavg epoch Loss = 0.7202\tavg epoch acc = 0.7975\n","Epoch 4\tavg epoch Loss = 0.62\tavg epoch acc = 0.8162\n","Epoch 5\tavg epoch Loss = 0.5546\tavg epoch acc = 0.8271\n","Epoch 6\tavg epoch Loss = 0.5042\tavg epoch acc = 0.836\n","Epoch 7\tavg epoch Loss = 0.4628\tavg epoch acc = 0.8424\n","Epoch 8\tavg epoch Loss = 0.4276\tavg epoch acc = 0.8469\n","Epoch 9\tavg epoch Loss = 0.3974\tavg epoch acc = 0.8523\n","training took 59.38 s\n","Avg test loss = 0.656\tAvg test acc = 0.86\n","Epoch 0\tavg epoch Loss = 2.155\tavg epoch acc = 0.5636\n","Epoch 1\tavg epoch Loss = 1.511\tavg epoch acc = 0.6883\n","Epoch 2\tavg epoch Loss = 0.9404\tavg epoch acc = 0.7613\n","Epoch 3\tavg epoch Loss = 0.7198\tavg epoch acc = 0.7982\n","Epoch 4\tavg epoch Loss = 0.6201\tavg epoch acc = 0.8176\n","Epoch 5\tavg epoch Loss = 0.5545\tavg epoch acc = 0.8296\n","Epoch 6\tavg epoch Loss = 0.5037\tavg epoch acc = 0.8386\n","Epoch 7\tavg epoch Loss = 0.4615\tavg epoch acc = 0.8454\n","Epoch 8\tavg epoch Loss = 0.426\tavg epoch acc = 0.8514\n","Epoch 9\tavg epoch Loss = 0.3956\tavg epoch acc = 0.8569\n","training took 59.54 s\n","Avg test loss = 0.66\tAvg test acc = 0.854\n","Epoch 0\tavg epoch Loss = 2.155\tavg epoch acc = 0.5519\n","Epoch 1\tavg epoch Loss = 1.511\tavg epoch acc = 0.6938\n","Epoch 2\tavg epoch Loss = 0.9404\tavg epoch acc = 0.7626\n","Epoch 3\tavg epoch Loss = 0.7204\tavg epoch acc = 0.7997\n","Epoch 4\tavg epoch Loss = 0.6208\tavg epoch acc = 0.8182\n","Epoch 5\tavg epoch Loss = 0.5553\tavg epoch acc = 0.8296\n","Epoch 6\tavg epoch Loss = 0.5045\tavg epoch acc = 0.8383\n","Epoch 7\tavg epoch Loss = 0.4626\tavg epoch acc = 0.845\n","Epoch 8\tavg epoch Loss = 0.4269\tavg epoch acc = 0.8507\n","Epoch 9\tavg epoch Loss = 0.3965\tavg epoch acc = 0.8552\n","training took 59.49 s\n","Avg test loss = 0.635\tAvg test acc = 0.858\n","{'lr': 1e-05, 'beta1': 0.1, 'beta2': 0.5, 'batch_size': 128, 'weight_decay': 0.0001, 'epsilon': 1e-10}\n","Epoch 0\tavg epoch Loss = 2.241\tavg epoch acc = 0.4931\n","Epoch 1\tavg epoch Loss = 1.971\tavg epoch acc = 0.6701\n","Epoch 2\tavg epoch Loss = 1.538\tavg epoch acc = 0.6893\n","Epoch 3\tavg epoch Loss = 1.133\tavg epoch acc = 0.7376\n","Epoch 4\tavg epoch Loss = 0.8835\tavg epoch acc = 0.7728\n","Epoch 5\tavg epoch Loss = 0.7499\tavg epoch acc = 0.7944\n","Epoch 6\tavg epoch Loss = 0.6702\tavg epoch acc = 0.8084\n","Epoch 7\tavg epoch Loss = 0.6144\tavg epoch acc = 0.8194\n","Epoch 8\tavg epoch Loss = 0.5707\tavg epoch acc = 0.8271\n","Epoch 9\tavg epoch Loss = 0.534\tavg epoch acc = 0.8335\n","training took 50.26 s\n","Avg test loss = 0.663\tAvg test acc = 0.839\n","Epoch 0\tavg epoch Loss = 2.241\tavg epoch acc = 0.4962\n","Epoch 1\tavg epoch Loss = 1.971\tavg epoch acc = 0.674\n","Epoch 2\tavg epoch Loss = 1.537\tavg epoch acc = 0.6901\n","Epoch 3\tavg epoch Loss = 1.132\tavg epoch acc = 0.7376\n","Epoch 4\tavg epoch Loss = 0.8832\tavg epoch acc = 0.7736\n","Epoch 5\tavg epoch Loss = 0.7501\tavg epoch acc = 0.7963\n","Epoch 6\tavg epoch Loss = 0.6704\tavg epoch acc = 0.81\n","Epoch 7\tavg epoch Loss = 0.6148\tavg epoch acc = 0.8207\n","Epoch 8\tavg epoch Loss = 0.5715\tavg epoch acc = 0.8284\n","Epoch 9\tavg epoch Loss = 0.535\tavg epoch acc = 0.8342\n","training took 50.11 s\n","Avg test loss = 0.671\tAvg test acc = 0.835\n","Epoch 0\tavg epoch Loss = 2.24\tavg epoch acc = 0.4984\n","Epoch 1\tavg epoch Loss = 1.967\tavg epoch acc = 0.667\n","Epoch 2\tavg epoch Loss = 1.529\tavg epoch acc = 0.6891\n","Epoch 3\tavg epoch Loss = 1.125\tavg epoch acc = 0.7391\n","Epoch 4\tavg epoch Loss = 0.8769\tavg epoch acc = 0.7751\n","Epoch 5\tavg epoch Loss = 0.7447\tavg epoch acc = 0.7965\n","Epoch 6\tavg epoch Loss = 0.6657\tavg epoch acc = 0.8103\n","Epoch 7\tavg epoch Loss = 0.6105\tavg epoch acc = 0.8221\n","Epoch 8\tavg epoch Loss = 0.5676\tavg epoch acc = 0.8294\n","Epoch 9\tavg epoch Loss = 0.5315\tavg epoch acc = 0.8359\n","training took 50.2 s\n","Avg test loss = 0.64\tAvg test acc = 0.84\n","Epoch 0\tavg epoch Loss = 2.24\tavg epoch acc = 0.4979\n","Epoch 1\tavg epoch Loss = 1.968\tavg epoch acc = 0.6667\n","Epoch 2\tavg epoch Loss = 1.531\tavg epoch acc = 0.6888\n","Epoch 3\tavg epoch Loss = 1.125\tavg epoch acc = 0.7379\n","Epoch 4\tavg epoch Loss = 0.8753\tavg epoch acc = 0.775\n","Epoch 5\tavg epoch Loss = 0.7422\tavg epoch acc = 0.7975\n","Epoch 6\tavg epoch Loss = 0.6628\tavg epoch acc = 0.8122\n","Epoch 7\tavg epoch Loss = 0.6073\tavg epoch acc = 0.8229\n","Epoch 8\tavg epoch Loss = 0.5641\tavg epoch acc = 0.8299\n","Epoch 9\tavg epoch Loss = 0.5276\tavg epoch acc = 0.8359\n","training took 50.1 s\n","Avg test loss = 0.687\tAvg test acc = 0.833\n","Epoch 0\tavg epoch Loss = 2.241\tavg epoch acc = 0.4999\n","Epoch 1\tavg epoch Loss = 1.974\tavg epoch acc = 0.6761\n","Epoch 2\tavg epoch Loss = 1.543\tavg epoch acc = 0.6921\n","Epoch 3\tavg epoch Loss = 1.138\tavg epoch acc = 0.7386\n","Epoch 4\tavg epoch Loss = 0.8859\tavg epoch acc = 0.7733\n","Epoch 5\tavg epoch Loss = 0.7507\tavg epoch acc = 0.796\n","Epoch 6\tavg epoch Loss = 0.6701\tavg epoch acc = 0.81\n","Epoch 7\tavg epoch Loss = 0.6137\tavg epoch acc = 0.8216\n","Epoch 8\tavg epoch Loss = 0.5697\tavg epoch acc = 0.8299\n","Epoch 9\tavg epoch Loss = 0.5328\tavg epoch acc = 0.8365\n","training took 50.21 s\n","Avg test loss = 0.639\tAvg test acc = 0.843\n","{'lr': 1e-05, 'beta1': 0.1, 'beta2': 0.5, 'batch_size': 128, 'weight_decay': 0.0001, 'epsilon': 5.0500000000000006e-09}\n","Epoch 0\tavg epoch Loss = 2.241\tavg epoch acc = 0.491\n","Epoch 1\tavg epoch Loss = 1.972\tavg epoch acc = 0.6707\n","Epoch 2\tavg epoch Loss = 1.538\tavg epoch acc = 0.6905\n","Epoch 3\tavg epoch Loss = 1.132\tavg epoch acc = 0.7389\n","Epoch 4\tavg epoch Loss = 0.8809\tavg epoch acc = 0.7748\n","Epoch 5\tavg epoch Loss = 0.7464\tavg epoch acc = 0.7969\n","Epoch 6\tavg epoch Loss = 0.6662\tavg epoch acc = 0.8113\n","Epoch 7\tavg epoch Loss = 0.6103\tavg epoch acc = 0.8221\n","Epoch 8\tavg epoch Loss = 0.5669\tavg epoch acc = 0.8295\n","Epoch 9\tavg epoch Loss = 0.5303\tavg epoch acc = 0.8355\n","training took 50.14 s\n","Avg test loss = 0.659\tAvg test acc = 0.838\n","Epoch 0\tavg epoch Loss = 2.24\tavg epoch acc = 0.4987\n","Epoch 1\tavg epoch Loss = 1.97\tavg epoch acc = 0.6708\n","Epoch 2\tavg epoch Loss = 1.536\tavg epoch acc = 0.6894\n","Epoch 3\tavg epoch Loss = 1.13\tavg epoch acc = 0.7386\n","Epoch 4\tavg epoch Loss = 0.8815\tavg epoch acc = 0.7737\n","Epoch 5\tavg epoch Loss = 0.7484\tavg epoch acc = 0.7953\n","Epoch 6\tavg epoch Loss = 0.6687\tavg epoch acc = 0.8099\n","Epoch 7\tavg epoch Loss = 0.6128\tavg epoch acc = 0.8208\n","Epoch 8\tavg epoch Loss = 0.5693\tavg epoch acc = 0.8288\n","Epoch 9\tavg epoch Loss = 0.5325\tavg epoch acc = 0.8351\n","training took 50.46 s\n","Avg test loss = 0.645\tAvg test acc = 0.844\n","Epoch 0\tavg epoch Loss = 2.24\tavg epoch acc = 0.5115\n","Epoch 1\tavg epoch Loss = 1.968\tavg epoch acc = 0.6761\n","Epoch 2\tavg epoch Loss = 1.531\tavg epoch acc = 0.6905\n","Epoch 3\tavg epoch Loss = 1.125\tavg epoch acc = 0.7391\n","Epoch 4\tavg epoch Loss = 0.8766\tavg epoch acc = 0.7748\n","Epoch 5\tavg epoch Loss = 0.7439\tavg epoch acc = 0.7964\n","Epoch 6\tavg epoch Loss = 0.6646\tavg epoch acc = 0.8101\n","Epoch 7\tavg epoch Loss = 0.6091\tavg epoch acc = 0.821\n","Epoch 8\tavg epoch Loss = 0.5658\tavg epoch acc = 0.8286\n","Epoch 9\tavg epoch Loss = 0.5292\tavg epoch acc = 0.8349\n","training took 50.29 s\n","Avg test loss = 0.673\tAvg test acc = 0.836\n","Epoch 0\tavg epoch Loss = 2.241\tavg epoch acc = 0.4992\n","Epoch 1\tavg epoch Loss = 1.971\tavg epoch acc = 0.6732\n","Epoch 2\tavg epoch Loss = 1.538\tavg epoch acc = 0.6897\n","Epoch 3\tavg epoch Loss = 1.133\tavg epoch acc = 0.7374\n","Epoch 4\tavg epoch Loss = 0.8829\tavg epoch acc = 0.773\n","Epoch 5\tavg epoch Loss = 0.7483\tavg epoch acc = 0.7948\n","Epoch 6\tavg epoch Loss = 0.6679\tavg epoch acc = 0.8096\n","Epoch 7\tavg epoch Loss = 0.6118\tavg epoch acc = 0.8208\n","Epoch 8\tavg epoch Loss = 0.5683\tavg epoch acc = 0.8287\n","Epoch 9\tavg epoch Loss = 0.5315\tavg epoch acc = 0.8349\n","training took 50.44 s\n","Avg test loss = 0.659\tAvg test acc = 0.836\n","Epoch 0\tavg epoch Loss = 2.241\tavg epoch acc = 0.485\n","Epoch 1\tavg epoch Loss = 1.972\tavg epoch acc = 0.665\n","Epoch 2\tavg epoch Loss = 1.54\tavg epoch acc = 0.6881\n","Epoch 3\tavg epoch Loss = 1.135\tavg epoch acc = 0.7368\n","Epoch 4\tavg epoch Loss = 0.8846\tavg epoch acc = 0.7725\n","Epoch 5\tavg epoch Loss = 0.7502\tavg epoch acc = 0.7952\n","Epoch 6\tavg epoch Loss = 0.6702\tavg epoch acc = 0.8099\n","Epoch 7\tavg epoch Loss = 0.6143\tavg epoch acc = 0.821\n","Epoch 8\tavg epoch Loss = 0.5708\tavg epoch acc = 0.8286\n","Epoch 9\tavg epoch Loss = 0.5341\tavg epoch acc = 0.8354\n","training took 50.3 s\n","Avg test loss = 0.664\tAvg test acc = 0.839\n","{'lr': 1e-05, 'beta1': 0.1, 'beta2': 0.5, 'batch_size': 128, 'weight_decay': 0.0001, 'epsilon': 1e-08}\n","Epoch 0\tavg epoch Loss = 2.24\tavg epoch acc = 0.4882\n","Epoch 1\tavg epoch Loss = 1.969\tavg epoch acc = 0.6735\n","Epoch 2\tavg epoch Loss = 1.531\tavg epoch acc = 0.6927\n","Epoch 3\tavg epoch Loss = 1.124\tavg epoch acc = 0.7395\n","Epoch 4\tavg epoch Loss = 0.8749\tavg epoch acc = 0.7741\n","Epoch 5\tavg epoch Loss = 0.7425\tavg epoch acc = 0.7962\n","Epoch 6\tavg epoch Loss = 0.6634\tavg epoch acc = 0.8108\n","Epoch 7\tavg epoch Loss = 0.6077\tavg epoch acc = 0.8214\n","Epoch 8\tavg epoch Loss = 0.5643\tavg epoch acc = 0.829\n","Epoch 9\tavg epoch Loss = 0.5277\tavg epoch acc = 0.8355\n","training took 50.38 s\n","Avg test loss = 0.667\tAvg test acc = 0.836\n","Epoch 0\tavg epoch Loss = 2.24\tavg epoch acc = 0.5106\n","Epoch 1\tavg epoch Loss = 1.97\tavg epoch acc = 0.6702\n","Epoch 2\tavg epoch Loss = 1.537\tavg epoch acc = 0.688\n","Epoch 3\tavg epoch Loss = 1.133\tavg epoch acc = 0.7374\n","Epoch 4\tavg epoch Loss = 0.8818\tavg epoch acc = 0.773\n","Epoch 5\tavg epoch Loss = 0.7471\tavg epoch acc = 0.7954\n","Epoch 6\tavg epoch Loss = 0.6669\tavg epoch acc = 0.81\n","Epoch 7\tavg epoch Loss = 0.611\tavg epoch acc = 0.8221\n","Epoch 8\tavg epoch Loss = 0.5677\tavg epoch acc = 0.8301\n","Epoch 9\tavg epoch Loss = 0.5312\tavg epoch acc = 0.8368\n","training took 50.34 s\n","Avg test loss = 0.685\tAvg test acc = 0.836\n","Epoch 0\tavg epoch Loss = 2.24\tavg epoch acc = 0.4888\n","Epoch 1\tavg epoch Loss = 1.97\tavg epoch acc = 0.6675\n","Epoch 2\tavg epoch Loss = 1.533\tavg epoch acc = 0.6887\n","Epoch 3\tavg epoch Loss = 1.127\tavg epoch acc = 0.7379\n","Epoch 4\tavg epoch Loss = 0.8793\tavg epoch acc = 0.7743\n","Epoch 5\tavg epoch Loss = 0.7469\tavg epoch acc = 0.7961\n","Epoch 6\tavg epoch Loss = 0.668\tavg epoch acc = 0.8111\n","Epoch 7\tavg epoch Loss = 0.6128\tavg epoch acc = 0.8215\n","Epoch 8\tavg epoch Loss = 0.5697\tavg epoch acc = 0.8291\n","Epoch 9\tavg epoch Loss = 0.5333\tavg epoch acc = 0.8354\n","training took 50.45 s\n","Avg test loss = 0.653\tAvg test acc = 0.839\n","Epoch 0\tavg epoch Loss = 2.24\tavg epoch acc = 0.5004\n","Epoch 1\tavg epoch Loss = 1.968\tavg epoch acc = 0.6693\n","Epoch 2\tavg epoch Loss = 1.53\tavg epoch acc = 0.6898\n","Epoch 3\tavg epoch Loss = 1.125\tavg epoch acc = 0.7395\n","Epoch 4\tavg epoch Loss = 0.8766\tavg epoch acc = 0.7759\n","Epoch 5\tavg epoch Loss = 0.7439\tavg epoch acc = 0.7967\n","Epoch 6\tavg epoch Loss = 0.6643\tavg epoch acc = 0.8114\n","Epoch 7\tavg epoch Loss = 0.6087\tavg epoch acc = 0.8221\n","Epoch 8\tavg epoch Loss = 0.5654\tavg epoch acc = 0.8299\n","Epoch 9\tavg epoch Loss = 0.5289\tavg epoch acc = 0.8356\n","training took 50.24 s\n","Avg test loss = 0.667\tAvg test acc = 0.836\n","Epoch 0\tavg epoch Loss = 2.24\tavg epoch acc = 0.5065\n","Epoch 1\tavg epoch Loss = 1.97\tavg epoch acc = 0.673\n","Epoch 2\tavg epoch Loss = 1.535\tavg epoch acc = 0.691\n","Epoch 3\tavg epoch Loss = 1.132\tavg epoch acc = 0.7386\n","Epoch 4\tavg epoch Loss = 0.8837\tavg epoch acc = 0.7739\n","Epoch 5\tavg epoch Loss = 0.751\tavg epoch acc = 0.7964\n","Epoch 6\tavg epoch Loss = 0.6718\tavg epoch acc = 0.8093\n","Epoch 7\tavg epoch Loss = 0.6164\tavg epoch acc = 0.8201\n","Epoch 8\tavg epoch Loss = 0.573\tavg epoch acc = 0.8276\n","Epoch 9\tavg epoch Loss = 0.5363\tavg epoch acc = 0.8336\n","training took 50.18 s\n","Avg test loss = 0.624\tAvg test acc = 0.847\n","{'lr': 1e-05, 'beta1': 0.1, 'beta2': 0.5, 'batch_size': 128, 'weight_decay': 0.050050000000000004, 'epsilon': 1e-10}\n","Epoch 0\tavg epoch Loss = 2.24\tavg epoch acc = 0.496\n","Epoch 1\tavg epoch Loss = 1.969\tavg epoch acc = 0.6686\n","Epoch 2\tavg epoch Loss = 1.534\tavg epoch acc = 0.688\n","Epoch 3\tavg epoch Loss = 1.129\tavg epoch acc = 0.7374\n","Epoch 4\tavg epoch Loss = 0.8798\tavg epoch acc = 0.7735\n","Epoch 5\tavg epoch Loss = 0.7462\tavg epoch acc = 0.7963\n","Epoch 6\tavg epoch Loss = 0.6666\tavg epoch acc = 0.8111\n","Epoch 7\tavg epoch Loss = 0.6111\tavg epoch acc = 0.8214\n","Epoch 8\tavg epoch Loss = 0.5679\tavg epoch acc = 0.8294\n","Epoch 9\tavg epoch Loss = 0.5316\tavg epoch acc = 0.8356\n","training took 50.2 s\n","Avg test loss = 0.677\tAvg test acc = 0.836\n","Epoch 0\tavg epoch Loss = 2.24\tavg epoch acc = 0.5074\n","Epoch 1\tavg epoch Loss = 1.97\tavg epoch acc = 0.6745\n","Epoch 2\tavg epoch Loss = 1.535\tavg epoch acc = 0.6911\n","Epoch 3\tavg epoch Loss = 1.129\tavg epoch acc = 0.7391\n","Epoch 4\tavg epoch Loss = 0.8797\tavg epoch acc = 0.7742\n","Epoch 5\tavg epoch Loss = 0.7459\tavg epoch acc = 0.7963\n","Epoch 6\tavg epoch Loss = 0.666\tavg epoch acc = 0.8104\n","Epoch 7\tavg epoch Loss = 0.6101\tavg epoch acc = 0.8212\n","Epoch 8\tavg epoch Loss = 0.5665\tavg epoch acc = 0.8291\n","Epoch 9\tavg epoch Loss = 0.5297\tavg epoch acc = 0.8356\n","training took 50.19 s\n","Avg test loss = 0.666\tAvg test acc = 0.835\n","Epoch 0\tavg epoch Loss = 2.241\tavg epoch acc = 0.484\n","Epoch 1\tavg epoch Loss = 1.971\tavg epoch acc = 0.67\n","Epoch 2\tavg epoch Loss = 1.538\tavg epoch acc = 0.6895\n","Epoch 3\tavg epoch Loss = 1.134\tavg epoch acc = 0.7373\n","Epoch 4\tavg epoch Loss = 0.886\tavg epoch acc = 0.7729\n","Epoch 5\tavg epoch Loss = 0.753\tavg epoch acc = 0.7946\n","Epoch 6\tavg epoch Loss = 0.6736\tavg epoch acc = 0.8091\n","Epoch 7\tavg epoch Loss = 0.6183\tavg epoch acc = 0.8197\n","Epoch 8\tavg epoch Loss = 0.5752\tavg epoch acc = 0.8274\n","Epoch 9\tavg epoch Loss = 0.5389\tavg epoch acc = 0.8334\n","training took 50.11 s\n","Avg test loss = 0.633\tAvg test acc = 0.843\n","Epoch 0\tavg epoch Loss = 2.24\tavg epoch acc = 0.497\n","Epoch 1\tavg epoch Loss = 1.968\tavg epoch acc = 0.6686\n","Epoch 2\tavg epoch Loss = 1.533\tavg epoch acc = 0.6896\n","Epoch 3\tavg epoch Loss = 1.13\tavg epoch acc = 0.7384\n","Epoch 4\tavg epoch Loss = 0.8812\tavg epoch acc = 0.7737\n","Epoch 5\tavg epoch Loss = 0.7478\tavg epoch acc = 0.7951\n","Epoch 6\tavg epoch Loss = 0.668\tavg epoch acc = 0.8097\n","Epoch 7\tavg epoch Loss = 0.6121\tavg epoch acc = 0.8205\n","Epoch 8\tavg epoch Loss = 0.5686\tavg epoch acc = 0.828\n","Epoch 9\tavg epoch Loss = 0.5319\tavg epoch acc = 0.8346\n","training took 50.24 s\n","Avg test loss = 0.653\tAvg test acc = 0.842\n","Epoch 0\tavg epoch Loss = 2.24\tavg epoch acc = 0.5038\n","Epoch 1\tavg epoch Loss = 1.968\tavg epoch acc = 0.672\n","Epoch 2\tavg epoch Loss = 1.53\tavg epoch acc = 0.691\n","Epoch 3\tavg epoch Loss = 1.122\tavg epoch acc = 0.7395\n","Epoch 4\tavg epoch Loss = 0.8734\tavg epoch acc = 0.7768\n","Epoch 5\tavg epoch Loss = 0.7408\tavg epoch acc = 0.7982\n","Epoch 6\tavg epoch Loss = 0.6617\tavg epoch acc = 0.8131\n","Epoch 7\tavg epoch Loss = 0.6065\tavg epoch acc = 0.8241\n","Epoch 8\tavg epoch Loss = 0.5634\tavg epoch acc = 0.8322\n","Epoch 9\tavg epoch Loss = 0.5271\tavg epoch acc = 0.8388\n","training took 50.14 s\n","Avg test loss = 0.663\tAvg test acc = 0.838\n","{'lr': 1e-05, 'beta1': 0.1, 'beta2': 0.5, 'batch_size': 128, 'weight_decay': 0.050050000000000004, 'epsilon': 5.0500000000000006e-09}\n","Epoch 0\tavg epoch Loss = 2.24\tavg epoch acc = 0.4936\n","Epoch 1\tavg epoch Loss = 1.968\tavg epoch acc = 0.6682\n","Epoch 2\tavg epoch Loss = 1.532\tavg epoch acc = 0.6912\n","Epoch 3\tavg epoch Loss = 1.127\tavg epoch acc = 0.7379\n","Epoch 4\tavg epoch Loss = 0.8793\tavg epoch acc = 0.7744\n","Epoch 5\tavg epoch Loss = 0.7471\tavg epoch acc = 0.7966\n","Epoch 6\tavg epoch Loss = 0.6677\tavg epoch acc = 0.8121\n","Epoch 7\tavg epoch Loss = 0.6121\tavg epoch acc = 0.8228\n","Epoch 8\tavg epoch Loss = 0.5689\tavg epoch acc = 0.8305\n","Epoch 9\tavg epoch Loss = 0.5323\tavg epoch acc = 0.8367\n","training took 50.47 s\n","Avg test loss = 0.658\tAvg test acc = 0.834\n","Epoch 0\tavg epoch Loss = 2.24\tavg epoch acc = 0.5054\n","Epoch 1\tavg epoch Loss = 1.969\tavg epoch acc = 0.6688\n","Epoch 2\tavg epoch Loss = 1.535\tavg epoch acc = 0.6889\n","Epoch 3\tavg epoch Loss = 1.13\tavg epoch acc = 0.7379\n","Epoch 4\tavg epoch Loss = 0.8808\tavg epoch acc = 0.7739\n","Epoch 5\tavg epoch Loss = 0.7476\tavg epoch acc = 0.7958\n","Epoch 6\tavg epoch Loss = 0.6682\tavg epoch acc = 0.8098\n","Epoch 7\tavg epoch Loss = 0.6126\tavg epoch acc = 0.8204\n","Epoch 8\tavg epoch Loss = 0.5691\tavg epoch acc = 0.8281\n","Epoch 9\tavg epoch Loss = 0.5326\tavg epoch acc = 0.8348\n","training took 50.24 s\n","Avg test loss = 0.653\tAvg test acc = 0.84\n","Epoch 0\tavg epoch Loss = 2.24\tavg epoch acc = 0.502\n","Epoch 1\tavg epoch Loss = 1.967\tavg epoch acc = 0.6727\n","Epoch 2\tavg epoch Loss = 1.531\tavg epoch acc = 0.6914\n","Epoch 3\tavg epoch Loss = 1.127\tavg epoch acc = 0.7389\n","Epoch 4\tavg epoch Loss = 0.8785\tavg epoch acc = 0.7744\n","Epoch 5\tavg epoch Loss = 0.7459\tavg epoch acc = 0.797\n","Epoch 6\tavg epoch Loss = 0.6665\tavg epoch acc = 0.8102\n","Epoch 7\tavg epoch Loss = 0.6109\tavg epoch acc = 0.8211\n","Epoch 8\tavg epoch Loss = 0.5675\tavg epoch acc = 0.8289\n","Epoch 9\tavg epoch Loss = 0.5308\tavg epoch acc = 0.8352\n","training took 50.28 s\n","Avg test loss = 0.672\tAvg test acc = 0.836\n","Epoch 0\tavg epoch Loss = 2.24\tavg epoch acc = 0.4942\n","Epoch 1\tavg epoch Loss = 1.967\tavg epoch acc = 0.6716\n","Epoch 2\tavg epoch Loss = 1.527\tavg epoch acc = 0.6902\n","Epoch 3\tavg epoch Loss = 1.122\tavg epoch acc = 0.7398\n","Epoch 4\tavg epoch Loss = 0.8747\tavg epoch acc = 0.7743\n","Epoch 5\tavg epoch Loss = 0.7429\tavg epoch acc = 0.7964\n","Epoch 6\tavg epoch Loss = 0.6641\tavg epoch acc = 0.8108\n","Epoch 7\tavg epoch Loss = 0.6089\tavg epoch acc = 0.8219\n","Epoch 8\tavg epoch Loss = 0.5659\tavg epoch acc = 0.8297\n","Epoch 9\tavg epoch Loss = 0.5296\tavg epoch acc = 0.836\n","training took 50.14 s\n","Avg test loss = 0.639\tAvg test acc = 0.844\n","Epoch 0\tavg epoch Loss = 2.241\tavg epoch acc = 0.4975\n","Epoch 1\tavg epoch Loss = 1.97\tavg epoch acc = 0.6693\n","Epoch 2\tavg epoch Loss = 1.534\tavg epoch acc = 0.6884\n","Epoch 3\tavg epoch Loss = 1.129\tavg epoch acc = 0.7376\n","Epoch 4\tavg epoch Loss = 0.8803\tavg epoch acc = 0.774\n","Epoch 5\tavg epoch Loss = 0.7474\tavg epoch acc = 0.7958\n","Epoch 6\tavg epoch Loss = 0.668\tavg epoch acc = 0.8097\n","Epoch 7\tavg epoch Loss = 0.6126\tavg epoch acc = 0.8199\n","Epoch 8\tavg epoch Loss = 0.5696\tavg epoch acc = 0.8274\n","Epoch 9\tavg epoch Loss = 0.5333\tavg epoch acc = 0.8338\n","training took 50.3 s\n","Avg test loss = 0.673\tAvg test acc = 0.839\n","{'lr': 1e-05, 'beta1': 0.1, 'beta2': 0.5, 'batch_size': 128, 'weight_decay': 0.050050000000000004, 'epsilon': 1e-08}\n","Epoch 0\tavg epoch Loss = 2.241\tavg epoch acc = 0.4967\n","Epoch 1\tavg epoch Loss = 1.971\tavg epoch acc = 0.6706\n","Epoch 2\tavg epoch Loss = 1.536\tavg epoch acc = 0.6874\n","Epoch 3\tavg epoch Loss = 1.13\tavg epoch acc = 0.7368\n","Epoch 4\tavg epoch Loss = 0.8807\tavg epoch acc = 0.7732\n","Epoch 5\tavg epoch Loss = 0.7479\tavg epoch acc = 0.7951\n","Epoch 6\tavg epoch Loss = 0.6688\tavg epoch acc = 0.8091\n","Epoch 7\tavg epoch Loss = 0.6139\tavg epoch acc = 0.82\n","Epoch 8\tavg epoch Loss = 0.571\tavg epoch acc = 0.8279\n","Epoch 9\tavg epoch Loss = 0.5347\tavg epoch acc = 0.8335\n","training took 49.97 s\n","Avg test loss = 0.665\tAvg test acc = 0.835\n","Epoch 0\tavg epoch Loss = 2.241\tavg epoch acc = 0.4968\n","Epoch 1\tavg epoch Loss = 1.97\tavg epoch acc = 0.6693\n","Epoch 2\tavg epoch Loss = 1.534\tavg epoch acc = 0.6901\n","Epoch 3\tavg epoch Loss = 1.128\tavg epoch acc = 0.7386\n","Epoch 4\tavg epoch Loss = 0.8795\tavg epoch acc = 0.7741\n","Epoch 5\tavg epoch Loss = 0.7467\tavg epoch acc = 0.7966\n","Epoch 6\tavg epoch Loss = 0.6675\tavg epoch acc = 0.8112\n","Epoch 7\tavg epoch Loss = 0.6118\tavg epoch acc = 0.8219\n","Epoch 8\tavg epoch Loss = 0.5683\tavg epoch acc = 0.8308\n","Epoch 9\tavg epoch Loss = 0.5317\tavg epoch acc = 0.8367\n","training took 50.01 s\n","Avg test loss = 0.646\tAvg test acc = 0.843\n","Epoch 0\tavg epoch Loss = 2.24\tavg epoch acc = 0.4923\n","Epoch 1\tavg epoch Loss = 1.967\tavg epoch acc = 0.6701\n","Epoch 2\tavg epoch Loss = 1.53\tavg epoch acc = 0.6898\n","Epoch 3\tavg epoch Loss = 1.126\tavg epoch acc = 0.738\n","Epoch 4\tavg epoch Loss = 0.8792\tavg epoch acc = 0.774\n","Epoch 5\tavg epoch Loss = 0.7476\tavg epoch acc = 0.7957\n","Epoch 6\tavg epoch Loss = 0.6683\tavg epoch acc = 0.8091\n","Epoch 7\tavg epoch Loss = 0.6127\tavg epoch acc = 0.82\n","Epoch 8\tavg epoch Loss = 0.5692\tavg epoch acc = 0.827\n","Epoch 9\tavg epoch Loss = 0.5325\tavg epoch acc = 0.8333\n","training took 49.92 s\n","Avg test loss = 0.667\tAvg test acc = 0.837\n","Epoch 0\tavg epoch Loss = 2.241\tavg epoch acc = 0.4986\n","Epoch 1\tavg epoch Loss = 1.97\tavg epoch acc = 0.6743\n","Epoch 2\tavg epoch Loss = 1.536\tavg epoch acc = 0.6925\n","Epoch 3\tavg epoch Loss = 1.13\tavg epoch acc = 0.7404\n","Epoch 4\tavg epoch Loss = 0.8812\tavg epoch acc = 0.7749\n","Epoch 5\tavg epoch Loss = 0.7478\tavg epoch acc = 0.7969\n","Epoch 6\tavg epoch Loss = 0.6677\tavg epoch acc = 0.8112\n","Epoch 7\tavg epoch Loss = 0.6118\tavg epoch acc = 0.8231\n","Epoch 8\tavg epoch Loss = 0.5684\tavg epoch acc = 0.8308\n","Epoch 9\tavg epoch Loss = 0.532\tavg epoch acc = 0.8373\n","training took 50.22 s\n","Avg test loss = 0.671\tAvg test acc = 0.839\n","Epoch 0\tavg epoch Loss = 2.241\tavg epoch acc = 0.5051\n","Epoch 1\tavg epoch Loss = 1.97\tavg epoch acc = 0.6693\n","Epoch 2\tavg epoch Loss = 1.535\tavg epoch acc = 0.6896\n","Epoch 3\tavg epoch Loss = 1.13\tavg epoch acc = 0.7371\n","Epoch 4\tavg epoch Loss = 0.8802\tavg epoch acc = 0.7738\n","Epoch 5\tavg epoch Loss = 0.7469\tavg epoch acc = 0.7961\n","Epoch 6\tavg epoch Loss = 0.6675\tavg epoch acc = 0.8101\n","Epoch 7\tavg epoch Loss = 0.6121\tavg epoch acc = 0.8206\n","Epoch 8\tavg epoch Loss = 0.5689\tavg epoch acc = 0.8275\n","Epoch 9\tavg epoch Loss = 0.5324\tavg epoch acc = 0.834\n","training took 50.0 s\n","Avg test loss = 0.657\tAvg test acc = 0.838\n","{'lr': 1e-05, 'beta1': 0.1, 'beta2': 0.5, 'batch_size': 128, 'weight_decay': 0.1, 'epsilon': 1e-10}\n","Epoch 0\tavg epoch Loss = 2.241\tavg epoch acc = 0.5008\n","Epoch 1\tavg epoch Loss = 1.971\tavg epoch acc = 0.6697\n","Epoch 2\tavg epoch Loss = 1.537\tavg epoch acc = 0.689\n","Epoch 3\tavg epoch Loss = 1.133\tavg epoch acc = 0.7368\n","Epoch 4\tavg epoch Loss = 0.884\tavg epoch acc = 0.773\n","Epoch 5\tavg epoch Loss = 0.7502\tavg epoch acc = 0.7951\n","Epoch 6\tavg epoch Loss = 0.6702\tavg epoch acc = 0.8093\n","Epoch 7\tavg epoch Loss = 0.6144\tavg epoch acc = 0.8206\n","Epoch 8\tavg epoch Loss = 0.5709\tavg epoch acc = 0.8283\n","Epoch 9\tavg epoch Loss = 0.5343\tavg epoch acc = 0.8341\n","training took 50.2 s\n","Avg test loss = 0.636\tAvg test acc = 0.845\n","Epoch 0\tavg epoch Loss = 2.24\tavg epoch acc = 0.501\n","Epoch 1\tavg epoch Loss = 1.969\tavg epoch acc = 0.6695\n","Epoch 2\tavg epoch Loss = 1.533\tavg epoch acc = 0.6902\n","Epoch 3\tavg epoch Loss = 1.127\tavg epoch acc = 0.7393\n","Epoch 4\tavg epoch Loss = 0.8783\tavg epoch acc = 0.7742\n","Epoch 5\tavg epoch Loss = 0.7452\tavg epoch acc = 0.7967\n","Epoch 6\tavg epoch Loss = 0.6654\tavg epoch acc = 0.811\n","Epoch 7\tavg epoch Loss = 0.6097\tavg epoch acc = 0.8221\n","Epoch 8\tavg epoch Loss = 0.5664\tavg epoch acc = 0.8298\n","Epoch 9\tavg epoch Loss = 0.5297\tavg epoch acc = 0.8368\n","training took 50.06 s\n","Avg test loss = 0.685\tAvg test acc = 0.836\n","Epoch 0\tavg epoch Loss = 2.24\tavg epoch acc = 0.5011\n","Epoch 1\tavg epoch Loss = 1.966\tavg epoch acc = 0.6693\n","Epoch 2\tavg epoch Loss = 1.527\tavg epoch acc = 0.6893\n","Epoch 3\tavg epoch Loss = 1.121\tavg epoch acc = 0.7385\n","Epoch 4\tavg epoch Loss = 0.8746\tavg epoch acc = 0.7752\n","Epoch 5\tavg epoch Loss = 0.7429\tavg epoch acc = 0.7972\n","Epoch 6\tavg epoch Loss = 0.6643\tavg epoch acc = 0.8113\n","Epoch 7\tavg epoch Loss = 0.609\tavg epoch acc = 0.8227\n","Epoch 8\tavg epoch Loss = 0.5659\tavg epoch acc = 0.8302\n","Epoch 9\tavg epoch Loss = 0.5293\tavg epoch acc = 0.8365\n","training took 50.18 s\n","Avg test loss = 0.674\tAvg test acc = 0.834\n","Epoch 0\tavg epoch Loss = 2.24\tavg epoch acc = 0.4934\n","Epoch 1\tavg epoch Loss = 1.969\tavg epoch acc = 0.6659\n","Epoch 2\tavg epoch Loss = 1.536\tavg epoch acc = 0.688\n","Epoch 3\tavg epoch Loss = 1.132\tavg epoch acc = 0.7365\n","Epoch 4\tavg epoch Loss = 0.8822\tavg epoch acc = 0.7729\n","Epoch 5\tavg epoch Loss = 0.7489\tavg epoch acc = 0.7948\n","Epoch 6\tavg epoch Loss = 0.6693\tavg epoch acc = 0.8091\n","Epoch 7\tavg epoch Loss = 0.6137\tavg epoch acc = 0.8199\n","Epoch 8\tavg epoch Loss = 0.5703\tavg epoch acc = 0.8271\n","Epoch 9\tavg epoch Loss = 0.5336\tavg epoch acc = 0.8333\n","training took 50.05 s\n","Avg test loss = 0.65\tAvg test acc = 0.84\n","Epoch 0\tavg epoch Loss = 2.24\tavg epoch acc = 0.4974\n","Epoch 1\tavg epoch Loss = 1.969\tavg epoch acc = 0.6724\n","Epoch 2\tavg epoch Loss = 1.536\tavg epoch acc = 0.6913\n","Epoch 3\tavg epoch Loss = 1.132\tavg epoch acc = 0.7388\n","Epoch 4\tavg epoch Loss = 0.8822\tavg epoch acc = 0.7731\n","Epoch 5\tavg epoch Loss = 0.7489\tavg epoch acc = 0.7955\n","Epoch 6\tavg epoch Loss = 0.6695\tavg epoch acc = 0.8098\n","Epoch 7\tavg epoch Loss = 0.6141\tavg epoch acc = 0.8207\n","Epoch 8\tavg epoch Loss = 0.5711\tavg epoch acc = 0.8281\n","Epoch 9\tavg epoch Loss = 0.5345\tavg epoch acc = 0.8344\n","training took 50.17 s\n","Avg test loss = 0.646\tAvg test acc = 0.841\n","{'lr': 1e-05, 'beta1': 0.1, 'beta2': 0.5, 'batch_size': 128, 'weight_decay': 0.1, 'epsilon': 5.0500000000000006e-09}\n","Epoch 0\tavg epoch Loss = 2.24\tavg epoch acc = 0.4983\n","Epoch 1\tavg epoch Loss = 1.968\tavg epoch acc = 0.6701\n","Epoch 2\tavg epoch Loss = 1.532\tavg epoch acc = 0.6896\n","Epoch 3\tavg epoch Loss = 1.127\tavg epoch acc = 0.7377\n","Epoch 4\tavg epoch Loss = 0.8788\tavg epoch acc = 0.774\n","Epoch 5\tavg epoch Loss = 0.746\tavg epoch acc = 0.7964\n","Epoch 6\tavg epoch Loss = 0.6666\tavg epoch acc = 0.8101\n","Epoch 7\tavg epoch Loss = 0.6112\tavg epoch acc = 0.8215\n","Epoch 8\tavg epoch Loss = 0.5682\tavg epoch acc = 0.8291\n","Epoch 9\tavg epoch Loss = 0.5319\tavg epoch acc = 0.8354\n","training took 50.03 s\n","Avg test loss = 0.66\tAvg test acc = 0.842\n","Epoch 0\tavg epoch Loss = 2.24\tavg epoch acc = 0.4942\n","Epoch 1\tavg epoch Loss = 1.965\tavg epoch acc = 0.6657\n","Epoch 2\tavg epoch Loss = 1.528\tavg epoch acc = 0.6893\n","Epoch 3\tavg epoch Loss = 1.125\tavg epoch acc = 0.7384\n","Epoch 4\tavg epoch Loss = 0.8783\tavg epoch acc = 0.7742\n","Epoch 5\tavg epoch Loss = 0.7464\tavg epoch acc = 0.796\n","Epoch 6\tavg epoch Loss = 0.6671\tavg epoch acc = 0.81\n","Epoch 7\tavg epoch Loss = 0.6114\tavg epoch acc = 0.8214\n","Epoch 8\tavg epoch Loss = 0.568\tavg epoch acc = 0.829\n","Epoch 9\tavg epoch Loss = 0.5315\tavg epoch acc = 0.8352\n","training took 50.21 s\n","Avg test loss = 0.683\tAvg test acc = 0.832\n","Epoch 0\tavg epoch Loss = 2.241\tavg epoch acc = 0.5042\n","Epoch 1\tavg epoch Loss = 1.971\tavg epoch acc = 0.6722\n","Epoch 2\tavg epoch Loss = 1.537\tavg epoch acc = 0.6883\n","Epoch 3\tavg epoch Loss = 1.133\tavg epoch acc = 0.7358\n","Epoch 4\tavg epoch Loss = 0.8842\tavg epoch acc = 0.7716\n","Epoch 5\tavg epoch Loss = 0.7507\tavg epoch acc = 0.7932\n","Epoch 6\tavg epoch Loss = 0.6709\tavg epoch acc = 0.8073\n","Epoch 7\tavg epoch Loss = 0.6153\tavg epoch acc = 0.8189\n","Epoch 8\tavg epoch Loss = 0.572\tavg epoch acc = 0.8257\n","Epoch 9\tavg epoch Loss = 0.5355\tavg epoch acc = 0.8328\n","training took 50.08 s\n","Avg test loss = 0.65\tAvg test acc = 0.838\n","Epoch 0\tavg epoch Loss = 2.241\tavg epoch acc = 0.4938\n","Epoch 1\tavg epoch Loss = 1.971\tavg epoch acc = 0.6715\n","Epoch 2\tavg epoch Loss = 1.535\tavg epoch acc = 0.6907\n","Epoch 3\tavg epoch Loss = 1.13\tavg epoch acc = 0.7384\n","Epoch 4\tavg epoch Loss = 0.8811\tavg epoch acc = 0.7748\n","Epoch 5\tavg epoch Loss = 0.7485\tavg epoch acc = 0.7969\n","Epoch 6\tavg epoch Loss = 0.6691\tavg epoch acc = 0.8111\n","Epoch 7\tavg epoch Loss = 0.6136\tavg epoch acc = 0.8228\n","Epoch 8\tavg epoch Loss = 0.5703\tavg epoch acc = 0.8305\n","Epoch 9\tavg epoch Loss = 0.5338\tavg epoch acc = 0.8369\n","training took 50.2 s\n","Avg test loss = 0.654\tAvg test acc = 0.839\n","Epoch 0\tavg epoch Loss = 2.24\tavg epoch acc = 0.5044\n","Epoch 1\tavg epoch Loss = 1.967\tavg epoch acc = 0.6743\n","Epoch 2\tavg epoch Loss = 1.529\tavg epoch acc = 0.6918\n","Epoch 3\tavg epoch Loss = 1.122\tavg epoch acc = 0.741\n","Epoch 4\tavg epoch Loss = 0.8752\tavg epoch acc = 0.7759\n","Epoch 5\tavg epoch Loss = 0.7439\tavg epoch acc = 0.7974\n","Epoch 6\tavg epoch Loss = 0.6656\tavg epoch acc = 0.8112\n","Epoch 7\tavg epoch Loss = 0.6106\tavg epoch acc = 0.8214\n","Epoch 8\tavg epoch Loss = 0.5676\tavg epoch acc = 0.8283\n","Epoch 9\tavg epoch Loss = 0.5313\tavg epoch acc = 0.8341\n","training took 50.09 s\n","Avg test loss = 0.657\tAvg test acc = 0.841\n","{'lr': 1e-05, 'beta1': 0.1, 'beta2': 0.5, 'batch_size': 128, 'weight_decay': 0.1, 'epsilon': 1e-08}\n","Epoch 0\tavg epoch Loss = 2.241\tavg epoch acc = 0.4938\n","Epoch 1\tavg epoch Loss = 1.972\tavg epoch acc = 0.6696\n","Epoch 2\tavg epoch Loss = 1.539\tavg epoch acc = 0.6861\n","Epoch 3\tavg epoch Loss = 1.135\tavg epoch acc = 0.7357\n","Epoch 4\tavg epoch Loss = 0.8847\tavg epoch acc = 0.7709\n","Epoch 5\tavg epoch Loss = 0.7503\tavg epoch acc = 0.7936\n","Epoch 6\tavg epoch Loss = 0.6699\tavg epoch acc = 0.8077\n","Epoch 7\tavg epoch Loss = 0.6136\tavg epoch acc = 0.8182\n","Epoch 8\tavg epoch Loss = 0.5699\tavg epoch acc = 0.8253\n","Epoch 9\tavg epoch Loss = 0.5333\tavg epoch acc = 0.8323\n","training took 50.21 s\n","Avg test loss = 0.646\tAvg test acc = 0.842\n","Epoch 0\tavg epoch Loss = 2.241\tavg epoch acc = 0.4985\n","Epoch 1\tavg epoch Loss = 1.972\tavg epoch acc = 0.6699\n","Epoch 2\tavg epoch Loss = 1.541\tavg epoch acc = 0.6882\n","Epoch 3\tavg epoch Loss = 1.136\tavg epoch acc = 0.7372\n","Epoch 4\tavg epoch Loss = 0.8842\tavg epoch acc = 0.7739\n","Epoch 5\tavg epoch Loss = 0.7488\tavg epoch acc = 0.7953\n","Epoch 6\tavg epoch Loss = 0.6682\tavg epoch acc = 0.8097\n","Epoch 7\tavg epoch Loss = 0.6121\tavg epoch acc = 0.8215\n","Epoch 8\tavg epoch Loss = 0.5687\tavg epoch acc = 0.8296\n","Epoch 9\tavg epoch Loss = 0.532\tavg epoch acc = 0.836\n","training took 50.06 s\n","Avg test loss = 0.688\tAvg test acc = 0.835\n","Epoch 0\tavg epoch Loss = 2.241\tavg epoch acc = 0.5014\n","Epoch 1\tavg epoch Loss = 1.971\tavg epoch acc = 0.6713\n","Epoch 2\tavg epoch Loss = 1.537\tavg epoch acc = 0.6914\n","Epoch 3\tavg epoch Loss = 1.131\tavg epoch acc = 0.7389\n","Epoch 4\tavg epoch Loss = 0.8808\tavg epoch acc = 0.775\n","Epoch 5\tavg epoch Loss = 0.7472\tavg epoch acc = 0.797\n","Epoch 6\tavg epoch Loss = 0.6677\tavg epoch acc = 0.8111\n","Epoch 7\tavg epoch Loss = 0.6122\tavg epoch acc = 0.8219\n","Epoch 8\tavg epoch Loss = 0.569\tavg epoch acc = 0.8304\n","Epoch 9\tavg epoch Loss = 0.5326\tavg epoch acc = 0.8362\n","training took 50.24 s\n","Avg test loss = 0.65\tAvg test acc = 0.841\n","Epoch 0\tavg epoch Loss = 2.24\tavg epoch acc = 0.4863\n","Epoch 1\tavg epoch Loss = 1.968\tavg epoch acc = 0.6697\n","Epoch 2\tavg epoch Loss = 1.533\tavg epoch acc = 0.6894\n","Epoch 3\tavg epoch Loss = 1.13\tavg epoch acc = 0.7377\n","Epoch 4\tavg epoch Loss = 0.8819\tavg epoch acc = 0.773\n","Epoch 5\tavg epoch Loss = 0.7494\tavg epoch acc = 0.7956\n","Epoch 6\tavg epoch Loss = 0.6699\tavg epoch acc = 0.8101\n","Epoch 7\tavg epoch Loss = 0.6145\tavg epoch acc = 0.8211\n","Epoch 8\tavg epoch Loss = 0.5714\tavg epoch acc = 0.8288\n","Epoch 9\tavg epoch Loss = 0.535\tavg epoch acc = 0.8355\n","training took 50.16 s\n","Avg test loss = 0.655\tAvg test acc = 0.836\n","Epoch 0\tavg epoch Loss = 2.24\tavg epoch acc = 0.5056\n","Epoch 1\tavg epoch Loss = 1.968\tavg epoch acc = 0.6727\n","Epoch 2\tavg epoch Loss = 1.532\tavg epoch acc = 0.6915\n","Epoch 3\tavg epoch Loss = 1.127\tavg epoch acc = 0.7403\n","Epoch 4\tavg epoch Loss = 0.8801\tavg epoch acc = 0.7758\n","Epoch 5\tavg epoch Loss = 0.7479\tavg epoch acc = 0.7976\n","Epoch 6\tavg epoch Loss = 0.6687\tavg epoch acc = 0.8115\n","Epoch 7\tavg epoch Loss = 0.6132\tavg epoch acc = 0.8229\n","Epoch 8\tavg epoch Loss = 0.5698\tavg epoch acc = 0.8308\n","Epoch 9\tavg epoch Loss = 0.533\tavg epoch acc = 0.8368\n","training took 50.24 s\n","Avg test loss = 0.657\tAvg test acc = 0.838\n","{'lr': 1e-05, 'beta1': 0.1, 'beta2': 0.62475, 'batch_size': 32, 'weight_decay': 0.0001, 'epsilon': 1e-10}\n","Epoch 0\tavg epoch Loss = 1.955\tavg epoch acc = 0.6024\n","Epoch 1\tavg epoch Loss = 0.9785\tavg epoch acc = 0.7549\n","Epoch 2\tavg epoch Loss = 0.6653\tavg epoch acc = 0.8078\n","Epoch 3\tavg epoch Loss = 0.5551\tavg epoch acc = 0.828\n","Epoch 4\tavg epoch Loss = 0.4824\tavg epoch acc = 0.8394\n","Epoch 5\tavg epoch Loss = 0.427\tavg epoch acc = 0.8481\n","Epoch 6\tavg epoch Loss = 0.3829\tavg epoch acc = 0.8555\n","Epoch 7\tavg epoch Loss = 0.3481\tavg epoch acc = 0.8618\n","Epoch 8\tavg epoch Loss = 0.3198\tavg epoch acc = 0.868\n","Epoch 9\tavg epoch Loss = 0.2966\tavg epoch acc = 0.8741\n","training took 111.6 s\n","Avg test loss = 0.576\tAvg test acc = 0.88\n","Epoch 0\tavg epoch Loss = 1.954\tavg epoch acc = 0.5954\n","Epoch 1\tavg epoch Loss = 0.9743\tavg epoch acc = 0.7558\n","Epoch 2\tavg epoch Loss = 0.6602\tavg epoch acc = 0.8081\n","Epoch 3\tavg epoch Loss = 0.5493\tavg epoch acc = 0.8278\n","Epoch 4\tavg epoch Loss = 0.4761\tavg epoch acc = 0.8399\n","Epoch 5\tavg epoch Loss = 0.4207\tavg epoch acc = 0.8484\n","Epoch 6\tavg epoch Loss = 0.377\tavg epoch acc = 0.8554\n","Epoch 7\tavg epoch Loss = 0.3422\tavg epoch acc = 0.862\n","Epoch 8\tavg epoch Loss = 0.3138\tavg epoch acc = 0.8678\n","Epoch 9\tavg epoch Loss = 0.2905\tavg epoch acc = 0.8739\n","training took 111.4 s\n","Avg test loss = 0.646\tAvg test acc = 0.873\n","Epoch 0\tavg epoch Loss = 1.954\tavg epoch acc = 0.5976\n","Epoch 1\tavg epoch Loss = 0.9753\tavg epoch acc = 0.7551\n","Epoch 2\tavg epoch Loss = 0.6635\tavg epoch acc = 0.8083\n","Epoch 3\tavg epoch Loss = 0.5532\tavg epoch acc = 0.8281\n","Epoch 4\tavg epoch Loss = 0.4799\tavg epoch acc = 0.8401\n","Epoch 5\tavg epoch Loss = 0.4239\tavg epoch acc = 0.8485\n","Epoch 6\tavg epoch Loss = 0.3801\tavg epoch acc = 0.8551\n","Epoch 7\tavg epoch Loss = 0.3452\tavg epoch acc = 0.8611\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"e6pnb9SkouDI"},"source":["###Nesterov"],"id":"e6pnb9SkouDI"},{"cell_type":"code","metadata":{"id":"J6egfPHBorlC"},"source":["search_grid_nesterov = {\n","    'lr': np.logspace(0, 1),\n","    'batch_size': [32, 64, 128]\n","}\n","\n","if hyperparameter_tune:\n","    results_nesterov_prot = tune_optimizer(\n","        model=Net().to(device),\n","        optim_fun=NesterovOptimizer,\n","        xtrain=train_dataset.data,\n","        ytrain=train_dataset.targets,\n","        search_grid=search_grid_nesterov,\n","        nfolds=5,\n","        func=protected_training,\n","        **training_config\n","    )\n","\n","else:\n","    results_nesterov_prot = optimizers[NesterovOptimizer]"],"id":"J6egfPHBorlC","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JT4QvX46owJT"},"source":["###Minibatch"],"id":"JT4QvX46owJT"},{"cell_type":"code","metadata":{"id":"v36dhlsxorzj"},"source":["dec_lr_set =  [0]*1 + [1]*1\n","random.shuffle(dec_lr_set)\n","search_grid_mini  = {\n","        'lr': np.linspace(0.00001, 0.01, 5),\n","        'batch_size': [32, 64, 128],\n","        'decreasing_lr': dec_lr_set,\n","    }\n","if hyperparameter_tune:\n","    results_mini_prot = tune_optimizer(\n","        model=Net().to(device),\n","        optim_fun=MiniBatchOptimizer,\n","        xtrain=train_dataset.data,\n","        ytrain=train_dataset.targets,\n","        search_grid=search_grid_mini,\n","        nfolds=5,\n","        func=protected_training,\n","        **training_config\n","    )\n","\n","else:\n","    results_mini_prot = optimizers[MiniBatchOptimizer]"],"id":"v36dhlsxorzj","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aTGiymqzTC5F"},"source":["## Train robust models"],"id":"aTGiymqzTC5F"},{"cell_type":"code","metadata":{"id":"3x4JuZVETC5G"},"source":["from adversary import protect"],"id":"3x4JuZVETC5G","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UFME603ZTC5G"},"source":["### Minibatch (for now, loop later)"],"id":"UFME603ZTC5G"},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":232},"id":"C8vJ8xgkTC5G","executionInfo":{"status":"error","timestamp":1623288595918,"user_tz":-120,"elapsed":219,"user":{"displayName":"Baris Sevilmis","photoUrl":"","userId":"05631870087761794056"}},"outputId":"95c9382c-c73c-49d4-cc70-e97405500e19"},"source":["robust_net = Net().to(device)\n","protect_epochs = training_config['epochs']\n","protect_lr = results_mini_prot['lr']\n","protect_bz = results_mini_prot['batch_size']\n","protect_dec_lr = results_mini_prot['decreasing_lr']\n","prot_train_loader, prot_test_loader = build_data_loaders(train_dataset, test_dataset, protect_bz)\n","mini_opt_proc = MiniBatchOptimizer(robust_net.parameters(), lr=protect_lr, decreasing_lr=protect_dec_lr)\n","robust_net = protect(robust_net, mini_opt_proc, training_config['loss_fun'], prot_train_loader, prot_test_loader, device=device, epochs=protect_epochs)"],"id":"C8vJ8xgkTC5G","execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-28-91eca63f114a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mrobust_net\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprotect_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprotect_lr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprotect_bz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprotect_dec_lr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecreasing_lr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'epochs' is not defined"]}]},{"cell_type":"markdown","metadata":{"id":"P6G89LD0TC5G"},"source":["### Adam"],"id":"P6G89LD0TC5G"},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":269},"id":"16pWnK7TTC5H","executionInfo":{"status":"error","timestamp":1623290987223,"user_tz":-120,"elapsed":263,"user":{"displayName":"Baris Sevilmis","photoUrl":"","userId":"05631870087761794056"}},"outputId":"3f200c9c-4e47-4e85-b20a-6b91671b034c"},"source":["robust_net = Net().to(device)\n","protect_epochs = training_config['epochs']\n","protect_lr_adam = results_adam_prot['lr']\n","protect_bz_adam = results_adam_prot['batch_size']\n","protect_beta1 = results_adam_prot['beta1']\n","protect_beta2 = results_adam_prot['beta2']\n","protect_weight_decay = results_adam_prot['weight_decay']\n","protect_epsilon = results_adam_prot['epsilon']\n","prot_train_loader, prot_test_loader = build_data_loaders(train_dataset, test_dataset, protect_bz)\n","adam_opt_proc = AdamOptimizer(net_naive.parameters(), lr=protect_lr_adam, beta1=protect_beta1,beta2=protect_beta2,weight_decay=protect_weight_decay,epsilon=protect_epsilon)\n","robust_net_adam = protect(robust_net, adam_opt_proc, training_config['loss_fun'], prot_train_loader, prot_test_loader, device=device, epochs=training_config['epochs'])"],"id":"16pWnK7TTC5H","execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-48-db2045aba439>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mrobust_net\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprot_train_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprot_test_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_data_loaders\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprotect_bz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0madam_opt_proc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAdamOptimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet_naive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbest_adam_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbest_adam_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'beta1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbest_adam_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'beta2'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mweight_decay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbest_adam_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'weight_decay'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbest_adam_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'epsilon'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mrobust_net_adam\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprotect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrobust_net\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madam_opt_proc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprot_train_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprot_test_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'epochs'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'protect_bz' is not defined"]}]},{"cell_type":"markdown","metadata":{"id":"Dy6ZxVp0TC5H"},"source":["### Nesterov\n","\n"],"id":"Dy6ZxVp0TC5H"},{"cell_type":"code","metadata":{"id":"zM_3v15STC5H"},"source":["robust_networks = dict()\n","batch_log_interval = 0\n","epsilon = 0.25\n","\n","for optimizer, optimizer_params in prot_optimizers.items():\n","    # Instantiate model\n","    net = Net().to(device)\n","    # Instantiate optimizer\n","    optimizer_params = optimizer_params.copy()\n","    batch_size = optimizer_params.pop('batch_size')\n","    optimizer_instance = optimizer(net.parameters(), **optimizer_params)\n","    # Instantiate data loaders\n","    train_loader, test_loader = build_data_loaders(train_dataset, test_dataset, batch_size)\n","    # Train robust model\n","    protect(\n","        model=net,\n","        optim=optimizer_instance,\n","        train_loader=train_loader,\n","        test_loader=test_loader,\n","        epsilon=epsilon,\n","        **training_config\n","    )\n","    # Save robust net\n","    robust_networks[optimizer] = net"],"id":"zM_3v15STC5H","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bNwEfCJ3gXP7"},"source":["###Minibatch"],"id":"bNwEfCJ3gXP7"},{"cell_type":"code","metadata":{"id":"-xnntG3cggIS"},"source":[""],"id":"-xnntG3cggIS","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4qVv9q6eTC5H"},"source":["## Attack robust models"],"id":"4qVv9q6eTC5H"},{"cell_type":"markdown","metadata":{"id":"R6vqeaYzTC5I"},"source":["### Minibatch (for now, loop later)"],"id":"R6vqeaYzTC5I"},{"cell_type":"code","metadata":{"id":"OQdRN5UwTC5I"},"source":["accuracy_robust = []\n","losses_robust = []\n","# This should be the first term test_loader is used\n","for eps in epsilons:\n","    loss_attack, acc_attack = attack(robust_net, criterion, prot_test_loader, eps, device=device)\n","    accuracy_robust.append(acc_attack)\n","    losses_robust.append(loss_attack)"],"id":"OQdRN5UwTC5I","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iQc7A5jETC5I"},"source":["### Adam"],"id":"iQc7A5jETC5I"},{"cell_type":"code","metadata":{"id":"qCLBCNYTTC5I"},"source":["accuracy_robust_adam = []\n","losses_robust_adam = []\n","# This should be the first term test_loader is used\n","for eps in epsilons:\n","    loss_attack, acc_attack = attack(robust_net_adam, criterion, prot_test_loader, eps, device=device)\n","    accuracy_robust_adam.append(acc_attack)\n","    losses_robust_adam.append(loss_attack)"],"id":"qCLBCNYTTC5I","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tcc0rN-VTC5I"},"source":["## Comparison"],"id":"tcc0rN-VTC5I"},{"cell_type":"markdown","metadata":{"id":"Z_rGhjZxTC5I"},"source":["# Comparative analysis"],"id":"Z_rGhjZxTC5I"},{"cell_type":"markdown","metadata":{"id":"treK0pzuTC5I"},"source":["### Minibatch (for now)"],"id":"treK0pzuTC5I"},{"cell_type":"code","metadata":{"id":"yY6YSGTNTC5J"},"source":["plt.figure(figsize=(5,5))\n","plt.plot(epsilons, accuracy_naive, \"*-\", c='blue', label='Naive Model')\n","plt.plot(epsilons, accuracy_robust, \"*-\", c='orange', label='Robust Model')\n","\n","plt.yticks(np.arange(0, 1.1, step=0.1))\n","plt.xticks(np.arange(0, 0.5, step=0.05))\n","\n","plt.title(\"Accuracy vs Epsilon\")\n","plt.xlabel(\"Epsilon\")\n","plt.ylabel(\"Accuracy\")\n","plt.legend();"],"id":"yY6YSGTNTC5J","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"byYxhmiCTC5J"},"source":["Lots of plots\n","\n","* diff naive vs robust (algo as hue)"],"id":"byYxhmiCTC5J"}]}