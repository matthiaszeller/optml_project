{"nbformat":4,"nbformat_minor":5,"metadata":{"kernelspec":{"name":"python391jvsc74a57bd0fe366cf0acf0ec4657f8e8dacfa2befd1e22c17f5ab271a2cdab9201ebd0edfa","display_name":"Python 3.9.1 64-bit ('DL': conda)"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.1"},"metadata":{"interpreter":{"hash":"aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"}},"colab":{"name":"Merged-notebook.ipynb","provenance":[],"collapsed_sections":["9kL7lW6RTC5B","xOu0V6AjTC5F","R6vqeaYzTC5I","iQc7A5jETC5I","tcc0rN-VTC5I","treK0pzuTC5I"]},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"UJ_a9gfoTC4y"},"source":["# guidelines\n","\n","TODO : import whenever needed, not centralized"],"id":"UJ_a9gfoTC4y"},{"cell_type":"markdown","metadata":{"id":"qm2EKZTHTC41"},"source":["states https://pytorch.org/tutorials/beginner/saving_loading_models.html"],"id":"qm2EKZTHTC41"},{"cell_type":"markdown","metadata":{"id":"NsH47FguTC41"},"source":["# Introduction "],"id":"NsH47FguTC41"},{"cell_type":"markdown","metadata":{"id":"clL0GDWjTC42"},"source":["## Aim"],"id":"clL0GDWjTC42"},{"cell_type":"markdown","metadata":{"id":"_cM5-hWaTC42"},"source":["## Data"],"id":"_cM5-hWaTC42"},{"cell_type":"markdown","metadata":{"id":"8XnMM2bBTC43"},"source":["First load the dataset:"],"id":"8XnMM2bBTC43"},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UkmF8OX2YVg6","executionInfo":{"status":"ok","timestamp":1623615169806,"user_tz":-120,"elapsed":21325,"user":{"displayName":"Baris Sevilmis","photoUrl":"","userId":"05631870087761794056"}},"outputId":"3593a2bc-4b5d-4e06-cd52-c5e6a3c9ccc5"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"id":"UkmF8OX2YVg6","execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wvXzTwJKYoAq","executionInfo":{"status":"ok","timestamp":1623615207139,"user_tz":-120,"elapsed":1092,"user":{"displayName":"Baris Sevilmis","photoUrl":"","userId":"05631870087761794056"}},"outputId":"050a5591-672d-408b-cd9d-f52570c54562"},"source":["#%cd drive/MyDrive/\n","#%cd Colab\\ Notebooks\n","#%cd CS439/optml_project/\n","!ls"],"id":"wvXzTwJKYoAq","execution_count":6,"outputs":[{"output_type":"stream","text":["/content/drive/MyDrive\n","/content/drive/MyDrive/Colab Notebooks\n","/content/drive/MyDrive/Colab Notebooks/CS439/optml_project\n"," adversary.py\t        data_utils.py\t\t  Nesterov.ipynb   res\n"," adv_test.py\t        Hyperparam-tuning.ipynb   net.py\t   Research\n"," alt_adv_test.py        Matt_notebook.ipynb\t  optimizer.py\t   test.py\n"," Baris_Notebook.ipynb   Merged-notebook.ipynb\t  __pycache__\t   training.py\n"," data\t\t       'MF Notebook.ipynb'\t  README.md\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"W_KxujBATC43","executionInfo":{"status":"ok","timestamp":1623615226047,"user_tz":-120,"elapsed":1536,"user":{"displayName":"Baris Sevilmis","photoUrl":"","userId":"05631870087761794056"}}},"source":["from data_utils import get_mnist\n","\n","train_dataset, test_dataset = get_mnist(normalize=True)"],"id":"W_KxujBATC43","execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nid4IHn6TC44"},"source":["# Import (Remove section later on)"],"id":"nid4IHn6TC44"},{"cell_type":"code","metadata":{"id":"ydlgk0IATC45","executionInfo":{"status":"ok","timestamp":1623615226048,"user_tz":-120,"elapsed":4,"user":{"displayName":"Baris Sevilmis","photoUrl":"","userId":"05631870087761794056"}}},"source":["import numpy as np\n","import torch\n","import matplotlib.pyplot as plt\n","import pandas as pd"],"id":"ydlgk0IATC45","execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"N2coYXcoTC45","executionInfo":{"status":"ok","timestamp":1623615227626,"user_tz":-120,"elapsed":1581,"user":{"displayName":"Baris Sevilmis","photoUrl":"","userId":"05631870087761794056"}}},"source":["from adversary import attack, protected_training\n","from net import Net\n","from torch.optim import Optimizer\n","from training import training, testing\n","from pathlib import Path\n","from data_utils import build_data_loaders\n","import random"],"id":"N2coYXcoTC45","execution_count":10,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JOCvUKD4TC45"},"source":["## Setup"],"id":"JOCvUKD4TC45"},{"cell_type":"markdown","metadata":{"id":"Jo1zcsgCTC46"},"source":["Below one can find flags that will setup the notebook:"],"id":"Jo1zcsgCTC46"},{"cell_type":"code","metadata":{"id":"FIDMg4EQTC46","executionInfo":{"status":"ok","timestamp":1623615227626,"user_tz":-120,"elapsed":3,"user":{"displayName":"Baris Sevilmis","photoUrl":"","userId":"05631870087761794056"}}},"source":["# Whether to tune the hyperparameters in this notebook\n","# Note that this might take a long time (especially for Adam)\n","hyperparameter_tune = False\n","prot_hyperparameter_tune = False"],"id":"FIDMg4EQTC46","execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yU6gHibuTC46","executionInfo":{"status":"ok","timestamp":1623615228148,"user_tz":-120,"elapsed":4,"user":{"displayName":"Baris Sevilmis","photoUrl":"","userId":"05631870087761794056"}},"outputId":"3775ac24-0575-4b38-c3a7-7cb5eaabe3ca"},"source":["# Whether to use the GPU, if it's not available, this will be ignored\n","use_cuda = True\n","\n","device = torch.device('cuda' if use_cuda and torch.cuda.is_available() else 'cpu')\n","print(\"Device chosen is {}\".format(device))"],"id":"yU6gHibuTC46","execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Device chosen is cpu\n"]}]},{"cell_type":"markdown","metadata":{"id":"x9yEXbkCTC47"},"source":["We setup the training parameters that we will use all along the notebook, in order to improve readability in downstream code:"],"id":"x9yEXbkCTC47"},{"cell_type":"markdown","metadata":{"id":"mwSjghI5TC47"},"source":["Note that we will use a model with a 10-dimensional output, where each output is passed through softmax. When receiving an output \n","\n","$$Z = \\begin{bmatrix} \\mathbf z_1 & \\dots & \\mathbf z_B \\end{bmatrix}^\\top \\in \\mathbb R^{B \\times 10}$$\n","\n","with $B$ the batch size, we first retrieve the maximal component of each $\\mathbf z_i$:\n","\n","$$\\hat y_i = \\text{argmax}_{k = 1, \\ldots, 10} \\; z_{ik}, \\quad i = 1, \\ldots, B$$\n","\n","and then compute the accuracy:\n","\n","$$\\text{acc} = \\frac 1 B \\sum_{i=1}^B I\\left\\{ \\hat y_i = y_i \\right\\} $$\n","\n","with $I$ the indicator function and $y_i \\in \\{1, \\ldots, 10\\}$ the true target. "],"id":"mwSjghI5TC47"},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-k633Z4qTC48","executionInfo":{"status":"ok","timestamp":1623615229299,"user_tz":-120,"elapsed":3,"user":{"displayName":"Baris Sevilmis","photoUrl":"","userId":"05631870087761794056"}},"outputId":"e2521401-b76d-4591-b3ed-15de5f10b7ae"},"source":["from training import accuracy\n","\n","training_config = {\n","    # Loss function\n","    'loss_fun': torch.nn.CrossEntropyLoss(),\n","    # Performance evaluation function\n","    'metric_fun': accuracy,\n","    # The device to train on\n","    'device': device,\n","    # Number of epochs\n","    'epochs': 10,\n","}\n","\n","test_config = training_config.copy()\n","test_config.pop('epochs')"],"id":"-k633Z4qTC48","execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["10"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"code","metadata":{"id":"duD86o_VTC48","executionInfo":{"status":"ok","timestamp":1623615233031,"user_tz":-120,"elapsed":3456,"user":{"displayName":"Baris Sevilmis","photoUrl":"","userId":"05631870087761794056"}}},"source":["# View the source code\n","??accuracy"],"id":"duD86o_VTC48","execution_count":14,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eLHWxZnwTC48"},"source":["# Model"],"id":"eLHWxZnwTC48"},{"cell_type":"markdown","metadata":{"id":"ShHEMS_2TC49"},"source":["We use a simple standard model for the MNIST dataset (can be found [here](https://github.com/floydhub/mnist/blob/master/ConvNet.py))."],"id":"ShHEMS_2TC49"},{"cell_type":"code","metadata":{"id":"xQPq9DYgTC49","executionInfo":{"status":"ok","timestamp":1623615233085,"user_tz":-120,"elapsed":58,"user":{"displayName":"Baris Sevilmis","photoUrl":"","userId":"05631870087761794056"}}},"source":["from net import Net"],"id":"xQPq9DYgTC49","execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"37yE7eiYTC49","executionInfo":{"status":"ok","timestamp":1623615234700,"user_tz":-120,"elapsed":460,"user":{"displayName":"Baris Sevilmis","photoUrl":"","userId":"05631870087761794056"}}},"source":["??Net"],"id":"37yE7eiYTC49","execution_count":16,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Wi6r1BeyTC4-"},"source":["# Hyperparameter tuning"],"id":"Wi6r1BeyTC4-"},{"cell_type":"code","metadata":{"id":"lJkShBNlTC4-","executionInfo":{"status":"ok","timestamp":1623615235262,"user_tz":-120,"elapsed":565,"user":{"displayName":"Baris Sevilmis","photoUrl":"","userId":"05631870087761794056"}}},"source":["from training import tune_optimizer\n","from optimizer import AdamOptimizer, NesterovOptimizer, MiniBatchOptimizer\n","from data_utils import get_best_hyperparams"],"id":"lJkShBNlTC4-","execution_count":1,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qVEQ7Sq9TC4-"},"source":["If the `hyperparameter_tune` flag was set to `True` above, the following code will run hyperparameter tuning on all optimizers. Note that one can either run KFold cross validation (by providing `n_folds`) or use a simple train/test split (by providing `train_ratio`)."],"id":"qVEQ7Sq9TC4-"},{"cell_type":"markdown","metadata":{"id":"ZudQ63PlTC4-"},"source":["If the flag is set to `False`, the cell below will simply set up the hyperparameters that we carefully cross-validated:"],"id":"ZudQ63PlTC4-"},{"cell_type":"code","metadata":{"id":"2s-KL5tQTC4-","executionInfo":{"status":"ok","timestamp":1623615239771,"user_tz":-120,"elapsed":1603,"user":{"displayName":"Baris Sevilmis","photoUrl":"","userId":"05631870087761794056"}}},"source":["optimizers = {\n","    AdamOptimizer: get_best_hyperparams('./res/adam_tuning_round3.json'),\n","    NesterovOptimizer: get_best_hyperparams('./res/nesterov_tuning_round2.json'),\n","    MiniBatchOptimizer: get_best_hyperparams('./res/minibatch_tuning_round2.json')\n","}"],"id":"2s-KL5tQTC4-","execution_count":11,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"n0IP8shlTC4_"},"source":["## Adam"],"id":"n0IP8shlTC4_"},{"cell_type":"code","metadata":{"id":"CGoUXfziTC4_","executionInfo":{"status":"ok","timestamp":1623615239772,"user_tz":-120,"elapsed":3,"user":{"displayName":"Baris Sevilmis","photoUrl":"","userId":"05631870087761794056"}}},"source":["search_grid_adam = {\n","        'lr': np.linspace(0.001, 0.01, 2),\n","        'beta1':  np.linspace(0.1, 0.9, 2),\n","        'beta2': np.linspace(0.5, 0.999, 2),\n","        'batch_size': [32, 64, 128],\n","        'weight_decay': np.linspace(0.001, 0.1, 2),\n","        'epsilon': np.linspace(1e-10, 1e-8, 2),\n","    }\n","\n","if hyperparameter_tune:\n","    results_adam = tune_optimizer(\n","        model=Net().to(device),\n","        optim_fun=AdamOptimizer,\n","        xtrain=train_dataset.data,\n","        ytrain=train_dataset.targets,\n","        search_grid=search_grid_adam,\n","        nfolds=3,\n","        **training_config)\n","\n","else:\n","    results_adam = optimizers[AdamOptimizer]"],"id":"CGoUXfziTC4_","execution_count":19,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zID5R12xTC4_"},"source":["## Nesterov"],"id":"zID5R12xTC4_"},{"cell_type":"code","metadata":{"id":"GngpxuJ3TC4_","executionInfo":{"status":"ok","timestamp":1623615241221,"user_tz":-120,"elapsed":2,"user":{"displayName":"Baris Sevilmis","photoUrl":"","userId":"05631870087761794056"}}},"source":["search_grid_nesterov = {\n","    'lr': np.logspace(0, 1),\n","    'batch_size': [32, 64, 128]\n","}\n","\n","if hyperparameter_tune:\n","    results_nesterov = tune_optimizer(\n","        model=Net().to(device),\n","        optim_fun=NesterovOptimizer,\n","        xtrain=train_dataset.data,\n","        ytrain=train_dataset.targets,\n","        search_grid=search_grid_nesterov,\n","        nfolds=3,\n","        **training_config\n","    )\n","\n","else:\n","    results_nesterov = optimizers[NesterovOptimizer]"],"id":"GngpxuJ3TC4_","execution_count":20,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QdZrv5wMTC5A"},"source":["## Minibatch"],"id":"QdZrv5wMTC5A"},{"cell_type":"code","metadata":{"id":"Nqw3LTmHTC5A","executionInfo":{"status":"ok","timestamp":1623615241506,"user_tz":-120,"elapsed":2,"user":{"displayName":"Baris Sevilmis","photoUrl":"","userId":"05631870087761794056"}}},"source":["dec_lr_set =  [0]*1 + [1]*1\n","random.shuffle(dec_lr_set)\n","search_grid_mini  = {\n","        'lr': np.linspace(0.00001, 0.01, 5),\n","        'batch_size': [32, 64, 128],\n","        'decreasing_lr': dec_lr_set,\n","    }\n","if hyperparameter_tune:\n","    results_mini = tune_optimizer(\n","        model=Net().to(device),\n","        optim_fun=MiniBatchOptimizer,\n","        xtrain=train_dataset.data,\n","        ytrain=train_dataset.targets,\n","        search_grid=search_grid_mini,\n","        nfolds=3,\n","        **training_config\n","    )\n","\n","else:\n","    results_mini = optimizers[MiniBatchOptimizer]"],"id":"Nqw3LTmHTC5A","execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5qHNhl3sTC5A","executionInfo":{"status":"ok","timestamp":1623615288589,"user_tz":-120,"elapsed":214,"user":{"displayName":"Baris Sevilmis","photoUrl":"","userId":"05631870087761794056"}},"outputId":"b54fcb71-7e62-4d50-c251-47254e43a73e"},"source":["df_analysis = pd.DataFrame(results_mini)\n","best_acc = 0.0\n","for index, row in df_analysis.iterrows():    \n","        trial_acc = row[\"metric_test\"]\n","        if trial_acc > best_acc:\n","            best_acc = trial_acc\n","            learning_rate = round(row[\"lr\"], 6)\n","            decreasing_lr = row[\"decreasing_lr\"]\n","\n","print(\"Best Accuracy was {}% with Learning Rate {} and Decreasing LR: {}\".format(100*best_acc, learning_rate, decreasing_lr))\n"],"id":"5qHNhl3sTC5A","execution_count":26,"outputs":[{"output_type":"stream","text":["Best Accuracy was 98.94448138297872% with Learning Rate 0.125893 and Decreasing LR: False\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"9kL7lW6RTC5B"},"source":["## Comparison"],"id":"9kL7lW6RTC5B"},{"source":["### TODO"],"cell_type":"markdown","metadata":{}},{"cell_type":"markdown","metadata":{"id":"jZSmvLRTTC5B"},"source":["# Attack on naive model\n","\n"],"id":"jZSmvLRTTC5B"},{"cell_type":"code","metadata":{"id":"GQiIUAR8TC5B","executionInfo":{"status":"ok","timestamp":1623615428149,"user_tz":-120,"elapsed":247,"user":{"displayName":"Baris Sevilmis","photoUrl":"","userId":"05631870087761794056"}}},"source":["from data_utils import build_data_loaders\n","from training import training, testing"],"id":"GQiIUAR8TC5B","execution_count":27,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bwA_rKY9TC5B"},"source":["## Train naive models"],"id":"bwA_rKY9TC5B"},{"cell_type":"markdown","metadata":{"id":"TwbOM_NuTC5C"},"source":["### Adam"],"id":"TwbOM_NuTC5C"},{"cell_type":"code","metadata":{"id":"d-XosMjITC5C","executionInfo":{"status":"ok","timestamp":1623615439403,"user_tz":-120,"elapsed":10614,"user":{"displayName":"Baris Sevilmis","photoUrl":"","userId":"05631870087761794056"}}},"source":["net_naive_adam = Net().to(device)\n","train_loader, test_loader = build_data_loaders(train_dataset, test_dataset, results_adam['batch_size'])"],"id":"d-XosMjITC5C","execution_count":28,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2Eaql9dQTC5C","executionInfo":{"status":"ok","timestamp":1623615468807,"user_tz":-120,"elapsed":29407,"user":{"displayName":"Baris Sevilmis","photoUrl":"","userId":"05631870087761794056"}},"outputId":"fc74c0c7-5bc8-4b4a-9bf9-68bfe8f064e2"},"source":["adam_opt_naive = AdamOptimizer(net_naive_adam.parameters(), lr=results_adam['lr'], beta1=results_adam['beta1'],beta2=results_adam['beta2'],weight_decay=results_adam['weight_decay'],epsilon=results_adam['epsilon'])\n","loss_train, acc_train = training(net_naive_adam, train_loader, adam_opt_naive, training_config['loss_fun'], training_config['metric_fun'], epochs=training_config['epochs'], device=device)\n","loss_test, acc_test = testing(net_naive_adam, test_loader, training_config['loss_fun'], training_config['metric_fun'], device=device)"],"id":"2Eaql9dQTC5C","execution_count":29,"outputs":[{"output_type":"stream","text":["Launching training on cuda\n","batch 100\tloss = 2.267\tacc = 0.2031\n","batch 200\tloss = 2.093\tacc = 0.5781\n","batch 300\tloss = 1.363\tacc = 0.6406\n","batch 400\tloss = 0.5689\tacc = 0.8594\n","batch 500\tloss = 0.3135\tacc = 0.9062\n","batch 600\tloss = 0.4358\tacc = 0.8594\n","batch 700\tloss = 0.2853\tacc = 0.9219\n","batch 800\tloss = 0.3075\tacc = 0.875\n","batch 900\tloss = 0.139\tacc = 0.9531\n","epoch 0\tavg epoch loss = 0.9228\tavg epoch acc = 0.7384\n","batch 100\tloss = 0.08239\tacc = 0.9688\n","batch 200\tloss = 0.1757\tacc = 0.9688\n","batch 300\tloss = 0.1137\tacc = 0.9688\n","batch 400\tloss = 0.2313\tacc = 0.9688\n","batch 500\tloss = 0.1433\tacc = 0.9531\n","batch 600\tloss = 0.2047\tacc = 0.9219\n","batch 700\tloss = 0.1001\tacc = 0.9844\n","batch 800\tloss = 0.08361\tacc = 0.9688\n","batch 900\tloss = 0.0476\tacc = 0.9844\n","epoch 1\tavg epoch loss = 0.1227\tavg epoch acc = 0.964\n","batch 100\tloss = 0.05947\tacc = 0.9688\n","batch 200\tloss = 0.08712\tacc = 0.9688\n","batch 300\tloss = 0.05056\tacc = 0.9844\n","batch 400\tloss = 0.1957\tacc = 0.9688\n","batch 500\tloss = 0.088\tacc = 0.9688\n","batch 600\tloss = 0.1514\tacc = 0.9375\n","batch 700\tloss = 0.07535\tacc = 0.9688\n","batch 800\tloss = 0.03285\tacc = 1.0\n","batch 900\tloss = 0.03104\tacc = 0.9844\n","epoch 2\tavg epoch loss = 0.0773\tavg epoch acc = 0.9773\n","batch 100\tloss = 0.03597\tacc = 0.9844\n","batch 200\tloss = 0.0566\tacc = 0.9688\n","batch 300\tloss = 0.02922\tacc = 1.0\n","batch 400\tloss = 0.178\tacc = 0.9688\n","batch 500\tloss = 0.06642\tacc = 0.9844\n","batch 600\tloss = 0.1257\tacc = 0.9688\n","batch 700\tloss = 0.06084\tacc = 0.9688\n","batch 800\tloss = 0.01932\tacc = 1.0\n","batch 900\tloss = 0.02618\tacc = 1.0\n","epoch 3\tavg epoch loss = 0.06011\tavg epoch acc = 0.9825\n","batch 100\tloss = 0.0301\tacc = 0.9844\n","batch 200\tloss = 0.04102\tacc = 0.9844\n","batch 300\tloss = 0.02301\tacc = 1.0\n","batch 400\tloss = 0.1703\tacc = 0.9688\n","batch 500\tloss = 0.05543\tacc = 0.9688\n","batch 600\tloss = 0.1074\tacc = 0.9531\n","batch 700\tloss = 0.06169\tacc = 0.9688\n","batch 800\tloss = 0.01272\tacc = 1.0\n","batch 900\tloss = 0.02263\tacc = 1.0\n","epoch 4\tavg epoch loss = 0.05044\tavg epoch acc = 0.9853\n","batch 100\tloss = 0.02736\tacc = 0.9844\n","batch 200\tloss = 0.03166\tacc = 0.9844\n","batch 300\tloss = 0.021\tacc = 1.0\n","batch 400\tloss = 0.1648\tacc = 0.9688\n","batch 500\tloss = 0.04658\tacc = 0.9688\n","batch 600\tloss = 0.09615\tacc = 0.9688\n","batch 700\tloss = 0.05327\tacc = 0.9688\n","batch 800\tloss = 0.01034\tacc = 1.0\n","batch 900\tloss = 0.02048\tacc = 1.0\n","epoch 5\tavg epoch loss = 0.04416\tavg epoch acc = 0.9872\n","batch 100\tloss = 0.02478\tacc = 0.9844\n","batch 200\tloss = 0.02864\tacc = 0.9844\n","batch 300\tloss = 0.01822\tacc = 1.0\n","batch 400\tloss = 0.1623\tacc = 0.9688\n","batch 500\tloss = 0.04238\tacc = 0.9688\n","batch 600\tloss = 0.08759\tacc = 0.9688\n","batch 700\tloss = 0.04983\tacc = 0.9844\n","batch 800\tloss = 0.009335\tacc = 1.0\n","batch 900\tloss = 0.01782\tacc = 1.0\n","epoch 6\tavg epoch loss = 0.03943\tavg epoch acc = 0.9887\n","batch 100\tloss = 0.02312\tacc = 0.9844\n","batch 200\tloss = 0.02482\tacc = 0.9844\n","batch 300\tloss = 0.01659\tacc = 1.0\n","batch 400\tloss = 0.1567\tacc = 0.9688\n","batch 500\tloss = 0.03978\tacc = 0.9688\n","batch 600\tloss = 0.07879\tacc = 0.9688\n","batch 700\tloss = 0.04147\tacc = 0.9844\n","batch 800\tloss = 0.008387\tacc = 1.0\n","batch 900\tloss = 0.0152\tacc = 1.0\n","epoch 7\tavg epoch loss = 0.03558\tavg epoch acc = 0.99\n","batch 100\tloss = 0.01984\tacc = 1.0\n","batch 200\tloss = 0.02171\tacc = 0.9844\n","batch 300\tloss = 0.01448\tacc = 1.0\n","batch 400\tloss = 0.1523\tacc = 0.9688\n","batch 500\tloss = 0.0364\tacc = 0.9688\n","batch 600\tloss = 0.07547\tacc = 0.9688\n","batch 700\tloss = 0.03034\tacc = 0.9844\n","batch 800\tloss = 0.007634\tacc = 1.0\n","batch 900\tloss = 0.01386\tacc = 1.0\n","epoch 8\tavg epoch loss = 0.03258\tavg epoch acc = 0.9911\n","batch 100\tloss = 0.01813\tacc = 1.0\n","batch 200\tloss = 0.01912\tacc = 0.9844\n","batch 300\tloss = 0.01239\tacc = 1.0\n","batch 400\tloss = 0.1459\tacc = 0.9688\n","batch 500\tloss = 0.0336\tacc = 0.9844\n","batch 600\tloss = 0.07152\tacc = 0.9688\n","batch 700\tloss = 0.0228\tacc = 1.0\n","batch 800\tloss = 0.006713\tacc = 1.0\n","batch 900\tloss = 0.01336\tacc = 1.0\n","epoch 9\tavg epoch loss = 0.0301\tavg epoch acc = 0.9919\n","training took 29.4 s\n","Avg test loss = 0.0343\tAvg test acc = 0.988\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"PRHfeJn0TC5C"},"source":["### Nesterov\n","\n"],"id":"PRHfeJn0TC5C"},{"cell_type":"code","metadata":{"id":"3oAvdXjwTC5C","colab":{"base_uri":"https://localhost:8080/","height":249},"executionInfo":{"status":"error","timestamp":1623615469045,"user_tz":-120,"elapsed":27,"user":{"displayName":"Baris Sevilmis","photoUrl":"","userId":"05631870087761794056"}},"outputId":"1ade6c5a-b1d0-4739-c1df-26c5777bdfdc"},"source":["naive_networks = dict()\n","data_naive = list()\n","batch_log_interval = 0\n","\n","for optimizer, optimizer_params in optimizers.items():\n","    print(f'--- {optimizer}')\n","    optimizer_params = optimizer_params.copy()\n","    \n","    net = Net().to(device)\n","    # Instantiate data loaders with selected batch size\n","    batch_size = optimizer_params.pop('batch_size')\n","    train_loader, test_loader = build_data_loaders(train_dataset, test_dataset, batch_size)\n","    # Instantiate optimizer\n","    optimizer_instance = optimizer(net.parameters(), **optimizer_params)\n","    # Train\n","    loss_train, acc_train = training(\n","        model=net, \n","        dataset=train_loader, \n","        optim=optimizer_instance,\n","        batch_log_interval=batch_log_interval,\n","        **training_config\n","    )\n","    # Test\n","    loss_test, acc_test = testing(\n","        model=net,\n","        dataset=test_loader,\n","        **test_config\n","    )\n","    # Log\n","    data_naive.append({\n","        'optimizer': str(optimizer),\n","        'loss_train': loss_train,\n","        'acc_train': acc_train,\n","        'loss_test': loss_test,\n","        'acc_test': acc_test\n","    })\n","    # Save naive model\n","    naive_networks[optimizer] = net"],"id":"3oAvdXjwTC5C","execution_count":30,"outputs":[{"output_type":"stream","text":["--- <class 'optimizer.AdamOptimizer'>\n"],"name":"stdout"},{"output_type":"error","ename":"TypeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-30-70fb781770c5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_data_loaders\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;31m# Instantiate optimizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0moptimizer_instance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptimizer_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0;31m# Train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     loss_train, acc_train = training(\n","\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'loss_train'"]}]},{"cell_type":"markdown","metadata":{"id":"xCXPQZVwTC5B"},"source":["### Minibatch (for now, loop later)"],"id":"xCXPQZVwTC5B"},{"cell_type":"code","metadata":{"id":"PtrqA0NwTC5B","executionInfo":{"status":"ok","timestamp":1623616153981,"user_tz":-120,"elapsed":225,"user":{"displayName":"Baris Sevilmis","photoUrl":"","userId":"05631870087761794056"}}},"source":["net_naive_mini = Net().to(device)\n","train_loader, test_loader = build_data_loaders(train_dataset, test_dataset, results_mini['batch_size'])"],"id":"PtrqA0NwTC5B","execution_count":31,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BqDCrck6TC5C","executionInfo":{"status":"ok","timestamp":1623616168518,"user_tz":-120,"elapsed":14324,"user":{"displayName":"Baris Sevilmis","photoUrl":"","userId":"05631870087761794056"}},"outputId":"38c73fec-bdf3-4a37-c3cb-7a6ba1e95677"},"source":["mini_opt_naive = MiniBatchOptimizer(net_naive_mini.parameters(), lr=results_mini['lr'], decreasing_lr=results_mini['decreasing_lr'])\n","loss_train, acc_train = training(net_naive_mini, train_loader, mini_opt_naive, training_config['loss_fun'], training_config['metric_fun'], epochs=training_config['epochs'], device=device)\n","loss_test, acc_test = testing(net_naive_mini, test_loader,training_config['loss_fun'], training_config['metric_fun'], device=device)"],"id":"BqDCrck6TC5C","execution_count":32,"outputs":[{"output_type":"stream","text":["Launching training on cuda\n","batch 100\tloss = 0.2113\tacc = 0.9453\n","batch 200\tloss = 0.1763\tacc = 0.9609\n","batch 300\tloss = 0.08091\tacc = 0.9766\n","batch 400\tloss = 0.01724\tacc = 1.0\n","epoch 0\tavg epoch loss = 0.2232\tavg epoch acc = 0.9323\n","batch 100\tloss = 0.04453\tacc = 0.9844\n","batch 200\tloss = 0.118\tacc = 0.9844\n","batch 300\tloss = 0.05569\tacc = 0.9844\n","batch 400\tloss = 0.003604\tacc = 1.0\n","epoch 1\tavg epoch loss = 0.05207\tavg epoch acc = 0.9838\n","batch 100\tloss = 0.01543\tacc = 1.0\n","batch 200\tloss = 0.09866\tacc = 0.9844\n","batch 300\tloss = 0.04226\tacc = 0.9844\n","batch 400\tloss = 0.001441\tacc = 1.0\n","epoch 2\tavg epoch loss = 0.03439\tavg epoch acc = 0.9899\n","batch 100\tloss = 0.008184\tacc = 1.0\n","batch 200\tloss = 0.08595\tacc = 0.9844\n","batch 300\tloss = 0.03442\tacc = 0.9844\n","batch 400\tloss = 0.0008632\tacc = 1.0\n","epoch 3\tavg epoch loss = 0.0252\tavg epoch acc = 0.9929\n","batch 100\tloss = 0.005902\tacc = 1.0\n","batch 200\tloss = 0.07282\tacc = 0.9844\n","batch 300\tloss = 0.03281\tacc = 0.9844\n","batch 400\tloss = 0.0005941\tacc = 1.0\n","epoch 4\tavg epoch loss = 0.0189\tavg epoch acc = 0.9948\n","batch 100\tloss = 0.008805\tacc = 0.9922\n","batch 200\tloss = 0.06125\tacc = 0.9766\n","batch 300\tloss = 0.03049\tacc = 0.9844\n","batch 400\tloss = 0.0004151\tacc = 1.0\n","epoch 5\tavg epoch loss = 0.0143\tavg epoch acc = 0.9961\n","batch 100\tloss = 0.01059\tacc = 0.9922\n","batch 200\tloss = 0.04787\tacc = 0.9766\n","batch 300\tloss = 0.02871\tacc = 0.9844\n","batch 400\tloss = 0.0003885\tacc = 1.0\n","epoch 6\tavg epoch loss = 0.01068\tavg epoch acc = 0.9974\n","batch 100\tloss = 0.006552\tacc = 1.0\n","batch 200\tloss = 0.03549\tacc = 0.9844\n","batch 300\tloss = 0.02717\tacc = 0.9844\n","batch 400\tloss = 0.0004033\tacc = 1.0\n","epoch 7\tavg epoch loss = 0.008093\tavg epoch acc = 0.9982\n","batch 100\tloss = 0.003565\tacc = 1.0\n","batch 200\tloss = 0.02073\tacc = 0.9844\n","batch 300\tloss = 0.02166\tacc = 0.9922\n","batch 400\tloss = 0.0005596\tacc = 1.0\n","epoch 8\tavg epoch loss = 0.006094\tavg epoch acc = 0.9987\n","batch 100\tloss = 0.002047\tacc = 1.0\n","batch 200\tloss = 0.01543\tacc = 0.9922\n","batch 300\tloss = 0.0155\tacc = 0.9922\n","batch 400\tloss = 0.0005971\tacc = 1.0\n","epoch 9\tavg epoch loss = 0.004691\tavg epoch acc = 0.9991\n","training took 14.2 s\n","Avg test loss = 0.0442\tAvg test acc = 0.988\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"PM2opkkMTC5D"},"source":["## Attack naive models"],"id":"PM2opkkMTC5D"},{"cell_type":"code","metadata":{"id":"B6wX6BPXTC5D","executionInfo":{"status":"ok","timestamp":1623616168519,"user_tz":-120,"elapsed":16,"user":{"displayName":"Baris Sevilmis","photoUrl":"","userId":"05631870087761794056"}}},"source":["from adversary import attack"],"id":"B6wX6BPXTC5D","execution_count":33,"outputs":[]},{"cell_type":"code","metadata":{"id":"MrOvET6zTC5D","executionInfo":{"status":"ok","timestamp":1623616168519,"user_tz":-120,"elapsed":15,"user":{"displayName":"Baris Sevilmis","photoUrl":"","userId":"05631870087761794056"}}},"source":["epsilons = np.arange(0, 0.5, 0.05)"],"id":"MrOvET6zTC5D","execution_count":34,"outputs":[]},{"cell_type":"code","metadata":{"id":"xMPRU4x6TC5D","executionInfo":{"status":"ok","timestamp":1623616168846,"user_tz":-120,"elapsed":4,"user":{"displayName":"Baris Sevilmis","photoUrl":"","userId":"05631870087761794056"}}},"source":["# use the lst_optimizer\n","# Only one optimizer used in this part?"],"id":"xMPRU4x6TC5D","execution_count":35,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Pf2OYPFsTC5E"},"source":["### Adam"],"id":"Pf2OYPFsTC5E"},{"cell_type":"code","metadata":{"id":"Hu7pNd_HTC5E","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623616171456,"user_tz":-120,"elapsed":2613,"user":{"displayName":"Baris Sevilmis","photoUrl":"","userId":"05631870087761794056"}},"outputId":"b5682f68-f536-4edd-f6c5-757e1117048e"},"source":["accuracy_naive_adam= []\n","losses_naive_adam= []\n","\n","for eps in epsilons:\n","    loss_attack, acc_attack  = attack(net_naive_adam, training_config['loss_fun'],training_config['metric_fun'], test_loader, epsilon=eps, device=device)\n","    accuracy_naive_adam.append(acc_attack)\n","    losses_naive_adam.append(loss_attack)"],"id":"Hu7pNd_HTC5E","execution_count":36,"outputs":[{"output_type":"stream","text":["Epsilon: 0.00\tTest Accuracy = 0.970\n","Epsilon: 0.05\tTest Accuracy = 0.965\n","Epsilon: 0.10\tTest Accuracy = 0.956\n","Epsilon: 0.15\tTest Accuracy = 0.947\n","Epsilon: 0.20\tTest Accuracy = 0.932\n","Epsilon: 0.25\tTest Accuracy = 0.916\n","Epsilon: 0.30\tTest Accuracy = 0.891\n","Epsilon: 0.35\tTest Accuracy = 0.855\n","Epsilon: 0.40\tTest Accuracy = 0.809\n","Epsilon: 0.45\tTest Accuracy = 0.745\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"bpjf-wgDTC5E"},"source":["### Nesterov"],"id":"bpjf-wgDTC5E"},{"cell_type":"code","metadata":{"id":"dPVWZPnSTC5E","executionInfo":{"status":"ok","timestamp":1623616171457,"user_tz":-120,"elapsed":4,"user":{"displayName":"Baris Sevilmis","photoUrl":"","userId":"05631870087761794056"}}},"source":["data_naive = list()\n","\n","for optimizer, network in naive_networks.items():\n","    print(f'--- {optimizer}')\n","    \n","    for eps in epsilons:\n","        loss_attack, acc_attack = attack(\n","            model=network, \n","            loss_fun=training_config['loss_fun'],\n","            test_loader=test_loader, \n","            epsilon=eps, \n","            device=training_config['loss_fun']\n","        )\n","        # Log\n","        data_naive.append({\n","            'optimizer': str(optimizer),\n","            'epsilon': eps,\n","            'loss': loss_attack,\n","            'acc': acc_attack\n","        })"],"id":"dPVWZPnSTC5E","execution_count":37,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JmX-0IG4TC5E"},"source":["### Minibatch (for now, loop later)"],"id":"JmX-0IG4TC5E"},{"cell_type":"code","metadata":{"id":"ypKAQIMETC5E","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623616174149,"user_tz":-120,"elapsed":2695,"user":{"displayName":"Baris Sevilmis","photoUrl":"","userId":"05631870087761794056"}},"outputId":"078c2e82-ea2b-4ec0-a24b-f86ad3d13f98"},"source":["accuracy_naive= []\n","losses_naive= []\n","\n","for eps in epsilons:\n","    loss_attack, acc_attack  = attack(net_naive_mini,  training_config['loss_fun'],training_config['metric_fun'], test_loader, epsilon=eps, device=device)\n","    accuracy_naive.append(acc_attack)\n","    losses_naive.append(loss_attack)"],"id":"ypKAQIMETC5E","execution_count":38,"outputs":[{"output_type":"stream","text":["Epsilon: 0.00\tTest Accuracy = 0.969\n","Epsilon: 0.05\tTest Accuracy = 0.963\n","Epsilon: 0.10\tTest Accuracy = 0.954\n","Epsilon: 0.15\tTest Accuracy = 0.944\n","Epsilon: 0.20\tTest Accuracy = 0.933\n","Epsilon: 0.25\tTest Accuracy = 0.915\n","Epsilon: 0.30\tTest Accuracy = 0.888\n","Epsilon: 0.35\tTest Accuracy = 0.854\n","Epsilon: 0.40\tTest Accuracy = 0.805\n","Epsilon: 0.45\tTest Accuracy = 0.743\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"xOu0V6AjTC5F"},"source":["## Comparison"],"id":"xOu0V6AjTC5F"},{"cell_type":"markdown","metadata":{"id":"eQCOdFFQTC5F"},"source":["# Attack on robust model"],"id":"eQCOdFFQTC5F"},{"cell_type":"markdown","metadata":{"id":"La4ABLV5gCOd"},"source":["## Hyperparameter optimization on robust models\n","\n","- Set hyperparameter tuning for robust models:\n","-- True, in case you want to get tuned hyperparameters.\n","-- False, by default. If you want to tryout, we have already processed it and got the same results out.\n"],"id":"La4ABLV5gCOd"},{"cell_type":"code","metadata":{"id":"DkqBVJufgg-z","colab":{"base_uri":"https://localhost:8080/","height":351},"executionInfo":{"status":"error","timestamp":1623617263506,"user_tz":-120,"elapsed":228,"user":{"displayName":"Baris Sevilmis","photoUrl":"","userId":"05631870087761794056"}},"outputId":"f6b4fdd5-0490-47a7-88f7-80319364fa38"},"source":["prot_optimizers = {\n","    AdamOptimizer: get_best_hyperparams('./res/prot_adam_tuning.json'),\n","    NesterovOptimizer: get_best_hyperparams('./res/prot_nesterov_tuning.json'),\n","    MiniBatchOptimizer: get_best_hyperparams('./res/prot_minibatch_tuning.json')\n","}"],"id":"DkqBVJufgg-z","execution_count":2,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"B-JYd7t8oyOt"},"source":["### Adam"],"id":"B-JYd7t8oyOt"},{"cell_type":"code","metadata":{"id":"1-LkqzEzgBbH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623627106131,"user_tz":-120,"elapsed":9830369,"user":{"displayName":"Baris Sevilmis","photoUrl":"","userId":"05631870087761794056"}},"outputId":"8e866013-c4cc-4fe5-c1f6-99220cfc624c"},"source":["search_grid_adam = {\n","        'lr': np.linspace(0.001, 0.01, 2),\n","        'beta1':  np.linspace(0.1, 0.9, 2),\n","        'beta2': np.linspace(0.5, 0.999, 2),\n","        'batch_size': [32, 64, 128],\n","        'weight_decay': np.linspace(0.001, 0.1, 2),\n","        'epsilon': np.linspace(1e-10, 1e-8, 2),\n","    }\n","\n","if prot_hyperparameter_tune:\n","    results_adam_prot = tune_optimizer(\n","        model=Net().to(device),\n","        optim_fun=AdamOptimizer,\n","        xtrain=train_dataset.data,\n","        ytrain=train_dataset.targets,\n","        search_grid=search_grid_adam,\n","        nfolds=3,\n","        func=protected_training,\n","        **training_config)\n","\n","else:\n","    results_adam_prot = optimizers[AdamOptimizer]"],"id":"1-LkqzEzgBbH","execution_count":40,"outputs":[{"output_type":"stream","text":["Launching hyperparameter tuning:\n","\tlr = [0.001 0.01 ]\n","\tbeta1 = [0.1 0.9]\n","\tbeta2 = [0.5   0.999]\n","\tbatch_size = [32, 64, 128]\n","\tweight_decay = [0.001 0.1  ]\n","\tepsilon = [1.e-10 1.e-08]\n","{'lr': 0.001, 'beta1': 0.1, 'beta2': 0.5, 'batch_size': 32, 'weight_decay': 0.001, 'epsilon': 1e-10}\n","Epoch 0\tavg epoch Loss = 0.2438\tavg epoch acc = 0.9275\n","Epoch 1\tavg epoch Loss = 0.09376\tavg epoch acc = 0.6452\n","Epoch 2\tavg epoch Loss = 0.07647\tavg epoch acc = 0.1528\n","Epoch 3\tavg epoch Loss = 0.07911\tavg epoch acc = 0.1184\n","Epoch 4\tavg epoch Loss = 0.07892\tavg epoch acc = 0.1192\n","Epoch 5\tavg epoch Loss = 0.08224\tavg epoch acc = 0.1398\n","Epoch 6\tavg epoch Loss = 0.08445\tavg epoch acc = 0.2138\n","Epoch 7\tavg epoch Loss = 0.0906\tavg epoch acc = 0.2257\n","Epoch 8\tavg epoch Loss = 0.08997\tavg epoch acc = 0.1785\n","Epoch 9\tavg epoch Loss = 0.09514\tavg epoch acc = 0.2173\n","training took 54.68 s\n","Avg test loss = 1.68e+03\tAvg test acc = 0.204\n","Epoch 0\tavg epoch Loss = 0.2485\tavg epoch acc = 0.9345\n","Epoch 1\tavg epoch Loss = 0.09958\tavg epoch acc = 0.7869\n","Epoch 2\tavg epoch Loss = 0.07919\tavg epoch acc = 0.3891\n","Epoch 3\tavg epoch Loss = 0.08093\tavg epoch acc = 0.3961\n","Epoch 4\tavg epoch Loss = 0.08434\tavg epoch acc = 0.4123\n","Epoch 5\tavg epoch Loss = 0.08629\tavg epoch acc = 0.3817\n","Epoch 6\tavg epoch Loss = 0.09744\tavg epoch acc = 0.2493\n","Epoch 7\tavg epoch Loss = 0.1069\tavg epoch acc = 0.2222\n","Epoch 8\tavg epoch Loss = 0.1129\tavg epoch acc = 0.1899\n","Epoch 9\tavg epoch Loss = 0.1163\tavg epoch acc = 0.2149\n","training took 54.73 s\n","Avg test loss = 1.83e+03\tAvg test acc = 0.245\n","Epoch 0\tavg epoch Loss = 0.2534\tavg epoch acc = 0.9293\n","Epoch 1\tavg epoch Loss = 0.1017\tavg epoch acc = 0.7124\n","Epoch 2\tavg epoch Loss = 0.08227\tavg epoch acc = 0.4092\n","Epoch 3\tavg epoch Loss = 0.08418\tavg epoch acc = 0.3356\n","Epoch 4\tavg epoch Loss = 0.09011\tavg epoch acc = 0.3023\n","Epoch 5\tavg epoch Loss = 0.09781\tavg epoch acc = 0.2166\n","Epoch 6\tavg epoch Loss = 0.1006\tavg epoch acc = 0.2009\n","Epoch 7\tavg epoch Loss = 0.11\tavg epoch acc = 0.2097\n","Epoch 8\tavg epoch Loss = 0.1185\tavg epoch acc = 0.2059\n","Epoch 9\tavg epoch Loss = 0.1197\tavg epoch acc = 0.1855\n","training took 54.5 s\n","Avg test loss = 2.13e+03\tAvg test acc = 0.193\n","{'lr': 0.001, 'beta1': 0.1, 'beta2': 0.5, 'batch_size': 32, 'weight_decay': 0.001, 'epsilon': 1e-08}\n","Epoch 0\tavg epoch Loss = 0.248\tavg epoch acc = 0.9213\n","Epoch 1\tavg epoch Loss = 0.1042\tavg epoch acc = 0.809\n","Epoch 2\tavg epoch Loss = 0.07998\tavg epoch acc = 0.4966\n","Epoch 3\tavg epoch Loss = 0.07513\tavg epoch acc = 0.2843\n","Epoch 4\tavg epoch Loss = 0.07739\tavg epoch acc = 0.345\n","Epoch 5\tavg epoch Loss = 0.0823\tavg epoch acc = 0.3255\n","Epoch 6\tavg epoch Loss = 0.08738\tavg epoch acc = 0.4124\n","Epoch 7\tavg epoch Loss = 0.09096\tavg epoch acc = 0.4082\n","Epoch 8\tavg epoch Loss = 0.09444\tavg epoch acc = 0.3488\n","Epoch 9\tavg epoch Loss = 0.09849\tavg epoch acc = 0.3221\n","training took 54.39 s\n","Avg test loss = 5.38e+02\tAvg test acc = 0.434\n","Epoch 0\tavg epoch Loss = 0.248\tavg epoch acc = 0.9299\n","Epoch 1\tavg epoch Loss = 0.09943\tavg epoch acc = 0.7219\n","Epoch 2\tavg epoch Loss = 0.08214\tavg epoch acc = 0.3947\n","Epoch 3\tavg epoch Loss = 0.07828\tavg epoch acc = 0.3829\n","Epoch 4\tavg epoch Loss = 0.08069\tavg epoch acc = 0.4124\n","Epoch 5\tavg epoch Loss = 0.08181\tavg epoch acc = 0.4229\n","Epoch 6\tavg epoch Loss = 0.09402\tavg epoch acc = 0.4253\n","Epoch 7\tavg epoch Loss = 0.0984\tavg epoch acc = 0.4016\n","Epoch 8\tavg epoch Loss = 0.09842\tavg epoch acc = 0.4311\n","Epoch 9\tavg epoch Loss = 0.111\tavg epoch acc = 0.4191\n","training took 54.36 s\n","Avg test loss = 7.75e+02\tAvg test acc = 0.4\n","Epoch 0\tavg epoch Loss = 0.2467\tavg epoch acc = 0.9294\n","Epoch 1\tavg epoch Loss = 0.09928\tavg epoch acc = 0.7768\n","Epoch 2\tavg epoch Loss = 0.07882\tavg epoch acc = 0.3587\n","Epoch 3\tavg epoch Loss = 0.07609\tavg epoch acc = 0.2186\n","Epoch 4\tavg epoch Loss = 0.07968\tavg epoch acc = 0.2137\n","Epoch 5\tavg epoch Loss = 0.08097\tavg epoch acc = 0.1915\n","Epoch 6\tavg epoch Loss = 0.08817\tavg epoch acc = 0.2086\n","Epoch 7\tavg epoch Loss = 0.08659\tavg epoch acc = 0.2058\n","Epoch 8\tavg epoch Loss = 0.0883\tavg epoch acc = 0.2052\n","Epoch 9\tavg epoch Loss = 0.09034\tavg epoch acc = 0.1702\n","training took 54.59 s\n","Avg test loss = 8.92e+02\tAvg test acc = 0.216\n","{'lr': 0.001, 'beta1': 0.1, 'beta2': 0.5, 'batch_size': 32, 'weight_decay': 0.1, 'epsilon': 1e-10}\n","Epoch 0\tavg epoch Loss = 0.2505\tavg epoch acc = 0.9278\n","Epoch 1\tavg epoch Loss = 0.1011\tavg epoch acc = 0.8035\n","Epoch 2\tavg epoch Loss = 0.07747\tavg epoch acc = 0.43\n","Epoch 3\tavg epoch Loss = 0.07302\tavg epoch acc = 0.2061\n","Epoch 4\tavg epoch Loss = 0.07425\tavg epoch acc = 0.2479\n","Epoch 5\tavg epoch Loss = 0.07135\tavg epoch acc = 0.2354\n","Epoch 6\tavg epoch Loss = 0.07556\tavg epoch acc = 0.322\n","Epoch 7\tavg epoch Loss = 0.07369\tavg epoch acc = 0.3671\n","Epoch 8\tavg epoch Loss = 0.07568\tavg epoch acc = 0.4341\n","Epoch 9\tavg epoch Loss = 0.0755\tavg epoch acc = 0.4517\n","training took 54.81 s\n","Avg test loss = 2.3e+02\tAvg test acc = 0.426\n","Epoch 0\tavg epoch Loss = 0.2505\tavg epoch acc = 0.9302\n","Epoch 1\tavg epoch Loss = 0.1059\tavg epoch acc = 0.8779\n","Epoch 2\tavg epoch Loss = 0.07679\tavg epoch acc = 0.5752\n","Epoch 3\tavg epoch Loss = 0.06894\tavg epoch acc = 0.3\n","Epoch 4\tavg epoch Loss = 0.07184\tavg epoch acc = 0.2662\n","Epoch 5\tavg epoch Loss = 0.06865\tavg epoch acc = 0.2109\n","Epoch 6\tavg epoch Loss = 0.07007\tavg epoch acc = 0.1946\n","Epoch 7\tavg epoch Loss = 0.06959\tavg epoch acc = 0.1939\n","Epoch 8\tavg epoch Loss = 0.06632\tavg epoch acc = 0.1853\n","Epoch 9\tavg epoch Loss = 0.07645\tavg epoch acc = 0.499\n","training took 54.51 s\n","Avg test loss = 1.22e+02\tAvg test acc = 0.551\n","Epoch 0\tavg epoch Loss = 0.2492\tavg epoch acc = 0.9366\n","Epoch 1\tavg epoch Loss = 0.1019\tavg epoch acc = 0.8411\n","Epoch 2\tavg epoch Loss = 0.07972\tavg epoch acc = 0.5638\n","Epoch 3\tavg epoch Loss = 0.07494\tavg epoch acc = 0.4734\n","Epoch 4\tavg epoch Loss = 0.07118\tavg epoch acc = 0.4713\n","Epoch 5\tavg epoch Loss = 0.07092\tavg epoch acc = 0.4909\n","Epoch 6\tavg epoch Loss = 0.07204\tavg epoch acc = 0.4552\n","Epoch 7\tavg epoch Loss = 0.07757\tavg epoch acc = 0.4734\n","Epoch 8\tavg epoch Loss = 0.07814\tavg epoch acc = 0.541\n","Epoch 9\tavg epoch Loss = 0.07767\tavg epoch acc = 0.5352\n","training took 54.73 s\n","Avg test loss = 85.8\tAvg test acc = 0.526\n","{'lr': 0.001, 'beta1': 0.1, 'beta2': 0.5, 'batch_size': 32, 'weight_decay': 0.1, 'epsilon': 1e-08}\n","Epoch 0\tavg epoch Loss = 0.2498\tavg epoch acc = 0.9289\n","Epoch 1\tavg epoch Loss = 0.1021\tavg epoch acc = 0.8283\n","Epoch 2\tavg epoch Loss = 0.07637\tavg epoch acc = 0.4553\n","Epoch 3\tavg epoch Loss = 0.07181\tavg epoch acc = 0.2568\n","Epoch 4\tavg epoch Loss = 0.07259\tavg epoch acc = 0.2922\n","Epoch 5\tavg epoch Loss = 0.07759\tavg epoch acc = 0.4\n","Epoch 6\tavg epoch Loss = 0.07965\tavg epoch acc = 0.5143\n","Epoch 7\tavg epoch Loss = 0.08035\tavg epoch acc = 0.4959\n","Epoch 8\tavg epoch Loss = 0.07668\tavg epoch acc = 0.5307\n","Epoch 9\tavg epoch Loss = 0.07698\tavg epoch acc = 0.5491\n","training took 54.96 s\n","Avg test loss = 97.5\tAvg test acc = 0.568\n","Epoch 0\tavg epoch Loss = 0.2507\tavg epoch acc = 0.937\n","Epoch 1\tavg epoch Loss = 0.1015\tavg epoch acc = 0.8268\n","Epoch 2\tavg epoch Loss = 0.07504\tavg epoch acc = 0.4332\n","Epoch 3\tavg epoch Loss = 0.06828\tavg epoch acc = 0.2422\n","Epoch 4\tavg epoch Loss = 0.06498\tavg epoch acc = 0.2292\n","Epoch 5\tavg epoch Loss = 0.06416\tavg epoch acc = 0.1955\n","Epoch 6\tavg epoch Loss = 0.06533\tavg epoch acc = 0.2114\n","Epoch 7\tavg epoch Loss = 0.06384\tavg epoch acc = 0.263\n","Epoch 8\tavg epoch Loss = 0.06708\tavg epoch acc = 0.3362\n","Epoch 9\tavg epoch Loss = 0.06217\tavg epoch acc = 0.2997\n","training took 54.31 s\n","Avg test loss = 1.44e+02\tAvg test acc = 0.302\n","Epoch 0\tavg epoch Loss = 0.2492\tavg epoch acc = 0.939\n","Epoch 1\tavg epoch Loss = 0.09761\tavg epoch acc = 0.7997\n","Epoch 2\tavg epoch Loss = 0.077\tavg epoch acc = 0.5565\n","Epoch 3\tavg epoch Loss = 0.07256\tavg epoch acc = 0.4664\n","Epoch 4\tavg epoch Loss = 0.06789\tavg epoch acc = 0.507\n","Epoch 5\tavg epoch Loss = 0.07094\tavg epoch acc = 0.5493\n","Epoch 6\tavg epoch Loss = 0.06835\tavg epoch acc = 0.5223\n","Epoch 7\tavg epoch Loss = 0.06942\tavg epoch acc = 0.4974\n","Epoch 8\tavg epoch Loss = 0.06861\tavg epoch acc = 0.4465\n","Epoch 9\tavg epoch Loss = 0.06792\tavg epoch acc = 0.3534\n","training took 54.66 s\n","Avg test loss = 1.11e+02\tAvg test acc = 0.51\n","{'lr': 0.001, 'beta1': 0.1, 'beta2': 0.5, 'batch_size': 64, 'weight_decay': 0.001, 'epsilon': 1e-10}\n","Epoch 0\tavg epoch Loss = 0.3015\tavg epoch acc = 0.9293\n","Epoch 1\tavg epoch Loss = 0.1091\tavg epoch acc = 0.9687\n","Epoch 2\tavg epoch Loss = 0.07934\tavg epoch acc = 0.9197\n","Epoch 3\tavg epoch Loss = 0.06048\tavg epoch acc = 0.7012\n","Epoch 4\tavg epoch Loss = 0.04863\tavg epoch acc = 0.4853\n","Epoch 5\tavg epoch Loss = 0.04426\tavg epoch acc = 0.3726\n","Epoch 6\tavg epoch Loss = 0.04124\tavg epoch acc = 0.3049\n","Epoch 7\tavg epoch Loss = 0.03917\tavg epoch acc = 0.284\n","Epoch 8\tavg epoch Loss = 0.04033\tavg epoch acc = 0.3032\n","Epoch 9\tavg epoch Loss = 0.03894\tavg epoch acc = 0.3897\n","training took 28.54 s\n","Avg test loss = 8.08e+02\tAvg test acc = 0.277\n","Epoch 0\tavg epoch Loss = 0.3084\tavg epoch acc = 0.9186\n","Epoch 1\tavg epoch Loss = 0.112\tavg epoch acc = 0.9575\n","Epoch 2\tavg epoch Loss = 0.08119\tavg epoch acc = 0.8775\n","Epoch 3\tavg epoch Loss = 0.06197\tavg epoch acc = 0.6531\n","Epoch 4\tavg epoch Loss = 0.05389\tavg epoch acc = 0.4166\n","Epoch 5\tavg epoch Loss = 0.05128\tavg epoch acc = 0.257\n","Epoch 6\tavg epoch Loss = 0.05252\tavg epoch acc = 0.1908\n","Epoch 7\tavg epoch Loss = 0.0504\tavg epoch acc = 0.2496\n","Epoch 8\tavg epoch Loss = 0.05206\tavg epoch acc = 0.2701\n","Epoch 9\tavg epoch Loss = 0.04906\tavg epoch acc = 0.2364\n","training took 28.41 s\n","Avg test loss = 8.2e+02\tAvg test acc = 0.291\n","Epoch 0\tavg epoch Loss = 0.3009\tavg epoch acc = 0.9225\n","Epoch 1\tavg epoch Loss = 0.1085\tavg epoch acc = 0.9536\n","Epoch 2\tavg epoch Loss = 0.07912\tavg epoch acc = 0.8984\n","Epoch 3\tavg epoch Loss = 0.05987\tavg epoch acc = 0.6896\n","Epoch 4\tavg epoch Loss = 0.05113\tavg epoch acc = 0.526\n","Epoch 5\tavg epoch Loss = 0.04852\tavg epoch acc = 0.3784\n","Epoch 6\tavg epoch Loss = 0.04528\tavg epoch acc = 0.3025\n","Epoch 7\tavg epoch Loss = 0.04508\tavg epoch acc = 0.2779\n","Epoch 8\tavg epoch Loss = 0.04748\tavg epoch acc = 0.3085\n","Epoch 9\tavg epoch Loss = 0.04796\tavg epoch acc = 0.2911\n","training took 28.23 s\n","Avg test loss = 6.17e+02\tAvg test acc = 0.33\n","{'lr': 0.001, 'beta1': 0.1, 'beta2': 0.5, 'batch_size': 64, 'weight_decay': 0.001, 'epsilon': 1e-08}\n","Epoch 0\tavg epoch Loss = 0.3001\tavg epoch acc = 0.9245\n","Epoch 1\tavg epoch Loss = 0.1072\tavg epoch acc = 0.9554\n","Epoch 2\tavg epoch Loss = 0.07808\tavg epoch acc = 0.8804\n","Epoch 3\tavg epoch Loss = 0.06155\tavg epoch acc = 0.6277\n","Epoch 4\tavg epoch Loss = 0.05382\tavg epoch acc = 0.3677\n","Epoch 5\tavg epoch Loss = 0.05182\tavg epoch acc = 0.2888\n","Epoch 6\tavg epoch Loss = 0.05367\tavg epoch acc = 0.3422\n","Epoch 7\tavg epoch Loss = 0.0557\tavg epoch acc = 0.3884\n","Epoch 8\tavg epoch Loss = 0.05685\tavg epoch acc = 0.3908\n","Epoch 9\tavg epoch Loss = 0.05489\tavg epoch acc = 0.3426\n","training took 28.32 s\n","Avg test loss = 5.5e+02\tAvg test acc = 0.43\n","Epoch 0\tavg epoch Loss = 0.3025\tavg epoch acc = 0.9226\n","Epoch 1\tavg epoch Loss = 0.1027\tavg epoch acc = 0.9477\n","Epoch 2\tavg epoch Loss = 0.07074\tavg epoch acc = 0.8439\n","Epoch 3\tavg epoch Loss = 0.05448\tavg epoch acc = 0.6248\n","Epoch 4\tavg epoch Loss = 0.04741\tavg epoch acc = 0.4613\n","Epoch 5\tavg epoch Loss = 0.04481\tavg epoch acc = 0.3557\n","Epoch 6\tavg epoch Loss = 0.04641\tavg epoch acc = 0.3406\n","Epoch 7\tavg epoch Loss = 0.04839\tavg epoch acc = 0.2694\n","Epoch 8\tavg epoch Loss = 0.04678\tavg epoch acc = 0.2713\n","Epoch 9\tavg epoch Loss = 0.0487\tavg epoch acc = 0.2433\n","training took 28.39 s\n","Avg test loss = 1.25e+03\tAvg test acc = 0.269\n","Epoch 0\tavg epoch Loss = 0.3027\tavg epoch acc = 0.9269\n","Epoch 1\tavg epoch Loss = 0.1125\tavg epoch acc = 0.9706\n","Epoch 2\tavg epoch Loss = 0.08011\tavg epoch acc = 0.9301\n","Epoch 3\tavg epoch Loss = 0.06028\tavg epoch acc = 0.7219\n","Epoch 4\tavg epoch Loss = 0.04979\tavg epoch acc = 0.5878\n","Epoch 5\tavg epoch Loss = 0.04735\tavg epoch acc = 0.5327\n","Epoch 6\tavg epoch Loss = 0.04572\tavg epoch acc = 0.5453\n","Epoch 7\tavg epoch Loss = 0.04398\tavg epoch acc = 0.5313\n","Epoch 8\tavg epoch Loss = 0.0435\tavg epoch acc = 0.4446\n","Epoch 9\tavg epoch Loss = 0.04124\tavg epoch acc = 0.4285\n","training took 28.69 s\n","Avg test loss = 3.59e+02\tAvg test acc = 0.523\n","{'lr': 0.001, 'beta1': 0.1, 'beta2': 0.5, 'batch_size': 64, 'weight_decay': 0.1, 'epsilon': 1e-10}\n","Epoch 0\tavg epoch Loss = 0.3063\tavg epoch acc = 0.922\n","Epoch 1\tavg epoch Loss = 0.1109\tavg epoch acc = 0.9607\n","Epoch 2\tavg epoch Loss = 0.07935\tavg epoch acc = 0.8979\n","Epoch 3\tavg epoch Loss = 0.06139\tavg epoch acc = 0.7411\n","Epoch 4\tavg epoch Loss = 0.05197\tavg epoch acc = 0.5586\n","Epoch 5\tavg epoch Loss = 0.04769\tavg epoch acc = 0.4639\n","Epoch 6\tavg epoch Loss = 0.04539\tavg epoch acc = 0.4117\n","Epoch 7\tavg epoch Loss = 0.04402\tavg epoch acc = 0.422\n","Epoch 8\tavg epoch Loss = 0.04145\tavg epoch acc = 0.3941\n","Epoch 9\tavg epoch Loss = 0.03746\tavg epoch acc = 0.3258\n","training took 28.79 s\n","Avg test loss = 2.61e+02\tAvg test acc = 0.272\n","Epoch 0\tavg epoch Loss = 0.3046\tavg epoch acc = 0.925\n","Epoch 1\tavg epoch Loss = 0.1127\tavg epoch acc = 0.9683\n","Epoch 2\tavg epoch Loss = 0.08223\tavg epoch acc = 0.9462\n","Epoch 3\tavg epoch Loss = 0.06365\tavg epoch acc = 0.8128\n","Epoch 4\tavg epoch Loss = 0.05161\tavg epoch acc = 0.6436\n","Epoch 5\tavg epoch Loss = 0.04827\tavg epoch acc = 0.5891\n","Epoch 6\tavg epoch Loss = 0.04355\tavg epoch acc = 0.4963\n","Epoch 7\tavg epoch Loss = 0.04066\tavg epoch acc = 0.4552\n","Epoch 8\tavg epoch Loss = 0.03975\tavg epoch acc = 0.2852\n","Epoch 9\tavg epoch Loss = 0.04077\tavg epoch acc = 0.2594\n","training took 28.55 s\n","Avg test loss = 2.5e+02\tAvg test acc = 0.303\n","Epoch 0\tavg epoch Loss = 0.3044\tavg epoch acc = 0.9204\n","Epoch 1\tavg epoch Loss = 0.11\tavg epoch acc = 0.9553\n","Epoch 2\tavg epoch Loss = 0.08002\tavg epoch acc = 0.8806\n","Epoch 3\tavg epoch Loss = 0.06036\tavg epoch acc = 0.6237\n","Epoch 4\tavg epoch Loss = 0.052\tavg epoch acc = 0.3674\n","Epoch 5\tavg epoch Loss = 0.04804\tavg epoch acc = 0.269\n","Epoch 6\tavg epoch Loss = 0.04529\tavg epoch acc = 0.1925\n","Epoch 7\tavg epoch Loss = 0.04293\tavg epoch acc = 0.1642\n","Epoch 8\tavg epoch Loss = 0.04242\tavg epoch acc = 0.1681\n","Epoch 9\tavg epoch Loss = 0.04209\tavg epoch acc = 0.1947\n","training took 28.37 s\n","Avg test loss = 3.34e+02\tAvg test acc = 0.201\n","{'lr': 0.001, 'beta1': 0.1, 'beta2': 0.5, 'batch_size': 64, 'weight_decay': 0.1, 'epsilon': 1e-08}\n","Epoch 0\tavg epoch Loss = 0.303\tavg epoch acc = 0.9253\n","Epoch 1\tavg epoch Loss = 0.1101\tavg epoch acc = 0.9671\n","Epoch 2\tavg epoch Loss = 0.07827\tavg epoch acc = 0.9237\n","Epoch 3\tavg epoch Loss = 0.05889\tavg epoch acc = 0.7251\n","Epoch 4\tavg epoch Loss = 0.0489\tavg epoch acc = 0.6003\n","Epoch 5\tavg epoch Loss = 0.04441\tavg epoch acc = 0.5507\n","Epoch 6\tavg epoch Loss = 0.04075\tavg epoch acc = 0.4682\n","Epoch 7\tavg epoch Loss = 0.04175\tavg epoch acc = 0.5249\n","Epoch 8\tavg epoch Loss = 0.04035\tavg epoch acc = 0.5568\n","Epoch 9\tavg epoch Loss = 0.03835\tavg epoch acc = 0.5484\n","training took 28.47 s\n","Avg test loss = 1.36e+02\tAvg test acc = 0.534\n","Epoch 0\tavg epoch Loss = 0.306\tavg epoch acc = 0.9283\n","Epoch 1\tavg epoch Loss = 0.1128\tavg epoch acc = 0.9692\n","Epoch 2\tavg epoch Loss = 0.08221\tavg epoch acc = 0.9483\n","Epoch 3\tavg epoch Loss = 0.06063\tavg epoch acc = 0.767\n","Epoch 4\tavg epoch Loss = 0.04832\tavg epoch acc = 0.4251\n","Epoch 5\tavg epoch Loss = 0.04337\tavg epoch acc = 0.2551\n","Epoch 6\tavg epoch Loss = 0.04109\tavg epoch acc = 0.2275\n","Epoch 7\tavg epoch Loss = 0.03889\tavg epoch acc = 0.2304\n","Epoch 8\tavg epoch Loss = 0.03881\tavg epoch acc = 0.2457\n","Epoch 9\tavg epoch Loss = 0.03712\tavg epoch acc = 0.2469\n","training took 28.57 s\n","Avg test loss = 2.94e+02\tAvg test acc = 0.203\n","Epoch 0\tavg epoch Loss = 0.3037\tavg epoch acc = 0.9163\n","Epoch 1\tavg epoch Loss = 0.1086\tavg epoch acc = 0.9481\n","Epoch 2\tavg epoch Loss = 0.08061\tavg epoch acc = 0.9213\n","Epoch 3\tavg epoch Loss = 0.06143\tavg epoch acc = 0.7736\n","Epoch 4\tavg epoch Loss = 0.05023\tavg epoch acc = 0.571\n","Epoch 5\tavg epoch Loss = 0.04551\tavg epoch acc = 0.4515\n","Epoch 6\tavg epoch Loss = 0.04184\tavg epoch acc = 0.4017\n","Epoch 7\tavg epoch Loss = 0.03908\tavg epoch acc = 0.3406\n","Epoch 8\tavg epoch Loss = 0.03682\tavg epoch acc = 0.3459\n","Epoch 9\tavg epoch Loss = 0.03541\tavg epoch acc = 0.3464\n","training took 29.15 s\n","Avg test loss = 1.62e+02\tAvg test acc = 0.412\n","{'lr': 0.001, 'beta1': 0.1, 'beta2': 0.5, 'batch_size': 128, 'weight_decay': 0.001, 'epsilon': 1e-10}\n","Epoch 0\tavg epoch Loss = 0.4058\tavg epoch acc = 0.9022\n","Epoch 1\tavg epoch Loss = 0.1291\tavg epoch acc = 0.9695\n","Epoch 2\tavg epoch Loss = 0.09249\tavg epoch acc = 0.9748\n","Epoch 3\tavg epoch Loss = 0.07403\tavg epoch acc = 0.9764\n","Epoch 4\tavg epoch Loss = 0.06116\tavg epoch acc = 0.9736\n","Epoch 5\tavg epoch Loss = 0.04889\tavg epoch acc = 0.9593\n","Epoch 6\tavg epoch Loss = 0.04005\tavg epoch acc = 0.9223\n","Epoch 7\tavg epoch Loss = 0.03241\tavg epoch acc = 0.8717\n","Epoch 8\tavg epoch Loss = 0.02754\tavg epoch acc = 0.8004\n","Epoch 9\tavg epoch Loss = 0.02174\tavg epoch acc = 0.7378\n","training took 18.23 s\n","Avg test loss = 30.3\tAvg test acc = 0.719\n","Epoch 0\tavg epoch Loss = 0.4074\tavg epoch acc = 0.9002\n","Epoch 1\tavg epoch Loss = 0.1257\tavg epoch acc = 0.9668\n","Epoch 2\tavg epoch Loss = 0.08875\tavg epoch acc = 0.969\n","Epoch 3\tavg epoch Loss = 0.06959\tavg epoch acc = 0.9664\n","Epoch 4\tavg epoch Loss = 0.05492\tavg epoch acc = 0.9499\n","Epoch 5\tavg epoch Loss = 0.04363\tavg epoch acc = 0.9079\n","Epoch 6\tavg epoch Loss = 0.03453\tavg epoch acc = 0.8175\n","Epoch 7\tavg epoch Loss = 0.02909\tavg epoch acc = 0.7481\n","Epoch 8\tavg epoch Loss = 0.02561\tavg epoch acc = 0.6602\n","Epoch 9\tavg epoch Loss = 0.0231\tavg epoch acc = 0.6173\n","training took 18.02 s\n","Avg test loss = 55.2\tAvg test acc = 0.63\n","Epoch 0\tavg epoch Loss = 0.4003\tavg epoch acc = 0.9032\n","Epoch 1\tavg epoch Loss = 0.1247\tavg epoch acc = 0.9652\n","Epoch 2\tavg epoch Loss = 0.08657\tavg epoch acc = 0.9635\n","Epoch 3\tavg epoch Loss = 0.06651\tavg epoch acc = 0.9514\n","Epoch 4\tavg epoch Loss = 0.05252\tavg epoch acc = 0.9148\n","Epoch 5\tavg epoch Loss = 0.04192\tavg epoch acc = 0.8161\n","Epoch 6\tavg epoch Loss = 0.03401\tavg epoch acc = 0.6996\n","Epoch 7\tavg epoch Loss = 0.02842\tavg epoch acc = 0.61\n","Epoch 8\tavg epoch Loss = 0.02417\tavg epoch acc = 0.4871\n","Epoch 9\tavg epoch Loss = 0.02057\tavg epoch acc = 0.4225\n","training took 18.03 s\n","Avg test loss = 1.58e+02\tAvg test acc = 0.439\n","{'lr': 0.001, 'beta1': 0.1, 'beta2': 0.5, 'batch_size': 128, 'weight_decay': 0.001, 'epsilon': 1e-08}\n","Epoch 0\tavg epoch Loss = 0.4037\tavg epoch acc = 0.9032\n","Epoch 1\tavg epoch Loss = 0.1304\tavg epoch acc = 0.9691\n","Epoch 2\tavg epoch Loss = 0.09356\tavg epoch acc = 0.975\n","Epoch 3\tavg epoch Loss = 0.07448\tavg epoch acc = 0.9785\n","Epoch 4\tavg epoch Loss = 0.06057\tavg epoch acc = 0.9759\n","Epoch 5\tavg epoch Loss = 0.04953\tavg epoch acc = 0.9622\n","Epoch 6\tavg epoch Loss = 0.04024\tavg epoch acc = 0.9178\n","Epoch 7\tavg epoch Loss = 0.03185\tavg epoch acc = 0.8443\n","Epoch 8\tavg epoch Loss = 0.02654\tavg epoch acc = 0.7679\n","Epoch 9\tavg epoch Loss = 0.02189\tavg epoch acc = 0.7114\n","training took 18.04 s\n","Avg test loss = 30.4\tAvg test acc = 0.698\n","Epoch 0\tavg epoch Loss = 0.4048\tavg epoch acc = 0.9017\n","Epoch 1\tavg epoch Loss = 0.1251\tavg epoch acc = 0.9674\n","Epoch 2\tavg epoch Loss = 0.08974\tavg epoch acc = 0.9736\n","Epoch 3\tavg epoch Loss = 0.07041\tavg epoch acc = 0.9761\n","Epoch 4\tavg epoch Loss = 0.05736\tavg epoch acc = 0.9712\n","Epoch 5\tavg epoch Loss = 0.04648\tavg epoch acc = 0.958\n","Epoch 6\tavg epoch Loss = 0.03938\tavg epoch acc = 0.9276\n","Epoch 7\tavg epoch Loss = 0.03215\tavg epoch acc = 0.8527\n","Epoch 8\tavg epoch Loss = 0.02699\tavg epoch acc = 0.7794\n","Epoch 9\tavg epoch Loss = 0.02342\tavg epoch acc = 0.7284\n","training took 18.04 s\n","Avg test loss = 51.3\tAvg test acc = 0.637\n","Epoch 0\tavg epoch Loss = 0.4048\tavg epoch acc = 0.902\n","Epoch 1\tavg epoch Loss = 0.1267\tavg epoch acc = 0.9682\n","Epoch 2\tavg epoch Loss = 0.08996\tavg epoch acc = 0.9728\n","Epoch 3\tavg epoch Loss = 0.07068\tavg epoch acc = 0.9704\n","Epoch 4\tavg epoch Loss = 0.05603\tavg epoch acc = 0.9565\n","Epoch 5\tavg epoch Loss = 0.0458\tavg epoch acc = 0.894\n","Epoch 6\tavg epoch Loss = 0.03634\tavg epoch acc = 0.8069\n","Epoch 7\tavg epoch Loss = 0.02954\tavg epoch acc = 0.7154\n","Epoch 8\tavg epoch Loss = 0.02393\tavg epoch acc = 0.6129\n","Epoch 9\tavg epoch Loss = 0.02022\tavg epoch acc = 0.5429\n","training took 18.09 s\n","Avg test loss = 75.5\tAvg test acc = 0.537\n","{'lr': 0.001, 'beta1': 0.1, 'beta2': 0.5, 'batch_size': 128, 'weight_decay': 0.1, 'epsilon': 1e-10}\n","Epoch 0\tavg epoch Loss = 0.4008\tavg epoch acc = 0.9015\n","Epoch 1\tavg epoch Loss = 0.1282\tavg epoch acc = 0.9671\n","Epoch 2\tavg epoch Loss = 0.09284\tavg epoch acc = 0.9744\n","Epoch 3\tavg epoch Loss = 0.07408\tavg epoch acc = 0.9769\n","Epoch 4\tavg epoch Loss = 0.06166\tavg epoch acc = 0.9741\n","Epoch 5\tavg epoch Loss = 0.05193\tavg epoch acc = 0.9572\n","Epoch 6\tavg epoch Loss = 0.04375\tavg epoch acc = 0.9156\n","Epoch 7\tavg epoch Loss = 0.03726\tavg epoch acc = 0.8353\n","Epoch 8\tavg epoch Loss = 0.03199\tavg epoch acc = 0.7776\n","Epoch 9\tavg epoch Loss = 0.02835\tavg epoch acc = 0.7411\n","training took 18.08 s\n","Avg test loss = 20.7\tAvg test acc = 0.764\n","Epoch 0\tavg epoch Loss = 0.4107\tavg epoch acc = 0.9007\n","Epoch 1\tavg epoch Loss = 0.1283\tavg epoch acc = 0.9683\n","Epoch 2\tavg epoch Loss = 0.09091\tavg epoch acc = 0.9751\n","Epoch 3\tavg epoch Loss = 0.07195\tavg epoch acc = 0.9774\n","Epoch 4\tavg epoch Loss = 0.0592\tavg epoch acc = 0.9772\n","Epoch 5\tavg epoch Loss = 0.04949\tavg epoch acc = 0.9687\n","Epoch 6\tavg epoch Loss = 0.04152\tavg epoch acc = 0.9503\n","Epoch 7\tavg epoch Loss = 0.03638\tavg epoch acc = 0.9188\n","Epoch 8\tavg epoch Loss = 0.03027\tavg epoch acc = 0.8674\n","Epoch 9\tavg epoch Loss = 0.02611\tavg epoch acc = 0.817\n","training took 18.22 s\n","Avg test loss = 11.1\tAvg test acc = 0.801\n","Epoch 0\tavg epoch Loss = 0.4058\tavg epoch acc = 0.9019\n","Epoch 1\tavg epoch Loss = 0.1288\tavg epoch acc = 0.9686\n","Epoch 2\tavg epoch Loss = 0.09239\tavg epoch acc = 0.9731\n","Epoch 3\tavg epoch Loss = 0.07201\tavg epoch acc = 0.9731\n","Epoch 4\tavg epoch Loss = 0.05783\tavg epoch acc = 0.967\n","Epoch 5\tavg epoch Loss = 0.04756\tavg epoch acc = 0.9508\n","Epoch 6\tavg epoch Loss = 0.03977\tavg epoch acc = 0.9135\n","Epoch 7\tavg epoch Loss = 0.03279\tavg epoch acc = 0.8727\n","Epoch 8\tavg epoch Loss = 0.02817\tavg epoch acc = 0.7928\n","Epoch 9\tavg epoch Loss = 0.02421\tavg epoch acc = 0.7127\n","training took 18.15 s\n","Avg test loss = 19.7\tAvg test acc = 0.704\n","{'lr': 0.001, 'beta1': 0.1, 'beta2': 0.5, 'batch_size': 128, 'weight_decay': 0.1, 'epsilon': 1e-08}\n","Epoch 0\tavg epoch Loss = 0.4043\tavg epoch acc = 0.899\n","Epoch 1\tavg epoch Loss = 0.1281\tavg epoch acc = 0.9637\n","Epoch 2\tavg epoch Loss = 0.08949\tavg epoch acc = 0.9652\n","Epoch 3\tavg epoch Loss = 0.06959\tavg epoch acc = 0.9636\n","Epoch 4\tavg epoch Loss = 0.05597\tavg epoch acc = 0.9577\n","Epoch 5\tavg epoch Loss = 0.04685\tavg epoch acc = 0.9382\n","Epoch 6\tavg epoch Loss = 0.03843\tavg epoch acc = 0.8925\n","Epoch 7\tavg epoch Loss = 0.03271\tavg epoch acc = 0.838\n","Epoch 8\tavg epoch Loss = 0.0277\tavg epoch acc = 0.7736\n","Epoch 9\tavg epoch Loss = 0.02394\tavg epoch acc = 0.6894\n","training took 18.12 s\n","Avg test loss = 35.9\tAvg test acc = 0.668\n","Epoch 0\tavg epoch Loss = 0.4118\tavg epoch acc = 0.9003\n","Epoch 1\tavg epoch Loss = 0.1334\tavg epoch acc = 0.9646\n","Epoch 2\tavg epoch Loss = 0.09521\tavg epoch acc = 0.9711\n","Epoch 3\tavg epoch Loss = 0.07493\tavg epoch acc = 0.9709\n","Epoch 4\tavg epoch Loss = 0.0602\tavg epoch acc = 0.9582\n","Epoch 5\tavg epoch Loss = 0.04932\tavg epoch acc = 0.9259\n","Epoch 6\tavg epoch Loss = 0.03939\tavg epoch acc = 0.8461\n","Epoch 7\tavg epoch Loss = 0.03443\tavg epoch acc = 0.762\n","Epoch 8\tavg epoch Loss = 0.03031\tavg epoch acc = 0.7056\n","Epoch 9\tavg epoch Loss = 0.02608\tavg epoch acc = 0.6218\n","training took 18.06 s\n","Avg test loss = 32.8\tAvg test acc = 0.637\n","Epoch 0\tavg epoch Loss = 0.4043\tavg epoch acc = 0.9046\n","Epoch 1\tavg epoch Loss = 0.1266\tavg epoch acc = 0.9689\n","Epoch 2\tavg epoch Loss = 0.09115\tavg epoch acc = 0.9757\n","Epoch 3\tavg epoch Loss = 0.07275\tavg epoch acc = 0.9788\n","Epoch 4\tavg epoch Loss = 0.06024\tavg epoch acc = 0.9774\n","Epoch 5\tavg epoch Loss = 0.0505\tavg epoch acc = 0.9708\n","Epoch 6\tavg epoch Loss = 0.04246\tavg epoch acc = 0.9584\n","Epoch 7\tavg epoch Loss = 0.03722\tavg epoch acc = 0.9364\n","Epoch 8\tavg epoch Loss = 0.03206\tavg epoch acc = 0.8946\n","Epoch 9\tavg epoch Loss = 0.02825\tavg epoch acc = 0.8696\n","training took 18.06 s\n","Avg test loss = 3.68\tAvg test acc = 0.895\n","{'lr': 0.001, 'beta1': 0.1, 'beta2': 0.999, 'batch_size': 32, 'weight_decay': 0.001, 'epsilon': 1e-10}\n","Epoch 0\tavg epoch Loss = 0.5775\tavg epoch acc = 0.836\n","Epoch 1\tavg epoch Loss = 0.1404\tavg epoch acc = 0.9659\n","Epoch 2\tavg epoch Loss = 0.09471\tavg epoch acc = 0.9765\n","Epoch 3\tavg epoch Loss = 0.06775\tavg epoch acc = 0.9815\n","Epoch 4\tavg epoch Loss = 0.04956\tavg epoch acc = 0.9826\n","Epoch 5\tavg epoch Loss = 0.03862\tavg epoch acc = 0.982\n","Epoch 6\tavg epoch Loss = 0.02901\tavg epoch acc = 0.9808\n","Epoch 7\tavg epoch Loss = 0.02427\tavg epoch acc = 0.9782\n","Epoch 8\tavg epoch Loss = 0.02038\tavg epoch acc = 0.9787\n","Epoch 9\tavg epoch Loss = 0.01776\tavg epoch acc = 0.9694\n","training took 55.07 s\n","Avg test loss = 0.378\tAvg test acc = 0.952\n","Epoch 0\tavg epoch Loss = 0.5832\tavg epoch acc = 0.8318\n","Epoch 1\tavg epoch Loss = 0.1421\tavg epoch acc = 0.9665\n","Epoch 2\tavg epoch Loss = 0.09592\tavg epoch acc = 0.9792\n","Epoch 3\tavg epoch Loss = 0.06837\tavg epoch acc = 0.9847\n","Epoch 4\tavg epoch Loss = 0.05026\tavg epoch acc = 0.9862\n","Epoch 5\tavg epoch Loss = 0.03994\tavg epoch acc = 0.9859\n","Epoch 6\tavg epoch Loss = 0.03067\tavg epoch acc = 0.9835\n","Epoch 7\tavg epoch Loss = 0.02439\tavg epoch acc = 0.9815\n","Epoch 8\tavg epoch Loss = 0.02039\tavg epoch acc = 0.9784\n","Epoch 9\tavg epoch Loss = 0.01637\tavg epoch acc = 0.9732\n","training took 54.96 s\n","Avg test loss = 0.344\tAvg test acc = 0.964\n","Epoch 0\tavg epoch Loss = 0.584\tavg epoch acc = 0.8318\n","Epoch 1\tavg epoch Loss = 0.1436\tavg epoch acc = 0.9656\n","Epoch 2\tavg epoch Loss = 0.09838\tavg epoch acc = 0.9795\n","Epoch 3\tavg epoch Loss = 0.06913\tavg epoch acc = 0.985\n","Epoch 4\tavg epoch Loss = 0.05182\tavg epoch acc = 0.9858\n","Epoch 5\tavg epoch Loss = 0.03784\tavg epoch acc = 0.9851\n","Epoch 6\tavg epoch Loss = 0.03047\tavg epoch acc = 0.9825\n","Epoch 7\tavg epoch Loss = 0.02403\tavg epoch acc = 0.9768\n","Epoch 8\tavg epoch Loss = 0.02001\tavg epoch acc = 0.9707\n","Epoch 9\tavg epoch Loss = 0.01658\tavg epoch acc = 0.964\n","training took 54.81 s\n","Avg test loss = 0.431\tAvg test acc = 0.958\n","{'lr': 0.001, 'beta1': 0.1, 'beta2': 0.999, 'batch_size': 32, 'weight_decay': 0.001, 'epsilon': 1e-08}\n","Epoch 0\tavg epoch Loss = 0.5813\tavg epoch acc = 0.8327\n","Epoch 1\tavg epoch Loss = 0.1407\tavg epoch acc = 0.9647\n","Epoch 2\tavg epoch Loss = 0.0956\tavg epoch acc = 0.9768\n","Epoch 3\tavg epoch Loss = 0.06918\tavg epoch acc = 0.9818\n","Epoch 4\tavg epoch Loss = 0.0511\tavg epoch acc = 0.982\n","Epoch 5\tavg epoch Loss = 0.03881\tavg epoch acc = 0.9821\n","Epoch 6\tavg epoch Loss = 0.03116\tavg epoch acc = 0.9807\n","Epoch 7\tavg epoch Loss = 0.02483\tavg epoch acc = 0.9793\n","Epoch 8\tavg epoch Loss = 0.02054\tavg epoch acc = 0.9752\n","Epoch 9\tavg epoch Loss = 0.01667\tavg epoch acc = 0.9731\n","training took 55.31 s\n","Avg test loss = 0.321\tAvg test acc = 0.962\n","Epoch 0\tavg epoch Loss = 0.5864\tavg epoch acc = 0.8357\n","Epoch 1\tavg epoch Loss = 0.1398\tavg epoch acc = 0.9662\n","Epoch 2\tavg epoch Loss = 0.09237\tavg epoch acc = 0.978\n","Epoch 3\tavg epoch Loss = 0.06533\tavg epoch acc = 0.9828\n","Epoch 4\tavg epoch Loss = 0.04916\tavg epoch acc = 0.9829\n","Epoch 5\tavg epoch Loss = 0.03807\tavg epoch acc = 0.9809\n","Epoch 6\tavg epoch Loss = 0.02819\tavg epoch acc = 0.9797\n","Epoch 7\tavg epoch Loss = 0.02438\tavg epoch acc = 0.9767\n","Epoch 8\tavg epoch Loss = 0.01921\tavg epoch acc = 0.9742\n","Epoch 9\tavg epoch Loss = 0.01644\tavg epoch acc = 0.9688\n","training took 56.07 s\n","Avg test loss = 0.334\tAvg test acc = 0.952\n","Epoch 0\tavg epoch Loss = 0.5856\tavg epoch acc = 0.834\n","Epoch 1\tavg epoch Loss = 0.1402\tavg epoch acc = 0.9679\n","Epoch 2\tavg epoch Loss = 0.09487\tavg epoch acc = 0.9788\n","Epoch 3\tavg epoch Loss = 0.06763\tavg epoch acc = 0.9838\n","Epoch 4\tavg epoch Loss = 0.0486\tavg epoch acc = 0.9861\n","Epoch 5\tavg epoch Loss = 0.03961\tavg epoch acc = 0.9854\n","Epoch 6\tavg epoch Loss = 0.03015\tavg epoch acc = 0.9833\n","Epoch 7\tavg epoch Loss = 0.02386\tavg epoch acc = 0.9811\n","Epoch 8\tavg epoch Loss = 0.01965\tavg epoch acc = 0.9768\n","Epoch 9\tavg epoch Loss = 0.01714\tavg epoch acc = 0.9728\n","training took 54.83 s\n","Avg test loss = 0.34\tAvg test acc = 0.945\n","{'lr': 0.001, 'beta1': 0.1, 'beta2': 0.999, 'batch_size': 32, 'weight_decay': 0.1, 'epsilon': 1e-10}\n","Epoch 0\tavg epoch Loss = 0.5872\tavg epoch acc = 0.8312\n","Epoch 1\tavg epoch Loss = 0.1479\tavg epoch acc = 0.9671\n","Epoch 2\tavg epoch Loss = 0.1023\tavg epoch acc = 0.9791\n","Epoch 3\tavg epoch Loss = 0.07596\tavg epoch acc = 0.9842\n","Epoch 4\tavg epoch Loss = 0.05972\tavg epoch acc = 0.9857\n","Epoch 5\tavg epoch Loss = 0.04782\tavg epoch acc = 0.9876\n","Epoch 6\tavg epoch Loss = 0.04016\tavg epoch acc = 0.9887\n","Epoch 7\tavg epoch Loss = 0.0343\tavg epoch acc = 0.9883\n","Epoch 8\tavg epoch Loss = 0.03032\tavg epoch acc = 0.9882\n","Epoch 9\tavg epoch Loss = 0.02798\tavg epoch acc = 0.9867\n","training took 55.13 s\n","Avg test loss = 0.157\tAvg test acc = 0.975\n","Epoch 0\tavg epoch Loss = 0.5875\tavg epoch acc = 0.8318\n","Epoch 1\tavg epoch Loss = 0.1469\tavg epoch acc = 0.9669\n","Epoch 2\tavg epoch Loss = 0.101\tavg epoch acc = 0.9783\n","Epoch 3\tavg epoch Loss = 0.07583\tavg epoch acc = 0.981\n","Epoch 4\tavg epoch Loss = 0.05849\tavg epoch acc = 0.9825\n","Epoch 5\tavg epoch Loss = 0.04649\tavg epoch acc = 0.9829\n","Epoch 6\tavg epoch Loss = 0.04066\tavg epoch acc = 0.985\n","Epoch 7\tavg epoch Loss = 0.03164\tavg epoch acc = 0.9852\n","Epoch 8\tavg epoch Loss = 0.03037\tavg epoch acc = 0.9858\n","Epoch 9\tavg epoch Loss = 0.02638\tavg epoch acc = 0.9867\n","training took 54.7 s\n","Avg test loss = 0.126\tAvg test acc = 0.98\n","Epoch 0\tavg epoch Loss = 0.581\tavg epoch acc = 0.8376\n","Epoch 1\tavg epoch Loss = 0.1427\tavg epoch acc = 0.9699\n","Epoch 2\tavg epoch Loss = 0.0997\tavg epoch acc = 0.9811\n","Epoch 3\tavg epoch Loss = 0.07282\tavg epoch acc = 0.9844\n","Epoch 4\tavg epoch Loss = 0.05703\tavg epoch acc = 0.9855\n","Epoch 5\tavg epoch Loss = 0.04494\tavg epoch acc = 0.9856\n","Epoch 6\tavg epoch Loss = 0.03773\tavg epoch acc = 0.9851\n","Epoch 7\tavg epoch Loss = 0.03161\tavg epoch acc = 0.984\n","Epoch 8\tavg epoch Loss = 0.02816\tavg epoch acc = 0.9848\n","Epoch 9\tavg epoch Loss = 0.02464\tavg epoch acc = 0.9861\n","training took 54.83 s\n","Avg test loss = 0.169\tAvg test acc = 0.976\n","{'lr': 0.001, 'beta1': 0.1, 'beta2': 0.999, 'batch_size': 32, 'weight_decay': 0.1, 'epsilon': 1e-08}\n","Epoch 0\tavg epoch Loss = 0.5871\tavg epoch acc = 0.8346\n","Epoch 1\tavg epoch Loss = 0.1462\tavg epoch acc = 0.9692\n","Epoch 2\tavg epoch Loss = 0.1017\tavg epoch acc = 0.9802\n","Epoch 3\tavg epoch Loss = 0.07626\tavg epoch acc = 0.9843\n","Epoch 4\tavg epoch Loss = 0.05902\tavg epoch acc = 0.9857\n","Epoch 5\tavg epoch Loss = 0.046\tavg epoch acc = 0.9859\n","Epoch 6\tavg epoch Loss = 0.03917\tavg epoch acc = 0.9863\n","Epoch 7\tavg epoch Loss = 0.03355\tavg epoch acc = 0.9859\n","Epoch 8\tavg epoch Loss = 0.02756\tavg epoch acc = 0.9878\n","Epoch 9\tavg epoch Loss = 0.02667\tavg epoch acc = 0.9864\n","training took 54.99 s\n","Avg test loss = 0.152\tAvg test acc = 0.977\n","Epoch 0\tavg epoch Loss = 0.587\tavg epoch acc = 0.8325\n","Epoch 1\tavg epoch Loss = 0.146\tavg epoch acc = 0.965\n","Epoch 2\tavg epoch Loss = 0.1004\tavg epoch acc = 0.9769\n","Epoch 3\tavg epoch Loss = 0.07432\tavg epoch acc = 0.9798\n","Epoch 4\tavg epoch Loss = 0.05809\tavg epoch acc = 0.9815\n","Epoch 5\tavg epoch Loss = 0.04725\tavg epoch acc = 0.9799\n","Epoch 6\tavg epoch Loss = 0.03818\tavg epoch acc = 0.9807\n","Epoch 7\tavg epoch Loss = 0.03306\tavg epoch acc = 0.982\n","Epoch 8\tavg epoch Loss = 0.02851\tavg epoch acc = 0.983\n","Epoch 9\tavg epoch Loss = 0.02547\tavg epoch acc = 0.9828\n","training took 56.13 s\n","Avg test loss = 0.161\tAvg test acc = 0.975\n","Epoch 0\tavg epoch Loss = 0.5822\tavg epoch acc = 0.8335\n","Epoch 1\tavg epoch Loss = 0.1408\tavg epoch acc = 0.9696\n","Epoch 2\tavg epoch Loss = 0.09796\tavg epoch acc = 0.9807\n","Epoch 3\tavg epoch Loss = 0.07311\tavg epoch acc = 0.9846\n","Epoch 4\tavg epoch Loss = 0.05782\tavg epoch acc = 0.9865\n","Epoch 5\tavg epoch Loss = 0.04679\tavg epoch acc = 0.9872\n","Epoch 6\tavg epoch Loss = 0.03924\tavg epoch acc = 0.9872\n","Epoch 7\tavg epoch Loss = 0.03234\tavg epoch acc = 0.9876\n","Epoch 8\tavg epoch Loss = 0.02918\tavg epoch acc = 0.9877\n","Epoch 9\tavg epoch Loss = 0.02475\tavg epoch acc = 0.9878\n","training took 56.38 s\n","Avg test loss = 0.136\tAvg test acc = 0.979\n","{'lr': 0.001, 'beta1': 0.1, 'beta2': 0.999, 'batch_size': 64, 'weight_decay': 0.001, 'epsilon': 1e-10}\n","Epoch 0\tavg epoch Loss = 0.8684\tavg epoch acc = 0.7527\n","Epoch 1\tavg epoch Loss = 0.1926\tavg epoch acc = 0.9524\n","Epoch 2\tavg epoch Loss = 0.1263\tavg epoch acc = 0.971\n","Epoch 3\tavg epoch Loss = 0.09494\tavg epoch acc = 0.9792\n","Epoch 4\tavg epoch Loss = 0.07467\tavg epoch acc = 0.9843\n","Epoch 5\tavg epoch Loss = 0.05865\tavg epoch acc = 0.9876\n","Epoch 6\tavg epoch Loss = 0.04658\tavg epoch acc = 0.9906\n","Epoch 7\tavg epoch Loss = 0.04042\tavg epoch acc = 0.9908\n","Epoch 8\tavg epoch Loss = 0.03221\tavg epoch acc = 0.9922\n","Epoch 9\tavg epoch Loss = 0.02768\tavg epoch acc = 0.9921\n","training took 29.38 s\n","Avg test loss = 0.139\tAvg test acc = 0.982\n","Epoch 0\tavg epoch Loss = 0.8779\tavg epoch acc = 0.7479\n","Epoch 1\tavg epoch Loss = 0.1952\tavg epoch acc = 0.953\n","Epoch 2\tavg epoch Loss = 0.1267\tavg epoch acc = 0.9679\n","Epoch 3\tavg epoch Loss = 0.096\tavg epoch acc = 0.9762\n","Epoch 4\tavg epoch Loss = 0.07511\tavg epoch acc = 0.9824\n","Epoch 5\tavg epoch Loss = 0.06061\tavg epoch acc = 0.9863\n","Epoch 6\tavg epoch Loss = 0.04996\tavg epoch acc = 0.9889\n","Epoch 7\tavg epoch Loss = 0.04145\tavg epoch acc = 0.9905\n","Epoch 8\tavg epoch Loss = 0.03388\tavg epoch acc = 0.9908\n","Epoch 9\tavg epoch Loss = 0.02962\tavg epoch acc = 0.9911\n","training took 29.23 s\n","Avg test loss = 0.139\tAvg test acc = 0.984\n","Epoch 0\tavg epoch Loss = 0.8734\tavg epoch acc = 0.7476\n","Epoch 1\tavg epoch Loss = 0.1903\tavg epoch acc = 0.95\n","Epoch 2\tavg epoch Loss = 0.124\tavg epoch acc = 0.9703\n","Epoch 3\tavg epoch Loss = 0.09387\tavg epoch acc = 0.9776\n","Epoch 4\tavg epoch Loss = 0.07432\tavg epoch acc = 0.9829\n","Epoch 5\tavg epoch Loss = 0.05844\tavg epoch acc = 0.9869\n","Epoch 6\tavg epoch Loss = 0.04817\tavg epoch acc = 0.9889\n","Epoch 7\tavg epoch Loss = 0.03925\tavg epoch acc = 0.9904\n","Epoch 8\tavg epoch Loss = 0.03552\tavg epoch acc = 0.9909\n","Epoch 9\tavg epoch Loss = 0.03075\tavg epoch acc = 0.992\n","training took 29.34 s\n","Avg test loss = 0.219\tAvg test acc = 0.979\n","{'lr': 0.001, 'beta1': 0.1, 'beta2': 0.999, 'batch_size': 64, 'weight_decay': 0.001, 'epsilon': 1e-08}\n","Epoch 0\tavg epoch Loss = 0.8714\tavg epoch acc = 0.7488\n","Epoch 1\tavg epoch Loss = 0.1978\tavg epoch acc = 0.9504\n","Epoch 2\tavg epoch Loss = 0.1307\tavg epoch acc = 0.969\n","Epoch 3\tavg epoch Loss = 0.0967\tavg epoch acc = 0.9769\n","Epoch 4\tavg epoch Loss = 0.07648\tavg epoch acc = 0.9822\n","Epoch 5\tavg epoch Loss = 0.06097\tavg epoch acc = 0.9865\n","Epoch 6\tavg epoch Loss = 0.04829\tavg epoch acc = 0.9898\n","Epoch 7\tavg epoch Loss = 0.04063\tavg epoch acc = 0.9908\n","Epoch 8\tavg epoch Loss = 0.03256\tavg epoch acc = 0.9919\n","Epoch 9\tavg epoch Loss = 0.02977\tavg epoch acc = 0.9926\n","training took 29.97 s\n","Avg test loss = 0.15\tAvg test acc = 0.982\n","Epoch 0\tavg epoch Loss = 0.8726\tavg epoch acc = 0.753\n","Epoch 1\tavg epoch Loss = 0.19\tavg epoch acc = 0.9535\n","Epoch 2\tavg epoch Loss = 0.126\tavg epoch acc = 0.9697\n","Epoch 3\tavg epoch Loss = 0.09474\tavg epoch acc = 0.9771\n","Epoch 4\tavg epoch Loss = 0.07554\tavg epoch acc = 0.9824\n","Epoch 5\tavg epoch Loss = 0.06116\tavg epoch acc = 0.9861\n","Epoch 6\tavg epoch Loss = 0.05088\tavg epoch acc = 0.9883\n","Epoch 7\tavg epoch Loss = 0.04113\tavg epoch acc = 0.9901\n","Epoch 8\tavg epoch Loss = 0.03519\tavg epoch acc = 0.9899\n","Epoch 9\tavg epoch Loss = 0.02763\tavg epoch acc = 0.9913\n","training took 29.25 s\n","Avg test loss = 0.191\tAvg test acc = 0.981\n","Epoch 0\tavg epoch Loss = 0.8738\tavg epoch acc = 0.747\n","Epoch 1\tavg epoch Loss = 0.1923\tavg epoch acc = 0.9509\n","Epoch 2\tavg epoch Loss = 0.1248\tavg epoch acc = 0.9716\n","Epoch 3\tavg epoch Loss = 0.09429\tavg epoch acc = 0.9798\n","Epoch 4\tavg epoch Loss = 0.07213\tavg epoch acc = 0.9838\n","Epoch 5\tavg epoch Loss = 0.05722\tavg epoch acc = 0.9862\n","Epoch 6\tavg epoch Loss = 0.04825\tavg epoch acc = 0.988\n","Epoch 7\tavg epoch Loss = 0.03993\tavg epoch acc = 0.989\n","Epoch 8\tavg epoch Loss = 0.03153\tavg epoch acc = 0.9908\n","Epoch 9\tavg epoch Loss = 0.02768\tavg epoch acc = 0.991\n","training took 28.88 s\n","Avg test loss = 0.138\tAvg test acc = 0.983\n","{'lr': 0.001, 'beta1': 0.1, 'beta2': 0.999, 'batch_size': 64, 'weight_decay': 0.1, 'epsilon': 1e-10}\n","Epoch 0\tavg epoch Loss = 0.8749\tavg epoch acc = 0.7481\n","Epoch 1\tavg epoch Loss = 0.1895\tavg epoch acc = 0.9546\n","Epoch 2\tavg epoch Loss = 0.1269\tavg epoch acc = 0.9711\n","Epoch 3\tavg epoch Loss = 0.097\tavg epoch acc = 0.9779\n","Epoch 4\tavg epoch Loss = 0.07729\tavg epoch acc = 0.9824\n","Epoch 5\tavg epoch Loss = 0.06931\tavg epoch acc = 0.9858\n","Epoch 6\tavg epoch Loss = 0.05203\tavg epoch acc = 0.9889\n","Epoch 7\tavg epoch Loss = 0.04409\tavg epoch acc = 0.9901\n","Epoch 8\tavg epoch Loss = 0.03665\tavg epoch acc = 0.9913\n","Epoch 9\tavg epoch Loss = 0.03337\tavg epoch acc = 0.9919\n","training took 29.22 s\n","Avg test loss = 0.209\tAvg test acc = 0.974\n","Epoch 0\tavg epoch Loss = 0.875\tavg epoch acc = 0.7514\n","Epoch 1\tavg epoch Loss = 0.1974\tavg epoch acc = 0.9535\n","Epoch 2\tavg epoch Loss = 0.1283\tavg epoch acc = 0.9714\n","Epoch 3\tavg epoch Loss = 0.09823\tavg epoch acc = 0.9775\n","Epoch 4\tavg epoch Loss = 0.07851\tavg epoch acc = 0.9819\n","Epoch 5\tavg epoch Loss = 0.06496\tavg epoch acc = 0.9852\n","Epoch 6\tavg epoch Loss = 0.05469\tavg epoch acc = 0.9879\n","Epoch 7\tavg epoch Loss = 0.04533\tavg epoch acc = 0.9893\n","Epoch 8\tavg epoch Loss = 0.03841\tavg epoch acc = 0.9906\n","Epoch 9\tavg epoch Loss = 0.03385\tavg epoch acc = 0.9914\n","training took 29.66 s\n","Avg test loss = 0.0886\tAvg test acc = 0.987\n","Epoch 0\tavg epoch Loss = 0.8611\tavg epoch acc = 0.7481\n","Epoch 1\tavg epoch Loss = 0.1945\tavg epoch acc = 0.951\n","Epoch 2\tavg epoch Loss = 0.1288\tavg epoch acc = 0.9699\n","Epoch 3\tavg epoch Loss = 0.09968\tavg epoch acc = 0.9778\n","Epoch 4\tavg epoch Loss = 0.07737\tavg epoch acc = 0.9834\n","Epoch 5\tavg epoch Loss = 0.06318\tavg epoch acc = 0.9865\n","Epoch 6\tavg epoch Loss = 0.05167\tavg epoch acc = 0.989\n","Epoch 7\tavg epoch Loss = 0.04286\tavg epoch acc = 0.9904\n","Epoch 8\tavg epoch Loss = 0.03899\tavg epoch acc = 0.991\n","Epoch 9\tavg epoch Loss = 0.03422\tavg epoch acc = 0.9915\n","training took 30.01 s\n","Avg test loss = 0.107\tAvg test acc = 0.984\n","{'lr': 0.001, 'beta1': 0.1, 'beta2': 0.999, 'batch_size': 64, 'weight_decay': 0.1, 'epsilon': 1e-08}\n","Epoch 0\tavg epoch Loss = 0.8731\tavg epoch acc = 0.7499\n","Epoch 1\tavg epoch Loss = 0.1951\tavg epoch acc = 0.9524\n","Epoch 2\tavg epoch Loss = 0.1301\tavg epoch acc = 0.9697\n","Epoch 3\tavg epoch Loss = 0.09917\tavg epoch acc = 0.9772\n","Epoch 4\tavg epoch Loss = 0.07894\tavg epoch acc = 0.9822\n","Epoch 5\tavg epoch Loss = 0.06559\tavg epoch acc = 0.9858\n","Epoch 6\tavg epoch Loss = 0.05327\tavg epoch acc = 0.9885\n","Epoch 7\tavg epoch Loss = 0.04687\tavg epoch acc = 0.99\n","Epoch 8\tavg epoch Loss = 0.03969\tavg epoch acc = 0.9915\n","Epoch 9\tavg epoch Loss = 0.03509\tavg epoch acc = 0.992\n","training took 29.1 s\n","Avg test loss = 0.112\tAvg test acc = 0.983\n","Epoch 0\tavg epoch Loss = 0.8728\tavg epoch acc = 0.7496\n","Epoch 1\tavg epoch Loss = 0.1957\tavg epoch acc = 0.9507\n","Epoch 2\tavg epoch Loss = 0.1305\tavg epoch acc = 0.9701\n","Epoch 3\tavg epoch Loss = 0.09951\tavg epoch acc = 0.9782\n","Epoch 4\tavg epoch Loss = 0.07824\tavg epoch acc = 0.9835\n","Epoch 5\tavg epoch Loss = 0.06342\tavg epoch acc = 0.9869\n","Epoch 6\tavg epoch Loss = 0.05311\tavg epoch acc = 0.9891\n","Epoch 7\tavg epoch Loss = 0.04358\tavg epoch acc = 0.9909\n","Epoch 8\tavg epoch Loss = 0.03785\tavg epoch acc = 0.9919\n","Epoch 9\tavg epoch Loss = 0.03548\tavg epoch acc = 0.9924\n","training took 29.03 s\n","Avg test loss = 0.123\tAvg test acc = 0.984\n","Epoch 0\tavg epoch Loss = 0.8678\tavg epoch acc = 0.7491\n","Epoch 1\tavg epoch Loss = 0.1941\tavg epoch acc = 0.9545\n","Epoch 2\tavg epoch Loss = 0.1283\tavg epoch acc = 0.9712\n","Epoch 3\tavg epoch Loss = 0.09784\tavg epoch acc = 0.9781\n","Epoch 4\tavg epoch Loss = 0.07863\tavg epoch acc = 0.9822\n","Epoch 5\tavg epoch Loss = 0.06342\tavg epoch acc = 0.9857\n","Epoch 6\tavg epoch Loss = 0.05268\tavg epoch acc = 0.9878\n","Epoch 7\tavg epoch Loss = 0.04445\tavg epoch acc = 0.9884\n","Epoch 8\tavg epoch Loss = 0.03776\tavg epoch acc = 0.9899\n","Epoch 9\tavg epoch Loss = 0.03232\tavg epoch acc = 0.9907\n","training took 28.84 s\n","Avg test loss = 0.249\tAvg test acc = 0.969\n","{'lr': 0.001, 'beta1': 0.1, 'beta2': 0.999, 'batch_size': 128, 'weight_decay': 0.001, 'epsilon': 1e-10}\n","Epoch 0\tavg epoch Loss = 1.328\tavg epoch acc = 0.6173\n","Epoch 1\tavg epoch Loss = 0.3099\tavg epoch acc = 0.9142\n","Epoch 2\tavg epoch Loss = 0.1975\tavg epoch acc = 0.9497\n","Epoch 3\tavg epoch Loss = 0.1465\tavg epoch acc = 0.9652\n","Epoch 4\tavg epoch Loss = 0.1219\tavg epoch acc = 0.9716\n","Epoch 5\tavg epoch Loss = 0.09364\tavg epoch acc = 0.9771\n","Epoch 6\tavg epoch Loss = 0.07771\tavg epoch acc = 0.9801\n","Epoch 7\tavg epoch Loss = 0.06473\tavg epoch acc = 0.9839\n","Epoch 8\tavg epoch Loss = 0.05455\tavg epoch acc = 0.9865\n","Epoch 9\tavg epoch Loss = 0.04579\tavg epoch acc = 0.9887\n","training took 17.76 s\n","Avg test loss = 0.136\tAvg test acc = 0.978\n","Epoch 0\tavg epoch Loss = 1.322\tavg epoch acc = 0.6162\n","Epoch 1\tavg epoch Loss = 0.3031\tavg epoch acc = 0.9129\n","Epoch 2\tavg epoch Loss = 0.1939\tavg epoch acc = 0.9503\n","Epoch 3\tavg epoch Loss = 0.1432\tavg epoch acc = 0.9671\n","Epoch 4\tavg epoch Loss = 0.112\tavg epoch acc = 0.9748\n","Epoch 5\tavg epoch Loss = 0.08984\tavg epoch acc = 0.9803\n","Epoch 6\tavg epoch Loss = 0.07333\tavg epoch acc = 0.9832\n","Epoch 7\tavg epoch Loss = 0.0608\tavg epoch acc = 0.9851\n","Epoch 8\tavg epoch Loss = 0.05132\tavg epoch acc = 0.9867\n","Epoch 9\tavg epoch Loss = 0.04608\tavg epoch acc = 0.9882\n","training took 17.93 s\n","Avg test loss = 0.118\tAvg test acc = 0.984\n","Epoch 0\tavg epoch Loss = 1.318\tavg epoch acc = 0.6233\n","Epoch 1\tavg epoch Loss = 0.2995\tavg epoch acc = 0.9163\n","Epoch 2\tavg epoch Loss = 0.1872\tavg epoch acc = 0.9512\n","Epoch 3\tavg epoch Loss = 0.1401\tavg epoch acc = 0.9663\n","Epoch 4\tavg epoch Loss = 0.1122\tavg epoch acc = 0.9729\n","Epoch 5\tavg epoch Loss = 0.09164\tavg epoch acc = 0.9777\n","Epoch 6\tavg epoch Loss = 0.07626\tavg epoch acc = 0.9807\n","Epoch 7\tavg epoch Loss = 0.06478\tavg epoch acc = 0.984\n","Epoch 8\tavg epoch Loss = 0.05272\tavg epoch acc = 0.9863\n","Epoch 9\tavg epoch Loss = 0.04611\tavg epoch acc = 0.9889\n","training took 18.29 s\n","Avg test loss = 0.12\tAvg test acc = 0.982\n","{'lr': 0.001, 'beta1': 0.1, 'beta2': 0.999, 'batch_size': 128, 'weight_decay': 0.001, 'epsilon': 1e-08}\n","Epoch 0\tavg epoch Loss = 1.33\tavg epoch acc = 0.6151\n","Epoch 1\tavg epoch Loss = 0.3079\tavg epoch acc = 0.9146\n","Epoch 2\tavg epoch Loss = 0.1938\tavg epoch acc = 0.9499\n","Epoch 3\tavg epoch Loss = 0.1445\tavg epoch acc = 0.9645\n","Epoch 4\tavg epoch Loss = 0.1139\tavg epoch acc = 0.9728\n","Epoch 5\tavg epoch Loss = 0.09274\tavg epoch acc = 0.9776\n","Epoch 6\tavg epoch Loss = 0.07695\tavg epoch acc = 0.9811\n","Epoch 7\tavg epoch Loss = 0.0632\tavg epoch acc = 0.984\n","Epoch 8\tavg epoch Loss = 0.05466\tavg epoch acc = 0.9862\n","Epoch 9\tavg epoch Loss = 0.04521\tavg epoch acc = 0.9873\n","training took 18.47 s\n","Avg test loss = 0.169\tAvg test acc = 0.974\n","Epoch 0\tavg epoch Loss = 1.327\tavg epoch acc = 0.6214\n","Epoch 1\tavg epoch Loss = 0.3105\tavg epoch acc = 0.9159\n","Epoch 2\tavg epoch Loss = 0.1967\tavg epoch acc = 0.9505\n","Epoch 3\tavg epoch Loss = 0.1441\tavg epoch acc = 0.9656\n","Epoch 4\tavg epoch Loss = 0.1109\tavg epoch acc = 0.9733\n","Epoch 5\tavg epoch Loss = 0.08856\tavg epoch acc = 0.9784\n","Epoch 6\tavg epoch Loss = 0.07297\tavg epoch acc = 0.9825\n","Epoch 7\tavg epoch Loss = 0.06165\tavg epoch acc = 0.985\n","Epoch 8\tavg epoch Loss = 0.05242\tavg epoch acc = 0.9879\n","Epoch 9\tavg epoch Loss = 0.04534\tavg epoch acc = 0.9885\n","training took 17.99 s\n","Avg test loss = 0.126\tAvg test acc = 0.983\n","Epoch 0\tavg epoch Loss = 1.331\tavg epoch acc = 0.6154\n","Epoch 1\tavg epoch Loss = 0.3075\tavg epoch acc = 0.9144\n","Epoch 2\tavg epoch Loss = 0.1944\tavg epoch acc = 0.9511\n","Epoch 3\tavg epoch Loss = 0.1447\tavg epoch acc = 0.967\n","Epoch 4\tavg epoch Loss = 0.1133\tavg epoch acc = 0.9743\n","Epoch 5\tavg epoch Loss = 0.09325\tavg epoch acc = 0.9794\n","Epoch 6\tavg epoch Loss = 0.07513\tavg epoch acc = 0.9818\n","Epoch 7\tavg epoch Loss = 0.06315\tavg epoch acc = 0.9848\n","Epoch 8\tavg epoch Loss = 0.05349\tavg epoch acc = 0.9871\n","Epoch 9\tavg epoch Loss = 0.0449\tavg epoch acc = 0.988\n","training took 17.77 s\n","Avg test loss = 0.138\tAvg test acc = 0.978\n","{'lr': 0.001, 'beta1': 0.1, 'beta2': 0.999, 'batch_size': 128, 'weight_decay': 0.1, 'epsilon': 1e-10}\n","Epoch 0\tavg epoch Loss = 1.318\tavg epoch acc = 0.6258\n","Epoch 1\tavg epoch Loss = 0.3002\tavg epoch acc = 0.9141\n","Epoch 2\tavg epoch Loss = 0.1898\tavg epoch acc = 0.9481\n","Epoch 3\tavg epoch Loss = 0.1425\tavg epoch acc = 0.9632\n","Epoch 4\tavg epoch Loss = 0.1142\tavg epoch acc = 0.9686\n","Epoch 5\tavg epoch Loss = 0.09449\tavg epoch acc = 0.9734\n","Epoch 6\tavg epoch Loss = 0.07847\tavg epoch acc = 0.9773\n","Epoch 7\tavg epoch Loss = 0.06611\tavg epoch acc = 0.9804\n","Epoch 8\tavg epoch Loss = 0.05629\tavg epoch acc = 0.9837\n","Epoch 9\tavg epoch Loss = 0.05556\tavg epoch acc = 0.9844\n","training took 17.7 s\n","Avg test loss = 0.139\tAvg test acc = 0.979\n","Epoch 0\tavg epoch Loss = 1.325\tavg epoch acc = 0.6159\n","Epoch 1\tavg epoch Loss = 0.3062\tavg epoch acc = 0.914\n","Epoch 2\tavg epoch Loss = 0.1898\tavg epoch acc = 0.9499\n","Epoch 3\tavg epoch Loss = 0.1405\tavg epoch acc = 0.9662\n","Epoch 4\tavg epoch Loss = 0.1111\tavg epoch acc = 0.9741\n","Epoch 5\tavg epoch Loss = 0.09175\tavg epoch acc = 0.9789\n","Epoch 6\tavg epoch Loss = 0.07673\tavg epoch acc = 0.982\n","Epoch 7\tavg epoch Loss = 0.06484\tavg epoch acc = 0.9846\n","Epoch 8\tavg epoch Loss = 0.05518\tavg epoch acc = 0.9865\n","Epoch 9\tavg epoch Loss = 0.04735\tavg epoch acc = 0.9881\n","training took 17.77 s\n","Avg test loss = 0.143\tAvg test acc = 0.977\n","Epoch 0\tavg epoch Loss = 1.327\tavg epoch acc = 0.6181\n","Epoch 1\tavg epoch Loss = 0.3034\tavg epoch acc = 0.9142\n","Epoch 2\tavg epoch Loss = 0.1928\tavg epoch acc = 0.951\n","Epoch 3\tavg epoch Loss = 0.143\tavg epoch acc = 0.966\n","Epoch 4\tavg epoch Loss = 0.1147\tavg epoch acc = 0.9741\n","Epoch 5\tavg epoch Loss = 0.09565\tavg epoch acc = 0.9786\n","Epoch 6\tavg epoch Loss = 0.08003\tavg epoch acc = 0.9821\n","Epoch 7\tavg epoch Loss = 0.06737\tavg epoch acc = 0.985\n","Epoch 8\tavg epoch Loss = 0.05789\tavg epoch acc = 0.9868\n","Epoch 9\tavg epoch Loss = 0.04816\tavg epoch acc = 0.9887\n","training took 17.78 s\n","Avg test loss = 0.119\tAvg test acc = 0.98\n","{'lr': 0.001, 'beta1': 0.1, 'beta2': 0.999, 'batch_size': 128, 'weight_decay': 0.1, 'epsilon': 1e-08}\n","Epoch 0\tavg epoch Loss = 1.326\tavg epoch acc = 0.6192\n","Epoch 1\tavg epoch Loss = 0.3125\tavg epoch acc = 0.9133\n","Epoch 2\tavg epoch Loss = 0.1934\tavg epoch acc = 0.949\n","Epoch 3\tavg epoch Loss = 0.1447\tavg epoch acc = 0.9658\n","Epoch 4\tavg epoch Loss = 0.1142\tavg epoch acc = 0.9744\n","Epoch 5\tavg epoch Loss = 0.09323\tavg epoch acc = 0.9797\n","Epoch 6\tavg epoch Loss = 0.07806\tavg epoch acc = 0.9831\n","Epoch 7\tavg epoch Loss = 0.06476\tavg epoch acc = 0.9855\n","Epoch 8\tavg epoch Loss = 0.05534\tavg epoch acc = 0.9878\n","Epoch 9\tavg epoch Loss = 0.04738\tavg epoch acc = 0.9889\n","training took 17.65 s\n","Avg test loss = 0.144\tAvg test acc = 0.975\n","Epoch 0\tavg epoch Loss = 1.324\tavg epoch acc = 0.6193\n","Epoch 1\tavg epoch Loss = 0.3074\tavg epoch acc = 0.9159\n","Epoch 2\tavg epoch Loss = 0.1965\tavg epoch acc = 0.9518\n","Epoch 3\tavg epoch Loss = 0.1473\tavg epoch acc = 0.9666\n","Epoch 4\tavg epoch Loss = 0.1167\tavg epoch acc = 0.9741\n","Epoch 5\tavg epoch Loss = 0.09616\tavg epoch acc = 0.9794\n","Epoch 6\tavg epoch Loss = 0.08041\tavg epoch acc = 0.9825\n","Epoch 7\tavg epoch Loss = 0.06843\tavg epoch acc = 0.9847\n","Epoch 8\tavg epoch Loss = 0.05697\tavg epoch acc = 0.9864\n","Epoch 9\tavg epoch Loss = 0.0495\tavg epoch acc = 0.9883\n","training took 17.56 s\n","Avg test loss = 0.148\tAvg test acc = 0.974\n","Epoch 0\tavg epoch Loss = 1.331\tavg epoch acc = 0.6165\n","Epoch 1\tavg epoch Loss = 0.3045\tavg epoch acc = 0.9138\n","Epoch 2\tavg epoch Loss = 0.1866\tavg epoch acc = 0.9507\n","Epoch 3\tavg epoch Loss = 0.1403\tavg epoch acc = 0.9639\n","Epoch 4\tavg epoch Loss = 0.1113\tavg epoch acc = 0.9714\n","Epoch 5\tavg epoch Loss = 0.09207\tavg epoch acc = 0.9756\n","Epoch 6\tavg epoch Loss = 0.07666\tavg epoch acc = 0.9788\n","Epoch 7\tavg epoch Loss = 0.06514\tavg epoch acc = 0.9824\n","Epoch 8\tavg epoch Loss = 0.05466\tavg epoch acc = 0.9853\n","Epoch 9\tavg epoch Loss = 0.04694\tavg epoch acc = 0.9873\n","training took 17.61 s\n","Avg test loss = 0.127\tAvg test acc = 0.981\n","{'lr': 0.001, 'beta1': 0.9, 'beta2': 0.5, 'batch_size': 32, 'weight_decay': 0.001, 'epsilon': 1e-10}\n","Epoch 0\tavg epoch Loss = 1.549e+23\tavg epoch acc = 0.09105\n","Epoch 1\tavg epoch Loss = 3.644e+23\tavg epoch acc = 0.1185\n","Epoch 2\tavg epoch Loss = 5.979e+23\tavg epoch acc = 0.1085\n","Epoch 3\tavg epoch Loss = 5.507e+23\tavg epoch acc = 0.09298\n","Epoch 4\tavg epoch Loss = 4.199e+23\tavg epoch acc = 0.09705\n","Epoch 5\tavg epoch Loss = 2.189e+24\tavg epoch acc = 0.1111\n","Epoch 6\tavg epoch Loss = 7.378e+24\tavg epoch acc = 0.1344\n","Epoch 7\tavg epoch Loss = 3.169e+25\tavg epoch acc = 0.1419\n","Epoch 8\tavg epoch Loss = 7.637e+25\tavg epoch acc = 0.1175\n","Epoch 9\tavg epoch Loss = 5.993e+25\tavg epoch acc = 0.09845\n","training took 55.14 s\n","Avg test loss = nan\tAvg test acc = 0.0992\n","Epoch 0\tavg epoch Loss = 7.161e+24\tavg epoch acc = 0.0998\n","Epoch 1\tavg epoch Loss = 5.743e+26\tavg epoch acc = 0.1098\n","Epoch 2\tavg epoch Loss = 1.227e+28\tavg epoch acc = 0.09548\n","Epoch 3\tavg epoch Loss = 2.391e+28\tavg epoch acc = 0.1011\n","Epoch 4\tavg epoch Loss = 2.08e+28\tavg epoch acc = 0.09365\n","Epoch 5\tavg epoch Loss = 5.943e+28\tavg epoch acc = 0.09383\n","Epoch 6\tavg epoch Loss = 3.1e+29\tavg epoch acc = 0.09632\n","Epoch 7\tavg epoch Loss = 2.54e+29\tavg epoch acc = 0.09592\n","Epoch 8\tavg epoch Loss = 6.029e+29\tavg epoch acc = 0.09435\n","Epoch 9\tavg epoch Loss = 3.499e+29\tavg epoch acc = 0.1069\n","training took 54.99 s\n","Avg test loss = nan\tAvg test acc = 0.117\n","Epoch 0\tavg epoch Loss = 2.179e+10\tavg epoch acc = 0.09778\n","Epoch 1\tavg epoch Loss = 3.276e+09\tavg epoch acc = 0.0982\n","Epoch 2\tavg epoch Loss = 1.078e+09\tavg epoch acc = 0.0982\n","Epoch 3\tavg epoch Loss = 1.459e+12\tavg epoch acc = 0.09963\n","Epoch 4\tavg epoch Loss = 5.038e+12\tavg epoch acc = 0.1015\n","Epoch 5\tavg epoch Loss = 5.025e+12\tavg epoch acc = 0.1015\n","Epoch 6\tavg epoch Loss = 5.012e+12\tavg epoch acc = 0.1015\n","Epoch 7\tavg epoch Loss = 4.999e+12\tavg epoch acc = 0.1015\n","Epoch 8\tavg epoch Loss = 4.987e+12\tavg epoch acc = 0.1015\n","Epoch 9\tavg epoch Loss = 4.974e+12\tavg epoch acc = 0.1015\n","training took 54.94 s\n","Avg test loss = 1.32e+24\tAvg test acc = 0.104\n","{'lr': 0.001, 'beta1': 0.9, 'beta2': 0.5, 'batch_size': 32, 'weight_decay': 0.001, 'epsilon': 1e-08}\n","Epoch 0\tavg epoch Loss = nan\tavg epoch acc = 0.1032\n","Epoch 1\tavg epoch Loss = nan\tavg epoch acc = 0.0986\n","Epoch 2\tavg epoch Loss = nan\tavg epoch acc = 0.0986\n","Epoch 3\tavg epoch Loss = nan\tavg epoch acc = 0.0986\n","Epoch 4\tavg epoch Loss = nan\tavg epoch acc = 0.0986\n","Epoch 5\tavg epoch Loss = nan\tavg epoch acc = 0.0986\n","Epoch 6\tavg epoch Loss = nan\tavg epoch acc = 0.0986\n","Epoch 7\tavg epoch Loss = nan\tavg epoch acc = 0.0986\n","Epoch 8\tavg epoch Loss = nan\tavg epoch acc = 0.0986\n","Epoch 9\tavg epoch Loss = nan\tavg epoch acc = 0.0986\n","training took 54.72 s\n","Avg test loss = nan\tAvg test acc = 0.0989\n","Epoch 0\tavg epoch Loss = 1.873e+19\tavg epoch acc = 0.09635\n","Epoch 1\tavg epoch Loss = 6.136e+27\tavg epoch acc = 0.1109\n","Epoch 2\tavg epoch Loss = 9.182e+28\tavg epoch acc = 0.1134\n","Epoch 3\tavg epoch Loss = 2.19e+28\tavg epoch acc = 0.1135\n","Epoch 4\tavg epoch Loss = 6.127e+28\tavg epoch acc = 0.1157\n","Epoch 5\tavg epoch Loss = 1.26e+29\tavg epoch acc = 0.1157\n","Epoch 6\tavg epoch Loss = 1.189e+29\tavg epoch acc = 0.1157\n","Epoch 7\tavg epoch Loss = 7.332e+28\tavg epoch acc = 0.1158\n","Epoch 8\tavg epoch Loss = 7.523e+28\tavg epoch acc = 0.1159\n","Epoch 9\tavg epoch Loss = 6.333e+28\tavg epoch acc = 0.1159\n","training took 54.83 s\n","Avg test loss = 8.97e+32\tAvg test acc = 0.113\n","Epoch 0\tavg epoch Loss = 1.544e+14\tavg epoch acc = 0.1083\n","Epoch 1\tavg epoch Loss = 1.274e+16\tavg epoch acc = 0.1022\n","Epoch 2\tavg epoch Loss = 4.057e+15\tavg epoch acc = 0.09988\n","Epoch 3\tavg epoch Loss = 3.144e+15\tavg epoch acc = 0.1275\n","Epoch 4\tavg epoch Loss = 2.301e+15\tavg epoch acc = 0.1077\n","Epoch 5\tavg epoch Loss = 3.588e+15\tavg epoch acc = 0.08422\n","Epoch 6\tavg epoch Loss = 1.442e+19\tavg epoch acc = 0.08858\n","Epoch 7\tavg epoch Loss = 5.425e+18\tavg epoch acc = 0.0737\n","Epoch 8\tavg epoch Loss = 1.554e+18\tavg epoch acc = 0.09392\n","Epoch 9\tavg epoch Loss = 9.543e+18\tavg epoch acc = 0.1024\n","training took 54.87 s\n","Avg test loss = 1.03e+28\tAvg test acc = 0.112\n","{'lr': 0.001, 'beta1': 0.9, 'beta2': 0.5, 'batch_size': 32, 'weight_decay': 0.1, 'epsilon': 1e-10}\n","Epoch 0\tavg epoch Loss = 7.122e+31\tavg epoch acc = 0.0794\n","Epoch 1\tavg epoch Loss = 5.912e+33\tavg epoch acc = 0.07945\n","Epoch 2\tavg epoch Loss = 4.092e+16\tavg epoch acc = 0.0994\n","Epoch 3\tavg epoch Loss = 3.184e+16\tavg epoch acc = 0.0994\n","Epoch 4\tavg epoch Loss = 2.477e+16\tavg epoch acc = 0.0994\n","Epoch 5\tavg epoch Loss = 1.927e+16\tavg epoch acc = 0.0994\n","Epoch 6\tavg epoch Loss = 1.499e+16\tavg epoch acc = 0.0994\n","Epoch 7\tavg epoch Loss = 1.165e+16\tavg epoch acc = 0.0994\n","Epoch 8\tavg epoch Loss = 9.062e+15\tavg epoch acc = 0.0994\n","Epoch 9\tavg epoch Loss = 7.044e+15\tavg epoch acc = 0.0994\n","training took 55.3 s\n","Avg test loss = 6.18e+15\tAvg test acc = 0.0971\n","Epoch 0\tavg epoch Loss = 8.234e+17\tavg epoch acc = 0.1164\n","Epoch 1\tavg epoch Loss = 5.531e+17\tavg epoch acc = 0.1178\n","Epoch 2\tavg epoch Loss = 7.658e+22\tavg epoch acc = 0.1174\n","Epoch 3\tavg epoch Loss = 1.513e+23\tavg epoch acc = 0.108\n","Epoch 4\tavg epoch Loss = 5.781e+24\tavg epoch acc = 0.0987\n","Epoch 5\tavg epoch Loss = 1.138e+24\tavg epoch acc = 0.1066\n","Epoch 6\tavg epoch Loss = 6.233e+23\tavg epoch acc = 0.107\n","Epoch 7\tavg epoch Loss = 4.102e+22\tavg epoch acc = 0.1072\n","Epoch 8\tavg epoch Loss = 1.461e+23\tavg epoch acc = 0.106\n","Epoch 9\tavg epoch Loss = 1.624e+23\tavg epoch acc = 0.1057\n","training took 54.78 s\n","Avg test loss = nan\tAvg test acc = 0.101\n","Epoch 0\tavg epoch Loss = 4.631e+29\tavg epoch acc = 0.09922\n","Epoch 1\tavg epoch Loss = 7.736e+32\tavg epoch acc = 0.09792\n","Epoch 2\tavg epoch Loss = 9.658e+33\tavg epoch acc = 0.09792\n","Epoch 3\tavg epoch Loss = 5.138e+33\tavg epoch acc = 0.09792\n","Epoch 4\tavg epoch Loss = 3.972e+33\tavg epoch acc = 0.09792\n","Epoch 5\tavg epoch Loss = 1.776e+33\tavg epoch acc = 0.09792\n","Epoch 6\tavg epoch Loss = 2.086e+33\tavg epoch acc = 0.09792\n","Epoch 7\tavg epoch Loss = 7.67e+32\tavg epoch acc = 0.09792\n","Epoch 8\tavg epoch Loss = 4.1e+32\tavg epoch acc = 0.09792\n","Epoch 9\tavg epoch Loss = 2.091e+32\tavg epoch acc = 0.09792\n","training took 55.06 s\n","Avg test loss = nan\tAvg test acc = 0.1\n","{'lr': 0.001, 'beta1': 0.9, 'beta2': 0.5, 'batch_size': 32, 'weight_decay': 0.1, 'epsilon': 1e-08}\n","Epoch 0\tavg epoch Loss = 5.007e+17\tavg epoch acc = 0.1426\n","Epoch 1\tavg epoch Loss = nan\tavg epoch acc = 0.1022\n","Epoch 2\tavg epoch Loss = nan\tavg epoch acc = 0.09742\n","Epoch 3\tavg epoch Loss = nan\tavg epoch acc = 0.09742\n","Epoch 4\tavg epoch Loss = nan\tavg epoch acc = 0.09742\n","Epoch 5\tavg epoch Loss = nan\tavg epoch acc = 0.09742\n","Epoch 6\tavg epoch Loss = nan\tavg epoch acc = 0.09742\n","Epoch 7\tavg epoch Loss = nan\tavg epoch acc = 0.09742\n","Epoch 8\tavg epoch Loss = nan\tavg epoch acc = 0.09742\n","Epoch 9\tavg epoch Loss = nan\tavg epoch acc = 0.09742\n","training took 55.04 s\n","Avg test loss = nan\tAvg test acc = 0.101\n","Epoch 0\tavg epoch Loss = 5.441e+12\tavg epoch acc = 0.09892\n","Epoch 1\tavg epoch Loss = nan\tavg epoch acc = 0.1\n","Epoch 2\tavg epoch Loss = nan\tavg epoch acc = 0.09897\n","Epoch 3\tavg epoch Loss = nan\tavg epoch acc = 0.09897\n","Epoch 4\tavg epoch Loss = nan\tavg epoch acc = 0.09897\n","Epoch 5\tavg epoch Loss = nan\tavg epoch acc = 0.09897\n","Epoch 6\tavg epoch Loss = nan\tavg epoch acc = 0.09897\n","Epoch 7\tavg epoch Loss = nan\tavg epoch acc = 0.09897\n","Epoch 8\tavg epoch Loss = nan\tavg epoch acc = 0.09897\n","Epoch 9\tavg epoch Loss = nan\tavg epoch acc = 0.09897\n","training took 54.8 s\n","Avg test loss = nan\tAvg test acc = 0.0982\n","Epoch 0\tavg epoch Loss = 2.509e+20\tavg epoch acc = 0.1123\n","Epoch 1\tavg epoch Loss = 2.342e+26\tavg epoch acc = 0.1263\n","Epoch 2\tavg epoch Loss = 7.164e+31\tavg epoch acc = 0.1306\n","Epoch 3\tavg epoch Loss = 8.968e+32\tavg epoch acc = 0.1297\n","Epoch 4\tavg epoch Loss = 5.369e+32\tavg epoch acc = 0.1296\n","Epoch 5\tavg epoch Loss = 3.286e+32\tavg epoch acc = 0.1291\n","Epoch 6\tavg epoch Loss = 1.751e+32\tavg epoch acc = 0.1288\n","Epoch 7\tavg epoch Loss = 9.481e+31\tavg epoch acc = 0.1286\n","Epoch 8\tavg epoch Loss = 5.018e+31\tavg epoch acc = 0.1288\n","Epoch 9\tavg epoch Loss = 2.875e+31\tavg epoch acc = 0.129\n","training took 55.2 s\n","Avg test loss = 5.07e+34\tAvg test acc = 0.13\n","{'lr': 0.001, 'beta1': 0.9, 'beta2': 0.5, 'batch_size': 64, 'weight_decay': 0.001, 'epsilon': 1e-10}\n","Epoch 0\tavg epoch Loss = 6.699e+13\tavg epoch acc = 0.1008\n","Epoch 1\tavg epoch Loss = 4.939e+26\tavg epoch acc = 0.104\n","Epoch 2\tavg epoch Loss = 3.472e+28\tavg epoch acc = 0.1001\n","Epoch 3\tavg epoch Loss = 5.081e+31\tavg epoch acc = 0.1\n","Epoch 4\tavg epoch Loss = 4.945e+31\tavg epoch acc = 0.09997\n","Epoch 5\tavg epoch Loss = 4.888e+31\tavg epoch acc = 0.1001\n","Epoch 6\tavg epoch Loss = 4.824e+31\tavg epoch acc = 0.1001\n","Epoch 7\tavg epoch Loss = 4.811e+31\tavg epoch acc = 0.1001\n","Epoch 8\tavg epoch Loss = 4.817e+31\tavg epoch acc = 0.1001\n","Epoch 9\tavg epoch Loss = 4.776e+31\tavg epoch acc = 0.1001\n","training took 28.52 s\n","Avg test loss = nan\tAvg test acc = 0.0974\n","Epoch 0\tavg epoch Loss = 3.326e+14\tavg epoch acc = 0.1062\n","Epoch 1\tavg epoch Loss = 1.976e+26\tavg epoch acc = 0.111\n","Epoch 2\tavg epoch Loss = 8.437e+28\tavg epoch acc = 0.0932\n","Epoch 3\tavg epoch Loss = 1.769e+29\tavg epoch acc = 0.09765\n","Epoch 4\tavg epoch Loss = 3.48e+30\tavg epoch acc = 0.1074\n","Epoch 5\tavg epoch Loss = 3.263e+30\tavg epoch acc = 0.1082\n","Epoch 6\tavg epoch Loss = 9.629e+30\tavg epoch acc = 0.1077\n","Epoch 7\tavg epoch Loss = 1.074e+31\tavg epoch acc = 0.1072\n","Epoch 8\tavg epoch Loss = 1.039e+31\tavg epoch acc = 0.1073\n","Epoch 9\tavg epoch Loss = 1.056e+31\tavg epoch acc = 0.1072\n","training took 28.33 s\n","Avg test loss = 7.78e+29\tAvg test acc = 0.111\n","Epoch 0\tavg epoch Loss = 1.401e+04\tavg epoch acc = 0.1015\n","Epoch 1\tavg epoch Loss = 2.511e+03\tavg epoch acc = 0.09935\n","Epoch 2\tavg epoch Loss = 147.0\tavg epoch acc = 0.09588\n","Epoch 3\tavg epoch Loss = 41.05\tavg epoch acc = 0.09592\n","Epoch 4\tavg epoch Loss = 28.97\tavg epoch acc = 0.09592\n","Epoch 5\tavg epoch Loss = 25.37\tavg epoch acc = 0.09595\n","Epoch 6\tavg epoch Loss = 20.13\tavg epoch acc = 0.09592\n","Epoch 7\tavg epoch Loss = 16.89\tavg epoch acc = 0.09592\n","Epoch 8\tavg epoch Loss = 14.51\tavg epoch acc = 0.09595\n","Epoch 9\tavg epoch Loss = 13.44\tavg epoch acc = 0.09595\n","training took 28.45 s\n","Avg test loss = 5.25e+23\tAvg test acc = 0.0949\n","{'lr': 0.001, 'beta1': 0.9, 'beta2': 0.5, 'batch_size': 64, 'weight_decay': 0.001, 'epsilon': 1e-08}\n","Epoch 0\tavg epoch Loss = 1.756e+04\tavg epoch acc = 0.07963\n","Epoch 1\tavg epoch Loss = 2.817e+03\tavg epoch acc = 0.07773\n","Epoch 2\tavg epoch Loss = 865.9\tavg epoch acc = 0.08353\n","Epoch 3\tavg epoch Loss = 166.8\tavg epoch acc = 0.08347\n","Epoch 4\tavg epoch Loss = 113.2\tavg epoch acc = 0.08347\n","Epoch 5\tavg epoch Loss = 82.48\tavg epoch acc = 0.08342\n","Epoch 6\tavg epoch Loss = 67.18\tavg epoch acc = 0.0834\n","Epoch 7\tavg epoch Loss = 59.72\tavg epoch acc = 0.0834\n","Epoch 8\tavg epoch Loss = 39.96\tavg epoch acc = 0.0834\n","Epoch 9\tavg epoch Loss = 32.68\tavg epoch acc = 0.08345\n","training took 28.32 s\n","Avg test loss = 2.12e+16\tAvg test acc = 0.0816\n","Epoch 0\tavg epoch Loss = 1.219e+07\tavg epoch acc = 0.08128\n","Epoch 1\tavg epoch Loss = 3.613e+05\tavg epoch acc = 0.07405\n","Epoch 2\tavg epoch Loss = 5.907e+04\tavg epoch acc = 0.09105\n","Epoch 3\tavg epoch Loss = 1.836e+04\tavg epoch acc = 0.103\n","Epoch 4\tavg epoch Loss = 7.458e+03\tavg epoch acc = 0.1038\n","Epoch 5\tavg epoch Loss = 4.205e+03\tavg epoch acc = 0.09705\n","Epoch 6\tavg epoch Loss = 3.158e+03\tavg epoch acc = 0.05713\n","Epoch 7\tavg epoch Loss = 2.049e+03\tavg epoch acc = 0.02142\n","Epoch 8\tavg epoch Loss = 1.513e+03\tavg epoch acc = 0.007875\n","Epoch 9\tavg epoch Loss = 1.169e+03\tavg epoch acc = 0.01422\n","training took 28.35 s\n","Avg test loss = 3.62e+23\tAvg test acc = 0.0132\n","Epoch 0\tavg epoch Loss = 1.257e+04\tavg epoch acc = 0.1104\n","Epoch 1\tavg epoch Loss = 1.215e+03\tavg epoch acc = 0.1061\n","Epoch 2\tavg epoch Loss = 114.2\tavg epoch acc = 0.0996\n","Epoch 3\tavg epoch Loss = 60.01\tavg epoch acc = 0.0996\n","Epoch 4\tavg epoch Loss = 40.29\tavg epoch acc = 0.0996\n","Epoch 5\tavg epoch Loss = 33.31\tavg epoch acc = 0.0996\n","Epoch 6\tavg epoch Loss = 27.34\tavg epoch acc = 0.0996\n","Epoch 7\tavg epoch Loss = 24.51\tavg epoch acc = 0.0996\n","Epoch 8\tavg epoch Loss = 22.2\tavg epoch acc = 0.0996\n","Epoch 9\tavg epoch Loss = 22.33\tavg epoch acc = 0.0996\n","training took 28.43 s\n","Avg test loss = 2.5e+18\tAvg test acc = 0.0972\n","{'lr': 0.001, 'beta1': 0.9, 'beta2': 0.5, 'batch_size': 64, 'weight_decay': 0.1, 'epsilon': 1e-10}\n","Epoch 0\tavg epoch Loss = 1.043e+12\tavg epoch acc = 0.1067\n","Epoch 1\tavg epoch Loss = 4.069e+12\tavg epoch acc = 0.09823\n","Epoch 2\tavg epoch Loss = 3.019e+12\tavg epoch acc = 0.09823\n","Epoch 3\tavg epoch Loss = 1.112e+12\tavg epoch acc = 0.09823\n","Epoch 4\tavg epoch Loss = 4.377e+11\tavg epoch acc = 0.09823\n","Epoch 5\tavg epoch Loss = 2.209e+11\tavg epoch acc = 0.09823\n","Epoch 6\tavg epoch Loss = 1.151e+11\tavg epoch acc = 0.09823\n","Epoch 7\tavg epoch Loss = 6.389e+10\tavg epoch acc = 0.09823\n","Epoch 8\tavg epoch Loss = 3.771e+10\tavg epoch acc = 0.09823\n","Epoch 9\tavg epoch Loss = 2.345e+10\tavg epoch acc = 0.09823\n","training took 28.45 s\n","Avg test loss = nan\tAvg test acc = 0.0996\n","Epoch 0\tavg epoch Loss = 2.917e+22\tavg epoch acc = 0.1171\n","Epoch 1\tavg epoch Loss = 3.639e+24\tavg epoch acc = 0.09125\n","Epoch 2\tavg epoch Loss = 2.386e+25\tavg epoch acc = 0.0784\n","Epoch 3\tavg epoch Loss = 6.582e+24\tavg epoch acc = 0.05053\n","Epoch 4\tavg epoch Loss = 4.888e+24\tavg epoch acc = 0.0509\n","Epoch 5\tavg epoch Loss = 2.69e+24\tavg epoch acc = 0.05028\n","Epoch 6\tavg epoch Loss = 3.202e+24\tavg epoch acc = 0.05\n","Epoch 7\tavg epoch Loss = 7.61e+24\tavg epoch acc = 0.04965\n","Epoch 8\tavg epoch Loss = 6.675e+24\tavg epoch acc = 0.04925\n","Epoch 9\tavg epoch Loss = 5.057e+24\tavg epoch acc = 0.0483\n","training took 28.32 s\n","Avg test loss = 3.34e+29\tAvg test acc = 0.051\n","Epoch 0\tavg epoch Loss = 6.007e+06\tavg epoch acc = 0.1211\n","Epoch 1\tavg epoch Loss = 4.222e+04\tavg epoch acc = 0.1253\n","Epoch 2\tavg epoch Loss = 2.181e+04\tavg epoch acc = 0.1252\n","Epoch 3\tavg epoch Loss = 1.574e+04\tavg epoch acc = 0.125\n","Epoch 4\tavg epoch Loss = 1.44e+04\tavg epoch acc = 0.1246\n","Epoch 5\tavg epoch Loss = 1.143e+04\tavg epoch acc = 0.1243\n","Epoch 6\tavg epoch Loss = 1.097e+04\tavg epoch acc = 0.1198\n","Epoch 7\tavg epoch Loss = 1.039e+04\tavg epoch acc = 0.108\n","Epoch 8\tavg epoch Loss = 9.877e+03\tavg epoch acc = 0.08388\n","Epoch 9\tavg epoch Loss = 8.689e+03\tavg epoch acc = 0.06177\n","training took 28.46 s\n","Avg test loss = 2.24e+27\tAvg test acc = 0.0588\n","{'lr': 0.001, 'beta1': 0.9, 'beta2': 0.5, 'batch_size': 64, 'weight_decay': 0.1, 'epsilon': 1e-08}\n","Epoch 0\tavg epoch Loss = 6.331e+06\tavg epoch acc = 0.07677\n","Epoch 1\tavg epoch Loss = 5.047e+04\tavg epoch acc = 0.03562\n","Epoch 2\tavg epoch Loss = 2.792e+04\tavg epoch acc = 0.0457\n","Epoch 3\tavg epoch Loss = 1.701e+04\tavg epoch acc = 0.0492\n","Epoch 4\tavg epoch Loss = 1.172e+04\tavg epoch acc = 0.053\n","Epoch 5\tavg epoch Loss = 8.792e+03\tavg epoch acc = 0.05362\n","Epoch 6\tavg epoch Loss = 7.121e+03\tavg epoch acc = 0.07047\n","Epoch 7\tavg epoch Loss = 5.695e+03\tavg epoch acc = 0.08468\n","Epoch 8\tavg epoch Loss = 4.717e+03\tavg epoch acc = 0.1155\n","Epoch 9\tavg epoch Loss = 4.317e+03\tavg epoch acc = 0.1433\n","training took 28.44 s\n","Avg test loss = 1.05e+24\tAvg test acc = 0.148\n","Epoch 0\tavg epoch Loss = 6.057e+06\tavg epoch acc = 0.06722\n","Epoch 1\tavg epoch Loss = 6.459e+04\tavg epoch acc = 0.0552\n","Epoch 2\tavg epoch Loss = 4.289e+04\tavg epoch acc = 0.05538\n","Epoch 3\tavg epoch Loss = 3.177e+04\tavg epoch acc = 0.05555\n","Epoch 4\tavg epoch Loss = 2.646e+04\tavg epoch acc = 0.05575\n","Epoch 5\tavg epoch Loss = 1.953e+04\tavg epoch acc = 0.0559\n","Epoch 6\tavg epoch Loss = 1.824e+04\tavg epoch acc = 0.05597\n","Epoch 7\tavg epoch Loss = 1.633e+04\tavg epoch acc = 0.05607\n","Epoch 8\tavg epoch Loss = 1.471e+04\tavg epoch acc = 0.05613\n","Epoch 9\tavg epoch Loss = 1.313e+04\tavg epoch acc = 0.0563\n","training took 28.67 s\n","Avg test loss = 4.08e+26\tAvg test acc = 0.0557\n","Epoch 0\tavg epoch Loss = 8.882e+11\tavg epoch acc = 0.09638\n","Epoch 1\tavg epoch Loss = 7.841e+10\tavg epoch acc = 0.1232\n","Epoch 2\tavg epoch Loss = 1.081e+10\tavg epoch acc = 0.1292\n","Epoch 3\tavg epoch Loss = 6.072e+09\tavg epoch acc = 0.1299\n","Epoch 4\tavg epoch Loss = 6.162e+09\tavg epoch acc = 0.1298\n","Epoch 5\tavg epoch Loss = 4.577e+09\tavg epoch acc = 0.1294\n","Epoch 6\tavg epoch Loss = 3.926e+09\tavg epoch acc = 0.1201\n","Epoch 7\tavg epoch Loss = 2.698e+09\tavg epoch acc = 0.1033\n","Epoch 8\tavg epoch Loss = 1.026e+10\tavg epoch acc = 0.1298\n","Epoch 9\tavg epoch Loss = 8.749e+09\tavg epoch acc = 0.09175\n","training took 28.64 s\n","Avg test loss = 3.21e+26\tAvg test acc = 0.0493\n","{'lr': 0.001, 'beta1': 0.9, 'beta2': 0.5, 'batch_size': 128, 'weight_decay': 0.001, 'epsilon': 1e-10}\n","Epoch 0\tavg epoch Loss = 2.72e+13\tavg epoch acc = 0.09487\n","Epoch 1\tavg epoch Loss = 1.434e+20\tavg epoch acc = 0.08002\n","Epoch 2\tavg epoch Loss = 2.794e+24\tavg epoch acc = 0.09455\n","Epoch 3\tavg epoch Loss = 6.54e+28\tavg epoch acc = 0.09016\n","Epoch 4\tavg epoch Loss = 2.153e+29\tavg epoch acc = 0.0799\n","Epoch 5\tavg epoch Loss = 4.749e+28\tavg epoch acc = 0.07448\n","Epoch 6\tavg epoch Loss = 7.287e+30\tavg epoch acc = 0.07398\n","Epoch 7\tavg epoch Loss = 2.586e+28\tavg epoch acc = 0.0787\n","Epoch 8\tavg epoch Loss = 4.461e+29\tavg epoch acc = 0.0797\n","Epoch 9\tavg epoch Loss = 9.283e+28\tavg epoch acc = 0.09303\n","training took 17.64 s\n","Avg test loss = nan\tAvg test acc = 0.0936\n","Epoch 0\tavg epoch Loss = 3.115e+04\tavg epoch acc = 0.09148\n","Epoch 1\tavg epoch Loss = 5.857e+03\tavg epoch acc = 0.07945\n","Epoch 2\tavg epoch Loss = 2.516e+03\tavg epoch acc = 0.07975\n","Epoch 3\tavg epoch Loss = 554.3\tavg epoch acc = 0.0796\n","Epoch 4\tavg epoch Loss = 324.4\tavg epoch acc = 0.07962\n","Epoch 5\tavg epoch Loss = 252.3\tavg epoch acc = 0.0796\n","Epoch 6\tavg epoch Loss = 168.8\tavg epoch acc = 0.0796\n","Epoch 7\tavg epoch Loss = 140.8\tavg epoch acc = 0.0796\n","Epoch 8\tavg epoch Loss = 144.3\tavg epoch acc = 0.0796\n","Epoch 9\tavg epoch Loss = 111.6\tavg epoch acc = 0.0796\n","training took 17.5 s\n","Avg test loss = 2.03e+23\tAvg test acc = 0.0812\n","Epoch 0\tavg epoch Loss = 3.391e+11\tavg epoch acc = 0.09168\n","Epoch 1\tavg epoch Loss = 1.157e+19\tavg epoch acc = 0.0607\n","Epoch 2\tavg epoch Loss = 1.637e+22\tavg epoch acc = 0.08227\n","Epoch 3\tavg epoch Loss = 1.76e+22\tavg epoch acc = 0.08741\n","Epoch 4\tavg epoch Loss = 1.674e+22\tavg epoch acc = 0.08427\n","Epoch 5\tavg epoch Loss = 2.792e+23\tavg epoch acc = 0.06228\n","Epoch 6\tavg epoch Loss = 2.248e+23\tavg epoch acc = 0.0655\n","Epoch 7\tavg epoch Loss = 7.139e+22\tavg epoch acc = 0.06477\n","Epoch 8\tavg epoch Loss = 2.101e+22\tavg epoch acc = 0.06452\n","Epoch 9\tavg epoch Loss = 2.049e+22\tavg epoch acc = 0.06345\n","training took 17.57 s\n","Avg test loss = 4.92e+27\tAvg test acc = 0.062\n","{'lr': 0.001, 'beta1': 0.9, 'beta2': 0.5, 'batch_size': 128, 'weight_decay': 0.001, 'epsilon': 1e-08}\n","Epoch 0\tavg epoch Loss = 1.543e+04\tavg epoch acc = 0.1123\n","Epoch 1\tavg epoch Loss = 5.014e+03\tavg epoch acc = 0.1374\n","Epoch 2\tavg epoch Loss = 2.888e+03\tavg epoch acc = 0.1331\n","Epoch 3\tavg epoch Loss = 607.5\tavg epoch acc = 0.1164\n","Epoch 4\tavg epoch Loss = 138.3\tavg epoch acc = 0.1157\n","Epoch 5\tavg epoch Loss = 96.2\tavg epoch acc = 0.1147\n","Epoch 6\tavg epoch Loss = 83.95\tavg epoch acc = 0.1135\n","Epoch 7\tavg epoch Loss = 72.68\tavg epoch acc = 0.1132\n","Epoch 8\tavg epoch Loss = 73.76\tavg epoch acc = 0.112\n","Epoch 9\tavg epoch Loss = 57.08\tavg epoch acc = 0.1119\n","training took 17.52 s\n","Avg test loss = 7.76e+16\tAvg test acc = 0.112\n","Epoch 0\tavg epoch Loss = 2.582e+04\tavg epoch acc = 0.07191\n","Epoch 1\tavg epoch Loss = 1.131e+04\tavg epoch acc = 0.06874\n","Epoch 2\tavg epoch Loss = 9.528e+03\tavg epoch acc = 0.06817\n","Epoch 3\tavg epoch Loss = 8.345e+03\tavg epoch acc = 0.07426\n","Epoch 4\tavg epoch Loss = 7.622e+03\tavg epoch acc = 0.08793\n","Epoch 5\tavg epoch Loss = 7.056e+03\tavg epoch acc = 0.08559\n","Epoch 6\tavg epoch Loss = 6.493e+03\tavg epoch acc = 0.08788\n","Epoch 7\tavg epoch Loss = 5.958e+03\tavg epoch acc = 0.08711\n","Epoch 8\tavg epoch Loss = 5.548e+03\tavg epoch acc = 0.08741\n","Epoch 9\tavg epoch Loss = 5.162e+03\tavg epoch acc = 0.08629\n","training took 17.46 s\n","Avg test loss = 1.4e+13\tAvg test acc = 0.112\n","Epoch 0\tavg epoch Loss = 1.632e+04\tavg epoch acc = 0.1045\n","Epoch 1\tavg epoch Loss = 4.463e+03\tavg epoch acc = 0.1044\n","Epoch 2\tavg epoch Loss = 3.609e+03\tavg epoch acc = 0.09924\n","Epoch 3\tavg epoch Loss = 1.626e+03\tavg epoch acc = 0.09902\n","Epoch 4\tavg epoch Loss = 334.9\tavg epoch acc = 0.09904\n","Epoch 5\tavg epoch Loss = 111.8\tavg epoch acc = 0.09904\n","Epoch 6\tavg epoch Loss = 58.2\tavg epoch acc = 0.09902\n","Epoch 7\tavg epoch Loss = 35.21\tavg epoch acc = 0.09902\n","Epoch 8\tavg epoch Loss = 19.33\tavg epoch acc = 0.09909\n","Epoch 9\tavg epoch Loss = 124.5\tavg epoch acc = 0.09902\n","training took 17.52 s\n","Avg test loss = 1.39e+19\tAvg test acc = 0.0977\n","{'lr': 0.001, 'beta1': 0.9, 'beta2': 0.5, 'batch_size': 128, 'weight_decay': 0.1, 'epsilon': 1e-10}\n","Epoch 0\tavg epoch Loss = 8.783e+06\tavg epoch acc = 0.1025\n","Epoch 1\tavg epoch Loss = 3.829e+05\tavg epoch acc = 0.05998\n","Epoch 2\tavg epoch Loss = 3.171e+04\tavg epoch acc = 0.04635\n","Epoch 3\tavg epoch Loss = 1.968e+04\tavg epoch acc = 0.0471\n","Epoch 4\tavg epoch Loss = 1.512e+04\tavg epoch acc = 0.0467\n","Epoch 5\tavg epoch Loss = 1.187e+04\tavg epoch acc = 0.04683\n","Epoch 6\tavg epoch Loss = 9.459e+03\tavg epoch acc = 0.05079\n","Epoch 7\tavg epoch Loss = 8.883e+03\tavg epoch acc = 0.05044\n","Epoch 8\tavg epoch Loss = 7.9e+03\tavg epoch acc = 0.04935\n","Epoch 9\tavg epoch Loss = 7.498e+03\tavg epoch acc = 0.04917\n","training took 17.46 s\n","Avg test loss = 4.5e+26\tAvg test acc = 0.0518\n","Epoch 0\tavg epoch Loss = 3.017e+09\tavg epoch acc = 0.1005\n","Epoch 1\tavg epoch Loss = 8.823e+06\tavg epoch acc = 0.1258\n","Epoch 2\tavg epoch Loss = 7.41e+06\tavg epoch acc = 0.1346\n","Epoch 3\tavg epoch Loss = 6.365e+06\tavg epoch acc = 0.144\n","Epoch 4\tavg epoch Loss = 5.587e+06\tavg epoch acc = 0.1406\n","Epoch 5\tavg epoch Loss = 4.871e+06\tavg epoch acc = 0.1412\n","Epoch 6\tavg epoch Loss = 4.211e+06\tavg epoch acc = 0.1404\n","Epoch 7\tavg epoch Loss = 3.603e+06\tavg epoch acc = 0.1382\n","Epoch 8\tavg epoch Loss = 3.072e+06\tavg epoch acc = 0.1294\n","Epoch 9\tavg epoch Loss = 2.718e+06\tavg epoch acc = 0.1211\n","training took 17.57 s\n","Avg test loss = 2.09e+28\tAvg test acc = 0.106\n","Epoch 0\tavg epoch Loss = 2.055e+07\tavg epoch acc = 0.05042\n","Epoch 1\tavg epoch Loss = 1.189e+07\tavg epoch acc = 0.08853\n","Epoch 2\tavg epoch Loss = 3.042e+05\tavg epoch acc = 0.07695\n","Epoch 3\tavg epoch Loss = 8.244e+04\tavg epoch acc = 0.08377\n","Epoch 4\tavg epoch Loss = 5.159e+04\tavg epoch acc = 0.08125\n","Epoch 5\tavg epoch Loss = 3.764e+04\tavg epoch acc = 0.08329\n","Epoch 6\tavg epoch Loss = 2.909e+04\tavg epoch acc = 0.08716\n","Epoch 7\tavg epoch Loss = 2.502e+04\tavg epoch acc = 0.0935\n","Epoch 8\tavg epoch Loss = 2.123e+04\tavg epoch acc = 0.0939\n","Epoch 9\tavg epoch Loss = 1.82e+04\tavg epoch acc = 0.09447\n","training took 17.46 s\n","Avg test loss = 6.99e+31\tAvg test acc = 0.0979\n","{'lr': 0.001, 'beta1': 0.9, 'beta2': 0.5, 'batch_size': 128, 'weight_decay': 0.1, 'epsilon': 1e-08}\n","Epoch 0\tavg epoch Loss = 2.932e+07\tavg epoch acc = 0.09994\n","Epoch 1\tavg epoch Loss = 1.874e+14\tavg epoch acc = 0.08983\n","Epoch 2\tavg epoch Loss = 7.573e+18\tavg epoch acc = 0.09565\n","Epoch 3\tavg epoch Loss = 1.704e+21\tavg epoch acc = 0.08055\n","Epoch 4\tavg epoch Loss = 5.749e+22\tavg epoch acc = 0.0921\n","Epoch 5\tavg epoch Loss = 6.104e+23\tavg epoch acc = 0.1098\n","Epoch 6\tavg epoch Loss = 3.4e+24\tavg epoch acc = 0.1148\n","Epoch 7\tavg epoch Loss = 2.509e+24\tavg epoch acc = 0.06245\n","Epoch 8\tavg epoch Loss = 8.383e+23\tavg epoch acc = 0.09472\n","Epoch 9\tavg epoch Loss = 3.403e+24\tavg epoch acc = 0.1257\n","training took 17.49 s\n","Avg test loss = nan\tAvg test acc = 0.13\n","Epoch 0\tavg epoch Loss = 1.24e+07\tavg epoch acc = 0.09882\n","Epoch 1\tavg epoch Loss = 5.223e+05\tavg epoch acc = 0.08382\n","Epoch 2\tavg epoch Loss = 4.984e+04\tavg epoch acc = 0.08469\n","Epoch 3\tavg epoch Loss = 3.384e+04\tavg epoch acc = 0.08454\n","Epoch 4\tavg epoch Loss = 2.641e+04\tavg epoch acc = 0.08454\n","Epoch 5\tavg epoch Loss = 2.214e+04\tavg epoch acc = 0.08451\n","Epoch 6\tavg epoch Loss = 1.818e+04\tavg epoch acc = 0.08449\n","Epoch 7\tavg epoch Loss = 1.585e+04\tavg epoch acc = 0.08444\n","Epoch 8\tavg epoch Loss = 1.47e+04\tavg epoch acc = 0.08466\n","Epoch 9\tavg epoch Loss = 1.203e+04\tavg epoch acc = 0.08484\n","training took 17.53 s\n","Avg test loss = 5.1e+24\tAvg test acc = 0.0805\n","Epoch 0\tavg epoch Loss = 1.789e+07\tavg epoch acc = 0.09098\n","Epoch 1\tavg epoch Loss = 3.926e+06\tavg epoch acc = 0.1297\n","Epoch 2\tavg epoch Loss = 4.297e+05\tavg epoch acc = 0.1268\n","Epoch 3\tavg epoch Loss = 1.237e+05\tavg epoch acc = 0.1246\n","Epoch 4\tavg epoch Loss = 1.939e+04\tavg epoch acc = 0.1193\n","Epoch 5\tavg epoch Loss = 9.561e+03\tavg epoch acc = 0.118\n","Epoch 6\tavg epoch Loss = 1.014e+04\tavg epoch acc = 0.1173\n","Epoch 7\tavg epoch Loss = 8.92e+03\tavg epoch acc = 0.1164\n","Epoch 8\tavg epoch Loss = 8.949e+03\tavg epoch acc = 0.1157\n","Epoch 9\tavg epoch Loss = 8.89e+03\tavg epoch acc = 0.1151\n","training took 17.55 s\n","Avg test loss = 8.4e+26\tAvg test acc = 0.116\n","{'lr': 0.001, 'beta1': 0.9, 'beta2': 0.999, 'batch_size': 32, 'weight_decay': 0.001, 'epsilon': 1e-10}\n","Epoch 0\tavg epoch Loss = 0.6115\tavg epoch acc = 0.8261\n","Epoch 1\tavg epoch Loss = 0.1474\tavg epoch acc = 0.964\n","Epoch 2\tavg epoch Loss = 0.09919\tavg epoch acc = 0.9758\n","Epoch 3\tavg epoch Loss = 0.07248\tavg epoch acc = 0.9798\n","Epoch 4\tavg epoch Loss = 0.0542\tavg epoch acc = 0.9817\n","Epoch 5\tavg epoch Loss = 0.03887\tavg epoch acc = 0.9817\n","Epoch 6\tavg epoch Loss = 0.032\tavg epoch acc = 0.9809\n","Epoch 7\tavg epoch Loss = 0.02489\tavg epoch acc = 0.9777\n","Epoch 8\tavg epoch Loss = 0.02277\tavg epoch acc = 0.9739\n","Epoch 9\tavg epoch Loss = 0.01603\tavg epoch acc = 0.9741\n","training took 54.59 s\n","Avg test loss = 0.255\tAvg test acc = 0.969\n","Epoch 0\tavg epoch Loss = 0.6103\tavg epoch acc = 0.8273\n","Epoch 1\tavg epoch Loss = 0.1473\tavg epoch acc = 0.9677\n","Epoch 2\tavg epoch Loss = 0.0983\tavg epoch acc = 0.9778\n","Epoch 3\tavg epoch Loss = 0.07101\tavg epoch acc = 0.9806\n","Epoch 4\tavg epoch Loss = 0.05038\tavg epoch acc = 0.9807\n","Epoch 5\tavg epoch Loss = 0.04043\tavg epoch acc = 0.9793\n","Epoch 6\tavg epoch Loss = 0.03\tavg epoch acc = 0.9773\n","Epoch 7\tavg epoch Loss = 0.0227\tavg epoch acc = 0.9735\n","Epoch 8\tavg epoch Loss = 0.02045\tavg epoch acc = 0.9669\n","Epoch 9\tavg epoch Loss = 0.01662\tavg epoch acc = 0.9611\n","training took 54.75 s\n","Avg test loss = 0.34\tAvg test acc = 0.949\n","Epoch 0\tavg epoch Loss = 0.6058\tavg epoch acc = 0.8261\n","Epoch 1\tavg epoch Loss = 0.143\tavg epoch acc = 0.9659\n","Epoch 2\tavg epoch Loss = 0.09637\tavg epoch acc = 0.9769\n","Epoch 3\tavg epoch Loss = 0.07155\tavg epoch acc = 0.9819\n","Epoch 4\tavg epoch Loss = 0.05231\tavg epoch acc = 0.9837\n","Epoch 5\tavg epoch Loss = 0.03905\tavg epoch acc = 0.9815\n","Epoch 6\tavg epoch Loss = 0.03179\tavg epoch acc = 0.978\n","Epoch 7\tavg epoch Loss = 0.02366\tavg epoch acc = 0.9752\n","Epoch 8\tavg epoch Loss = 0.02145\tavg epoch acc = 0.9625\n","Epoch 9\tavg epoch Loss = 0.01429\tavg epoch acc = 0.9532\n","training took 54.75 s\n","Avg test loss = 0.416\tAvg test acc = 0.943\n","{'lr': 0.001, 'beta1': 0.9, 'beta2': 0.999, 'batch_size': 32, 'weight_decay': 0.001, 'epsilon': 1e-08}\n","Epoch 0\tavg epoch Loss = 0.6092\tavg epoch acc = 0.8254\n","Epoch 1\tavg epoch Loss = 0.1449\tavg epoch acc = 0.9602\n","Epoch 2\tavg epoch Loss = 0.09639\tavg epoch acc = 0.9679\n","Epoch 3\tavg epoch Loss = 0.06878\tavg epoch acc = 0.9698\n","Epoch 4\tavg epoch Loss = 0.05066\tavg epoch acc = 0.9716\n","Epoch 5\tavg epoch Loss = 0.03606\tavg epoch acc = 0.9692\n","Epoch 6\tavg epoch Loss = 0.02873\tavg epoch acc = 0.9682\n","Epoch 7\tavg epoch Loss = 0.02538\tavg epoch acc = 0.9657\n","Epoch 8\tavg epoch Loss = 0.01995\tavg epoch acc = 0.9619\n","Epoch 9\tavg epoch Loss = 0.01695\tavg epoch acc = 0.9589\n","training took 54.57 s\n","Avg test loss = 0.336\tAvg test acc = 0.952\n","Epoch 0\tavg epoch Loss = 0.6048\tavg epoch acc = 0.8273\n","Epoch 1\tavg epoch Loss = 0.1461\tavg epoch acc = 0.9661\n","Epoch 2\tavg epoch Loss = 0.09757\tavg epoch acc = 0.9783\n","Epoch 3\tavg epoch Loss = 0.07127\tavg epoch acc = 0.9831\n","Epoch 4\tavg epoch Loss = 0.05338\tavg epoch acc = 0.986\n","Epoch 5\tavg epoch Loss = 0.04022\tavg epoch acc = 0.9849\n","Epoch 6\tavg epoch Loss = 0.0309\tavg epoch acc = 0.9822\n","Epoch 7\tavg epoch Loss = 0.02636\tavg epoch acc = 0.9744\n","Epoch 8\tavg epoch Loss = 0.01892\tavg epoch acc = 0.968\n","Epoch 9\tavg epoch Loss = 0.01583\tavg epoch acc = 0.9606\n","training took 54.89 s\n","Avg test loss = 0.34\tAvg test acc = 0.947\n","Epoch 0\tavg epoch Loss = 0.6104\tavg epoch acc = 0.8246\n","Epoch 1\tavg epoch Loss = 0.1451\tavg epoch acc = 0.9675\n","Epoch 2\tavg epoch Loss = 0.09881\tavg epoch acc = 0.979\n","Epoch 3\tavg epoch Loss = 0.06991\tavg epoch acc = 0.9846\n","Epoch 4\tavg epoch Loss = 0.05348\tavg epoch acc = 0.985\n","Epoch 5\tavg epoch Loss = 0.0409\tavg epoch acc = 0.984\n","Epoch 6\tavg epoch Loss = 0.03128\tavg epoch acc = 0.9822\n","Epoch 7\tavg epoch Loss = 0.02617\tavg epoch acc = 0.9801\n","Epoch 8\tavg epoch Loss = 0.02087\tavg epoch acc = 0.9785\n","Epoch 9\tavg epoch Loss = 0.01613\tavg epoch acc = 0.9741\n","training took 54.89 s\n","Avg test loss = 0.249\tAvg test acc = 0.963\n","{'lr': 0.001, 'beta1': 0.9, 'beta2': 0.999, 'batch_size': 32, 'weight_decay': 0.1, 'epsilon': 1e-10}\n","Epoch 0\tavg epoch Loss = 0.6111\tavg epoch acc = 0.8299\n","Epoch 1\tavg epoch Loss = 0.1489\tavg epoch acc = 0.9688\n","Epoch 2\tavg epoch Loss = 0.09975\tavg epoch acc = 0.9794\n","Epoch 3\tavg epoch Loss = 0.07581\tavg epoch acc = 0.9831\n","Epoch 4\tavg epoch Loss = 0.05912\tavg epoch acc = 0.9851\n","Epoch 5\tavg epoch Loss = 0.04888\tavg epoch acc = 0.985\n","Epoch 6\tavg epoch Loss = 0.0419\tavg epoch acc = 0.9852\n","Epoch 7\tavg epoch Loss = 0.03243\tavg epoch acc = 0.9855\n","Epoch 8\tavg epoch Loss = 0.03053\tavg epoch acc = 0.9853\n","Epoch 9\tavg epoch Loss = 0.02724\tavg epoch acc = 0.9848\n","training took 55.06 s\n","Avg test loss = 0.176\tAvg test acc = 0.978\n","Epoch 0\tavg epoch Loss = 0.6077\tavg epoch acc = 0.8249\n","Epoch 1\tavg epoch Loss = 0.1505\tavg epoch acc = 0.9665\n","Epoch 2\tavg epoch Loss = 0.1034\tavg epoch acc = 0.9771\n","Epoch 3\tavg epoch Loss = 0.07608\tavg epoch acc = 0.9794\n","Epoch 4\tavg epoch Loss = 0.05936\tavg epoch acc = 0.9798\n","Epoch 5\tavg epoch Loss = 0.04887\tavg epoch acc = 0.981\n","Epoch 6\tavg epoch Loss = 0.03875\tavg epoch acc = 0.9825\n","Epoch 7\tavg epoch Loss = 0.03411\tavg epoch acc = 0.9805\n","Epoch 8\tavg epoch Loss = 0.02901\tavg epoch acc = 0.983\n","Epoch 9\tavg epoch Loss = 0.02555\tavg epoch acc = 0.9838\n","training took 54.54 s\n","Avg test loss = 0.138\tAvg test acc = 0.98\n","Epoch 0\tavg epoch Loss = 0.6173\tavg epoch acc = 0.8245\n","Epoch 1\tavg epoch Loss = 0.1472\tavg epoch acc = 0.9649\n","Epoch 2\tavg epoch Loss = 0.09998\tavg epoch acc = 0.9768\n","Epoch 3\tavg epoch Loss = 0.07591\tavg epoch acc = 0.9811\n","Epoch 4\tavg epoch Loss = 0.06106\tavg epoch acc = 0.9832\n","Epoch 5\tavg epoch Loss = 0.05055\tavg epoch acc = 0.9845\n","Epoch 6\tavg epoch Loss = 0.04248\tavg epoch acc = 0.9848\n","Epoch 7\tavg epoch Loss = 0.03448\tavg epoch acc = 0.9851\n","Epoch 8\tavg epoch Loss = 0.02917\tavg epoch acc = 0.9858\n","Epoch 9\tavg epoch Loss = 0.02471\tavg epoch acc = 0.9863\n","training took 54.53 s\n","Avg test loss = 0.12\tAvg test acc = 0.976\n","{'lr': 0.001, 'beta1': 0.9, 'beta2': 0.999, 'batch_size': 32, 'weight_decay': 0.1, 'epsilon': 1e-08}\n","Epoch 0\tavg epoch Loss = 0.6115\tavg epoch acc = 0.8222\n","Epoch 1\tavg epoch Loss = 0.149\tavg epoch acc = 0.9659\n","Epoch 2\tavg epoch Loss = 0.1017\tavg epoch acc = 0.9771\n","Epoch 3\tavg epoch Loss = 0.07775\tavg epoch acc = 0.9812\n","Epoch 4\tavg epoch Loss = 0.06177\tavg epoch acc = 0.9832\n","Epoch 5\tavg epoch Loss = 0.04909\tavg epoch acc = 0.9842\n","Epoch 6\tavg epoch Loss = 0.04132\tavg epoch acc = 0.9832\n","Epoch 7\tavg epoch Loss = 0.03359\tavg epoch acc = 0.9842\n","Epoch 8\tavg epoch Loss = 0.02945\tavg epoch acc = 0.9842\n","Epoch 9\tavg epoch Loss = 0.02656\tavg epoch acc = 0.9842\n","training took 54.37 s\n","Avg test loss = 0.124\tAvg test acc = 0.978\n","Epoch 0\tavg epoch Loss = 0.6044\tavg epoch acc = 0.8246\n","Epoch 1\tavg epoch Loss = 0.146\tavg epoch acc = 0.9631\n","Epoch 2\tavg epoch Loss = 0.1014\tavg epoch acc = 0.9772\n","Epoch 3\tavg epoch Loss = 0.07665\tavg epoch acc = 0.9822\n","Epoch 4\tavg epoch Loss = 0.05926\tavg epoch acc = 0.9838\n","Epoch 5\tavg epoch Loss = 0.04757\tavg epoch acc = 0.985\n","Epoch 6\tavg epoch Loss = 0.03986\tavg epoch acc = 0.9856\n","Epoch 7\tavg epoch Loss = 0.03309\tavg epoch acc = 0.987\n","Epoch 8\tavg epoch Loss = 0.02976\tavg epoch acc = 0.9865\n","Epoch 9\tavg epoch Loss = 0.0258\tavg epoch acc = 0.987\n","training took 54.55 s\n","Avg test loss = 0.15\tAvg test acc = 0.979\n","Epoch 0\tavg epoch Loss = 0.6122\tavg epoch acc = 0.8268\n","Epoch 1\tavg epoch Loss = 0.1483\tavg epoch acc = 0.9663\n","Epoch 2\tavg epoch Loss = 0.1016\tavg epoch acc = 0.9781\n","Epoch 3\tavg epoch Loss = 0.07681\tavg epoch acc = 0.9819\n","Epoch 4\tavg epoch Loss = 0.05888\tavg epoch acc = 0.9832\n","Epoch 5\tavg epoch Loss = 0.04935\tavg epoch acc = 0.9824\n","Epoch 6\tavg epoch Loss = 0.03988\tavg epoch acc = 0.9817\n","Epoch 7\tavg epoch Loss = 0.03366\tavg epoch acc = 0.9825\n","Epoch 8\tavg epoch Loss = 0.03037\tavg epoch acc = 0.9834\n","Epoch 9\tavg epoch Loss = 0.0265\tavg epoch acc = 0.9846\n","training took 55.8 s\n","Avg test loss = 0.129\tAvg test acc = 0.976\n","{'lr': 0.001, 'beta1': 0.9, 'beta2': 0.999, 'batch_size': 64, 'weight_decay': 0.001, 'epsilon': 1e-10}\n","Epoch 0\tavg epoch Loss = 0.9017\tavg epoch acc = 0.7389\n","Epoch 1\tavg epoch Loss = 0.1915\tavg epoch acc = 0.9505\n","Epoch 2\tavg epoch Loss = 0.1288\tavg epoch acc = 0.9685\n","Epoch 3\tavg epoch Loss = 0.09708\tavg epoch acc = 0.9772\n","Epoch 4\tavg epoch Loss = 0.07657\tavg epoch acc = 0.9819\n","Epoch 5\tavg epoch Loss = 0.06193\tavg epoch acc = 0.9855\n","Epoch 6\tavg epoch Loss = 0.04894\tavg epoch acc = 0.9879\n","Epoch 7\tavg epoch Loss = 0.04127\tavg epoch acc = 0.9891\n","Epoch 8\tavg epoch Loss = 0.03369\tavg epoch acc = 0.9902\n","Epoch 9\tavg epoch Loss = 0.03012\tavg epoch acc = 0.9893\n","training took 29.12 s\n","Avg test loss = 0.16\tAvg test acc = 0.98\n","Epoch 0\tavg epoch Loss = 0.9037\tavg epoch acc = 0.7428\n","Epoch 1\tavg epoch Loss = 0.2012\tavg epoch acc = 0.9508\n","Epoch 2\tavg epoch Loss = 0.1309\tavg epoch acc = 0.9694\n","Epoch 3\tavg epoch Loss = 0.09588\tavg epoch acc = 0.9761\n","Epoch 4\tavg epoch Loss = 0.0756\tavg epoch acc = 0.9793\n","Epoch 5\tavg epoch Loss = 0.05978\tavg epoch acc = 0.9828\n","Epoch 6\tavg epoch Loss = 0.04931\tavg epoch acc = 0.9847\n","Epoch 7\tavg epoch Loss = 0.04113\tavg epoch acc = 0.9872\n","Epoch 8\tavg epoch Loss = 0.03503\tavg epoch acc = 0.9882\n","Epoch 9\tavg epoch Loss = 0.02817\tavg epoch acc = 0.9882\n","training took 28.47 s\n","Avg test loss = 0.119\tAvg test acc = 0.986\n","Epoch 0\tavg epoch Loss = 0.9099\tavg epoch acc = 0.743\n","Epoch 1\tavg epoch Loss = 0.2001\tavg epoch acc = 0.9443\n","Epoch 2\tavg epoch Loss = 0.1344\tavg epoch acc = 0.9651\n","Epoch 3\tavg epoch Loss = 0.1025\tavg epoch acc = 0.973\n","Epoch 4\tavg epoch Loss = 0.0793\tavg epoch acc = 0.9807\n","Epoch 5\tavg epoch Loss = 0.06208\tavg epoch acc = 0.9844\n","Epoch 6\tavg epoch Loss = 0.05076\tavg epoch acc = 0.9872\n","Epoch 7\tavg epoch Loss = 0.04543\tavg epoch acc = 0.9888\n","Epoch 8\tavg epoch Loss = 0.04022\tavg epoch acc = 0.9889\n","Epoch 9\tavg epoch Loss = 0.03122\tavg epoch acc = 0.9897\n","training took 28.5 s\n","Avg test loss = 0.208\tAvg test acc = 0.982\n","{'lr': 0.001, 'beta1': 0.9, 'beta2': 0.999, 'batch_size': 64, 'weight_decay': 0.001, 'epsilon': 1e-08}\n","Epoch 0\tavg epoch Loss = 0.9046\tavg epoch acc = 0.7381\n","Epoch 1\tavg epoch Loss = 0.191\tavg epoch acc = 0.9442\n","Epoch 2\tavg epoch Loss = 0.1265\tavg epoch acc = 0.9659\n","Epoch 3\tavg epoch Loss = 0.093\tavg epoch acc = 0.9739\n","Epoch 4\tavg epoch Loss = 0.07281\tavg epoch acc = 0.9786\n","Epoch 5\tavg epoch Loss = 0.05797\tavg epoch acc = 0.9816\n","Epoch 6\tavg epoch Loss = 0.04908\tavg epoch acc = 0.9855\n","Epoch 7\tavg epoch Loss = 0.04072\tavg epoch acc = 0.9861\n","Epoch 8\tavg epoch Loss = 0.03458\tavg epoch acc = 0.9886\n","Epoch 9\tavg epoch Loss = 0.02929\tavg epoch acc = 0.9903\n","training took 28.6 s\n","Avg test loss = 0.193\tAvg test acc = 0.982\n","Epoch 0\tavg epoch Loss = 0.9035\tavg epoch acc = 0.741\n","Epoch 1\tavg epoch Loss = 0.1989\tavg epoch acc = 0.946\n","Epoch 2\tavg epoch Loss = 0.1343\tavg epoch acc = 0.9672\n","Epoch 3\tavg epoch Loss = 0.1013\tavg epoch acc = 0.9749\n","Epoch 4\tavg epoch Loss = 0.07961\tavg epoch acc = 0.9805\n","Epoch 5\tavg epoch Loss = 0.06278\tavg epoch acc = 0.9845\n","Epoch 6\tavg epoch Loss = 0.05042\tavg epoch acc = 0.9875\n","Epoch 7\tavg epoch Loss = 0.04267\tavg epoch acc = 0.9889\n","Epoch 8\tavg epoch Loss = 0.03521\tavg epoch acc = 0.99\n","Epoch 9\tavg epoch Loss = 0.03076\tavg epoch acc = 0.9901\n","training took 28.48 s\n","Avg test loss = 0.153\tAvg test acc = 0.983\n","Epoch 0\tavg epoch Loss = 0.9023\tavg epoch acc = 0.7456\n","Epoch 1\tavg epoch Loss = 0.1948\tavg epoch acc = 0.955\n","Epoch 2\tavg epoch Loss = 0.1298\tavg epoch acc = 0.9712\n","Epoch 3\tavg epoch Loss = 0.09764\tavg epoch acc = 0.9789\n","Epoch 4\tavg epoch Loss = 0.07523\tavg epoch acc = 0.9839\n","Epoch 5\tavg epoch Loss = 0.05865\tavg epoch acc = 0.9866\n","Epoch 6\tavg epoch Loss = 0.04937\tavg epoch acc = 0.9882\n","Epoch 7\tavg epoch Loss = 0.0405\tavg epoch acc = 0.9896\n","Epoch 8\tavg epoch Loss = 0.03531\tavg epoch acc = 0.9904\n","Epoch 9\tavg epoch Loss = 0.02892\tavg epoch acc = 0.9904\n","training took 28.41 s\n","Avg test loss = 0.128\tAvg test acc = 0.986\n","{'lr': 0.001, 'beta1': 0.9, 'beta2': 0.999, 'batch_size': 64, 'weight_decay': 0.1, 'epsilon': 1e-10}\n","Epoch 0\tavg epoch Loss = 0.9091\tavg epoch acc = 0.7405\n","Epoch 1\tavg epoch Loss = 0.1954\tavg epoch acc = 0.9484\n","Epoch 2\tavg epoch Loss = 0.1315\tavg epoch acc = 0.9694\n","Epoch 3\tavg epoch Loss = 0.1021\tavg epoch acc = 0.977\n","Epoch 4\tavg epoch Loss = 0.0818\tavg epoch acc = 0.9825\n","Epoch 5\tavg epoch Loss = 0.06885\tavg epoch acc = 0.9858\n","Epoch 6\tavg epoch Loss = 0.0552\tavg epoch acc = 0.9877\n","Epoch 7\tavg epoch Loss = 0.04628\tavg epoch acc = 0.9893\n","Epoch 8\tavg epoch Loss = 0.04003\tavg epoch acc = 0.9901\n","Epoch 9\tavg epoch Loss = 0.03512\tavg epoch acc = 0.9902\n","training took 28.38 s\n","Avg test loss = 0.141\tAvg test acc = 0.981\n","Epoch 0\tavg epoch Loss = 0.9048\tavg epoch acc = 0.7348\n","Epoch 1\tavg epoch Loss = 0.1905\tavg epoch acc = 0.9436\n","Epoch 2\tavg epoch Loss = 0.1278\tavg epoch acc = 0.9623\n","Epoch 3\tavg epoch Loss = 0.09757\tavg epoch acc = 0.9711\n","Epoch 4\tavg epoch Loss = 0.07781\tavg epoch acc = 0.9784\n","Epoch 5\tavg epoch Loss = 0.06405\tavg epoch acc = 0.9834\n","Epoch 6\tavg epoch Loss = 0.05285\tavg epoch acc = 0.9862\n","Epoch 7\tavg epoch Loss = 0.04461\tavg epoch acc = 0.9882\n","Epoch 8\tavg epoch Loss = 0.03941\tavg epoch acc = 0.9887\n","Epoch 9\tavg epoch Loss = 0.03569\tavg epoch acc = 0.9892\n","training took 28.56 s\n","Avg test loss = 0.121\tAvg test acc = 0.981\n","Epoch 0\tavg epoch Loss = 0.9125\tavg epoch acc = 0.7423\n","Epoch 1\tavg epoch Loss = 0.2035\tavg epoch acc = 0.9487\n","Epoch 2\tavg epoch Loss = 0.1381\tavg epoch acc = 0.9697\n","Epoch 3\tavg epoch Loss = 0.1056\tavg epoch acc = 0.9779\n","Epoch 4\tavg epoch Loss = 0.08249\tavg epoch acc = 0.9818\n","Epoch 5\tavg epoch Loss = 0.06807\tavg epoch acc = 0.9845\n","Epoch 6\tavg epoch Loss = 0.05625\tavg epoch acc = 0.9879\n","Epoch 7\tavg epoch Loss = 0.04816\tavg epoch acc = 0.9892\n","Epoch 8\tavg epoch Loss = 0.04082\tavg epoch acc = 0.9908\n","Epoch 9\tavg epoch Loss = 0.03621\tavg epoch acc = 0.9911\n","training took 28.37 s\n","Avg test loss = 0.0826\tAvg test acc = 0.987\n","{'lr': 0.001, 'beta1': 0.9, 'beta2': 0.999, 'batch_size': 64, 'weight_decay': 0.1, 'epsilon': 1e-08}\n","Epoch 0\tavg epoch Loss = 0.9123\tavg epoch acc = 0.743\n","Epoch 1\tavg epoch Loss = 0.2002\tavg epoch acc = 0.9498\n","Epoch 2\tavg epoch Loss = 0.1335\tavg epoch acc = 0.9703\n","Epoch 3\tavg epoch Loss = 0.1011\tavg epoch acc = 0.9776\n","Epoch 4\tavg epoch Loss = 0.08045\tavg epoch acc = 0.981\n","Epoch 5\tavg epoch Loss = 0.06438\tavg epoch acc = 0.9836\n","Epoch 6\tavg epoch Loss = 0.05389\tavg epoch acc = 0.9857\n","Epoch 7\tavg epoch Loss = 0.04692\tavg epoch acc = 0.9881\n","Epoch 8\tavg epoch Loss = 0.04055\tavg epoch acc = 0.9899\n","Epoch 9\tavg epoch Loss = 0.03681\tavg epoch acc = 0.9905\n","training took 28.5 s\n","Avg test loss = 0.145\tAvg test acc = 0.981\n","Epoch 0\tavg epoch Loss = 0.9064\tavg epoch acc = 0.7401\n","Epoch 1\tavg epoch Loss = 0.1944\tavg epoch acc = 0.9518\n","Epoch 2\tavg epoch Loss = 0.1305\tavg epoch acc = 0.9698\n","Epoch 3\tavg epoch Loss = 0.101\tavg epoch acc = 0.9766\n","Epoch 4\tavg epoch Loss = 0.08165\tavg epoch acc = 0.9808\n","Epoch 5\tavg epoch Loss = 0.06678\tavg epoch acc = 0.9846\n","Epoch 6\tavg epoch Loss = 0.05389\tavg epoch acc = 0.9879\n","Epoch 7\tavg epoch Loss = 0.04932\tavg epoch acc = 0.9898\n","Epoch 8\tavg epoch Loss = 0.0401\tavg epoch acc = 0.9911\n","Epoch 9\tavg epoch Loss = 0.03612\tavg epoch acc = 0.9914\n","training took 28.42 s\n","Avg test loss = 0.111\tAvg test acc = 0.985\n","Epoch 0\tavg epoch Loss = 0.9085\tavg epoch acc = 0.7366\n","Epoch 1\tavg epoch Loss = 0.1963\tavg epoch acc = 0.9487\n","Epoch 2\tavg epoch Loss = 0.1296\tavg epoch acc = 0.9687\n","Epoch 3\tavg epoch Loss = 0.09703\tavg epoch acc = 0.9774\n","Epoch 4\tavg epoch Loss = 0.07782\tavg epoch acc = 0.9829\n","Epoch 5\tavg epoch Loss = 0.0649\tavg epoch acc = 0.9869\n","Epoch 6\tavg epoch Loss = 0.05415\tavg epoch acc = 0.9891\n","Epoch 7\tavg epoch Loss = 0.04656\tavg epoch acc = 0.9903\n","Epoch 8\tavg epoch Loss = 0.04049\tavg epoch acc = 0.991\n","Epoch 9\tavg epoch Loss = 0.03588\tavg epoch acc = 0.9915\n","training took 28.68 s\n","Avg test loss = 0.0939\tAvg test acc = 0.985\n","{'lr': 0.001, 'beta1': 0.9, 'beta2': 0.999, 'batch_size': 128, 'weight_decay': 0.001, 'epsilon': 1e-10}\n","Epoch 0\tavg epoch Loss = 1.378\tavg epoch acc = 0.61\n","Epoch 1\tavg epoch Loss = 0.2988\tavg epoch acc = 0.9114\n","Epoch 2\tavg epoch Loss = 0.188\tavg epoch acc = 0.9477\n","Epoch 3\tavg epoch Loss = 0.1394\tavg epoch acc = 0.963\n","Epoch 4\tavg epoch Loss = 0.109\tavg epoch acc = 0.9711\n","Epoch 5\tavg epoch Loss = 0.08857\tavg epoch acc = 0.9759\n","Epoch 6\tavg epoch Loss = 0.07361\tavg epoch acc = 0.9791\n","Epoch 7\tavg epoch Loss = 0.06345\tavg epoch acc = 0.9808\n","Epoch 8\tavg epoch Loss = 0.05564\tavg epoch acc = 0.9822\n","Epoch 9\tavg epoch Loss = 0.0491\tavg epoch acc = 0.9844\n","training took 17.56 s\n","Avg test loss = 0.14\tAvg test acc = 0.981\n","Epoch 0\tavg epoch Loss = 1.382\tavg epoch acc = 0.6067\n","Epoch 1\tavg epoch Loss = 0.3006\tavg epoch acc = 0.9127\n","Epoch 2\tavg epoch Loss = 0.1827\tavg epoch acc = 0.9514\n","Epoch 3\tavg epoch Loss = 0.1357\tavg epoch acc = 0.9667\n","Epoch 4\tavg epoch Loss = 0.1079\tavg epoch acc = 0.9736\n","Epoch 5\tavg epoch Loss = 0.08988\tavg epoch acc = 0.9774\n","Epoch 6\tavg epoch Loss = 0.07549\tavg epoch acc = 0.9801\n","Epoch 7\tavg epoch Loss = 0.06387\tavg epoch acc = 0.9819\n","Epoch 8\tavg epoch Loss = 0.05317\tavg epoch acc = 0.9842\n","Epoch 9\tavg epoch Loss = 0.04577\tavg epoch acc = 0.9867\n","training took 17.59 s\n","Avg test loss = 0.128\tAvg test acc = 0.984\n","Epoch 0\tavg epoch Loss = 1.382\tavg epoch acc = 0.6133\n","Epoch 1\tavg epoch Loss = 0.2953\tavg epoch acc = 0.9088\n","Epoch 2\tavg epoch Loss = 0.1827\tavg epoch acc = 0.9449\n","Epoch 3\tavg epoch Loss = 0.1366\tavg epoch acc = 0.9591\n","Epoch 4\tavg epoch Loss = 0.1078\tavg epoch acc = 0.9655\n","Epoch 5\tavg epoch Loss = 0.08792\tavg epoch acc = 0.9688\n","Epoch 6\tavg epoch Loss = 0.07332\tavg epoch acc = 0.9727\n","Epoch 7\tavg epoch Loss = 0.0623\tavg epoch acc = 0.9748\n","Epoch 8\tavg epoch Loss = 0.0521\tavg epoch acc = 0.9784\n","Epoch 9\tavg epoch Loss = 0.04317\tavg epoch acc = 0.9793\n","training took 17.61 s\n","Avg test loss = 0.198\tAvg test acc = 0.975\n","{'lr': 0.001, 'beta1': 0.9, 'beta2': 0.999, 'batch_size': 128, 'weight_decay': 0.001, 'epsilon': 1e-08}\n","Epoch 0\tavg epoch Loss = 1.383\tavg epoch acc = 0.6138\n","Epoch 1\tavg epoch Loss = 0.299\tavg epoch acc = 0.9104\n","Epoch 2\tavg epoch Loss = 0.182\tavg epoch acc = 0.9481\n","Epoch 3\tavg epoch Loss = 0.1338\tavg epoch acc = 0.9627\n","Epoch 4\tavg epoch Loss = 0.1055\tavg epoch acc = 0.9693\n","Epoch 5\tavg epoch Loss = 0.08706\tavg epoch acc = 0.9726\n","Epoch 6\tavg epoch Loss = 0.07252\tavg epoch acc = 0.9756\n","Epoch 7\tavg epoch Loss = 0.06331\tavg epoch acc = 0.9785\n","Epoch 8\tavg epoch Loss = 0.05364\tavg epoch acc = 0.9799\n","Epoch 9\tavg epoch Loss = 0.0448\tavg epoch acc = 0.9829\n","training took 17.58 s\n","Avg test loss = 0.2\tAvg test acc = 0.974\n","Epoch 0\tavg epoch Loss = 1.384\tavg epoch acc = 0.6092\n","Epoch 1\tavg epoch Loss = 0.3005\tavg epoch acc = 0.9078\n","Epoch 2\tavg epoch Loss = 0.186\tavg epoch acc = 0.9462\n","Epoch 3\tavg epoch Loss = 0.1361\tavg epoch acc = 0.9624\n","Epoch 4\tavg epoch Loss = 0.1068\tavg epoch acc = 0.9699\n","Epoch 5\tavg epoch Loss = 0.08718\tavg epoch acc = 0.9743\n","Epoch 6\tavg epoch Loss = 0.07314\tavg epoch acc = 0.9773\n","Epoch 7\tavg epoch Loss = 0.06327\tavg epoch acc = 0.98\n","Epoch 8\tavg epoch Loss = 0.06002\tavg epoch acc = 0.9823\n","Epoch 9\tavg epoch Loss = 0.05194\tavg epoch acc = 0.9851\n","training took 17.58 s\n","Avg test loss = 0.12\tAvg test acc = 0.982\n","Epoch 0\tavg epoch Loss = 1.383\tavg epoch acc = 0.6046\n","Epoch 1\tavg epoch Loss = 0.299\tavg epoch acc = 0.9114\n","Epoch 2\tavg epoch Loss = 0.1805\tavg epoch acc = 0.9481\n","Epoch 3\tavg epoch Loss = 0.1335\tavg epoch acc = 0.9629\n","Epoch 4\tavg epoch Loss = 0.1045\tavg epoch acc = 0.9693\n","Epoch 5\tavg epoch Loss = 0.08755\tavg epoch acc = 0.9716\n","Epoch 6\tavg epoch Loss = 0.07423\tavg epoch acc = 0.9757\n","Epoch 7\tavg epoch Loss = 0.06314\tavg epoch acc = 0.9795\n","Epoch 8\tavg epoch Loss = 0.05346\tavg epoch acc = 0.9828\n","Epoch 9\tavg epoch Loss = 0.04518\tavg epoch acc = 0.9853\n","training took 17.6 s\n","Avg test loss = 0.182\tAvg test acc = 0.979\n","{'lr': 0.001, 'beta1': 0.9, 'beta2': 0.999, 'batch_size': 128, 'weight_decay': 0.1, 'epsilon': 1e-10}\n","Epoch 0\tavg epoch Loss = 1.386\tavg epoch acc = 0.609\n","Epoch 1\tavg epoch Loss = 0.3045\tavg epoch acc = 0.9103\n","Epoch 2\tavg epoch Loss = 0.1884\tavg epoch acc = 0.9485\n","Epoch 3\tavg epoch Loss = 0.1385\tavg epoch acc = 0.963\n","Epoch 4\tavg epoch Loss = 0.11\tavg epoch acc = 0.971\n","Epoch 5\tavg epoch Loss = 0.09046\tavg epoch acc = 0.9749\n","Epoch 6\tavg epoch Loss = 0.07592\tavg epoch acc = 0.976\n","Epoch 7\tavg epoch Loss = 0.06352\tavg epoch acc = 0.9775\n","Epoch 8\tavg epoch Loss = 0.05487\tavg epoch acc = 0.9793\n","Epoch 9\tavg epoch Loss = 0.04901\tavg epoch acc = 0.9811\n","training took 17.6 s\n","Avg test loss = 0.162\tAvg test acc = 0.976\n","Epoch 0\tavg epoch Loss = 1.387\tavg epoch acc = 0.6114\n","Epoch 1\tavg epoch Loss = 0.2992\tavg epoch acc = 0.9096\n","Epoch 2\tavg epoch Loss = 0.1804\tavg epoch acc = 0.9454\n","Epoch 3\tavg epoch Loss = 0.1357\tavg epoch acc = 0.961\n","Epoch 4\tavg epoch Loss = 0.1106\tavg epoch acc = 0.9676\n","Epoch 5\tavg epoch Loss = 0.09164\tavg epoch acc = 0.973\n","Epoch 6\tavg epoch Loss = 0.07656\tavg epoch acc = 0.976\n","Epoch 7\tavg epoch Loss = 0.06622\tavg epoch acc = 0.9788\n","Epoch 8\tavg epoch Loss = 0.05901\tavg epoch acc = 0.9813\n","Epoch 9\tavg epoch Loss = 0.0516\tavg epoch acc = 0.9848\n","training took 17.6 s\n","Avg test loss = 0.116\tAvg test acc = 0.98\n","Epoch 0\tavg epoch Loss = 1.378\tavg epoch acc = 0.6029\n","Epoch 1\tavg epoch Loss = 0.2989\tavg epoch acc = 0.9128\n","Epoch 2\tavg epoch Loss = 0.1836\tavg epoch acc = 0.9485\n","Epoch 3\tavg epoch Loss = 0.1381\tavg epoch acc = 0.9643\n","Epoch 4\tavg epoch Loss = 0.1101\tavg epoch acc = 0.9715\n","Epoch 5\tavg epoch Loss = 0.09205\tavg epoch acc = 0.9752\n","Epoch 6\tavg epoch Loss = 0.07808\tavg epoch acc = 0.9789\n","Epoch 7\tavg epoch Loss = 0.06694\tavg epoch acc = 0.9808\n","Epoch 8\tavg epoch Loss = 0.05824\tavg epoch acc = 0.9827\n","Epoch 9\tavg epoch Loss = 0.05129\tavg epoch acc = 0.9841\n","training took 17.51 s\n","Avg test loss = 0.194\tAvg test acc = 0.975\n","{'lr': 0.001, 'beta1': 0.9, 'beta2': 0.999, 'batch_size': 128, 'weight_decay': 0.1, 'epsilon': 1e-08}\n","Epoch 0\tavg epoch Loss = 1.384\tavg epoch acc = 0.612\n","Epoch 1\tavg epoch Loss = 0.3006\tavg epoch acc = 0.9118\n","Epoch 2\tavg epoch Loss = 0.1888\tavg epoch acc = 0.9474\n","Epoch 3\tavg epoch Loss = 0.1416\tavg epoch acc = 0.9634\n","Epoch 4\tavg epoch Loss = 0.1135\tavg epoch acc = 0.9708\n","Epoch 5\tavg epoch Loss = 0.09439\tavg epoch acc = 0.9751\n","Epoch 6\tavg epoch Loss = 0.07932\tavg epoch acc = 0.9784\n","Epoch 7\tavg epoch Loss = 0.06821\tavg epoch acc = 0.9809\n","Epoch 8\tavg epoch Loss = 0.05936\tavg epoch acc = 0.9833\n","Epoch 9\tavg epoch Loss = 0.05044\tavg epoch acc = 0.986\n","training took 17.61 s\n","Avg test loss = 0.132\tAvg test acc = 0.981\n","Epoch 0\tavg epoch Loss = 1.383\tavg epoch acc = 0.6084\n","Epoch 1\tavg epoch Loss = 0.3006\tavg epoch acc = 0.9099\n","Epoch 2\tavg epoch Loss = 0.1815\tavg epoch acc = 0.9473\n","Epoch 3\tavg epoch Loss = 0.134\tavg epoch acc = 0.9611\n","Epoch 4\tavg epoch Loss = 0.1069\tavg epoch acc = 0.9678\n","Epoch 5\tavg epoch Loss = 0.08955\tavg epoch acc = 0.9719\n","Epoch 6\tavg epoch Loss = 0.07671\tavg epoch acc = 0.9745\n","Epoch 7\tavg epoch Loss = 0.06682\tavg epoch acc = 0.9775\n","Epoch 8\tavg epoch Loss = 0.05938\tavg epoch acc = 0.9804\n","Epoch 9\tavg epoch Loss = 0.0527\tavg epoch acc = 0.9828\n","training took 17.63 s\n","Avg test loss = 0.144\tAvg test acc = 0.979\n","Epoch 0\tavg epoch Loss = 1.384\tavg epoch acc = 0.6061\n","Epoch 1\tavg epoch Loss = 0.2992\tavg epoch acc = 0.91\n","Epoch 2\tavg epoch Loss = 0.1853\tavg epoch acc = 0.9465\n","Epoch 3\tavg epoch Loss = 0.1368\tavg epoch acc = 0.9625\n","Epoch 4\tavg epoch Loss = 0.1079\tavg epoch acc = 0.9701\n","Epoch 5\tavg epoch Loss = 0.08835\tavg epoch acc = 0.9753\n","Epoch 6\tavg epoch Loss = 0.07366\tavg epoch acc = 0.9786\n","Epoch 7\tavg epoch Loss = 0.06359\tavg epoch acc = 0.9813\n","Epoch 8\tavg epoch Loss = 0.05603\tavg epoch acc = 0.984\n","Epoch 9\tavg epoch Loss = 0.04816\tavg epoch acc = 0.9848\n","training took 17.65 s\n","Avg test loss = 0.137\tAvg test acc = 0.979\n","{'lr': 0.01, 'beta1': 0.1, 'beta2': 0.5, 'batch_size': 32, 'weight_decay': 0.001, 'epsilon': 1e-10}\n","Epoch 0\tavg epoch Loss = 0.3836\tavg epoch acc = 0.4053\n","Epoch 1\tavg epoch Loss = 0.4421\tavg epoch acc = 0.3214\n","Epoch 2\tavg epoch Loss = 0.4242\tavg epoch acc = 0.242\n","Epoch 3\tavg epoch Loss = 0.4849\tavg epoch acc = 0.1619\n","Epoch 4\tavg epoch Loss = 0.4667\tavg epoch acc = 0.1596\n","Epoch 5\tavg epoch Loss = 0.4502\tavg epoch acc = 0.1618\n","Epoch 6\tavg epoch Loss = 0.4189\tavg epoch acc = 0.1416\n","Epoch 7\tavg epoch Loss = 0.4651\tavg epoch acc = 0.1422\n","Epoch 8\tavg epoch Loss = 0.4569\tavg epoch acc = 0.1595\n","Epoch 9\tavg epoch Loss = 0.5006\tavg epoch acc = 0.1534\n","training took 55.04 s\n","Avg test loss = 7.99e+04\tAvg test acc = 0.158\n","Epoch 0\tavg epoch Loss = 0.3468\tavg epoch acc = 0.4106\n","Epoch 1\tavg epoch Loss = 0.3625\tavg epoch acc = 0.3126\n","Epoch 2\tavg epoch Loss = 0.3919\tavg epoch acc = 0.3242\n","Epoch 3\tavg epoch Loss = 0.4189\tavg epoch acc = 0.3278\n","Epoch 4\tavg epoch Loss = 0.4303\tavg epoch acc = 0.2971\n","Epoch 5\tavg epoch Loss = 0.4338\tavg epoch acc = 0.3366\n","Epoch 6\tavg epoch Loss = 0.424\tavg epoch acc = 0.3437\n","Epoch 7\tavg epoch Loss = 0.4341\tavg epoch acc = 0.3845\n","Epoch 8\tavg epoch Loss = 0.4475\tavg epoch acc = 0.4287\n","Epoch 9\tavg epoch Loss = 0.4778\tavg epoch acc = 0.4608\n","training took 55.04 s\n","Avg test loss = 3.49e+04\tAvg test acc = 0.446\n","Epoch 0\tavg epoch Loss = 0.351\tavg epoch acc = 0.5935\n","Epoch 1\tavg epoch Loss = 0.4232\tavg epoch acc = 0.3304\n","Epoch 2\tavg epoch Loss = 0.4429\tavg epoch acc = 0.3695\n","Epoch 3\tavg epoch Loss = 0.4806\tavg epoch acc = 0.2891\n","Epoch 4\tavg epoch Loss = 0.4688\tavg epoch acc = 0.3874\n","Epoch 5\tavg epoch Loss = 0.4826\tavg epoch acc = 0.4008\n","Epoch 6\tavg epoch Loss = 0.5288\tavg epoch acc = 0.3065\n","Epoch 7\tavg epoch Loss = 0.5244\tavg epoch acc = 0.2568\n","Epoch 8\tavg epoch Loss = 0.6039\tavg epoch acc = 0.2067\n","Epoch 9\tavg epoch Loss = 0.5776\tavg epoch acc = 0.1971\n","training took 54.94 s\n","Avg test loss = 8.77e+04\tAvg test acc = 0.183\n","{'lr': 0.01, 'beta1': 0.1, 'beta2': 0.5, 'batch_size': 32, 'weight_decay': 0.001, 'epsilon': 1e-08}\n","Epoch 0\tavg epoch Loss = 0.3778\tavg epoch acc = 0.4636\n","Epoch 1\tavg epoch Loss = 0.4301\tavg epoch acc = 0.3387\n","Epoch 2\tavg epoch Loss = 0.4761\tavg epoch acc = 0.3312\n","Epoch 3\tavg epoch Loss = 0.4891\tavg epoch acc = 0.334\n","Epoch 4\tavg epoch Loss = 0.5166\tavg epoch acc = 0.4062\n","Epoch 5\tavg epoch Loss = 0.529\tavg epoch acc = 0.4292\n","Epoch 6\tavg epoch Loss = 0.512\tavg epoch acc = 0.2629\n","Epoch 7\tavg epoch Loss = 0.5159\tavg epoch acc = 0.2068\n","Epoch 8\tavg epoch Loss = 0.4909\tavg epoch acc = 0.1907\n","Epoch 9\tavg epoch Loss = 0.458\tavg epoch acc = 0.1763\n","training took 55.09 s\n","Avg test loss = 1.82e+04\tAvg test acc = 0.186\n","Epoch 0\tavg epoch Loss = 0.3537\tavg epoch acc = 0.5348\n","Epoch 1\tavg epoch Loss = 0.4377\tavg epoch acc = 0.4854\n","Epoch 2\tavg epoch Loss = 0.4739\tavg epoch acc = 0.4366\n","Epoch 3\tavg epoch Loss = 0.5457\tavg epoch acc = 0.418\n","Epoch 4\tavg epoch Loss = 0.5686\tavg epoch acc = 0.3983\n","Epoch 5\tavg epoch Loss = 0.5976\tavg epoch acc = 0.345\n","Epoch 6\tavg epoch Loss = 0.6052\tavg epoch acc = 0.3347\n","Epoch 7\tavg epoch Loss = 0.6355\tavg epoch acc = 0.2995\n","Epoch 8\tavg epoch Loss = 0.6592\tavg epoch acc = 0.2371\n","Epoch 9\tavg epoch Loss = 0.6417\tavg epoch acc = 0.2429\n","training took 56.13 s\n","Avg test loss = 1.78e+04\tAvg test acc = 0.239\n","Epoch 0\tavg epoch Loss = 0.3543\tavg epoch acc = 0.5149\n","Epoch 1\tavg epoch Loss = 0.4218\tavg epoch acc = 0.3671\n","Epoch 2\tavg epoch Loss = 0.4779\tavg epoch acc = 0.4248\n","Epoch 3\tavg epoch Loss = 0.4937\tavg epoch acc = 0.2892\n","Epoch 4\tavg epoch Loss = 0.5208\tavg epoch acc = 0.3277\n","Epoch 5\tavg epoch Loss = 0.5343\tavg epoch acc = 0.3274\n","Epoch 6\tavg epoch Loss = 0.6103\tavg epoch acc = 0.3315\n","Epoch 7\tavg epoch Loss = 0.6022\tavg epoch acc = 0.3068\n","Epoch 8\tavg epoch Loss = 0.5926\tavg epoch acc = 0.2808\n","Epoch 9\tavg epoch Loss = 0.5571\tavg epoch acc = 0.2258\n","training took 55.02 s\n","Avg test loss = 6.34e+04\tAvg test acc = 0.199\n","{'lr': 0.01, 'beta1': 0.1, 'beta2': 0.5, 'batch_size': 32, 'weight_decay': 0.1, 'epsilon': 1e-10}\n","Epoch 0\tavg epoch Loss = 0.323\tavg epoch acc = 0.5379\n","Epoch 1\tavg epoch Loss = 0.2675\tavg epoch acc = 0.5421\n","Epoch 2\tavg epoch Loss = 0.2426\tavg epoch acc = 0.5727\n","Epoch 3\tavg epoch Loss = 0.2461\tavg epoch acc = 0.5858\n","Epoch 4\tavg epoch Loss = 0.2451\tavg epoch acc = 0.5793\n","Epoch 5\tavg epoch Loss = 0.2473\tavg epoch acc = 0.5451\n","Epoch 6\tavg epoch Loss = 0.2399\tavg epoch acc = 0.5164\n","Epoch 7\tavg epoch Loss = 0.2375\tavg epoch acc = 0.5818\n","Epoch 8\tavg epoch Loss = 0.2328\tavg epoch acc = 0.5213\n","Epoch 9\tavg epoch Loss = 0.2381\tavg epoch acc = 0.5232\n","training took 54.77 s\n","Avg test loss = 1.94e+02\tAvg test acc = 0.542\n","Epoch 0\tavg epoch Loss = 0.335\tavg epoch acc = 0.5391\n","Epoch 1\tavg epoch Loss = 0.2905\tavg epoch acc = 0.4285\n","Epoch 2\tavg epoch Loss = 0.2738\tavg epoch acc = 0.4522\n","Epoch 3\tavg epoch Loss = 0.2652\tavg epoch acc = 0.5002\n","Epoch 4\tavg epoch Loss = 0.2708\tavg epoch acc = 0.5232\n","Epoch 5\tavg epoch Loss = 0.2833\tavg epoch acc = 0.5178\n","Epoch 6\tavg epoch Loss = 0.2746\tavg epoch acc = 0.5576\n","Epoch 7\tavg epoch Loss = 0.2675\tavg epoch acc = 0.623\n","Epoch 8\tavg epoch Loss = 0.2622\tavg epoch acc = 0.5081\n","Epoch 9\tavg epoch Loss = 0.2591\tavg epoch acc = 0.4644\n","training took 54.94 s\n","Avg test loss = 76.6\tAvg test acc = 0.599\n","Epoch 0\tavg epoch Loss = 0.3343\tavg epoch acc = 0.5886\n","Epoch 1\tavg epoch Loss = 0.2811\tavg epoch acc = 0.4514\n","Epoch 2\tavg epoch Loss = 0.2901\tavg epoch acc = 0.4971\n","Epoch 3\tavg epoch Loss = 0.2837\tavg epoch acc = 0.5585\n","Epoch 4\tavg epoch Loss = 0.2854\tavg epoch acc = 0.6107\n","Epoch 5\tavg epoch Loss = 0.28\tavg epoch acc = 0.5239\n","Epoch 6\tavg epoch Loss = 0.2829\tavg epoch acc = 0.5343\n","Epoch 7\tavg epoch Loss = 0.2846\tavg epoch acc = 0.5024\n","Epoch 8\tavg epoch Loss = 0.2716\tavg epoch acc = 0.481\n","Epoch 9\tavg epoch Loss = 0.2634\tavg epoch acc = 0.4506\n","training took 54.81 s\n","Avg test loss = 35.6\tAvg test acc = 0.532\n","{'lr': 0.01, 'beta1': 0.1, 'beta2': 0.5, 'batch_size': 32, 'weight_decay': 0.1, 'epsilon': 1e-08}\n","Epoch 0\tavg epoch Loss = 0.3131\tavg epoch acc = 0.5931\n","Epoch 1\tavg epoch Loss = 0.2754\tavg epoch acc = 0.4296\n","Epoch 2\tavg epoch Loss = 0.274\tavg epoch acc = 0.5739\n","Epoch 3\tavg epoch Loss = 0.2684\tavg epoch acc = 0.5596\n","Epoch 4\tavg epoch Loss = 0.2798\tavg epoch acc = 0.7248\n","Epoch 5\tavg epoch Loss = 0.2689\tavg epoch acc = 0.7206\n","Epoch 6\tavg epoch Loss = 0.2726\tavg epoch acc = 0.7222\n","Epoch 7\tavg epoch Loss = 0.2695\tavg epoch acc = 0.7637\n","Epoch 8\tavg epoch Loss = 0.2502\tavg epoch acc = 0.6689\n","Epoch 9\tavg epoch Loss = 0.2486\tavg epoch acc = 0.6423\n","training took 54.74 s\n","Avg test loss = 6.72\tAvg test acc = 0.795\n","Epoch 0\tavg epoch Loss = 0.3264\tavg epoch acc = 0.5431\n","Epoch 1\tavg epoch Loss = 0.2598\tavg epoch acc = 0.4409\n","Epoch 2\tavg epoch Loss = 0.2553\tavg epoch acc = 0.5432\n","Epoch 3\tavg epoch Loss = 0.2383\tavg epoch acc = 0.5543\n","Epoch 4\tavg epoch Loss = 0.2463\tavg epoch acc = 0.4566\n","Epoch 5\tavg epoch Loss = 0.2305\tavg epoch acc = 0.466\n","Epoch 6\tavg epoch Loss = 0.233\tavg epoch acc = 0.5143\n","Epoch 7\tavg epoch Loss = 0.2267\tavg epoch acc = 0.5102\n","Epoch 8\tavg epoch Loss = 0.234\tavg epoch acc = 0.4859\n","Epoch 9\tavg epoch Loss = 0.2263\tavg epoch acc = 0.4784\n","training took 54.55 s\n","Avg test loss = 1.66e+02\tAvg test acc = 0.578\n","Epoch 0\tavg epoch Loss = 0.3323\tavg epoch acc = 0.575\n","Epoch 1\tavg epoch Loss = 0.2773\tavg epoch acc = 0.5507\n","Epoch 2\tavg epoch Loss = 0.2873\tavg epoch acc = 0.607\n","Epoch 3\tavg epoch Loss = 0.2773\tavg epoch acc = 0.5868\n","Epoch 4\tavg epoch Loss = 0.2815\tavg epoch acc = 0.5458\n","Epoch 5\tavg epoch Loss = 0.2702\tavg epoch acc = 0.6032\n","Epoch 6\tavg epoch Loss = 0.2699\tavg epoch acc = 0.5298\n","Epoch 7\tavg epoch Loss = 0.2645\tavg epoch acc = 0.4434\n","Epoch 8\tavg epoch Loss = 0.263\tavg epoch acc = 0.4681\n","Epoch 9\tavg epoch Loss = 0.2713\tavg epoch acc = 0.5332\n","training took 54.97 s\n","Avg test loss = 64.7\tAvg test acc = 0.572\n","{'lr': 0.01, 'beta1': 0.1, 'beta2': 0.5, 'batch_size': 64, 'weight_decay': 0.001, 'epsilon': 1e-10}\n","Epoch 0\tavg epoch Loss = 0.2799\tavg epoch acc = 0.5033\n","Epoch 1\tavg epoch Loss = 0.2428\tavg epoch acc = 0.3114\n","Epoch 2\tavg epoch Loss = 0.2592\tavg epoch acc = 0.2804\n","Epoch 3\tavg epoch Loss = 0.2663\tavg epoch acc = 0.363\n","Epoch 4\tavg epoch Loss = 0.3299\tavg epoch acc = 0.3955\n","Epoch 5\tavg epoch Loss = 0.2976\tavg epoch acc = 0.4125\n","Epoch 6\tavg epoch Loss = 0.2965\tavg epoch acc = 0.3688\n","Epoch 7\tavg epoch Loss = 0.2852\tavg epoch acc = 0.3658\n","Epoch 8\tavg epoch Loss = 0.2763\tavg epoch acc = 0.3437\n","Epoch 9\tavg epoch Loss = 0.3166\tavg epoch acc = 0.3759\n","training took 28.49 s\n","Avg test loss = 6.69e+04\tAvg test acc = 0.4\n","Epoch 0\tavg epoch Loss = 0.2873\tavg epoch acc = 0.5556\n","Epoch 1\tavg epoch Loss = 0.2226\tavg epoch acc = 0.3382\n","Epoch 2\tavg epoch Loss = 0.2853\tavg epoch acc = 0.4152\n","Epoch 3\tavg epoch Loss = 0.2654\tavg epoch acc = 0.3501\n","Epoch 4\tavg epoch Loss = 0.2808\tavg epoch acc = 0.2369\n","Epoch 5\tavg epoch Loss = 0.2832\tavg epoch acc = 0.2041\n","Epoch 6\tavg epoch Loss = 0.289\tavg epoch acc = 0.2159\n","Epoch 7\tavg epoch Loss = 0.2998\tavg epoch acc = 0.2739\n","Epoch 8\tavg epoch Loss = 0.3072\tavg epoch acc = 0.1961\n","Epoch 9\tavg epoch Loss = 0.2974\tavg epoch acc = 0.2012\n","training took 28.69 s\n","Avg test loss = 1.53e+05\tAvg test acc = 0.2\n","Epoch 0\tavg epoch Loss = 0.287\tavg epoch acc = 0.5689\n","Epoch 1\tavg epoch Loss = 0.2375\tavg epoch acc = 0.2842\n","Epoch 2\tavg epoch Loss = 0.2627\tavg epoch acc = 0.2183\n","Epoch 3\tavg epoch Loss = 0.2591\tavg epoch acc = 0.2828\n","Epoch 4\tavg epoch Loss = 0.2565\tavg epoch acc = 0.3487\n","Epoch 5\tavg epoch Loss = 0.2654\tavg epoch acc = 0.3704\n","Epoch 6\tavg epoch Loss = 0.2614\tavg epoch acc = 0.4306\n","Epoch 7\tavg epoch Loss = 0.2805\tavg epoch acc = 0.4148\n","Epoch 8\tavg epoch Loss = 0.3379\tavg epoch acc = 0.2486\n","Epoch 9\tavg epoch Loss = 0.3116\tavg epoch acc = 0.2349\n","training took 28.44 s\n","Avg test loss = 7.46e+04\tAvg test acc = 0.255\n","{'lr': 0.01, 'beta1': 0.1, 'beta2': 0.5, 'batch_size': 64, 'weight_decay': 0.001, 'epsilon': 1e-08}\n","Epoch 0\tavg epoch Loss = 0.3041\tavg epoch acc = 0.6325\n","Epoch 1\tavg epoch Loss = 0.227\tavg epoch acc = 0.2861\n","Epoch 2\tavg epoch Loss = 0.2344\tavg epoch acc = 0.2286\n","Epoch 3\tavg epoch Loss = 0.2445\tavg epoch acc = 0.2246\n","Epoch 4\tavg epoch Loss = 0.2473\tavg epoch acc = 0.2087\n","Epoch 5\tavg epoch Loss = 0.2465\tavg epoch acc = 0.2781\n","Epoch 6\tavg epoch Loss = 0.2278\tavg epoch acc = 0.2228\n","Epoch 7\tavg epoch Loss = 0.264\tavg epoch acc = 0.1973\n","Epoch 8\tavg epoch Loss = 0.2532\tavg epoch acc = 0.1958\n","Epoch 9\tavg epoch Loss = 0.2602\tavg epoch acc = 0.1921\n","training took 28.55 s\n","Avg test loss = 4.57e+04\tAvg test acc = 0.186\n","Epoch 0\tavg epoch Loss = 0.2951\tavg epoch acc = 0.6758\n","Epoch 1\tavg epoch Loss = 0.2393\tavg epoch acc = 0.3524\n","Epoch 2\tavg epoch Loss = 0.2685\tavg epoch acc = 0.313\n","Epoch 3\tavg epoch Loss = 0.2908\tavg epoch acc = 0.3148\n","Epoch 4\tavg epoch Loss = 0.3127\tavg epoch acc = 0.2919\n","Epoch 5\tavg epoch Loss = 0.326\tavg epoch acc = 0.3316\n","Epoch 6\tavg epoch Loss = 0.3306\tavg epoch acc = 0.2532\n","Epoch 7\tavg epoch Loss = 0.3511\tavg epoch acc = 0.2346\n","Epoch 8\tavg epoch Loss = 0.3471\tavg epoch acc = 0.2286\n","Epoch 9\tavg epoch Loss = 0.3692\tavg epoch acc = 0.2286\n","training took 28.43 s\n","Avg test loss = 2.69e+04\tAvg test acc = 0.227\n","Epoch 0\tavg epoch Loss = 0.2841\tavg epoch acc = 0.5251\n","Epoch 1\tavg epoch Loss = 0.2282\tavg epoch acc = 0.2112\n","Epoch 2\tavg epoch Loss = 0.2339\tavg epoch acc = 0.2532\n","Epoch 3\tavg epoch Loss = 0.2678\tavg epoch acc = 0.2975\n","Epoch 4\tavg epoch Loss = 0.2739\tavg epoch acc = 0.2796\n","Epoch 5\tavg epoch Loss = 0.275\tavg epoch acc = 0.389\n","Epoch 6\tavg epoch Loss = 0.2752\tavg epoch acc = 0.3907\n","Epoch 7\tavg epoch Loss = 0.2782\tavg epoch acc = 0.3908\n","Epoch 8\tavg epoch Loss = 0.2829\tavg epoch acc = 0.3239\n","Epoch 9\tavg epoch Loss = 0.3046\tavg epoch acc = 0.2364\n","training took 28.46 s\n","Avg test loss = 4.26e+04\tAvg test acc = 0.32\n","{'lr': 0.01, 'beta1': 0.1, 'beta2': 0.5, 'batch_size': 64, 'weight_decay': 0.1, 'epsilon': 1e-10}\n","Epoch 0\tavg epoch Loss = 0.2893\tavg epoch acc = 0.5505\n","Epoch 1\tavg epoch Loss = 0.1979\tavg epoch acc = 0.3636\n","Epoch 2\tavg epoch Loss = 0.1978\tavg epoch acc = 0.3794\n","Epoch 3\tavg epoch Loss = 0.1962\tavg epoch acc = 0.4521\n","Epoch 4\tavg epoch Loss = 0.1893\tavg epoch acc = 0.4158\n","Epoch 5\tavg epoch Loss = 0.1895\tavg epoch acc = 0.4732\n","Epoch 6\tavg epoch Loss = 0.1823\tavg epoch acc = 0.4126\n","Epoch 7\tavg epoch Loss = 0.1851\tavg epoch acc = 0.4375\n","Epoch 8\tavg epoch Loss = 0.1721\tavg epoch acc = 0.411\n","Epoch 9\tavg epoch Loss = 0.1737\tavg epoch acc = 0.3807\n","training took 28.52 s\n","Avg test loss = 3.4e+02\tAvg test acc = 0.289\n","Epoch 0\tavg epoch Loss = 0.2953\tavg epoch acc = 0.6394\n","Epoch 1\tavg epoch Loss = 0.1926\tavg epoch acc = 0.36\n","Epoch 2\tavg epoch Loss = 0.1998\tavg epoch acc = 0.5398\n","Epoch 3\tavg epoch Loss = 0.1964\tavg epoch acc = 0.4716\n","Epoch 4\tavg epoch Loss = 0.1817\tavg epoch acc = 0.3739\n","Epoch 5\tavg epoch Loss = 0.1818\tavg epoch acc = 0.3683\n","Epoch 6\tavg epoch Loss = 0.1804\tavg epoch acc = 0.436\n","Epoch 7\tavg epoch Loss = 0.1787\tavg epoch acc = 0.4333\n","Epoch 8\tavg epoch Loss = 0.1786\tavg epoch acc = 0.4321\n","Epoch 9\tavg epoch Loss = 0.1782\tavg epoch acc = 0.4768\n","training took 28.56 s\n","Avg test loss = 91.9\tAvg test acc = 0.588\n","Epoch 0\tavg epoch Loss = 0.2847\tavg epoch acc = 0.6002\n","Epoch 1\tavg epoch Loss = 0.1994\tavg epoch acc = 0.5173\n","Epoch 2\tavg epoch Loss = 0.1833\tavg epoch acc = 0.4048\n","Epoch 3\tavg epoch Loss = 0.1815\tavg epoch acc = 0.4709\n","Epoch 4\tavg epoch Loss = 0.1851\tavg epoch acc = 0.4913\n","Epoch 5\tavg epoch Loss = 0.1729\tavg epoch acc = 0.494\n","Epoch 6\tavg epoch Loss = 0.1777\tavg epoch acc = 0.4348\n","Epoch 7\tavg epoch Loss = 0.1749\tavg epoch acc = 0.4972\n","Epoch 8\tavg epoch Loss = 0.1587\tavg epoch acc = 0.4481\n","Epoch 9\tavg epoch Loss = 0.1688\tavg epoch acc = 0.4349\n","training took 28.44 s\n","Avg test loss = 6.68e+02\tAvg test acc = 0.271\n","{'lr': 0.01, 'beta1': 0.1, 'beta2': 0.5, 'batch_size': 64, 'weight_decay': 0.1, 'epsilon': 1e-08}\n","Epoch 0\tavg epoch Loss = 0.2878\tavg epoch acc = 0.6149\n","Epoch 1\tavg epoch Loss = 0.1977\tavg epoch acc = 0.4486\n","Epoch 2\tavg epoch Loss = 0.2041\tavg epoch acc = 0.5843\n","Epoch 3\tavg epoch Loss = 0.1823\tavg epoch acc = 0.4706\n","Epoch 4\tavg epoch Loss = 0.1833\tavg epoch acc = 0.5279\n","Epoch 5\tavg epoch Loss = 0.1741\tavg epoch acc = 0.4887\n","Epoch 6\tavg epoch Loss = 0.1805\tavg epoch acc = 0.5598\n","Epoch 7\tavg epoch Loss = 0.1717\tavg epoch acc = 0.5786\n","Epoch 8\tavg epoch Loss = 0.1723\tavg epoch acc = 0.5619\n","Epoch 9\tavg epoch Loss = 0.1705\tavg epoch acc = 0.5806\n","training took 28.6 s\n","Avg test loss = 3.11e+02\tAvg test acc = 0.597\n","Epoch 0\tavg epoch Loss = 0.3009\tavg epoch acc = 0.5635\n","Epoch 1\tavg epoch Loss = 0.2005\tavg epoch acc = 0.458\n","Epoch 2\tavg epoch Loss = 0.1929\tavg epoch acc = 0.5458\n","Epoch 3\tavg epoch Loss = 0.1902\tavg epoch acc = 0.6214\n","Epoch 4\tavg epoch Loss = 0.1907\tavg epoch acc = 0.6111\n","Epoch 5\tavg epoch Loss = 0.1933\tavg epoch acc = 0.5766\n","Epoch 6\tavg epoch Loss = 0.1781\tavg epoch acc = 0.5792\n","Epoch 7\tavg epoch Loss = 0.1847\tavg epoch acc = 0.6428\n","Epoch 8\tavg epoch Loss = 0.1919\tavg epoch acc = 0.6852\n","Epoch 9\tavg epoch Loss = 0.1948\tavg epoch acc = 0.6276\n","training took 28.38 s\n","Avg test loss = 62.1\tAvg test acc = 0.552\n","Epoch 0\tavg epoch Loss = 0.2879\tavg epoch acc = 0.5622\n","Epoch 1\tavg epoch Loss = 0.1931\tavg epoch acc = 0.3475\n","Epoch 2\tavg epoch Loss = 0.2008\tavg epoch acc = 0.4622\n","Epoch 3\tavg epoch Loss = 0.1982\tavg epoch acc = 0.5689\n","Epoch 4\tavg epoch Loss = 0.1845\tavg epoch acc = 0.5598\n","Epoch 5\tavg epoch Loss = 0.1719\tavg epoch acc = 0.5376\n","Epoch 6\tavg epoch Loss = 0.1739\tavg epoch acc = 0.4386\n","Epoch 7\tavg epoch Loss = 0.1591\tavg epoch acc = 0.433\n","Epoch 8\tavg epoch Loss = 0.1653\tavg epoch acc = 0.4503\n","Epoch 9\tavg epoch Loss = 0.1638\tavg epoch acc = 0.3293\n","training took 28.55 s\n","Avg test loss = 9.1e+02\tAvg test acc = 0.319\n","{'lr': 0.01, 'beta1': 0.1, 'beta2': 0.5, 'batch_size': 128, 'weight_decay': 0.001, 'epsilon': 1e-10}\n","Epoch 0\tavg epoch Loss = 0.3183\tavg epoch acc = 0.7504\n","Epoch 1\tavg epoch Loss = 0.1213\tavg epoch acc = 0.4986\n","Epoch 2\tavg epoch Loss = 0.1348\tavg epoch acc = 0.4083\n","Epoch 3\tavg epoch Loss = 0.1553\tavg epoch acc = 0.3543\n","Epoch 4\tavg epoch Loss = 0.147\tavg epoch acc = 0.2832\n","Epoch 5\tavg epoch Loss = 0.1585\tavg epoch acc = 0.4449\n","Epoch 6\tavg epoch Loss = 0.1727\tavg epoch acc = 0.373\n","Epoch 7\tavg epoch Loss = 0.1741\tavg epoch acc = 0.3476\n","Epoch 8\tavg epoch Loss = 0.1834\tavg epoch acc = 0.3196\n","Epoch 9\tavg epoch Loss = 0.1865\tavg epoch acc = 0.3602\n","training took 17.64 s\n","Avg test loss = 4.88e+04\tAvg test acc = 0.328\n","Epoch 0\tavg epoch Loss = 0.3282\tavg epoch acc = 0.6642\n","Epoch 1\tavg epoch Loss = 0.1342\tavg epoch acc = 0.4194\n","Epoch 2\tavg epoch Loss = 0.1343\tavg epoch acc = 0.391\n","Epoch 3\tavg epoch Loss = 0.1437\tavg epoch acc = 0.3568\n","Epoch 4\tavg epoch Loss = 0.1501\tavg epoch acc = 0.4169\n","Epoch 5\tavg epoch Loss = 0.1665\tavg epoch acc = 0.3117\n","Epoch 6\tavg epoch Loss = 0.1747\tavg epoch acc = 0.2077\n","Epoch 7\tavg epoch Loss = 0.1643\tavg epoch acc = 0.2179\n","Epoch 8\tavg epoch Loss = 0.1729\tavg epoch acc = 0.2927\n","Epoch 9\tavg epoch Loss = 0.1703\tavg epoch acc = 0.291\n","training took 17.61 s\n","Avg test loss = 1.76e+04\tAvg test acc = 0.284\n","Epoch 0\tavg epoch Loss = 0.3059\tavg epoch acc = 0.7034\n","Epoch 1\tavg epoch Loss = 0.1294\tavg epoch acc = 0.4862\n","Epoch 2\tavg epoch Loss = 0.141\tavg epoch acc = 0.3123\n","Epoch 3\tavg epoch Loss = 0.1509\tavg epoch acc = 0.3075\n","Epoch 4\tavg epoch Loss = 0.1695\tavg epoch acc = 0.3296\n","Epoch 5\tavg epoch Loss = 0.1646\tavg epoch acc = 0.3653\n","Epoch 6\tavg epoch Loss = 0.1737\tavg epoch acc = 0.3634\n","Epoch 7\tavg epoch Loss = 0.157\tavg epoch acc = 0.3217\n","Epoch 8\tavg epoch Loss = 0.1702\tavg epoch acc = 0.3359\n","Epoch 9\tavg epoch Loss = 0.1803\tavg epoch acc = 0.2609\n","training took 17.54 s\n","Avg test loss = 7.85e+04\tAvg test acc = 0.221\n","{'lr': 0.01, 'beta1': 0.1, 'beta2': 0.5, 'batch_size': 128, 'weight_decay': 0.001, 'epsilon': 1e-08}\n","Epoch 0\tavg epoch Loss = 0.3099\tavg epoch acc = 0.6189\n","Epoch 1\tavg epoch Loss = 0.1223\tavg epoch acc = 0.5563\n","Epoch 2\tavg epoch Loss = 0.1234\tavg epoch acc = 0.2698\n","Epoch 3\tavg epoch Loss = 0.1493\tavg epoch acc = 0.2677\n","Epoch 4\tavg epoch Loss = 0.1486\tavg epoch acc = 0.2036\n","Epoch 5\tavg epoch Loss = 0.1599\tavg epoch acc = 0.3136\n","Epoch 6\tavg epoch Loss = 0.1816\tavg epoch acc = 0.2559\n","Epoch 7\tavg epoch Loss = 0.1823\tavg epoch acc = 0.1875\n","Epoch 8\tavg epoch Loss = 0.1667\tavg epoch acc = 0.2267\n","Epoch 9\tavg epoch Loss = 0.1556\tavg epoch acc = 0.1852\n","training took 17.57 s\n","Avg test loss = 3.13e+04\tAvg test acc = 0.259\n","Epoch 0\tavg epoch Loss = 0.3185\tavg epoch acc = 0.7276\n","Epoch 1\tavg epoch Loss = 0.1376\tavg epoch acc = 0.4884\n","Epoch 2\tavg epoch Loss = 0.1306\tavg epoch acc = 0.3324\n","Epoch 3\tavg epoch Loss = 0.1417\tavg epoch acc = 0.2388\n","Epoch 4\tavg epoch Loss = 0.1442\tavg epoch acc = 0.2715\n","Epoch 5\tavg epoch Loss = 0.1556\tavg epoch acc = 0.2512\n","Epoch 6\tavg epoch Loss = 0.1585\tavg epoch acc = 0.3037\n","Epoch 7\tavg epoch Loss = 0.1461\tavg epoch acc = 0.2708\n","Epoch 8\tavg epoch Loss = 0.1481\tavg epoch acc = 0.3037\n","Epoch 9\tavg epoch Loss = 0.1658\tavg epoch acc = 0.2862\n","training took 17.56 s\n","Avg test loss = 4.28e+04\tAvg test acc = 0.336\n","Epoch 0\tavg epoch Loss = 0.3289\tavg epoch acc = 0.6226\n","Epoch 1\tavg epoch Loss = 0.1364\tavg epoch acc = 0.4067\n","Epoch 2\tavg epoch Loss = 0.1489\tavg epoch acc = 0.3449\n","Epoch 3\tavg epoch Loss = 0.1943\tavg epoch acc = 0.3457\n","Epoch 4\tavg epoch Loss = 0.1864\tavg epoch acc = 0.3722\n","Epoch 5\tavg epoch Loss = 0.1719\tavg epoch acc = 0.3176\n","Epoch 6\tavg epoch Loss = 0.192\tavg epoch acc = 0.3093\n","Epoch 7\tavg epoch Loss = 0.1754\tavg epoch acc = 0.2904\n","Epoch 8\tavg epoch Loss = 0.1814\tavg epoch acc = 0.2911\n","Epoch 9\tavg epoch Loss = 0.1909\tavg epoch acc = 0.3214\n","training took 17.6 s\n","Avg test loss = 6.51e+04\tAvg test acc = 0.227\n","{'lr': 0.01, 'beta1': 0.1, 'beta2': 0.5, 'batch_size': 128, 'weight_decay': 0.1, 'epsilon': 1e-10}\n","Epoch 0\tavg epoch Loss = 0.3054\tavg epoch acc = 0.7006\n","Epoch 1\tavg epoch Loss = 0.1253\tavg epoch acc = 0.501\n","Epoch 2\tavg epoch Loss = 0.1184\tavg epoch acc = 0.333\n","Epoch 3\tavg epoch Loss = 0.1171\tavg epoch acc = 0.2944\n","Epoch 4\tavg epoch Loss = 0.1186\tavg epoch acc = 0.4438\n","Epoch 5\tavg epoch Loss = 0.1198\tavg epoch acc = 0.3906\n","Epoch 6\tavg epoch Loss = 0.1179\tavg epoch acc = 0.4334\n","Epoch 7\tavg epoch Loss = 0.1104\tavg epoch acc = 0.3994\n","Epoch 8\tavg epoch Loss = 0.1101\tavg epoch acc = 0.3897\n","Epoch 9\tavg epoch Loss = 0.1043\tavg epoch acc = 0.439\n","training took 17.52 s\n","Avg test loss = 3.15e+02\tAvg test acc = 0.566\n","Epoch 0\tavg epoch Loss = 0.306\tavg epoch acc = 0.7012\n","Epoch 1\tavg epoch Loss = 0.1228\tavg epoch acc = 0.3822\n","Epoch 2\tavg epoch Loss = 0.1241\tavg epoch acc = 0.3889\n","Epoch 3\tavg epoch Loss = 0.1217\tavg epoch acc = 0.4913\n","Epoch 4\tavg epoch Loss = 0.1191\tavg epoch acc = 0.3962\n","Epoch 5\tavg epoch Loss = 0.1096\tavg epoch acc = 0.3429\n","Epoch 6\tavg epoch Loss = 0.1134\tavg epoch acc = 0.3525\n","Epoch 7\tavg epoch Loss = 0.1096\tavg epoch acc = 0.35\n","Epoch 8\tavg epoch Loss = 0.1245\tavg epoch acc = 0.428\n","Epoch 9\tavg epoch Loss = 0.1116\tavg epoch acc = 0.3976\n","training took 17.55 s\n","Avg test loss = 4.49e+02\tAvg test acc = 0.297\n","Epoch 0\tavg epoch Loss = 0.3383\tavg epoch acc = 0.7427\n","Epoch 1\tavg epoch Loss = 0.1329\tavg epoch acc = 0.6151\n","Epoch 2\tavg epoch Loss = 0.1276\tavg epoch acc = 0.3678\n","Epoch 3\tavg epoch Loss = 0.1299\tavg epoch acc = 0.3729\n","Epoch 4\tavg epoch Loss = 0.1191\tavg epoch acc = 0.2946\n","Epoch 5\tavg epoch Loss = 0.116\tavg epoch acc = 0.2178\n","Epoch 6\tavg epoch Loss = 0.1079\tavg epoch acc = 0.2907\n","Epoch 7\tavg epoch Loss = 0.1056\tavg epoch acc = 0.3298\n","Epoch 8\tavg epoch Loss = 0.1091\tavg epoch acc = 0.4135\n","Epoch 9\tavg epoch Loss = 0.1135\tavg epoch acc = 0.3774\n","training took 17.59 s\n","Avg test loss = 6.48e+02\tAvg test acc = 0.356\n","{'lr': 0.01, 'beta1': 0.1, 'beta2': 0.5, 'batch_size': 128, 'weight_decay': 0.1, 'epsilon': 1e-08}\n","Epoch 0\tavg epoch Loss = 0.3047\tavg epoch acc = 0.7079\n","Epoch 1\tavg epoch Loss = 0.1338\tavg epoch acc = 0.5487\n","Epoch 2\tavg epoch Loss = 0.1247\tavg epoch acc = 0.4019\n","Epoch 3\tavg epoch Loss = 0.1238\tavg epoch acc = 0.3967\n","Epoch 4\tavg epoch Loss = 0.1217\tavg epoch acc = 0.4876\n","Epoch 5\tavg epoch Loss = 0.118\tavg epoch acc = 0.5036\n","Epoch 6\tavg epoch Loss = 0.1319\tavg epoch acc = 0.4365\n","Epoch 7\tavg epoch Loss = 0.1146\tavg epoch acc = 0.4005\n","Epoch 8\tavg epoch Loss = 0.1056\tavg epoch acc = 0.3362\n","Epoch 9\tavg epoch Loss = 0.1139\tavg epoch acc = 0.4882\n","training took 17.59 s\n","Avg test loss = 1.59e+02\tAvg test acc = 0.599\n","Epoch 0\tavg epoch Loss = 0.3246\tavg epoch acc = 0.7228\n","Epoch 1\tavg epoch Loss = 0.1271\tavg epoch acc = 0.5368\n","Epoch 2\tavg epoch Loss = 0.1205\tavg epoch acc = 0.4211\n","Epoch 3\tavg epoch Loss = 0.1215\tavg epoch acc = 0.4344\n","Epoch 4\tavg epoch Loss = 0.125\tavg epoch acc = 0.4616\n","Epoch 5\tavg epoch Loss = 0.1143\tavg epoch acc = 0.3967\n","Epoch 6\tavg epoch Loss = 0.1089\tavg epoch acc = 0.4833\n","Epoch 7\tavg epoch Loss = 0.106\tavg epoch acc = 0.4568\n","Epoch 8\tavg epoch Loss = 0.1049\tavg epoch acc = 0.3912\n","Epoch 9\tavg epoch Loss = 0.1096\tavg epoch acc = 0.4377\n","training took 17.58 s\n","Avg test loss = 7.13e+02\tAvg test acc = 0.385\n","Epoch 0\tavg epoch Loss = 0.3044\tavg epoch acc = 0.6541\n","Epoch 1\tavg epoch Loss = 0.1361\tavg epoch acc = 0.5702\n","Epoch 2\tavg epoch Loss = 0.1297\tavg epoch acc = 0.428\n","Epoch 3\tavg epoch Loss = 0.1241\tavg epoch acc = 0.4261\n","Epoch 4\tavg epoch Loss = 0.1281\tavg epoch acc = 0.4819\n","Epoch 5\tavg epoch Loss = 0.1185\tavg epoch acc = 0.4828\n","Epoch 6\tavg epoch Loss = 0.1258\tavg epoch acc = 0.3249\n","Epoch 7\tavg epoch Loss = 0.1133\tavg epoch acc = 0.3005\n","Epoch 8\tavg epoch Loss = 0.1086\tavg epoch acc = 0.3445\n","Epoch 9\tavg epoch Loss = 0.1129\tavg epoch acc = 0.3837\n","training took 17.58 s\n","Avg test loss = 4.85e+02\tAvg test acc = 0.416\n","{'lr': 0.01, 'beta1': 0.1, 'beta2': 0.999, 'batch_size': 32, 'weight_decay': 0.001, 'epsilon': 1e-10}\n","Epoch 0\tavg epoch Loss = 0.3131\tavg epoch acc = 0.8328\n","Epoch 1\tavg epoch Loss = 0.119\tavg epoch acc = 0.5525\n","Epoch 2\tavg epoch Loss = 0.1293\tavg epoch acc = 0.3772\n","Epoch 3\tavg epoch Loss = 0.1183\tavg epoch acc = 0.3157\n","Epoch 4\tavg epoch Loss = 0.1405\tavg epoch acc = 0.319\n","Epoch 5\tavg epoch Loss = 0.1444\tavg epoch acc = 0.2965\n","Epoch 6\tavg epoch Loss = 0.1457\tavg epoch acc = 0.3406\n","Epoch 7\tavg epoch Loss = 0.1017\tavg epoch acc = 0.2849\n","Epoch 8\tavg epoch Loss = 0.1699\tavg epoch acc = 0.2249\n","Epoch 9\tavg epoch Loss = 0.08236\tavg epoch acc = 0.214\n","training took 54.92 s\n","Avg test loss = 55.3\tAvg test acc = 0.212\n","Epoch 0\tavg epoch Loss = 0.324\tavg epoch acc = 0.817\n","Epoch 1\tavg epoch Loss = 0.1131\tavg epoch acc = 0.4854\n","Epoch 2\tavg epoch Loss = 0.1094\tavg epoch acc = 0.353\n","Epoch 3\tavg epoch Loss = 0.1315\tavg epoch acc = 0.2596\n","Epoch 4\tavg epoch Loss = 0.1165\tavg epoch acc = 0.1963\n","Epoch 5\tavg epoch Loss = 0.1181\tavg epoch acc = 0.1417\n","Epoch 6\tavg epoch Loss = 0.1291\tavg epoch acc = 0.1597\n","Epoch 7\tavg epoch Loss = 0.1216\tavg epoch acc = 0.181\n","Epoch 8\tavg epoch Loss = 0.1237\tavg epoch acc = 0.2404\n","Epoch 9\tavg epoch Loss = 0.1397\tavg epoch acc = 0.1776\n","training took 54.81 s\n","Avg test loss = 26.5\tAvg test acc = 0.129\n","Epoch 0\tavg epoch Loss = 0.3182\tavg epoch acc = 0.8158\n","Epoch 1\tavg epoch Loss = 0.1168\tavg epoch acc = 0.5424\n","Epoch 2\tavg epoch Loss = 0.1209\tavg epoch acc = 0.3998\n","Epoch 3\tavg epoch Loss = 0.137\tavg epoch acc = 0.307\n","Epoch 4\tavg epoch Loss = 0.1073\tavg epoch acc = 0.2943\n","Epoch 5\tavg epoch Loss = 0.1455\tavg epoch acc = 0.3032\n","Epoch 6\tavg epoch Loss = 0.1265\tavg epoch acc = 0.2617\n","Epoch 7\tavg epoch Loss = 0.1259\tavg epoch acc = 0.2753\n","Epoch 8\tavg epoch Loss = 0.1247\tavg epoch acc = 0.2813\n","Epoch 9\tavg epoch Loss = 0.1167\tavg epoch acc = 0.2361\n","training took 54.71 s\n","Avg test loss = 28.0\tAvg test acc = 0.202\n","{'lr': 0.01, 'beta1': 0.1, 'beta2': 0.999, 'batch_size': 32, 'weight_decay': 0.001, 'epsilon': 1e-08}\n","Epoch 0\tavg epoch Loss = 0.3228\tavg epoch acc = 0.8407\n","Epoch 1\tavg epoch Loss = 0.1372\tavg epoch acc = 0.5929\n","Epoch 2\tavg epoch Loss = 0.2534\tavg epoch acc = 0.356\n","Epoch 3\tavg epoch Loss = 0.08703\tavg epoch acc = 0.2866\n","Epoch 4\tavg epoch Loss = 0.2922\tavg epoch acc = 0.221\n","Epoch 5\tavg epoch Loss = 0.07956\tavg epoch acc = 0.2397\n","Epoch 6\tavg epoch Loss = 0.1078\tavg epoch acc = 0.2427\n","Epoch 7\tavg epoch Loss = 0.1003\tavg epoch acc = 0.1719\n","Epoch 8\tavg epoch Loss = 0.09972\tavg epoch acc = 0.1925\n","Epoch 9\tavg epoch Loss = 0.1139\tavg epoch acc = 0.1854\n","training took 54.67 s\n","Avg test loss = 13.3\tAvg test acc = 0.188\n","Epoch 0\tavg epoch Loss = 0.3204\tavg epoch acc = 0.8296\n","Epoch 1\tavg epoch Loss = 0.117\tavg epoch acc = 0.4807\n","Epoch 2\tavg epoch Loss = 0.124\tavg epoch acc = 0.258\n","Epoch 3\tavg epoch Loss = 0.1029\tavg epoch acc = 0.2254\n","Epoch 4\tavg epoch Loss = 0.124\tavg epoch acc = 0.1805\n","Epoch 5\tavg epoch Loss = 0.1347\tavg epoch acc = 0.184\n","Epoch 6\tavg epoch Loss = 0.1363\tavg epoch acc = 0.1546\n","Epoch 7\tavg epoch Loss = 0.1191\tavg epoch acc = 0.1517\n","Epoch 8\tavg epoch Loss = 0.1481\tavg epoch acc = 0.2\n","Epoch 9\tavg epoch Loss = 0.117\tavg epoch acc = 0.2244\n","training took 54.67 s\n","Avg test loss = 22.5\tAvg test acc = 0.22\n","Epoch 0\tavg epoch Loss = 0.3129\tavg epoch acc = 0.8191\n","Epoch 1\tavg epoch Loss = 0.1043\tavg epoch acc = 0.4986\n","Epoch 2\tavg epoch Loss = 0.1231\tavg epoch acc = 0.3118\n","Epoch 3\tavg epoch Loss = 0.123\tavg epoch acc = 0.2633\n","Epoch 4\tavg epoch Loss = 0.1148\tavg epoch acc = 0.2312\n","Epoch 5\tavg epoch Loss = 0.1337\tavg epoch acc = 0.2064\n","Epoch 6\tavg epoch Loss = 0.1041\tavg epoch acc = 0.1799\n","Epoch 7\tavg epoch Loss = 0.1328\tavg epoch acc = 0.2127\n","Epoch 8\tavg epoch Loss = 0.1127\tavg epoch acc = 0.1998\n","Epoch 9\tavg epoch Loss = 0.1565\tavg epoch acc = 0.1807\n","training took 54.79 s\n","Avg test loss = 22.8\tAvg test acc = 0.215\n","{'lr': 0.01, 'beta1': 0.1, 'beta2': 0.999, 'batch_size': 32, 'weight_decay': 0.1, 'epsilon': 1e-10}\n","Epoch 0\tavg epoch Loss = 0.3269\tavg epoch acc = 0.8871\n","Epoch 1\tavg epoch Loss = 0.1408\tavg epoch acc = 0.7236\n","Epoch 2\tavg epoch Loss = 1.426\tavg epoch acc = 0.4209\n","Epoch 3\tavg epoch Loss = 0.1356\tavg epoch acc = 0.6567\n","Epoch 4\tavg epoch Loss = 0.1382\tavg epoch acc = 0.7651\n","Epoch 5\tavg epoch Loss = 0.1266\tavg epoch acc = 0.7162\n","Epoch 6\tavg epoch Loss = 0.1354\tavg epoch acc = 0.7864\n","Epoch 7\tavg epoch Loss = 0.1191\tavg epoch acc = 0.7779\n","Epoch 8\tavg epoch Loss = 0.1509\tavg epoch acc = 0.7305\n","Epoch 9\tavg epoch Loss = 0.1157\tavg epoch acc = 0.6851\n","training took 54.66 s\n","Avg test loss = 1.3\tAvg test acc = 0.612\n","Epoch 0\tavg epoch Loss = 0.3135\tavg epoch acc = 0.8559\n","Epoch 1\tavg epoch Loss = 0.1298\tavg epoch acc = 0.7127\n","Epoch 2\tavg epoch Loss = 1.338\tavg epoch acc = 0.3695\n","Epoch 3\tavg epoch Loss = 2.303\tavg epoch acc = 0.1319\n","Epoch 4\tavg epoch Loss = 2.303\tavg epoch acc = 0.1105\n","Epoch 5\tavg epoch Loss = 2.302\tavg epoch acc = 0.1106\n","Epoch 6\tavg epoch Loss = 2.302\tavg epoch acc = 0.1106\n","Epoch 7\tavg epoch Loss = 2.302\tavg epoch acc = 0.1106\n","Epoch 8\tavg epoch Loss = 2.302\tavg epoch acc = 0.1106\n","Epoch 9\tavg epoch Loss = 2.302\tavg epoch acc = 0.1106\n","training took 54.83 s\n","Avg test loss = 2.3\tAvg test acc = 0.106\n","Epoch 0\tavg epoch Loss = 0.318\tavg epoch acc = 0.8674\n","Epoch 1\tavg epoch Loss = 0.1348\tavg epoch acc = 0.7275\n","Epoch 2\tavg epoch Loss = 0.2402\tavg epoch acc = 0.5614\n","Epoch 3\tavg epoch Loss = 0.1959\tavg epoch acc = 0.5107\n","Epoch 4\tavg epoch Loss = 0.1738\tavg epoch acc = 0.8071\n","Epoch 5\tavg epoch Loss = 0.1742\tavg epoch acc = 0.9124\n","Epoch 6\tavg epoch Loss = 0.1662\tavg epoch acc = 0.9236\n","Epoch 7\tavg epoch Loss = 0.1644\tavg epoch acc = 0.925\n","Epoch 8\tavg epoch Loss = 0.1605\tavg epoch acc = 0.9213\n","Epoch 9\tavg epoch Loss = 0.162\tavg epoch acc = 0.9274\n","training took 54.8 s\n","Avg test loss = 0.379\tAvg test acc = 0.919\n","{'lr': 0.01, 'beta1': 0.1, 'beta2': 0.999, 'batch_size': 32, 'weight_decay': 0.1, 'epsilon': 1e-08}\n","Epoch 0\tavg epoch Loss = 0.3226\tavg epoch acc = 0.8627\n","Epoch 1\tavg epoch Loss = 0.3957\tavg epoch acc = 0.642\n","Epoch 2\tavg epoch Loss = 0.1443\tavg epoch acc = 0.6136\n","Epoch 3\tavg epoch Loss = 0.1404\tavg epoch acc = 0.828\n","Epoch 4\tavg epoch Loss = 0.2643\tavg epoch acc = 0.7771\n","Epoch 5\tavg epoch Loss = 0.162\tavg epoch acc = 0.8925\n","Epoch 6\tavg epoch Loss = 0.1568\tavg epoch acc = 0.8959\n","Epoch 7\tavg epoch Loss = 0.1484\tavg epoch acc = 0.8987\n","Epoch 8\tavg epoch Loss = 0.1815\tavg epoch acc = 0.8391\n","Epoch 9\tavg epoch Loss = 0.1495\tavg epoch acc = 0.912\n","training took 54.7 s\n","Avg test loss = 0.638\tAvg test acc = 0.89\n","Epoch 0\tavg epoch Loss = 0.3273\tavg epoch acc = 0.8831\n","Epoch 1\tavg epoch Loss = 0.1368\tavg epoch acc = 0.7192\n","Epoch 2\tavg epoch Loss = 0.122\tavg epoch acc = 0.6305\n","Epoch 3\tavg epoch Loss = 0.1226\tavg epoch acc = 0.5602\n","Epoch 4\tavg epoch Loss = 1.837\tavg epoch acc = 0.2229\n","Epoch 5\tavg epoch Loss = 0.1302\tavg epoch acc = 0.6374\n","Epoch 6\tavg epoch Loss = 0.1356\tavg epoch acc = 0.5556\n","Epoch 7\tavg epoch Loss = 0.127\tavg epoch acc = 0.835\n","Epoch 8\tavg epoch Loss = 0.1366\tavg epoch acc = 0.7873\n","Epoch 9\tavg epoch Loss = 0.1248\tavg epoch acc = 0.7672\n","training took 54.62 s\n","Avg test loss = 0.72\tAvg test acc = 0.833\n","Epoch 0\tavg epoch Loss = 0.3336\tavg epoch acc = 0.8591\n","Epoch 1\tavg epoch Loss = 0.1139\tavg epoch acc = 0.7224\n","Epoch 2\tavg epoch Loss = 1.375\tavg epoch acc = 0.3906\n","Epoch 3\tavg epoch Loss = 2.303\tavg epoch acc = 0.1484\n","Epoch 4\tavg epoch Loss = 2.303\tavg epoch acc = 0.1096\n","Epoch 5\tavg epoch Loss = 2.303\tavg epoch acc = 0.1096\n","Epoch 6\tavg epoch Loss = 2.303\tavg epoch acc = 0.1096\n","Epoch 7\tavg epoch Loss = 2.303\tavg epoch acc = 0.1096\n","Epoch 8\tavg epoch Loss = 2.303\tavg epoch acc = 0.1096\n","Epoch 9\tavg epoch Loss = 2.303\tavg epoch acc = 0.1096\n","training took 54.82 s\n","Avg test loss = 2.3\tAvg test acc = 0.103\n","{'lr': 0.01, 'beta1': 0.1, 'beta2': 0.999, 'batch_size': 64, 'weight_decay': 0.001, 'epsilon': 1e-10}\n","Epoch 0\tavg epoch Loss = 0.442\tavg epoch acc = 0.878\n","Epoch 1\tavg epoch Loss = 0.1204\tavg epoch acc = 0.7738\n","Epoch 2\tavg epoch Loss = 0.07448\tavg epoch acc = 0.6592\n","Epoch 3\tavg epoch Loss = 0.07401\tavg epoch acc = 0.5584\n","Epoch 4\tavg epoch Loss = 0.0712\tavg epoch acc = 0.4394\n","Epoch 5\tavg epoch Loss = 0.07264\tavg epoch acc = 0.3828\n","Epoch 6\tavg epoch Loss = 0.07698\tavg epoch acc = 0.3963\n","Epoch 7\tavg epoch Loss = 0.08619\tavg epoch acc = 0.301\n","Epoch 8\tavg epoch Loss = 0.07796\tavg epoch acc = 0.305\n","Epoch 9\tavg epoch Loss = 0.08414\tavg epoch acc = 0.2918\n","training took 28.5 s\n","Avg test loss = 6.89\tAvg test acc = 0.325\n","Epoch 0\tavg epoch Loss = 0.4444\tavg epoch acc = 0.8748\n","Epoch 1\tavg epoch Loss = 0.1135\tavg epoch acc = 0.8517\n","Epoch 2\tavg epoch Loss = 1.816\tavg epoch acc = 0.2591\n","Epoch 3\tavg epoch Loss = 0.08561\tavg epoch acc = 0.1429\n","Epoch 4\tavg epoch Loss = 0.0633\tavg epoch acc = 0.1427\n","Epoch 5\tavg epoch Loss = 0.05987\tavg epoch acc = 0.1609\n","Epoch 6\tavg epoch Loss = 0.06136\tavg epoch acc = 0.1574\n","Epoch 7\tavg epoch Loss = 0.07191\tavg epoch acc = 0.1486\n","Epoch 8\tavg epoch Loss = 0.05457\tavg epoch acc = 0.1419\n","Epoch 9\tavg epoch Loss = 0.05955\tavg epoch acc = 0.1366\n","training took 28.6 s\n","Avg test loss = 5.04\tAvg test acc = 0.139\n","Epoch 0\tavg epoch Loss = 0.4251\tavg epoch acc = 0.8692\n","Epoch 1\tavg epoch Loss = 0.1089\tavg epoch acc = 0.8431\n","Epoch 2\tavg epoch Loss = 1.157\tavg epoch acc = 0.6228\n","Epoch 3\tavg epoch Loss = 0.1528\tavg epoch acc = 0.1747\n","Epoch 4\tavg epoch Loss = 0.08237\tavg epoch acc = 0.1873\n","Epoch 5\tavg epoch Loss = 0.06513\tavg epoch acc = 0.1739\n","Epoch 6\tavg epoch Loss = 0.06286\tavg epoch acc = 0.1896\n","Epoch 7\tavg epoch Loss = 0.0574\tavg epoch acc = 0.166\n","Epoch 8\tavg epoch Loss = 0.05867\tavg epoch acc = 0.1779\n","Epoch 9\tavg epoch Loss = 0.05744\tavg epoch acc = 0.1702\n","training took 28.46 s\n","Avg test loss = 11.7\tAvg test acc = 0.138\n","{'lr': 0.01, 'beta1': 0.1, 'beta2': 0.999, 'batch_size': 64, 'weight_decay': 0.001, 'epsilon': 1e-08}\n","Epoch 0\tavg epoch Loss = 0.4361\tavg epoch acc = 0.8643\n","Epoch 1\tavg epoch Loss = 0.1104\tavg epoch acc = 0.8457\n","Epoch 2\tavg epoch Loss = 1.017\tavg epoch acc = 0.3488\n","Epoch 3\tavg epoch Loss = 0.09586\tavg epoch acc = 0.2003\n","Epoch 4\tavg epoch Loss = 0.06841\tavg epoch acc = 0.1884\n","Epoch 5\tavg epoch Loss = 0.06669\tavg epoch acc = 0.1694\n","Epoch 6\tavg epoch Loss = 0.05852\tavg epoch acc = 0.1779\n","Epoch 7\tavg epoch Loss = 0.06602\tavg epoch acc = 0.178\n","Epoch 8\tavg epoch Loss = 0.07591\tavg epoch acc = 0.2079\n","Epoch 9\tavg epoch Loss = 0.068\tavg epoch acc = 0.2221\n","training took 28.48 s\n","Avg test loss = 7.75\tAvg test acc = 0.214\n","Epoch 0\tavg epoch Loss = 0.4346\tavg epoch acc = 0.8097\n","Epoch 1\tavg epoch Loss = 0.1056\tavg epoch acc = 0.7658\n","Epoch 2\tavg epoch Loss = 0.1233\tavg epoch acc = 0.5666\n","Epoch 3\tavg epoch Loss = 0.06283\tavg epoch acc = 0.4678\n","Epoch 4\tavg epoch Loss = 0.06176\tavg epoch acc = 0.4272\n","Epoch 5\tavg epoch Loss = 0.07539\tavg epoch acc = 0.3457\n","Epoch 6\tavg epoch Loss = 0.06235\tavg epoch acc = 0.2936\n","Epoch 7\tavg epoch Loss = 0.0838\tavg epoch acc = 0.3058\n","Epoch 8\tavg epoch Loss = 0.07819\tavg epoch acc = 0.2762\n","Epoch 9\tavg epoch Loss = 0.07171\tavg epoch acc = 0.2554\n","training took 28.52 s\n","Avg test loss = 9.7\tAvg test acc = 0.243\n","Epoch 0\tavg epoch Loss = 0.4385\tavg epoch acc = 0.8611\n","Epoch 1\tavg epoch Loss = 0.1047\tavg epoch acc = 0.82\n","Epoch 2\tavg epoch Loss = 0.08014\tavg epoch acc = 0.6882\n","Epoch 3\tavg epoch Loss = 0.07143\tavg epoch acc = 0.605\n","Epoch 4\tavg epoch Loss = 0.1707\tavg epoch acc = 0.3733\n","Epoch 5\tavg epoch Loss = 0.05641\tavg epoch acc = 0.3804\n","Epoch 6\tavg epoch Loss = 0.0805\tavg epoch acc = 0.3766\n","Epoch 7\tavg epoch Loss = 0.0739\tavg epoch acc = 0.3362\n","Epoch 8\tavg epoch Loss = 0.06853\tavg epoch acc = 0.3185\n","Epoch 9\tavg epoch Loss = 0.09282\tavg epoch acc = 0.3348\n","training took 28.43 s\n","Avg test loss = 10.1\tAvg test acc = 0.326\n","{'lr': 0.01, 'beta1': 0.1, 'beta2': 0.999, 'batch_size': 64, 'weight_decay': 0.1, 'epsilon': 1e-10}\n","Epoch 0\tavg epoch Loss = 0.4385\tavg epoch acc = 0.8603\n","Epoch 1\tavg epoch Loss = 0.1523\tavg epoch acc = 0.6607\n","Epoch 2\tavg epoch Loss = 0.09438\tavg epoch acc = 0.6915\n","Epoch 3\tavg epoch Loss = 0.08144\tavg epoch acc = 0.7129\n","Epoch 4\tavg epoch Loss = 0.09212\tavg epoch acc = 0.7115\n","Epoch 5\tavg epoch Loss = 1.132\tavg epoch acc = 0.5601\n","Epoch 6\tavg epoch Loss = 0.2764\tavg epoch acc = 0.2767\n","Epoch 7\tavg epoch Loss = 0.1635\tavg epoch acc = 0.4731\n","Epoch 8\tavg epoch Loss = 0.1683\tavg epoch acc = 0.714\n","Epoch 9\tavg epoch Loss = 0.1396\tavg epoch acc = 0.8638\n","training took 28.46 s\n","Avg test loss = 0.544\tAvg test acc = 0.89\n","Epoch 0\tavg epoch Loss = 0.4388\tavg epoch acc = 0.8738\n","Epoch 1\tavg epoch Loss = 0.1225\tavg epoch acc = 0.9342\n","Epoch 2\tavg epoch Loss = 0.09066\tavg epoch acc = 0.8392\n","Epoch 3\tavg epoch Loss = 0.8345\tavg epoch acc = 0.5189\n","Epoch 4\tavg epoch Loss = 0.1301\tavg epoch acc = 0.4154\n","Epoch 5\tavg epoch Loss = 0.1205\tavg epoch acc = 0.6326\n","Epoch 6\tavg epoch Loss = 0.1024\tavg epoch acc = 0.8189\n","Epoch 7\tavg epoch Loss = 0.09758\tavg epoch acc = 0.84\n","Epoch 8\tavg epoch Loss = 0.0937\tavg epoch acc = 0.824\n","Epoch 9\tavg epoch Loss = 0.0926\tavg epoch acc = 0.8068\n","training took 28.42 s\n","Avg test loss = 1.29\tAvg test acc = 0.731\n","Epoch 0\tavg epoch Loss = 0.4364\tavg epoch acc = 0.8773\n","Epoch 1\tavg epoch Loss = 0.1224\tavg epoch acc = 0.8622\n","Epoch 2\tavg epoch Loss = 0.08531\tavg epoch acc = 0.7512\n","Epoch 3\tavg epoch Loss = 0.08318\tavg epoch acc = 0.6838\n","Epoch 4\tavg epoch Loss = 0.99\tavg epoch acc = 0.3024\n","Epoch 5\tavg epoch Loss = 0.21\tavg epoch acc = 0.4136\n","Epoch 6\tavg epoch Loss = 0.1887\tavg epoch acc = 0.7467\n","Epoch 7\tavg epoch Loss = 0.15\tavg epoch acc = 0.872\n","Epoch 8\tavg epoch Loss = 0.09672\tavg epoch acc = 0.8895\n","Epoch 9\tavg epoch Loss = 0.8443\tavg epoch acc = 0.6054\n","training took 28.45 s\n","Avg test loss = 2.54\tAvg test acc = 0.0796\n","{'lr': 0.01, 'beta1': 0.1, 'beta2': 0.999, 'batch_size': 64, 'weight_decay': 0.1, 'epsilon': 1e-08}\n","Epoch 0\tavg epoch Loss = 0.4284\tavg epoch acc = 0.8872\n","Epoch 1\tavg epoch Loss = 0.114\tavg epoch acc = 0.9255\n","Epoch 2\tavg epoch Loss = 0.08765\tavg epoch acc = 0.8203\n","Epoch 3\tavg epoch Loss = 0.822\tavg epoch acc = 0.4216\n","Epoch 4\tavg epoch Loss = 0.09561\tavg epoch acc = 0.5917\n","Epoch 5\tavg epoch Loss = 0.09117\tavg epoch acc = 0.794\n","Epoch 6\tavg epoch Loss = 0.09151\tavg epoch acc = 0.8398\n","Epoch 7\tavg epoch Loss = 0.08541\tavg epoch acc = 0.8458\n","Epoch 8\tavg epoch Loss = 0.0835\tavg epoch acc = 0.8467\n","Epoch 9\tavg epoch Loss = 0.08317\tavg epoch acc = 0.8466\n","training took 28.64 s\n","Avg test loss = 0.642\tAvg test acc = 0.881\n","Epoch 0\tavg epoch Loss = 0.4312\tavg epoch acc = 0.8822\n","Epoch 1\tavg epoch Loss = 0.1131\tavg epoch acc = 0.8976\n","Epoch 2\tavg epoch Loss = 0.1744\tavg epoch acc = 0.5551\n","Epoch 3\tavg epoch Loss = 0.07458\tavg epoch acc = 0.6038\n","Epoch 4\tavg epoch Loss = 0.07615\tavg epoch acc = 0.7032\n","Epoch 5\tavg epoch Loss = 0.536\tavg epoch acc = 0.6411\n","Epoch 6\tavg epoch Loss = 0.2705\tavg epoch acc = 0.3239\n","Epoch 7\tavg epoch Loss = 0.1647\tavg epoch acc = 0.6069\n","Epoch 8\tavg epoch Loss = 1.425\tavg epoch acc = 0.4182\n","Epoch 9\tavg epoch Loss = 0.2666\tavg epoch acc = 0.8591\n","training took 28.42 s\n","Avg test loss = 0.642\tAvg test acc = 0.875\n","Epoch 0\tavg epoch Loss = 0.4496\tavg epoch acc = 0.8797\n","Epoch 1\tavg epoch Loss = 0.1215\tavg epoch acc = 0.9343\n","Epoch 2\tavg epoch Loss = 0.09424\tavg epoch acc = 0.8005\n","Epoch 3\tavg epoch Loss = 0.09148\tavg epoch acc = 0.7107\n","Epoch 4\tavg epoch Loss = 10.28\tavg epoch acc = 0.5879\n","Epoch 5\tavg epoch Loss = 0.4269\tavg epoch acc = 0.07748\n","Epoch 6\tavg epoch Loss = 0.1901\tavg epoch acc = 0.1724\n","Epoch 7\tavg epoch Loss = 0.1552\tavg epoch acc = 0.6046\n","Epoch 8\tavg epoch Loss = 0.1329\tavg epoch acc = 0.8781\n","Epoch 9\tavg epoch Loss = 0.08462\tavg epoch acc = 0.8854\n","training took 28.47 s\n","Avg test loss = 0.97\tAvg test acc = 0.825\n","{'lr': 0.01, 'beta1': 0.1, 'beta2': 0.999, 'batch_size': 128, 'weight_decay': 0.001, 'epsilon': 1e-10}\n","Epoch 0\tavg epoch Loss = 0.7187\tavg epoch acc = 0.7828\n","Epoch 1\tavg epoch Loss = 0.131\tavg epoch acc = 0.8289\n","Epoch 2\tavg epoch Loss = 0.08984\tavg epoch acc = 0.8262\n","Epoch 3\tavg epoch Loss = 0.07149\tavg epoch acc = 0.816\n","Epoch 4\tavg epoch Loss = 0.05598\tavg epoch acc = 0.7882\n","Epoch 5\tavg epoch Loss = 1.21\tavg epoch acc = 0.2903\n","Epoch 6\tavg epoch Loss = 0.09499\tavg epoch acc = 0.1453\n","Epoch 7\tavg epoch Loss = 0.05983\tavg epoch acc = 0.1511\n","Epoch 8\tavg epoch Loss = 0.04482\tavg epoch acc = 0.1382\n","Epoch 9\tavg epoch Loss = 0.03453\tavg epoch acc = 0.1324\n","training took 17.61 s\n","Avg test loss = 4.28\tAvg test acc = 0.124\n","Epoch 0\tavg epoch Loss = 0.6437\tavg epoch acc = 0.8277\n","Epoch 1\tavg epoch Loss = 0.1576\tavg epoch acc = 0.9498\n","Epoch 2\tavg epoch Loss = 0.0962\tavg epoch acc = 0.9366\n","Epoch 3\tavg epoch Loss = 0.06672\tavg epoch acc = 0.8862\n","Epoch 4\tavg epoch Loss = 0.05303\tavg epoch acc = 0.804\n","Epoch 5\tavg epoch Loss = 1.185\tavg epoch acc = 0.4184\n","Epoch 6\tavg epoch Loss = 0.0676\tavg epoch acc = 0.1995\n","Epoch 7\tavg epoch Loss = 0.03708\tavg epoch acc = 0.208\n","Epoch 8\tavg epoch Loss = 0.02851\tavg epoch acc = 0.2091\n","Epoch 9\tavg epoch Loss = 0.02991\tavg epoch acc = 0.1921\n","training took 17.66 s\n","Avg test loss = 3.38\tAvg test acc = 0.173\n","Epoch 0\tavg epoch Loss = 0.6627\tavg epoch acc = 0.8253\n","Epoch 1\tavg epoch Loss = 0.1553\tavg epoch acc = 0.956\n","Epoch 2\tavg epoch Loss = 0.0916\tavg epoch acc = 0.9298\n","Epoch 3\tavg epoch Loss = 0.06992\tavg epoch acc = 0.8501\n","Epoch 4\tavg epoch Loss = 0.0576\tavg epoch acc = 0.8086\n","Epoch 5\tavg epoch Loss = 1.311\tavg epoch acc = 0.3148\n","Epoch 6\tavg epoch Loss = 0.09949\tavg epoch acc = 0.2379\n","Epoch 7\tavg epoch Loss = 0.05422\tavg epoch acc = 0.2062\n","Epoch 8\tavg epoch Loss = 0.04192\tavg epoch acc = 0.2055\n","Epoch 9\tavg epoch Loss = 0.03825\tavg epoch acc = 0.1683\n","training took 17.53 s\n","Avg test loss = 3.61\tAvg test acc = 0.18\n","{'lr': 0.01, 'beta1': 0.1, 'beta2': 0.999, 'batch_size': 128, 'weight_decay': 0.001, 'epsilon': 1e-08}\n","Epoch 0\tavg epoch Loss = 0.6537\tavg epoch acc = 0.82\n","Epoch 1\tavg epoch Loss = 0.1775\tavg epoch acc = 0.918\n","Epoch 2\tavg epoch Loss = 0.09795\tavg epoch acc = 0.906\n","Epoch 3\tavg epoch Loss = 0.06596\tavg epoch acc = 0.8666\n","Epoch 4\tavg epoch Loss = 0.04857\tavg epoch acc = 0.8033\n","Epoch 5\tavg epoch Loss = 2.378\tavg epoch acc = 0.1481\n","Epoch 6\tavg epoch Loss = 0.06215\tavg epoch acc = 0.1944\n","Epoch 7\tavg epoch Loss = 0.03938\tavg epoch acc = 0.213\n","Epoch 8\tavg epoch Loss = 0.03187\tavg epoch acc = 0.2097\n","Epoch 9\tavg epoch Loss = 0.02783\tavg epoch acc = 0.2038\n","training took 17.56 s\n","Avg test loss = 2.9\tAvg test acc = 0.189\n","Epoch 0\tavg epoch Loss = 0.6613\tavg epoch acc = 0.8155\n","Epoch 1\tavg epoch Loss = 0.1475\tavg epoch acc = 0.9368\n","Epoch 2\tavg epoch Loss = 0.09063\tavg epoch acc = 0.9018\n","Epoch 3\tavg epoch Loss = 0.4331\tavg epoch acc = 0.508\n","Epoch 4\tavg epoch Loss = 0.05745\tavg epoch acc = 0.4162\n","Epoch 5\tavg epoch Loss = 0.03863\tavg epoch acc = 0.3825\n","Epoch 6\tavg epoch Loss = 0.03375\tavg epoch acc = 0.334\n","Epoch 7\tavg epoch Loss = 0.03683\tavg epoch acc = 0.3584\n","Epoch 8\tavg epoch Loss = 0.03436\tavg epoch acc = 0.338\n","Epoch 9\tavg epoch Loss = 0.03608\tavg epoch acc = 0.3438\n","training took 17.6 s\n","Avg test loss = 3.91\tAvg test acc = 0.393\n","Epoch 0\tavg epoch Loss = 0.6459\tavg epoch acc = 0.8174\n","Epoch 1\tavg epoch Loss = 0.1468\tavg epoch acc = 0.9184\n","Epoch 2\tavg epoch Loss = 0.09262\tavg epoch acc = 0.8979\n","Epoch 3\tavg epoch Loss = 0.3048\tavg epoch acc = 0.56\n","Epoch 4\tavg epoch Loss = 0.05938\tavg epoch acc = 0.5136\n","Epoch 5\tavg epoch Loss = 0.04174\tavg epoch acc = 0.4754\n","Epoch 6\tavg epoch Loss = 0.04036\tavg epoch acc = 0.4793\n","Epoch 7\tavg epoch Loss = 0.04632\tavg epoch acc = 0.452\n","Epoch 8\tavg epoch Loss = 0.03923\tavg epoch acc = 0.4416\n","Epoch 9\tavg epoch Loss = 0.04523\tavg epoch acc = 0.4338\n","training took 17.56 s\n","Avg test loss = 3.32\tAvg test acc = 0.402\n","{'lr': 0.01, 'beta1': 0.1, 'beta2': 0.999, 'batch_size': 128, 'weight_decay': 0.1, 'epsilon': 1e-10}\n","Epoch 0\tavg epoch Loss = 0.6437\tavg epoch acc = 0.8223\n","Epoch 1\tavg epoch Loss = 0.1556\tavg epoch acc = 0.9494\n","Epoch 2\tavg epoch Loss = 0.09874\tavg epoch acc = 0.9551\n","Epoch 3\tavg epoch Loss = 0.1013\tavg epoch acc = 0.8996\n","Epoch 4\tavg epoch Loss = 0.0606\tavg epoch acc = 0.8957\n","Epoch 5\tavg epoch Loss = 0.3317\tavg epoch acc = 0.262\n","Epoch 6\tavg epoch Loss = 0.05433\tavg epoch acc = 0.469\n","Epoch 7\tavg epoch Loss = 0.0502\tavg epoch acc = 0.6573\n","Epoch 8\tavg epoch Loss = 0.05172\tavg epoch acc = 0.7491\n","Epoch 9\tavg epoch Loss = 0.6832\tavg epoch acc = 0.3215\n","training took 17.65 s\n","Avg test loss = 2.85\tAvg test acc = 0.162\n","Epoch 0\tavg epoch Loss = 0.6579\tavg epoch acc = 0.8185\n","Epoch 1\tavg epoch Loss = 0.1624\tavg epoch acc = 0.9554\n","Epoch 2\tavg epoch Loss = 0.1101\tavg epoch acc = 0.9666\n","Epoch 3\tavg epoch Loss = 0.08607\tavg epoch acc = 0.9446\n","Epoch 4\tavg epoch Loss = 0.06483\tavg epoch acc = 0.8706\n","Epoch 5\tavg epoch Loss = 0.5665\tavg epoch acc = 0.6082\n","Epoch 6\tavg epoch Loss = 0.1391\tavg epoch acc = 0.1323\n","Epoch 7\tavg epoch Loss = 0.08758\tavg epoch acc = 0.2256\n","Epoch 8\tavg epoch Loss = 0.07447\tavg epoch acc = 0.3915\n","Epoch 9\tavg epoch Loss = 0.0865\tavg epoch acc = 0.6644\n","training took 17.58 s\n","Avg test loss = 1.38\tAvg test acc = 0.644\n","Epoch 0\tavg epoch Loss = 0.6468\tavg epoch acc = 0.8191\n","Epoch 1\tavg epoch Loss = 0.152\tavg epoch acc = 0.9115\n","Epoch 2\tavg epoch Loss = 0.1981\tavg epoch acc = 0.7924\n","Epoch 3\tavg epoch Loss = 0.06585\tavg epoch acc = 0.7976\n","Epoch 4\tavg epoch Loss = 0.05511\tavg epoch acc = 0.8108\n","Epoch 5\tavg epoch Loss = 0.108\tavg epoch acc = 0.6532\n","Epoch 6\tavg epoch Loss = 0.3616\tavg epoch acc = 0.5107\n","Epoch 7\tavg epoch Loss = 0.05913\tavg epoch acc = 0.5571\n","Epoch 8\tavg epoch Loss = 0.05235\tavg epoch acc = 0.6807\n","Epoch 9\tavg epoch Loss = 0.06261\tavg epoch acc = 0.6631\n","training took 17.59 s\n","Avg test loss = 1.2\tAvg test acc = 0.678\n","{'lr': 0.01, 'beta1': 0.1, 'beta2': 0.999, 'batch_size': 128, 'weight_decay': 0.1, 'epsilon': 1e-08}\n","Epoch 0\tavg epoch Loss = 0.6489\tavg epoch acc = 0.824\n","Epoch 1\tavg epoch Loss = 0.2188\tavg epoch acc = 0.9271\n","Epoch 2\tavg epoch Loss = 0.09119\tavg epoch acc = 0.8853\n","Epoch 3\tavg epoch Loss = 0.07512\tavg epoch acc = 0.9091\n","Epoch 4\tavg epoch Loss = 0.06047\tavg epoch acc = 0.8949\n","Epoch 5\tavg epoch Loss = 2.146\tavg epoch acc = 0.7202\n","Epoch 6\tavg epoch Loss = 0.2587\tavg epoch acc = 0.1556\n","Epoch 7\tavg epoch Loss = 0.09148\tavg epoch acc = 0.2542\n","Epoch 8\tavg epoch Loss = 0.06851\tavg epoch acc = 0.3989\n","Epoch 9\tavg epoch Loss = 0.07223\tavg epoch acc = 0.6188\n","training took 17.62 s\n","Avg test loss = 1.65\tAvg test acc = 0.723\n","Epoch 0\tavg epoch Loss = 0.729\tavg epoch acc = 0.7916\n","Epoch 1\tavg epoch Loss = 0.1379\tavg epoch acc = 0.8776\n","Epoch 2\tavg epoch Loss = 0.09123\tavg epoch acc = 0.8759\n","Epoch 3\tavg epoch Loss = 0.0825\tavg epoch acc = 0.8529\n","Epoch 4\tavg epoch Loss = 0.6924\tavg epoch acc = 0.3376\n","Epoch 5\tavg epoch Loss = 0.145\tavg epoch acc = 0.2648\n","Epoch 6\tavg epoch Loss = 0.07421\tavg epoch acc = 0.3179\n","Epoch 7\tavg epoch Loss = 0.06698\tavg epoch acc = 0.4675\n","Epoch 8\tavg epoch Loss = 0.07596\tavg epoch acc = 0.6314\n","Epoch 9\tavg epoch Loss = 0.06489\tavg epoch acc = 0.7056\n","training took 17.53 s\n","Avg test loss = 0.863\tAvg test acc = 0.739\n","Epoch 0\tavg epoch Loss = 0.6491\tavg epoch acc = 0.8166\n","Epoch 1\tavg epoch Loss = 0.1468\tavg epoch acc = 0.9169\n","Epoch 2\tavg epoch Loss = 0.108\tavg epoch acc = 0.8933\n","Epoch 3\tavg epoch Loss = 0.7017\tavg epoch acc = 0.3575\n","Epoch 4\tavg epoch Loss = 0.08223\tavg epoch acc = 0.1314\n","Epoch 5\tavg epoch Loss = 0.06126\tavg epoch acc = 0.1465\n","Epoch 6\tavg epoch Loss = 0.05492\tavg epoch acc = 0.2193\n","Epoch 7\tavg epoch Loss = 0.09309\tavg epoch acc = 0.5117\n","Epoch 8\tavg epoch Loss = 0.06828\tavg epoch acc = 0.6891\n","Epoch 9\tavg epoch Loss = 0.06065\tavg epoch acc = 0.7406\n","training took 17.55 s\n","Avg test loss = 1.11\tAvg test acc = 0.712\n","{'lr': 0.01, 'beta1': 0.9, 'beta2': 0.5, 'batch_size': 32, 'weight_decay': 0.001, 'epsilon': 1e-10}\n","Epoch 0\tavg epoch Loss = 5.006e+26\tavg epoch acc = 0.1182\n","Epoch 1\tavg epoch Loss = 1.328e+29\tavg epoch acc = 0.1265\n","Epoch 2\tavg epoch Loss = 3.522e+26\tavg epoch acc = 0.125\n","Epoch 3\tavg epoch Loss = 2.578e+26\tavg epoch acc = 0.1108\n","Epoch 4\tavg epoch Loss = 3.42e+26\tavg epoch acc = 0.1096\n","Epoch 5\tavg epoch Loss = 5.019e+26\tavg epoch acc = 0.1103\n","Epoch 6\tavg epoch Loss = 2.249e+26\tavg epoch acc = 0.1173\n","Epoch 7\tavg epoch Loss = 2.121e+26\tavg epoch acc = 0.1304\n","Epoch 8\tavg epoch Loss = 1.16e+27\tavg epoch acc = 0.1366\n","Epoch 9\tavg epoch Loss = 9.597e+26\tavg epoch acc = 0.1366\n","training took 54.79 s\n","Avg test loss = nan\tAvg test acc = 0.134\n","Epoch 0\tavg epoch Loss = nan\tavg epoch acc = 0.1124\n","Epoch 1\tavg epoch Loss = nan\tavg epoch acc = 0.09925\n","Epoch 2\tavg epoch Loss = nan\tavg epoch acc = 0.09925\n","Epoch 3\tavg epoch Loss = nan\tavg epoch acc = 0.09925\n","Epoch 4\tavg epoch Loss = nan\tavg epoch acc = 0.09925\n","Epoch 5\tavg epoch Loss = nan\tavg epoch acc = 0.09925\n","Epoch 6\tavg epoch Loss = nan\tavg epoch acc = 0.09925\n","Epoch 7\tavg epoch Loss = nan\tavg epoch acc = 0.09925\n","Epoch 8\tavg epoch Loss = nan\tavg epoch acc = 0.09925\n","Epoch 9\tavg epoch Loss = nan\tavg epoch acc = 0.09925\n","training took 54.62 s\n","Avg test loss = nan\tAvg test acc = 0.0977\n","Epoch 0\tavg epoch Loss = nan\tavg epoch acc = 0.09555\n","Epoch 1\tavg epoch Loss = nan\tavg epoch acc = 0.0988\n","Epoch 2\tavg epoch Loss = nan\tavg epoch acc = 0.0988\n","Epoch 3\tavg epoch Loss = nan\tavg epoch acc = 0.0988\n","Epoch 4\tavg epoch Loss = nan\tavg epoch acc = 0.0988\n","Epoch 5\tavg epoch Loss = nan\tavg epoch acc = 0.0988\n","Epoch 6\tavg epoch Loss = nan\tavg epoch acc = 0.0988\n","Epoch 7\tavg epoch Loss = nan\tavg epoch acc = 0.0988\n","Epoch 8\tavg epoch Loss = nan\tavg epoch acc = 0.0988\n","Epoch 9\tavg epoch Loss = nan\tavg epoch acc = 0.0988\n","training took 54.95 s\n","Avg test loss = nan\tAvg test acc = 0.0985\n","{'lr': 0.01, 'beta1': 0.9, 'beta2': 0.5, 'batch_size': 32, 'weight_decay': 0.001, 'epsilon': 1e-08}\n","Epoch 0\tavg epoch Loss = 6.731e+29\tavg epoch acc = 0.09823\n","Epoch 1\tavg epoch Loss = 6.005e+30\tavg epoch acc = 0.09853\n","Epoch 2\tavg epoch Loss = 3.842e+30\tavg epoch acc = 0.09853\n","Epoch 3\tavg epoch Loss = 2.884e+30\tavg epoch acc = 0.09853\n","Epoch 4\tavg epoch Loss = 2.737e+30\tavg epoch acc = 0.09853\n","Epoch 5\tavg epoch Loss = 3.038e+30\tavg epoch acc = 0.09853\n","Epoch 6\tavg epoch Loss = 2.313e+30\tavg epoch acc = 0.09853\n","Epoch 7\tavg epoch Loss = 2.417e+30\tavg epoch acc = 0.09853\n","Epoch 8\tavg epoch Loss = 1.708e+30\tavg epoch acc = 0.09853\n","Epoch 9\tavg epoch Loss = 1.927e+30\tavg epoch acc = 0.09853\n","training took 54.69 s\n","Avg test loss = nan\tAvg test acc = 0.0991\n","Epoch 0\tavg epoch Loss = 2.136e+27\tavg epoch acc = 0.1001\n","Epoch 1\tavg epoch Loss = 2.911e+32\tavg epoch acc = 0.09913\n","Epoch 2\tavg epoch Loss = 2.809e+31\tavg epoch acc = 0.0817\n","Epoch 3\tavg epoch Loss = 7.851e+29\tavg epoch acc = 0.0931\n","Epoch 4\tavg epoch Loss = 1.512e+30\tavg epoch acc = 0.09317\n","Epoch 5\tavg epoch Loss = 3.892e+30\tavg epoch acc = 0.0932\n","Epoch 6\tavg epoch Loss = 2.447e+30\tavg epoch acc = 0.09325\n","Epoch 7\tavg epoch Loss = 2.346e+30\tavg epoch acc = 0.09325\n","Epoch 8\tavg epoch Loss = 1.994e+30\tavg epoch acc = 0.09325\n","Epoch 9\tavg epoch Loss = 1.621e+30\tavg epoch acc = 0.09342\n","training took 54.73 s\n","Avg test loss = nan\tAvg test acc = 0.0964\n","Epoch 0\tavg epoch Loss = 3.727e+25\tavg epoch acc = 0.09935\n","Epoch 1\tavg epoch Loss = 5.195e+29\tavg epoch acc = 0.0982\n","Epoch 2\tavg epoch Loss = 6.783e+29\tavg epoch acc = 0.0982\n","Epoch 3\tavg epoch Loss = 2.544e+32\tavg epoch acc = 0.0982\n","Epoch 4\tavg epoch Loss = 8.658e+31\tavg epoch acc = 0.0982\n","Epoch 5\tavg epoch Loss = 2.811e+31\tavg epoch acc = 0.0982\n","Epoch 6\tavg epoch Loss = 1.151e+32\tavg epoch acc = 0.0997\n","Epoch 7\tavg epoch Loss = 1.877e+21\tavg epoch acc = 0.09947\n","Epoch 8\tavg epoch Loss = 1.83e+21\tavg epoch acc = 0.09947\n","Epoch 9\tavg epoch Loss = 1.785e+21\tavg epoch acc = 0.09947\n","training took 54.83 s\n","Avg test loss = 1.76e+21\tAvg test acc = 0.0989\n","{'lr': 0.01, 'beta1': 0.9, 'beta2': 0.5, 'batch_size': 32, 'weight_decay': 0.1, 'epsilon': 1e-10}\n","Epoch 0\tavg epoch Loss = 2.629e+32\tavg epoch acc = 0.1004\n","Epoch 1\tavg epoch Loss = 5.428e+17\tavg epoch acc = 0.09903\n","Epoch 2\tavg epoch Loss = 4.449e+16\tavg epoch acc = 0.09903\n","Epoch 3\tavg epoch Loss = 3.645e+15\tavg epoch acc = 0.09903\n","Epoch 4\tavg epoch Loss = 2.982e+14\tavg epoch acc = 0.09903\n","Epoch 5\tavg epoch Loss = 2.43e+13\tavg epoch acc = 0.09903\n","Epoch 6\tavg epoch Loss = 1.967e+12\tavg epoch acc = 0.09903\n","Epoch 7\tavg epoch Loss = 1.559e+11\tavg epoch acc = 0.09903\n","Epoch 8\tavg epoch Loss = 1.167e+10\tavg epoch acc = 0.0903\n","Epoch 9\tavg epoch Loss = 7.453e+08\tavg epoch acc = 0.09557\n","training took 54.73 s\n","Avg test loss = 9.35e+07\tAvg test acc = 0.0998\n","Epoch 0\tavg epoch Loss = nan\tavg epoch acc = 0.09882\n","Epoch 1\tavg epoch Loss = nan\tavg epoch acc = 0.0982\n","Epoch 2\tavg epoch Loss = nan\tavg epoch acc = 0.0982\n","Epoch 3\tavg epoch Loss = nan\tavg epoch acc = 0.0982\n","Epoch 4\tavg epoch Loss = nan\tavg epoch acc = 0.0982\n","Epoch 5\tavg epoch Loss = nan\tavg epoch acc = 0.0982\n","Epoch 6\tavg epoch Loss = nan\tavg epoch acc = 0.0982\n","Epoch 7\tavg epoch Loss = nan\tavg epoch acc = 0.0982\n","Epoch 8\tavg epoch Loss = nan\tavg epoch acc = 0.0982\n","Epoch 9\tavg epoch Loss = nan\tavg epoch acc = 0.0982\n","training took 54.81 s\n","Avg test loss = nan\tAvg test acc = 0.0998\n","Epoch 0\tavg epoch Loss = 1.266e+33\tavg epoch acc = 0.09785\n","Epoch 1\tavg epoch Loss = 1.383e+24\tavg epoch acc = 0.09022\n","Epoch 2\tavg epoch Loss = 1.134e+23\tavg epoch acc = 0.09022\n","Epoch 3\tavg epoch Loss = 9.294e+21\tavg epoch acc = 0.09022\n","Epoch 4\tavg epoch Loss = 7.62e+20\tavg epoch acc = 0.09022\n","Epoch 5\tavg epoch Loss = 6.247e+19\tavg epoch acc = 0.09022\n","Epoch 6\tavg epoch Loss = 5.121e+18\tavg epoch acc = 0.09022\n","Epoch 7\tavg epoch Loss = 4.199e+17\tavg epoch acc = 0.09022\n","Epoch 8\tavg epoch Loss = 3.442e+16\tavg epoch acc = 0.09022\n","Epoch 9\tavg epoch Loss = 2.821e+15\tavg epoch acc = 0.09022\n","training took 54.63 s\n","Avg test loss = 6.28e+14\tAvg test acc = 0.0906\n","{'lr': 0.01, 'beta1': 0.9, 'beta2': 0.5, 'batch_size': 32, 'weight_decay': 0.1, 'epsilon': 1e-08}\n","Epoch 0\tavg epoch Loss = 4.306e+29\tavg epoch acc = 0.09955\n","Epoch 1\tavg epoch Loss = 7.137e+32\tavg epoch acc = 0.1138\n","Epoch 2\tavg epoch Loss = 5.553e+19\tavg epoch acc = 0.1124\n","Epoch 3\tavg epoch Loss = 4.553e+18\tavg epoch acc = 0.1124\n","Epoch 4\tavg epoch Loss = 3.733e+17\tavg epoch acc = 0.1124\n","Epoch 5\tavg epoch Loss = 3.06e+16\tavg epoch acc = 0.1124\n","Epoch 6\tavg epoch Loss = 2.508e+15\tavg epoch acc = 0.1121\n","Epoch 7\tavg epoch Loss = 2.054e+14\tavg epoch acc = 0.1103\n","Epoch 8\tavg epoch Loss = 1.679e+13\tavg epoch acc = 0.1012\n","Epoch 9\tavg epoch Loss = 1.363e+12\tavg epoch acc = 0.1006\n","training took 54.66 s\n","Avg test loss = 2.99e+11\tAvg test acc = 0.0978\n","Epoch 0\tavg epoch Loss = 1.468e+13\tavg epoch acc = 0.09867\n","Epoch 1\tavg epoch Loss = 1.861e+11\tavg epoch acc = 0.0978\n","Epoch 2\tavg epoch Loss = 3.93e+08\tavg epoch acc = 0.0978\n","Epoch 3\tavg epoch Loss = 1.976e+07\tavg epoch acc = 0.09775\n","Epoch 4\tavg epoch Loss = nan\tavg epoch acc = 0.09775\n","Epoch 5\tavg epoch Loss = nan\tavg epoch acc = 0.0978\n","Epoch 6\tavg epoch Loss = nan\tavg epoch acc = 0.0978\n","Epoch 7\tavg epoch Loss = nan\tavg epoch acc = 0.0978\n","Epoch 8\tavg epoch Loss = nan\tavg epoch acc = 0.0978\n","Epoch 9\tavg epoch Loss = nan\tavg epoch acc = 0.0978\n","training took 54.78 s\n","Avg test loss = nan\tAvg test acc = 0.101\n","Epoch 0\tavg epoch Loss = 4.077e+30\tavg epoch acc = 0.099\n","Epoch 1\tavg epoch Loss = 2.917e+32\tavg epoch acc = 0.0986\n","Epoch 2\tavg epoch Loss = 4.285e+30\tavg epoch acc = 0.0986\n","Epoch 3\tavg epoch Loss = 3.988e+27\tavg epoch acc = 0.0986\n","Epoch 4\tavg epoch Loss = 3.556e+25\tavg epoch acc = 0.0974\n","Epoch 5\tavg epoch Loss = 1.869e+23\tavg epoch acc = 0.0981\n","Epoch 6\tavg epoch Loss = 6.167e+20\tavg epoch acc = 0.07815\n","Epoch 7\tavg epoch Loss = 2.785e+17\tavg epoch acc = 0.07118\n","Epoch 8\tavg epoch Loss = 4.615e+13\tavg epoch acc = 0.0726\n","Epoch 9\tavg epoch Loss = 3.439e+11\tavg epoch acc = 0.07493\n","training took 54.64 s\n","Avg test loss = 6.84e+30\tAvg test acc = 0.079\n","{'lr': 0.01, 'beta1': 0.9, 'beta2': 0.5, 'batch_size': 64, 'weight_decay': 0.001, 'epsilon': 1e-10}\n","Epoch 0\tavg epoch Loss = 2.268e+17\tavg epoch acc = 0.09755\n","Epoch 1\tavg epoch Loss = 2.672e+17\tavg epoch acc = 0.09832\n","Epoch 2\tavg epoch Loss = 1.301e+17\tavg epoch acc = 0.09832\n","Epoch 3\tavg epoch Loss = 3.908e+16\tavg epoch acc = 0.09832\n","Epoch 4\tavg epoch Loss = 1.845e+15\tavg epoch acc = 0.09832\n","Epoch 5\tavg epoch Loss = 2.161e+12\tavg epoch acc = 0.09832\n","Epoch 6\tavg epoch Loss = 1.582e+12\tavg epoch acc = 0.09832\n","Epoch 7\tavg epoch Loss = 1.216e+12\tavg epoch acc = 0.09832\n","Epoch 8\tavg epoch Loss = 9.014e+11\tavg epoch acc = 0.09832\n","Epoch 9\tavg epoch Loss = 6.624e+11\tavg epoch acc = 0.09832\n","training took 28.5 s\n","Avg test loss = nan\tAvg test acc = 0.0996\n","Epoch 0\tavg epoch Loss = 8.611e+31\tavg epoch acc = 0.1159\n","Epoch 1\tavg epoch Loss = 6.573e+19\tavg epoch acc = 0.08903\n","Epoch 2\tavg epoch Loss = 6.492e+19\tavg epoch acc = 0.08903\n","Epoch 3\tavg epoch Loss = 6.411e+19\tavg epoch acc = 0.08903\n","Epoch 4\tavg epoch Loss = 6.331e+19\tavg epoch acc = 0.08903\n","Epoch 5\tavg epoch Loss = 6.253e+19\tavg epoch acc = 0.08903\n","Epoch 6\tavg epoch Loss = 6.175e+19\tavg epoch acc = 0.08903\n","Epoch 7\tavg epoch Loss = 6.098e+19\tavg epoch acc = 0.08903\n","Epoch 8\tavg epoch Loss = 6.023e+19\tavg epoch acc = 0.08903\n","Epoch 9\tavg epoch Loss = 5.948e+19\tavg epoch acc = 0.08903\n","training took 28.52 s\n","Avg test loss = 5.86e+19\tAvg test acc = 0.0931\n","Epoch 0\tavg epoch Loss = 6.918e+22\tavg epoch acc = 0.09805\n","Epoch 1\tavg epoch Loss = 1.337e+25\tavg epoch acc = 0.09782\n","Epoch 2\tavg epoch Loss = 2.132e+24\tavg epoch acc = 0.09782\n","Epoch 3\tavg epoch Loss = 2.151e+24\tavg epoch acc = 0.09782\n","Epoch 4\tavg epoch Loss = 2.101e+24\tavg epoch acc = 0.09782\n","Epoch 5\tavg epoch Loss = 2.024e+24\tavg epoch acc = 0.09782\n","Epoch 6\tavg epoch Loss = 2.051e+24\tavg epoch acc = 0.09782\n","Epoch 7\tavg epoch Loss = 2.042e+24\tavg epoch acc = 0.09782\n","Epoch 8\tavg epoch Loss = 2.057e+24\tavg epoch acc = 0.09782\n","Epoch 9\tavg epoch Loss = 1.988e+24\tavg epoch acc = 0.09782\n","training took 28.67 s\n","Avg test loss = nan\tAvg test acc = 0.1\n","{'lr': 0.01, 'beta1': 0.9, 'beta2': 0.5, 'batch_size': 64, 'weight_decay': 0.001, 'epsilon': 1e-08}\n","Epoch 0\tavg epoch Loss = 4.783e+24\tavg epoch acc = 0.1095\n","Epoch 1\tavg epoch Loss = nan\tavg epoch acc = 0.09907\n","Epoch 2\tavg epoch Loss = nan\tavg epoch acc = 0.09967\n","Epoch 3\tavg epoch Loss = nan\tavg epoch acc = 0.09967\n","Epoch 4\tavg epoch Loss = nan\tavg epoch acc = 0.09967\n","Epoch 5\tavg epoch Loss = nan\tavg epoch acc = 0.09967\n","Epoch 6\tavg epoch Loss = nan\tavg epoch acc = 0.09967\n","Epoch 7\tavg epoch Loss = nan\tavg epoch acc = 0.09967\n","Epoch 8\tavg epoch Loss = nan\tavg epoch acc = 0.09967\n","Epoch 9\tavg epoch Loss = nan\tavg epoch acc = 0.09967\n","training took 28.41 s\n","Avg test loss = nan\tAvg test acc = 0.0969\n","Epoch 0\tavg epoch Loss = 4.392e+12\tavg epoch acc = 0.109\n","Epoch 1\tavg epoch Loss = 3.456e+10\tavg epoch acc = 0.1013\n","Epoch 2\tavg epoch Loss = 2.3e+10\tavg epoch acc = 0.1007\n","Epoch 3\tavg epoch Loss = 1.909e+10\tavg epoch acc = 0.1004\n","Epoch 4\tavg epoch Loss = 1.54e+10\tavg epoch acc = 0.1004\n","Epoch 5\tavg epoch Loss = 1.204e+10\tavg epoch acc = 0.1004\n","Epoch 6\tavg epoch Loss = 9.858e+09\tavg epoch acc = 0.1004\n","Epoch 7\tavg epoch Loss = 8.176e+09\tavg epoch acc = 0.1004\n","Epoch 8\tavg epoch Loss = 7.242e+09\tavg epoch acc = 0.1004\n","Epoch 9\tavg epoch Loss = 6.373e+09\tavg epoch acc = 0.1004\n","training took 28.47 s\n","Avg test loss = 5.84e+32\tAvg test acc = 0.101\n","Epoch 0\tavg epoch Loss = 1.643e+13\tavg epoch acc = 0.09967\n","Epoch 1\tavg epoch Loss = 2.77e+12\tavg epoch acc = 0.1019\n","Epoch 2\tavg epoch Loss = 1.36e+12\tavg epoch acc = 0.1037\n","Epoch 3\tavg epoch Loss = 1.343e+12\tavg epoch acc = 0.1037\n","Epoch 4\tavg epoch Loss = 1.326e+12\tavg epoch acc = 0.1037\n","Epoch 5\tavg epoch Loss = 1.31e+12\tavg epoch acc = 0.1037\n","Epoch 6\tavg epoch Loss = 1.294e+12\tavg epoch acc = 0.1037\n","Epoch 7\tavg epoch Loss = 1.278e+12\tavg epoch acc = 0.1037\n","Epoch 8\tavg epoch Loss = 1.262e+12\tavg epoch acc = 0.1037\n","Epoch 9\tavg epoch Loss = 1.246e+12\tavg epoch acc = 0.1037\n","training took 28.43 s\n","Avg test loss = inf\tAvg test acc = 0.106\n","{'lr': 0.01, 'beta1': 0.9, 'beta2': 0.5, 'batch_size': 64, 'weight_decay': 0.1, 'epsilon': 1e-10}\n","Epoch 0\tavg epoch Loss = nan\tavg epoch acc = 0.101\n","Epoch 1\tavg epoch Loss = nan\tavg epoch acc = 0.0975\n","Epoch 2\tavg epoch Loss = nan\tavg epoch acc = 0.0975\n","Epoch 3\tavg epoch Loss = nan\tavg epoch acc = 0.0975\n","Epoch 4\tavg epoch Loss = nan\tavg epoch acc = 0.0975\n","Epoch 5\tavg epoch Loss = nan\tavg epoch acc = 0.0975\n","Epoch 6\tavg epoch Loss = nan\tavg epoch acc = 0.0975\n","Epoch 7\tavg epoch Loss = nan\tavg epoch acc = 0.0975\n","Epoch 8\tavg epoch Loss = nan\tavg epoch acc = 0.0975\n","Epoch 9\tavg epoch Loss = nan\tavg epoch acc = 0.0975\n","training took 28.46 s\n","Avg test loss = nan\tAvg test acc = 0.101\n","Epoch 0\tavg epoch Loss = nan\tavg epoch acc = 0.094\n","Epoch 1\tavg epoch Loss = nan\tavg epoch acc = 0.09853\n","Epoch 2\tavg epoch Loss = nan\tavg epoch acc = 0.09853\n","Epoch 3\tavg epoch Loss = nan\tavg epoch acc = 0.09853\n","Epoch 4\tavg epoch Loss = nan\tavg epoch acc = 0.09853\n","Epoch 5\tavg epoch Loss = nan\tavg epoch acc = 0.09853\n","Epoch 6\tavg epoch Loss = nan\tavg epoch acc = 0.09853\n","Epoch 7\tavg epoch Loss = nan\tavg epoch acc = 0.09853\n","Epoch 8\tavg epoch Loss = nan\tavg epoch acc = 0.09853\n","Epoch 9\tavg epoch Loss = nan\tavg epoch acc = 0.09853\n","training took 28.42 s\n","Avg test loss = nan\tAvg test acc = 0.0991\n","Epoch 0\tavg epoch Loss = 3.08e+13\tavg epoch acc = 0.1013\n","Epoch 1\tavg epoch Loss = 4.89e+15\tavg epoch acc = 0.1001\n","Epoch 2\tavg epoch Loss = 6.588e+17\tavg epoch acc = 0.1001\n","Epoch 3\tavg epoch Loss = 2.242e+13\tavg epoch acc = 0.1001\n","Epoch 4\tavg epoch Loss = 3.056e+10\tavg epoch acc = 0.1001\n","Epoch 5\tavg epoch Loss = 1.223e+09\tavg epoch acc = 0.1001\n","Epoch 6\tavg epoch Loss = 2.875e+08\tavg epoch acc = 0.1001\n","Epoch 7\tavg epoch Loss = 7.141e+07\tavg epoch acc = 0.1001\n","Epoch 8\tavg epoch Loss = 2.437e+07\tavg epoch acc = 0.1001\n","Epoch 9\tavg epoch Loss = 3.109e+24\tavg epoch acc = 0.1001\n","training took 28.41 s\n","Avg test loss = nan\tAvg test acc = 0.0959\n","{'lr': 0.01, 'beta1': 0.9, 'beta2': 0.5, 'batch_size': 64, 'weight_decay': 0.1, 'epsilon': 1e-08}\n","Epoch 0\tavg epoch Loss = nan\tavg epoch acc = 0.09735\n","Epoch 1\tavg epoch Loss = nan\tavg epoch acc = 0.09815\n","Epoch 2\tavg epoch Loss = nan\tavg epoch acc = 0.09815\n","Epoch 3\tavg epoch Loss = nan\tavg epoch acc = 0.09815\n","Epoch 4\tavg epoch Loss = nan\tavg epoch acc = 0.09815\n","Epoch 5\tavg epoch Loss = nan\tavg epoch acc = 0.09815\n","Epoch 6\tavg epoch Loss = nan\tavg epoch acc = 0.09815\n","Epoch 7\tavg epoch Loss = nan\tavg epoch acc = 0.09815\n","Epoch 8\tavg epoch Loss = nan\tavg epoch acc = 0.09815\n","Epoch 9\tavg epoch Loss = nan\tavg epoch acc = 0.09815\n","training took 28.54 s\n","Avg test loss = nan\tAvg test acc = 0.0998\n","Epoch 0\tavg epoch Loss = nan\tavg epoch acc = 0.09847\n","Epoch 1\tavg epoch Loss = nan\tavg epoch acc = 0.09815\n","Epoch 2\tavg epoch Loss = nan\tavg epoch acc = 0.09815\n","Epoch 3\tavg epoch Loss = nan\tavg epoch acc = 0.09815\n","Epoch 4\tavg epoch Loss = nan\tavg epoch acc = 0.09815\n","Epoch 5\tavg epoch Loss = nan\tavg epoch acc = 0.09815\n","Epoch 6\tavg epoch Loss = nan\tavg epoch acc = 0.09815\n","Epoch 7\tavg epoch Loss = nan\tavg epoch acc = 0.09815\n","Epoch 8\tavg epoch Loss = nan\tavg epoch acc = 0.09815\n","Epoch 9\tavg epoch Loss = nan\tavg epoch acc = 0.09815\n","training took 28.42 s\n","Avg test loss = nan\tAvg test acc = 0.0998\n","Epoch 0\tavg epoch Loss = 3.606e+13\tavg epoch acc = 0.09402\n","Epoch 1\tavg epoch Loss = 3.987e+30\tavg epoch acc = 0.09985\n","Epoch 2\tavg epoch Loss = nan\tavg epoch acc = 0.09985\n","Epoch 3\tavg epoch Loss = nan\tavg epoch acc = 0.09985\n","Epoch 4\tavg epoch Loss = nan\tavg epoch acc = 0.09985\n","Epoch 5\tavg epoch Loss = nan\tavg epoch acc = 0.09985\n","Epoch 6\tavg epoch Loss = nan\tavg epoch acc = 0.09985\n","Epoch 7\tavg epoch Loss = nan\tavg epoch acc = 0.09985\n","Epoch 8\tavg epoch Loss = nan\tavg epoch acc = 0.09985\n","Epoch 9\tavg epoch Loss = nan\tavg epoch acc = 0.09985\n","training took 28.38 s\n","Avg test loss = nan\tAvg test acc = 0.0965\n","{'lr': 0.01, 'beta1': 0.9, 'beta2': 0.5, 'batch_size': 128, 'weight_decay': 0.001, 'epsilon': 1e-10}\n","Epoch 0\tavg epoch Loss = 1.531e+26\tavg epoch acc = 0.1012\n","Epoch 1\tavg epoch Loss = 7.726e+33\tavg epoch acc = 0.09892\n","Epoch 2\tavg epoch Loss = 4.378e+25\tavg epoch acc = 0.09809\n","Epoch 3\tavg epoch Loss = 4.35e+25\tavg epoch acc = 0.09809\n","Epoch 4\tavg epoch Loss = 4.323e+25\tavg epoch acc = 0.09809\n","Epoch 5\tavg epoch Loss = 4.296e+25\tavg epoch acc = 0.09809\n","Epoch 6\tavg epoch Loss = 4.269e+25\tavg epoch acc = 0.09809\n","Epoch 7\tavg epoch Loss = 4.243e+25\tavg epoch acc = 0.09809\n","Epoch 8\tavg epoch Loss = 4.216e+25\tavg epoch acc = 0.09809\n","Epoch 9\tavg epoch Loss = 4.19e+25\tavg epoch acc = 0.09809\n","training took 17.51 s\n","Avg test loss = 4.19e+25\tAvg test acc = 0.0961\n","Epoch 0\tavg epoch Loss = 1.135e+11\tavg epoch acc = 0.08996\n","Epoch 1\tavg epoch Loss = 3.237e+11\tavg epoch acc = 0.07508\n","Epoch 2\tavg epoch Loss = 3.732e+11\tavg epoch acc = 0.07558\n","Epoch 3\tavg epoch Loss = 5.084e+11\tavg epoch acc = 0.0754\n","Epoch 4\tavg epoch Loss = 4.793e+11\tavg epoch acc = 0.0754\n","Epoch 5\tavg epoch Loss = 5.188e+11\tavg epoch acc = 0.07543\n","Epoch 6\tavg epoch Loss = 4.055e+11\tavg epoch acc = 0.07528\n","Epoch 7\tavg epoch Loss = 3.032e+11\tavg epoch acc = 0.0754\n","Epoch 8\tavg epoch Loss = 2.674e+11\tavg epoch acc = 0.0754\n","Epoch 9\tavg epoch Loss = 2.689e+11\tavg epoch acc = 0.07538\n","training took 17.58 s\n","Avg test loss = 7.17e+34\tAvg test acc = 0.074\n","Epoch 0\tavg epoch Loss = 3.793e+25\tavg epoch acc = 0.1226\n","Epoch 1\tavg epoch Loss = nan\tavg epoch acc = 0.1159\n","Epoch 2\tavg epoch Loss = nan\tavg epoch acc = 0.09769\n","Epoch 3\tavg epoch Loss = nan\tavg epoch acc = 0.09769\n","Epoch 4\tavg epoch Loss = nan\tavg epoch acc = 0.09769\n","Epoch 5\tavg epoch Loss = nan\tavg epoch acc = 0.09769\n","Epoch 6\tavg epoch Loss = nan\tavg epoch acc = 0.09769\n","Epoch 7\tavg epoch Loss = nan\tavg epoch acc = 0.09769\n","Epoch 8\tavg epoch Loss = nan\tavg epoch acc = 0.09769\n","Epoch 9\tavg epoch Loss = nan\tavg epoch acc = 0.09769\n","training took 17.55 s\n","Avg test loss = nan\tAvg test acc = 0.101\n","{'lr': 0.01, 'beta1': 0.9, 'beta2': 0.5, 'batch_size': 128, 'weight_decay': 0.001, 'epsilon': 1e-08}\n","Epoch 0\tavg epoch Loss = 1.744e+11\tavg epoch acc = 0.0929\n","Epoch 1\tavg epoch Loss = 3.81e+10\tavg epoch acc = 0.1195\n","Epoch 2\tavg epoch Loss = 3.561e+10\tavg epoch acc = 0.1336\n","Epoch 3\tavg epoch Loss = 3.297e+10\tavg epoch acc = 0.1429\n","Epoch 4\tavg epoch Loss = 3.066e+10\tavg epoch acc = 0.1437\n","Epoch 5\tavg epoch Loss = 2.85e+10\tavg epoch acc = 0.1436\n","Epoch 6\tavg epoch Loss = 2.659e+10\tavg epoch acc = 0.1442\n","Epoch 7\tavg epoch Loss = 2.486e+10\tavg epoch acc = 0.144\n","Epoch 8\tavg epoch Loss = 2.331e+10\tavg epoch acc = 0.1448\n","Epoch 9\tavg epoch Loss = 2.184e+10\tavg epoch acc = 0.1452\n","training took 17.52 s\n","Avg test loss = 2.86e+31\tAvg test acc = 0.141\n","Epoch 0\tavg epoch Loss = 1.309e+23\tavg epoch acc = 0.09128\n","Epoch 1\tavg epoch Loss = nan\tavg epoch acc = 0.1028\n","Epoch 2\tavg epoch Loss = nan\tavg epoch acc = 0.09887\n","Epoch 3\tavg epoch Loss = nan\tavg epoch acc = 0.09887\n","Epoch 4\tavg epoch Loss = nan\tavg epoch acc = 0.09887\n","Epoch 5\tavg epoch Loss = nan\tavg epoch acc = 0.09887\n","Epoch 6\tavg epoch Loss = nan\tavg epoch acc = 0.09887\n","Epoch 7\tavg epoch Loss = nan\tavg epoch acc = 0.09887\n","Epoch 8\tavg epoch Loss = nan\tavg epoch acc = 0.09887\n","Epoch 9\tavg epoch Loss = nan\tavg epoch acc = 0.09887\n","training took 17.54 s\n","Avg test loss = nan\tAvg test acc = 0.0982\n","Epoch 0\tavg epoch Loss = 9.85e+19\tavg epoch acc = 0.0774\n","Epoch 1\tavg epoch Loss = 7.476e+20\tavg epoch acc = 0.07041\n","Epoch 2\tavg epoch Loss = 2.918e+21\tavg epoch acc = 0.1288\n","Epoch 3\tavg epoch Loss = 4.012e+21\tavg epoch acc = 0.1211\n","Epoch 4\tavg epoch Loss = 2.631e+23\tavg epoch acc = 0.1087\n","Epoch 5\tavg epoch Loss = 5.587e+26\tavg epoch acc = 0.09642\n","Epoch 6\tavg epoch Loss = 1.459e+25\tavg epoch acc = 0.08504\n","Epoch 7\tavg epoch Loss = 2.347e+25\tavg epoch acc = 0.08309\n","Epoch 8\tavg epoch Loss = 1.972e+25\tavg epoch acc = 0.07917\n","Epoch 9\tavg epoch Loss = 2.425e+25\tavg epoch acc = 0.07491\n","training took 17.49 s\n","Avg test loss = 8.63e+33\tAvg test acc = 0.0703\n","{'lr': 0.01, 'beta1': 0.9, 'beta2': 0.5, 'batch_size': 128, 'weight_decay': 0.1, 'epsilon': 1e-10}\n","Epoch 0\tavg epoch Loss = 4.729e+13\tavg epoch acc = 0.1018\n","Epoch 1\tavg epoch Loss = 5.572e+32\tavg epoch acc = 0.1003\n","Epoch 2\tavg epoch Loss = inf\tavg epoch acc = 0.09437\n","Epoch 3\tavg epoch Loss = 1.085e+15\tavg epoch acc = 0.08983\n","Epoch 4\tavg epoch Loss = 5.794e+14\tavg epoch acc = 0.08983\n","Epoch 5\tavg epoch Loss = 3.094e+14\tavg epoch acc = 0.08983\n","Epoch 6\tavg epoch Loss = 1.652e+14\tavg epoch acc = 0.08983\n","Epoch 7\tavg epoch Loss = 8.812e+13\tavg epoch acc = 0.08983\n","Epoch 8\tavg epoch Loss = 4.698e+13\tavg epoch acc = 0.08983\n","Epoch 9\tavg epoch Loss = 2.502e+13\tavg epoch acc = 0.08983\n","training took 17.48 s\n","Avg test loss = 1.8e+13\tAvg test acc = 0.0914\n","Epoch 0\tavg epoch Loss = 5.619e+21\tavg epoch acc = 0.09567\n","Epoch 1\tavg epoch Loss = 1.647e+32\tavg epoch acc = 0.09782\n","Epoch 2\tavg epoch Loss = nan\tavg epoch acc = 0.09782\n","Epoch 3\tavg epoch Loss = nan\tavg epoch acc = 0.09782\n","Epoch 4\tavg epoch Loss = nan\tavg epoch acc = 0.09782\n","Epoch 5\tavg epoch Loss = nan\tavg epoch acc = 0.09782\n","Epoch 6\tavg epoch Loss = nan\tavg epoch acc = 0.09782\n","Epoch 7\tavg epoch Loss = nan\tavg epoch acc = 0.09782\n","Epoch 8\tavg epoch Loss = nan\tavg epoch acc = 0.09782\n","Epoch 9\tavg epoch Loss = nan\tavg epoch acc = 0.09782\n","training took 17.46 s\n","Avg test loss = nan\tAvg test acc = 0.1\n","Epoch 0\tavg epoch Loss = 4.049e+28\tavg epoch acc = 0.0944\n","Epoch 1\tavg epoch Loss = nan\tavg epoch acc = 0.09807\n","Epoch 2\tavg epoch Loss = nan\tavg epoch acc = 0.09807\n","Epoch 3\tavg epoch Loss = nan\tavg epoch acc = 0.09807\n","Epoch 4\tavg epoch Loss = nan\tavg epoch acc = 0.09807\n","Epoch 5\tavg epoch Loss = nan\tavg epoch acc = 0.09807\n","Epoch 6\tavg epoch Loss = nan\tavg epoch acc = 0.09807\n","Epoch 7\tavg epoch Loss = nan\tavg epoch acc = 0.09807\n","Epoch 8\tavg epoch Loss = nan\tavg epoch acc = 0.09807\n","Epoch 9\tavg epoch Loss = nan\tavg epoch acc = 0.09807\n","training took 17.51 s\n","Avg test loss = nan\tAvg test acc = 0.1\n","{'lr': 0.01, 'beta1': 0.9, 'beta2': 0.5, 'batch_size': 128, 'weight_decay': 0.1, 'epsilon': 1e-08}\n","Epoch 0\tavg epoch Loss = 8.984e+27\tavg epoch acc = 0.09719\n","Epoch 1\tavg epoch Loss = nan\tavg epoch acc = 0.09739\n","Epoch 2\tavg epoch Loss = nan\tavg epoch acc = 0.09739\n","Epoch 3\tavg epoch Loss = nan\tavg epoch acc = 0.09739\n","Epoch 4\tavg epoch Loss = nan\tavg epoch acc = 0.09739\n","Epoch 5\tavg epoch Loss = nan\tavg epoch acc = 0.09739\n","Epoch 6\tavg epoch Loss = nan\tavg epoch acc = 0.09739\n","Epoch 7\tavg epoch Loss = nan\tavg epoch acc = 0.09739\n","Epoch 8\tavg epoch Loss = nan\tavg epoch acc = 0.09739\n","Epoch 9\tavg epoch Loss = nan\tavg epoch acc = 0.09739\n","training took 17.5 s\n","Avg test loss = nan\tAvg test acc = 0.101\n","Epoch 0\tavg epoch Loss = 7.641e+22\tavg epoch acc = 0.1006\n","Epoch 1\tavg epoch Loss = 2.492e+29\tavg epoch acc = 0.1008\n","Epoch 2\tavg epoch Loss = 6.596e+31\tavg epoch acc = 0.09867\n","Epoch 3\tavg epoch Loss = 6.121e+20\tavg epoch acc = 0.09729\n","Epoch 4\tavg epoch Loss = 3.272e+20\tavg epoch acc = 0.09729\n","Epoch 5\tavg epoch Loss = 1.749e+20\tavg epoch acc = 0.09729\n","Epoch 6\tavg epoch Loss = 9.349e+19\tavg epoch acc = 0.09729\n","Epoch 7\tavg epoch Loss = 4.998e+19\tavg epoch acc = 0.09729\n","Epoch 8\tavg epoch Loss = 2.671e+19\tavg epoch acc = 0.09729\n","Epoch 9\tavg epoch Loss = 1.428e+19\tavg epoch acc = 0.09729\n","training took 17.52 s\n","Avg test loss = 1.03e+19\tAvg test acc = 0.0983\n","Epoch 0\tavg epoch Loss = 4.425e+13\tavg epoch acc = 0.09964\n","Epoch 1\tavg epoch Loss = 1.128e+13\tavg epoch acc = 0.09797\n","Epoch 2\tavg epoch Loss = 2.834e+20\tavg epoch acc = 0.09797\n","Epoch 3\tavg epoch Loss = 1.102e+24\tavg epoch acc = 0.09797\n","Epoch 4\tavg epoch Loss = 2.556e+26\tavg epoch acc = 0.09797\n","Epoch 5\tavg epoch Loss = 2.367e+26\tavg epoch acc = 0.09797\n","Epoch 6\tavg epoch Loss = 3.797e+25\tavg epoch acc = 0.09797\n","Epoch 7\tavg epoch Loss = 9.805e+24\tavg epoch acc = 0.09797\n","Epoch 8\tavg epoch Loss = 1.637e+25\tavg epoch acc = 0.09797\n","Epoch 9\tavg epoch Loss = 1.88e+24\tavg epoch acc = 0.09797\n","training took 17.51 s\n","Avg test loss = nan\tAvg test acc = 0.1\n","{'lr': 0.01, 'beta1': 0.9, 'beta2': 0.999, 'batch_size': 32, 'weight_decay': 0.001, 'epsilon': 1e-10}\n","Epoch 0\tavg epoch Loss = 0.319\tavg epoch acc = 0.8361\n","Epoch 1\tavg epoch Loss = 0.1114\tavg epoch acc = 0.6058\n","Epoch 2\tavg epoch Loss = 0.12\tavg epoch acc = 0.3908\n","Epoch 3\tavg epoch Loss = 0.1318\tavg epoch acc = 0.3453\n","Epoch 4\tavg epoch Loss = 0.1107\tavg epoch acc = 0.2985\n","Epoch 5\tavg epoch Loss = 0.1147\tavg epoch acc = 0.2387\n","Epoch 6\tavg epoch Loss = 0.1325\tavg epoch acc = 0.1827\n","Epoch 7\tavg epoch Loss = 0.1172\tavg epoch acc = 0.2066\n","Epoch 8\tavg epoch Loss = 0.1004\tavg epoch acc = 0.2483\n","Epoch 9\tavg epoch Loss = 0.1213\tavg epoch acc = 0.2369\n","training took 55.07 s\n","Avg test loss = 1.13e+02\tAvg test acc = 0.208\n","Epoch 0\tavg epoch Loss = 0.3292\tavg epoch acc = 0.8532\n","Epoch 1\tavg epoch Loss = 0.121\tavg epoch acc = 0.6149\n","Epoch 2\tavg epoch Loss = 0.1104\tavg epoch acc = 0.4105\n","Epoch 3\tavg epoch Loss = 0.1314\tavg epoch acc = 0.3207\n","Epoch 4\tavg epoch Loss = 0.1265\tavg epoch acc = 0.2747\n","Epoch 5\tavg epoch Loss = 0.1296\tavg epoch acc = 0.2354\n","Epoch 6\tavg epoch Loss = 0.1193\tavg epoch acc = 0.1624\n","Epoch 7\tavg epoch Loss = 0.1366\tavg epoch acc = 0.1641\n","Epoch 8\tavg epoch Loss = 0.121\tavg epoch acc = 0.1589\n","Epoch 9\tavg epoch Loss = 0.1265\tavg epoch acc = 0.1618\n","training took 54.77 s\n","Avg test loss = 15.4\tAvg test acc = 0.179\n","Epoch 0\tavg epoch Loss = 0.3298\tavg epoch acc = 0.8675\n","Epoch 1\tavg epoch Loss = 0.1177\tavg epoch acc = 0.6029\n","Epoch 2\tavg epoch Loss = 0.1191\tavg epoch acc = 0.3275\n","Epoch 3\tavg epoch Loss = 0.1319\tavg epoch acc = 0.2195\n","Epoch 4\tavg epoch Loss = 0.1345\tavg epoch acc = 0.2567\n","Epoch 5\tavg epoch Loss = 0.1244\tavg epoch acc = 0.2329\n","Epoch 6\tavg epoch Loss = 0.1257\tavg epoch acc = 0.2019\n","Epoch 7\tavg epoch Loss = 0.1354\tavg epoch acc = 0.2711\n","Epoch 8\tavg epoch Loss = 0.1348\tavg epoch acc = 0.3078\n","Epoch 9\tavg epoch Loss = 0.1383\tavg epoch acc = 0.2589\n","training took 54.81 s\n","Avg test loss = 44.8\tAvg test acc = 0.279\n","{'lr': 0.01, 'beta1': 0.9, 'beta2': 0.999, 'batch_size': 32, 'weight_decay': 0.001, 'epsilon': 1e-08}\n","Epoch 0\tavg epoch Loss = 0.3199\tavg epoch acc = 0.7877\n","Epoch 1\tavg epoch Loss = 0.1129\tavg epoch acc = 0.5351\n","Epoch 2\tavg epoch Loss = 0.1186\tavg epoch acc = 0.3483\n","Epoch 3\tavg epoch Loss = 0.1303\tavg epoch acc = 0.2586\n","Epoch 4\tavg epoch Loss = 0.1089\tavg epoch acc = 0.2242\n","Epoch 5\tavg epoch Loss = 0.1379\tavg epoch acc = 0.195\n","Epoch 6\tavg epoch Loss = 0.1119\tavg epoch acc = 0.2039\n","Epoch 7\tavg epoch Loss = 0.1408\tavg epoch acc = 0.1916\n","Epoch 8\tavg epoch Loss = 0.133\tavg epoch acc = 0.1827\n","Epoch 9\tavg epoch Loss = 0.1153\tavg epoch acc = 0.1946\n","training took 54.96 s\n","Avg test loss = 11.8\tAvg test acc = 0.174\n","Epoch 0\tavg epoch Loss = 0.3321\tavg epoch acc = 0.8682\n","Epoch 1\tavg epoch Loss = 0.1077\tavg epoch acc = 0.573\n","Epoch 2\tavg epoch Loss = 0.1139\tavg epoch acc = 0.3847\n","Epoch 3\tavg epoch Loss = 0.1193\tavg epoch acc = 0.2871\n","Epoch 4\tavg epoch Loss = 0.1233\tavg epoch acc = 0.2137\n","Epoch 5\tavg epoch Loss = 0.1176\tavg epoch acc = 0.2099\n","Epoch 6\tavg epoch Loss = 0.137\tavg epoch acc = 0.2071\n","Epoch 7\tavg epoch Loss = 0.09915\tavg epoch acc = 0.2283\n","Epoch 8\tavg epoch Loss = 0.1219\tavg epoch acc = 0.2165\n","Epoch 9\tavg epoch Loss = 0.1205\tavg epoch acc = 0.2153\n","training took 55.05 s\n","Avg test loss = 14.8\tAvg test acc = 0.231\n","Epoch 0\tavg epoch Loss = 0.3208\tavg epoch acc = 0.8302\n","Epoch 1\tavg epoch Loss = 0.1134\tavg epoch acc = 0.5448\n","Epoch 2\tavg epoch Loss = 0.1103\tavg epoch acc = 0.4108\n","Epoch 3\tavg epoch Loss = 0.1207\tavg epoch acc = 0.3533\n","Epoch 4\tavg epoch Loss = 0.1217\tavg epoch acc = 0.3004\n","Epoch 5\tavg epoch Loss = 0.1299\tavg epoch acc = 0.2634\n","Epoch 6\tavg epoch Loss = 0.1143\tavg epoch acc = 0.249\n","Epoch 7\tavg epoch Loss = 0.1202\tavg epoch acc = 0.2407\n","Epoch 8\tavg epoch Loss = 0.109\tavg epoch acc = 0.2498\n","Epoch 9\tavg epoch Loss = 0.09672\tavg epoch acc = 0.2527\n","training took 56.11 s\n","Avg test loss = 18.2\tAvg test acc = 0.255\n","{'lr': 0.01, 'beta1': 0.9, 'beta2': 0.999, 'batch_size': 32, 'weight_decay': 0.1, 'epsilon': 1e-10}\n","Epoch 0\tavg epoch Loss = 0.3284\tavg epoch acc = 0.8755\n","Epoch 1\tavg epoch Loss = 0.124\tavg epoch acc = 0.7658\n","Epoch 2\tavg epoch Loss = 0.1245\tavg epoch acc = 0.638\n","Epoch 3\tavg epoch Loss = 0.1221\tavg epoch acc = 0.6229\n","Epoch 4\tavg epoch Loss = 0.1197\tavg epoch acc = 0.5861\n","Epoch 5\tavg epoch Loss = 0.1166\tavg epoch acc = 0.6271\n","Epoch 6\tavg epoch Loss = 0.1123\tavg epoch acc = 0.6507\n","Epoch 7\tavg epoch Loss = 0.1082\tavg epoch acc = 0.6547\n","Epoch 8\tavg epoch Loss = 0.1077\tavg epoch acc = 0.6707\n","Epoch 9\tavg epoch Loss = 0.1059\tavg epoch acc = 0.6716\n","training took 54.8 s\n","Avg test loss = 1.17\tAvg test acc = 0.704\n","Epoch 0\tavg epoch Loss = 0.3337\tavg epoch acc = 0.8791\n","Epoch 1\tavg epoch Loss = 0.1248\tavg epoch acc = 0.7213\n","Epoch 2\tavg epoch Loss = 0.125\tavg epoch acc = 0.6614\n","Epoch 3\tavg epoch Loss = 0.1283\tavg epoch acc = 0.6184\n","Epoch 4\tavg epoch Loss = 0.1162\tavg epoch acc = 0.6023\n","Epoch 5\tavg epoch Loss = 0.1178\tavg epoch acc = 0.5849\n","Epoch 6\tavg epoch Loss = 0.1168\tavg epoch acc = 0.5646\n","Epoch 7\tavg epoch Loss = 0.1186\tavg epoch acc = 0.6402\n","Epoch 8\tavg epoch Loss = 0.1107\tavg epoch acc = 0.6797\n","Epoch 9\tavg epoch Loss = 0.1071\tavg epoch acc = 0.6762\n","training took 55.01 s\n","Avg test loss = 0.804\tAvg test acc = 0.794\n","Epoch 0\tavg epoch Loss = 0.3307\tavg epoch acc = 0.8805\n","Epoch 1\tavg epoch Loss = 0.1235\tavg epoch acc = 0.7215\n","Epoch 2\tavg epoch Loss = 0.1251\tavg epoch acc = 0.6145\n","Epoch 3\tavg epoch Loss = 0.1254\tavg epoch acc = 0.5395\n","Epoch 4\tavg epoch Loss = 0.1142\tavg epoch acc = 0.6054\n","Epoch 5\tavg epoch Loss = 0.1189\tavg epoch acc = 0.5791\n","Epoch 6\tavg epoch Loss = 0.1097\tavg epoch acc = 0.6243\n","Epoch 7\tavg epoch Loss = 0.1064\tavg epoch acc = 0.6598\n","Epoch 8\tavg epoch Loss = 0.105\tavg epoch acc = 0.677\n","Epoch 9\tavg epoch Loss = 0.1034\tavg epoch acc = 0.687\n","training took 54.73 s\n","Avg test loss = 1.16\tAvg test acc = 0.731\n","{'lr': 0.01, 'beta1': 0.9, 'beta2': 0.999, 'batch_size': 32, 'weight_decay': 0.1, 'epsilon': 1e-08}\n","Epoch 0\tavg epoch Loss = 0.3329\tavg epoch acc = 0.8864\n","Epoch 1\tavg epoch Loss = 0.1311\tavg epoch acc = 0.7757\n","Epoch 2\tavg epoch Loss = 0.128\tavg epoch acc = 0.6767\n","Epoch 3\tavg epoch Loss = 0.1273\tavg epoch acc = 0.649\n","Epoch 4\tavg epoch Loss = 0.1231\tavg epoch acc = 0.6595\n","Epoch 5\tavg epoch Loss = 0.1162\tavg epoch acc = 0.6421\n","Epoch 6\tavg epoch Loss = 0.1132\tavg epoch acc = 0.6317\n","Epoch 7\tavg epoch Loss = 0.1092\tavg epoch acc = 0.6312\n","Epoch 8\tavg epoch Loss = 0.1118\tavg epoch acc = 0.6312\n","Epoch 9\tavg epoch Loss = 0.1112\tavg epoch acc = 0.6702\n","training took 54.74 s\n","Avg test loss = 1.24\tAvg test acc = 0.706\n","Epoch 0\tavg epoch Loss = 0.325\tavg epoch acc = 0.854\n","Epoch 1\tavg epoch Loss = 0.1329\tavg epoch acc = 0.7455\n","Epoch 2\tavg epoch Loss = 0.1263\tavg epoch acc = 0.6716\n","Epoch 3\tavg epoch Loss = 0.1253\tavg epoch acc = 0.6244\n","Epoch 4\tavg epoch Loss = 0.1207\tavg epoch acc = 0.6018\n","Epoch 5\tavg epoch Loss = 0.1195\tavg epoch acc = 0.6468\n","Epoch 6\tavg epoch Loss = 0.1084\tavg epoch acc = 0.6834\n","Epoch 7\tavg epoch Loss = 0.1118\tavg epoch acc = 0.6757\n","Epoch 8\tavg epoch Loss = 0.11\tavg epoch acc = 0.7049\n","Epoch 9\tavg epoch Loss = 0.1073\tavg epoch acc = 0.6935\n","training took 54.79 s\n","Avg test loss = 0.971\tAvg test acc = 0.738\n","Epoch 0\tavg epoch Loss = 0.3391\tavg epoch acc = 0.8931\n","Epoch 1\tavg epoch Loss = 0.1322\tavg epoch acc = 0.7936\n","Epoch 2\tavg epoch Loss = 0.1271\tavg epoch acc = 0.6781\n","Epoch 3\tavg epoch Loss = 0.1212\tavg epoch acc = 0.6291\n","Epoch 4\tavg epoch Loss = 0.12\tavg epoch acc = 0.6226\n","Epoch 5\tavg epoch Loss = 0.1159\tavg epoch acc = 0.6117\n","Epoch 6\tavg epoch Loss = 0.1126\tavg epoch acc = 0.6109\n","Epoch 7\tavg epoch Loss = 0.1113\tavg epoch acc = 0.636\n","Epoch 8\tavg epoch Loss = 0.1107\tavg epoch acc = 0.6386\n","Epoch 9\tavg epoch Loss = 0.111\tavg epoch acc = 0.6855\n","training took 54.94 s\n","Avg test loss = 0.968\tAvg test acc = 0.758\n","{'lr': 0.01, 'beta1': 0.9, 'beta2': 0.999, 'batch_size': 64, 'weight_decay': 0.001, 'epsilon': 1e-10}\n","Epoch 0\tavg epoch Loss = 0.4396\tavg epoch acc = 0.8813\n","Epoch 1\tavg epoch Loss = 0.1173\tavg epoch acc = 0.9006\n","Epoch 2\tavg epoch Loss = 0.07678\tavg epoch acc = 0.7744\n","Epoch 3\tavg epoch Loss = 0.06818\tavg epoch acc = 0.5902\n","Epoch 4\tavg epoch Loss = 0.07099\tavg epoch acc = 0.4495\n","Epoch 5\tavg epoch Loss = 0.08073\tavg epoch acc = 0.3816\n","Epoch 6\tavg epoch Loss = 0.07591\tavg epoch acc = 0.3852\n","Epoch 7\tavg epoch Loss = 0.0805\tavg epoch acc = 0.3387\n","Epoch 8\tavg epoch Loss = 0.07415\tavg epoch acc = 0.3589\n","Epoch 9\tavg epoch Loss = 0.08221\tavg epoch acc = 0.3267\n","training took 28.62 s\n","Avg test loss = 10.7\tAvg test acc = 0.32\n","Epoch 0\tavg epoch Loss = 0.4384\tavg epoch acc = 0.856\n","Epoch 1\tavg epoch Loss = 0.1095\tavg epoch acc = 0.8943\n","Epoch 2\tavg epoch Loss = 0.0747\tavg epoch acc = 0.7054\n","Epoch 3\tavg epoch Loss = 0.06817\tavg epoch acc = 0.5848\n","Epoch 4\tavg epoch Loss = 0.0716\tavg epoch acc = 0.4946\n","Epoch 5\tavg epoch Loss = 0.078\tavg epoch acc = 0.4152\n","Epoch 6\tavg epoch Loss = 0.07239\tavg epoch acc = 0.3824\n","Epoch 7\tavg epoch Loss = 0.07306\tavg epoch acc = 0.3659\n","Epoch 8\tavg epoch Loss = 0.07556\tavg epoch acc = 0.3076\n","Epoch 9\tavg epoch Loss = 0.07879\tavg epoch acc = 0.3344\n","training took 28.43 s\n","Avg test loss = 6.14\tAvg test acc = 0.293\n","Epoch 0\tavg epoch Loss = 0.4356\tavg epoch acc = 0.8902\n","Epoch 1\tavg epoch Loss = 0.1146\tavg epoch acc = 0.9295\n","Epoch 2\tavg epoch Loss = 0.08022\tavg epoch acc = 0.7723\n","Epoch 3\tavg epoch Loss = 0.07172\tavg epoch acc = 0.5746\n","Epoch 4\tavg epoch Loss = 0.07184\tavg epoch acc = 0.4768\n","Epoch 5\tavg epoch Loss = 0.06797\tavg epoch acc = 0.4344\n","Epoch 6\tavg epoch Loss = 0.06734\tavg epoch acc = 0.4055\n","Epoch 7\tavg epoch Loss = 0.06965\tavg epoch acc = 0.3322\n","Epoch 8\tavg epoch Loss = 0.07425\tavg epoch acc = 0.375\n","Epoch 9\tavg epoch Loss = 0.101\tavg epoch acc = 0.3518\n","training took 28.54 s\n","Avg test loss = 16.3\tAvg test acc = 0.265\n","{'lr': 0.01, 'beta1': 0.9, 'beta2': 0.999, 'batch_size': 64, 'weight_decay': 0.001, 'epsilon': 1e-08}\n","Epoch 0\tavg epoch Loss = 0.4472\tavg epoch acc = 0.8813\n","Epoch 1\tavg epoch Loss = 0.1165\tavg epoch acc = 0.9478\n","Epoch 2\tavg epoch Loss = 0.08053\tavg epoch acc = 0.7997\n","Epoch 3\tavg epoch Loss = 0.06584\tavg epoch acc = 0.5587\n","Epoch 4\tavg epoch Loss = 0.07717\tavg epoch acc = 0.3905\n","Epoch 5\tavg epoch Loss = 0.06729\tavg epoch acc = 0.3596\n","Epoch 6\tavg epoch Loss = 0.07768\tavg epoch acc = 0.3234\n","Epoch 7\tavg epoch Loss = 0.07612\tavg epoch acc = 0.3003\n","Epoch 8\tavg epoch Loss = 0.08469\tavg epoch acc = 0.3176\n","Epoch 9\tavg epoch Loss = 0.09415\tavg epoch acc = 0.2619\n","training took 28.63 s\n","Avg test loss = 10.4\tAvg test acc = 0.267\n","Epoch 0\tavg epoch Loss = 0.4349\tavg epoch acc = 0.8866\n","Epoch 1\tavg epoch Loss = 0.1168\tavg epoch acc = 0.9288\n","Epoch 2\tavg epoch Loss = 0.07779\tavg epoch acc = 0.7568\n","Epoch 3\tavg epoch Loss = 0.06603\tavg epoch acc = 0.5837\n","Epoch 4\tavg epoch Loss = 0.07554\tavg epoch acc = 0.4851\n","Epoch 5\tavg epoch Loss = 0.07059\tavg epoch acc = 0.432\n","Epoch 6\tavg epoch Loss = 0.07049\tavg epoch acc = 0.3926\n","Epoch 7\tavg epoch Loss = 0.08\tavg epoch acc = 0.3515\n","Epoch 8\tavg epoch Loss = 0.09263\tavg epoch acc = 0.3223\n","Epoch 9\tavg epoch Loss = 0.092\tavg epoch acc = 0.3029\n","training took 28.55 s\n","Avg test loss = 8.48\tAvg test acc = 0.27\n","Epoch 0\tavg epoch Loss = 0.4357\tavg epoch acc = 0.8399\n","Epoch 1\tavg epoch Loss = 0.1104\tavg epoch acc = 0.8438\n","Epoch 2\tavg epoch Loss = 0.0853\tavg epoch acc = 0.7339\n","Epoch 3\tavg epoch Loss = 0.07967\tavg epoch acc = 0.6498\n","Epoch 4\tavg epoch Loss = 0.07401\tavg epoch acc = 0.4949\n","Epoch 5\tavg epoch Loss = 0.07149\tavg epoch acc = 0.4453\n","Epoch 6\tavg epoch Loss = 0.07484\tavg epoch acc = 0.3554\n","Epoch 7\tavg epoch Loss = 0.08951\tavg epoch acc = 0.3709\n","Epoch 8\tavg epoch Loss = 0.07046\tavg epoch acc = 0.2431\n","Epoch 9\tavg epoch Loss = 0.08474\tavg epoch acc = 0.2092\n","training took 28.63 s\n","Avg test loss = 6.89\tAvg test acc = 0.265\n","{'lr': 0.01, 'beta1': 0.9, 'beta2': 0.999, 'batch_size': 64, 'weight_decay': 0.1, 'epsilon': 1e-10}\n","Epoch 0\tavg epoch Loss = 0.4418\tavg epoch acc = 0.8872\n","Epoch 1\tavg epoch Loss = 0.1215\tavg epoch acc = 0.9468\n","Epoch 2\tavg epoch Loss = 0.08968\tavg epoch acc = 0.8547\n","Epoch 3\tavg epoch Loss = 0.08406\tavg epoch acc = 0.7622\n","Epoch 4\tavg epoch Loss = 0.08213\tavg epoch acc = 0.7218\n","Epoch 5\tavg epoch Loss = 0.08715\tavg epoch acc = 0.6548\n","Epoch 6\tavg epoch Loss = 0.07776\tavg epoch acc = 0.6856\n","Epoch 7\tavg epoch Loss = 0.08334\tavg epoch acc = 0.6163\n","Epoch 8\tavg epoch Loss = 0.08121\tavg epoch acc = 0.6293\n","Epoch 9\tavg epoch Loss = 0.08066\tavg epoch acc = 0.6138\n","training took 28.55 s\n","Avg test loss = 1.37\tAvg test acc = 0.639\n","Epoch 0\tavg epoch Loss = 0.4326\tavg epoch acc = 0.869\n","Epoch 1\tavg epoch Loss = 0.116\tavg epoch acc = 0.9244\n","Epoch 2\tavg epoch Loss = 0.09165\tavg epoch acc = 0.8694\n","Epoch 3\tavg epoch Loss = 0.08683\tavg epoch acc = 0.7873\n","Epoch 4\tavg epoch Loss = 0.07868\tavg epoch acc = 0.7363\n","Epoch 5\tavg epoch Loss = 0.08288\tavg epoch acc = 0.7098\n","Epoch 6\tavg epoch Loss = 0.07642\tavg epoch acc = 0.6641\n","Epoch 7\tavg epoch Loss = 0.08291\tavg epoch acc = 0.6288\n","Epoch 8\tavg epoch Loss = 0.07364\tavg epoch acc = 0.6583\n","Epoch 9\tavg epoch Loss = 0.07945\tavg epoch acc = 0.629\n","training took 28.56 s\n","Avg test loss = 1.64\tAvg test acc = 0.612\n","Epoch 0\tavg epoch Loss = 0.4421\tavg epoch acc = 0.8762\n","Epoch 1\tavg epoch Loss = 0.1089\tavg epoch acc = 0.8925\n","Epoch 2\tavg epoch Loss = 0.08729\tavg epoch acc = 0.8639\n","Epoch 3\tavg epoch Loss = 0.07927\tavg epoch acc = 0.7556\n","Epoch 4\tavg epoch Loss = 0.08042\tavg epoch acc = 0.7493\n","Epoch 5\tavg epoch Loss = 0.07982\tavg epoch acc = 0.6671\n","Epoch 6\tavg epoch Loss = 0.08117\tavg epoch acc = 0.6314\n","Epoch 7\tavg epoch Loss = 0.0806\tavg epoch acc = 0.6024\n","Epoch 8\tavg epoch Loss = 0.08231\tavg epoch acc = 0.5931\n","Epoch 9\tavg epoch Loss = 0.08099\tavg epoch acc = 0.5695\n","training took 28.74 s\n","Avg test loss = 1.77\tAvg test acc = 0.571\n","{'lr': 0.01, 'beta1': 0.9, 'beta2': 0.999, 'batch_size': 64, 'weight_decay': 0.1, 'epsilon': 1e-08}\n","Epoch 0\tavg epoch Loss = 0.4414\tavg epoch acc = 0.8766\n","Epoch 1\tavg epoch Loss = 0.1155\tavg epoch acc = 0.9213\n","Epoch 2\tavg epoch Loss = 0.08895\tavg epoch acc = 0.8665\n","Epoch 3\tavg epoch Loss = 0.07941\tavg epoch acc = 0.7757\n","Epoch 4\tavg epoch Loss = 0.08079\tavg epoch acc = 0.6928\n","Epoch 5\tavg epoch Loss = 0.08422\tavg epoch acc = 0.6417\n","Epoch 6\tavg epoch Loss = 0.07848\tavg epoch acc = 0.6313\n","Epoch 7\tavg epoch Loss = 0.0834\tavg epoch acc = 0.6179\n","Epoch 8\tavg epoch Loss = 0.08123\tavg epoch acc = 0.6037\n","Epoch 9\tavg epoch Loss = 0.07775\tavg epoch acc = 0.584\n","training took 28.67 s\n","Avg test loss = 1.52\tAvg test acc = 0.631\n","Epoch 0\tavg epoch Loss = 0.4449\tavg epoch acc = 0.8824\n","Epoch 1\tavg epoch Loss = 0.1213\tavg epoch acc = 0.9547\n","Epoch 2\tavg epoch Loss = 0.09243\tavg epoch acc = 0.8462\n","Epoch 3\tavg epoch Loss = 0.08011\tavg epoch acc = 0.7896\n","Epoch 4\tavg epoch Loss = 0.08075\tavg epoch acc = 0.7129\n","Epoch 5\tavg epoch Loss = 0.07913\tavg epoch acc = 0.7106\n","Epoch 6\tavg epoch Loss = 0.09182\tavg epoch acc = 0.6905\n","Epoch 7\tavg epoch Loss = 0.07477\tavg epoch acc = 0.7045\n","Epoch 8\tavg epoch Loss = 0.08236\tavg epoch acc = 0.6139\n","Epoch 9\tavg epoch Loss = 0.0806\tavg epoch acc = 0.6224\n","training took 28.55 s\n","Avg test loss = 2.93\tAvg test acc = 0.506\n","Epoch 0\tavg epoch Loss = 0.4375\tavg epoch acc = 0.8678\n","Epoch 1\tavg epoch Loss = 0.121\tavg epoch acc = 0.9198\n","Epoch 2\tavg epoch Loss = 0.09662\tavg epoch acc = 0.8814\n","Epoch 3\tavg epoch Loss = 0.08613\tavg epoch acc = 0.8176\n","Epoch 4\tavg epoch Loss = 0.08096\tavg epoch acc = 0.7436\n","Epoch 5\tavg epoch Loss = 0.08227\tavg epoch acc = 0.7223\n","Epoch 6\tavg epoch Loss = 0.08142\tavg epoch acc = 0.6738\n","Epoch 7\tavg epoch Loss = 0.08274\tavg epoch acc = 0.646\n","Epoch 8\tavg epoch Loss = 0.08324\tavg epoch acc = 0.6072\n","Epoch 9\tavg epoch Loss = 0.08167\tavg epoch acc = 0.5964\n","training took 28.65 s\n","Avg test loss = 2.73\tAvg test acc = 0.465\n","{'lr': 0.01, 'beta1': 0.9, 'beta2': 0.999, 'batch_size': 128, 'weight_decay': 0.001, 'epsilon': 1e-10}\n","Epoch 0\tavg epoch Loss = 0.6313\tavg epoch acc = 0.8295\n","Epoch 1\tavg epoch Loss = 0.163\tavg epoch acc = 0.9678\n","Epoch 2\tavg epoch Loss = 0.09544\tavg epoch acc = 0.9665\n","Epoch 3\tavg epoch Loss = 0.06766\tavg epoch acc = 0.9471\n","Epoch 4\tavg epoch Loss = 0.05391\tavg epoch acc = 0.8548\n","Epoch 5\tavg epoch Loss = 0.04495\tavg epoch acc = 0.7564\n","Epoch 6\tavg epoch Loss = 0.04727\tavg epoch acc = 0.6395\n","Epoch 7\tavg epoch Loss = 0.03857\tavg epoch acc = 0.6116\n","Epoch 8\tavg epoch Loss = 0.04104\tavg epoch acc = 0.5562\n","Epoch 9\tavg epoch Loss = 0.04804\tavg epoch acc = 0.451\n","training took 17.64 s\n","Avg test loss = 2.79\tAvg test acc = 0.465\n","Epoch 0\tavg epoch Loss = 0.6252\tavg epoch acc = 0.8394\n","Epoch 1\tavg epoch Loss = 0.1542\tavg epoch acc = 0.9655\n","Epoch 2\tavg epoch Loss = 0.09376\tavg epoch acc = 0.9563\n","Epoch 3\tavg epoch Loss = 0.06878\tavg epoch acc = 0.935\n","Epoch 4\tavg epoch Loss = 0.05528\tavg epoch acc = 0.8751\n","Epoch 5\tavg epoch Loss = 0.04903\tavg epoch acc = 0.7968\n","Epoch 6\tavg epoch Loss = 0.04561\tavg epoch acc = 0.6507\n","Epoch 7\tavg epoch Loss = 0.04308\tavg epoch acc = 0.6077\n","Epoch 8\tavg epoch Loss = 0.03769\tavg epoch acc = 0.6009\n","Epoch 9\tavg epoch Loss = 0.04181\tavg epoch acc = 0.55\n","training took 17.6 s\n","Avg test loss = 3.19\tAvg test acc = 0.587\n","Epoch 0\tavg epoch Loss = 0.6468\tavg epoch acc = 0.8343\n","Epoch 1\tavg epoch Loss = 0.1494\tavg epoch acc = 0.9053\n","Epoch 2\tavg epoch Loss = 0.08958\tavg epoch acc = 0.8398\n","Epoch 3\tavg epoch Loss = 0.06567\tavg epoch acc = 0.7688\n","Epoch 4\tavg epoch Loss = 0.05861\tavg epoch acc = 0.7669\n","Epoch 5\tavg epoch Loss = 0.04956\tavg epoch acc = 0.761\n","Epoch 6\tavg epoch Loss = 0.04349\tavg epoch acc = 0.7228\n","Epoch 7\tavg epoch Loss = 0.04305\tavg epoch acc = 0.681\n","Epoch 8\tavg epoch Loss = 0.0393\tavg epoch acc = 0.613\n","Epoch 9\tavg epoch Loss = 0.03864\tavg epoch acc = 0.5437\n","training took 17.72 s\n","Avg test loss = 3.01\tAvg test acc = 0.465\n","{'lr': 0.01, 'beta1': 0.9, 'beta2': 0.999, 'batch_size': 128, 'weight_decay': 0.001, 'epsilon': 1e-08}\n","Epoch 0\tavg epoch Loss = 0.6324\tavg epoch acc = 0.8353\n","Epoch 1\tavg epoch Loss = 0.1564\tavg epoch acc = 0.9621\n","Epoch 2\tavg epoch Loss = 0.09317\tavg epoch acc = 0.949\n","Epoch 3\tavg epoch Loss = 0.07257\tavg epoch acc = 0.9271\n","Epoch 4\tavg epoch Loss = 0.05513\tavg epoch acc = 0.8647\n","Epoch 5\tavg epoch Loss = 0.0487\tavg epoch acc = 0.782\n","Epoch 6\tavg epoch Loss = 0.04721\tavg epoch acc = 0.7611\n","Epoch 7\tavg epoch Loss = 0.03927\tavg epoch acc = 0.6942\n","Epoch 8\tavg epoch Loss = 0.04123\tavg epoch acc = 0.6464\n","Epoch 9\tavg epoch Loss = 0.03603\tavg epoch acc = 0.6155\n","training took 17.74 s\n","Avg test loss = 2.18\tAvg test acc = 0.625\n","Epoch 0\tavg epoch Loss = 0.631\tavg epoch acc = 0.8321\n","Epoch 1\tavg epoch Loss = 0.149\tavg epoch acc = 0.9189\n","Epoch 2\tavg epoch Loss = 0.09116\tavg epoch acc = 0.8914\n","Epoch 3\tavg epoch Loss = 0.06867\tavg epoch acc = 0.8874\n","Epoch 4\tavg epoch Loss = 0.05799\tavg epoch acc = 0.8431\n","Epoch 5\tavg epoch Loss = 0.04954\tavg epoch acc = 0.7083\n","Epoch 6\tavg epoch Loss = 0.03873\tavg epoch acc = 0.6351\n","Epoch 7\tavg epoch Loss = 0.0426\tavg epoch acc = 0.572\n","Epoch 8\tavg epoch Loss = 0.03751\tavg epoch acc = 0.5246\n","Epoch 9\tavg epoch Loss = 0.03481\tavg epoch acc = 0.4683\n","training took 17.64 s\n","Avg test loss = 2.71\tAvg test acc = 0.475\n","Epoch 0\tavg epoch Loss = 0.633\tavg epoch acc = 0.8266\n","Epoch 1\tavg epoch Loss = 0.1417\tavg epoch acc = 0.9323\n","Epoch 2\tavg epoch Loss = 0.08773\tavg epoch acc = 0.8862\n","Epoch 3\tavg epoch Loss = 0.06349\tavg epoch acc = 0.913\n","Epoch 4\tavg epoch Loss = 0.05793\tavg epoch acc = 0.8613\n","Epoch 5\tavg epoch Loss = 0.04842\tavg epoch acc = 0.811\n","Epoch 6\tavg epoch Loss = 0.045\tavg epoch acc = 0.7182\n","Epoch 7\tavg epoch Loss = 0.04315\tavg epoch acc = 0.6133\n","Epoch 8\tavg epoch Loss = 0.0472\tavg epoch acc = 0.5986\n","Epoch 9\tavg epoch Loss = 0.04096\tavg epoch acc = 0.5381\n","training took 17.6 s\n","Avg test loss = 3.32\tAvg test acc = 0.473\n","{'lr': 0.01, 'beta1': 0.9, 'beta2': 0.999, 'batch_size': 128, 'weight_decay': 0.1, 'epsilon': 1e-10}\n","Epoch 0\tavg epoch Loss = 0.6303\tavg epoch acc = 0.8248\n","Epoch 1\tavg epoch Loss = 0.1481\tavg epoch acc = 0.9327\n","Epoch 2\tavg epoch Loss = 0.09147\tavg epoch acc = 0.8958\n","Epoch 3\tavg epoch Loss = 0.07463\tavg epoch acc = 0.9094\n","Epoch 4\tavg epoch Loss = 0.06096\tavg epoch acc = 0.9068\n","Epoch 5\tavg epoch Loss = 0.05643\tavg epoch acc = 0.884\n","Epoch 6\tavg epoch Loss = 0.05441\tavg epoch acc = 0.8544\n","Epoch 7\tavg epoch Loss = 0.04947\tavg epoch acc = 0.8253\n","Epoch 8\tavg epoch Loss = 0.04918\tavg epoch acc = 0.8183\n","Epoch 9\tavg epoch Loss = 0.04929\tavg epoch acc = 0.7775\n","training took 17.63 s\n","Avg test loss = 1.03\tAvg test acc = 0.717\n","Epoch 0\tavg epoch Loss = 0.6233\tavg epoch acc = 0.8364\n","Epoch 1\tavg epoch Loss = 0.146\tavg epoch acc = 0.9603\n","Epoch 2\tavg epoch Loss = 0.09352\tavg epoch acc = 0.9669\n","Epoch 3\tavg epoch Loss = 0.07265\tavg epoch acc = 0.9591\n","Epoch 4\tavg epoch Loss = 0.06478\tavg epoch acc = 0.9331\n","Epoch 5\tavg epoch Loss = 0.05974\tavg epoch acc = 0.8915\n","Epoch 6\tavg epoch Loss = 0.05564\tavg epoch acc = 0.8191\n","Epoch 7\tavg epoch Loss = 0.05143\tavg epoch acc = 0.7881\n","Epoch 8\tavg epoch Loss = 0.04557\tavg epoch acc = 0.786\n","Epoch 9\tavg epoch Loss = 0.04922\tavg epoch acc = 0.7733\n","training took 17.61 s\n","Avg test loss = 1.02\tAvg test acc = 0.768\n","Epoch 0\tavg epoch Loss = 0.6353\tavg epoch acc = 0.8268\n","Epoch 1\tavg epoch Loss = 0.1559\tavg epoch acc = 0.9587\n","Epoch 2\tavg epoch Loss = 0.0949\tavg epoch acc = 0.9103\n","Epoch 3\tavg epoch Loss = 0.06924\tavg epoch acc = 0.8217\n","Epoch 4\tavg epoch Loss = 0.06052\tavg epoch acc = 0.8449\n","Epoch 5\tavg epoch Loss = 0.05853\tavg epoch acc = 0.813\n","Epoch 6\tavg epoch Loss = 0.05681\tavg epoch acc = 0.7958\n","Epoch 7\tavg epoch Loss = 0.04692\tavg epoch acc = 0.815\n","Epoch 8\tavg epoch Loss = 0.05119\tavg epoch acc = 0.7838\n","Epoch 9\tavg epoch Loss = 0.04662\tavg epoch acc = 0.7748\n","training took 17.57 s\n","Avg test loss = 0.857\tAvg test acc = 0.802\n","{'lr': 0.01, 'beta1': 0.9, 'beta2': 0.999, 'batch_size': 128, 'weight_decay': 0.1, 'epsilon': 1e-08}\n","Epoch 0\tavg epoch Loss = 0.6288\tavg epoch acc = 0.8235\n","Epoch 1\tavg epoch Loss = 0.1359\tavg epoch acc = 0.9196\n","Epoch 2\tavg epoch Loss = 0.08838\tavg epoch acc = 0.9121\n","Epoch 3\tavg epoch Loss = 0.0684\tavg epoch acc = 0.9036\n","Epoch 4\tavg epoch Loss = 0.05524\tavg epoch acc = 0.9065\n","Epoch 5\tavg epoch Loss = 0.05189\tavg epoch acc = 0.855\n","Epoch 6\tavg epoch Loss = 0.05213\tavg epoch acc = 0.815\n","Epoch 7\tavg epoch Loss = 0.04553\tavg epoch acc = 0.7777\n","Epoch 8\tavg epoch Loss = 0.04834\tavg epoch acc = 0.7424\n","Epoch 9\tavg epoch Loss = 0.04626\tavg epoch acc = 0.7317\n","training took 17.56 s\n","Avg test loss = 1.13\tAvg test acc = 0.712\n","Epoch 0\tavg epoch Loss = 0.6072\tavg epoch acc = 0.8227\n","Epoch 1\tavg epoch Loss = 0.1531\tavg epoch acc = 0.9314\n","Epoch 2\tavg epoch Loss = 0.0953\tavg epoch acc = 0.8956\n","Epoch 3\tavg epoch Loss = 0.07548\tavg epoch acc = 0.8845\n","Epoch 4\tavg epoch Loss = 0.06484\tavg epoch acc = 0.872\n","Epoch 5\tavg epoch Loss = 0.06211\tavg epoch acc = 0.8485\n","Epoch 6\tavg epoch Loss = 0.05218\tavg epoch acc = 0.8335\n","Epoch 7\tavg epoch Loss = 0.05354\tavg epoch acc = 0.805\n","Epoch 8\tavg epoch Loss = 0.04964\tavg epoch acc = 0.7994\n","Epoch 9\tavg epoch Loss = 0.05422\tavg epoch acc = 0.7643\n","training took 17.59 s\n","Avg test loss = 0.758\tAvg test acc = 0.794\n","Epoch 0\tavg epoch Loss = 0.627\tavg epoch acc = 0.8372\n","Epoch 1\tavg epoch Loss = 0.1427\tavg epoch acc = 0.9444\n","Epoch 2\tavg epoch Loss = 0.09018\tavg epoch acc = 0.924\n","Epoch 3\tavg epoch Loss = 0.07328\tavg epoch acc = 0.9258\n","Epoch 4\tavg epoch Loss = 0.06155\tavg epoch acc = 0.9203\n","Epoch 5\tavg epoch Loss = 0.05743\tavg epoch acc = 0.8894\n","Epoch 6\tavg epoch Loss = 0.05285\tavg epoch acc = 0.8476\n","Epoch 7\tavg epoch Loss = 0.0558\tavg epoch acc = 0.8288\n","Epoch 8\tavg epoch Loss = 0.0514\tavg epoch acc = 0.7995\n","Epoch 9\tavg epoch Loss = 0.04655\tavg epoch acc = 0.8101\n","training took 17.61 s\n","Avg test loss = 0.976\tAvg test acc = 0.746\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"e6pnb9SkouDI"},"source":["### Nesterov"],"id":"e6pnb9SkouDI"},{"cell_type":"code","metadata":{"id":"J6egfPHBorlC","executionInfo":{"status":"ok","timestamp":1623627106367,"user_tz":-120,"elapsed":9,"user":{"displayName":"Baris Sevilmis","photoUrl":"","userId":"05631870087761794056"}}},"source":["search_grid_nesterov = {\n","    'lr': np.logspace(0, 1),\n","    'batch_size': [32, 64, 128]\n","}\n","\n","if hyperparameter_tune:\n","    results_nesterov_prot = tune_optimizer(\n","        model=Net().to(device),\n","        optim_fun=NesterovOptimizer,\n","        xtrain=train_dataset.data,\n","        ytrain=train_dataset.targets,\n","        search_grid=search_grid_nesterov,\n","        nfolds=3,\n","        func=protected_training,\n","        **training_config\n","    )\n","\n","else:\n","    results_nesterov_prot = optimizers[NesterovOptimizer]"],"id":"J6egfPHBorlC","execution_count":41,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JT4QvX46owJT"},"source":["### Minibatch"],"id":"JT4QvX46owJT"},{"cell_type":"code","metadata":{"id":"v36dhlsxorzj","executionInfo":{"status":"ok","timestamp":1623627106368,"user_tz":-120,"elapsed":8,"user":{"displayName":"Baris Sevilmis","photoUrl":"","userId":"05631870087761794056"}}},"source":["dec_lr_set =  [0]*1 + [1]*1\n","random.shuffle(dec_lr_set)\n","search_grid_mini  = {\n","        'lr': np.linspace(0.00001, 0.01, 5),\n","        'batch_size': [32, 64, 128],\n","        'decreasing_lr': dec_lr_set,\n","    }\n","if hyperparameter_tune:\n","    results_mini_prot = tune_optimizer(\n","        model=Net().to(device),\n","        optim_fun=MiniBatchOptimizer,\n","        xtrain=train_dataset.data,\n","        ytrain=train_dataset.targets,\n","        search_grid=search_grid_mini,\n","        nfolds=3,\n","        func=protected_training,\n","        **training_config\n","    )\n","\n","else:\n","    results_mini_prot = optimizers[MiniBatchOptimizer]"],"id":"v36dhlsxorzj","execution_count":42,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aTGiymqzTC5F"},"source":["## Train robust models"],"id":"aTGiymqzTC5F"},{"cell_type":"code","metadata":{"id":"3x4JuZVETC5G"},"source":["from adversary import protect"],"id":"3x4JuZVETC5G","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UFME603ZTC5G"},"source":["### Minibatch (for now, loop later)"],"id":"UFME603ZTC5G"},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":232},"id":"C8vJ8xgkTC5G","executionInfo":{"status":"error","timestamp":1623288595918,"user_tz":-120,"elapsed":219,"user":{"displayName":"Baris Sevilmis","photoUrl":"","userId":"05631870087761794056"}},"outputId":"95c9382c-c73c-49d4-cc70-e97405500e19"},"source":["robust_net = Net().to(device)\n","protect_epochs = training_config['epochs']\n","protect_lr = results_mini_prot['lr']\n","protect_bz = results_mini_prot['batch_size']\n","protect_dec_lr = results_mini_prot['decreasing_lr']\n","prot_train_loader, prot_test_loader = build_data_loaders(train_dataset, test_dataset, protect_bz)\n","mini_opt_proc = MiniBatchOptimizer(robust_net.parameters(), lr=protect_lr, decreasing_lr=protect_dec_lr)\n","robust_net = protect(robust_net, mini_opt_proc, training_config['loss_fun'], prot_train_loader, prot_test_loader, device=device, epochs=protect_epochs)"],"id":"C8vJ8xgkTC5G","execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-28-91eca63f114a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mrobust_net\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprotect_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprotect_lr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprotect_bz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprotect_dec_lr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecreasing_lr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'epochs' is not defined"]}]},{"cell_type":"markdown","metadata":{"id":"P6G89LD0TC5G"},"source":["### Adam"],"id":"P6G89LD0TC5G"},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":269},"id":"16pWnK7TTC5H","executionInfo":{"status":"error","timestamp":1623290987223,"user_tz":-120,"elapsed":263,"user":{"displayName":"Baris Sevilmis","photoUrl":"","userId":"05631870087761794056"}},"outputId":"3f200c9c-4e47-4e85-b20a-6b91671b034c"},"source":["robust_net = Net().to(device)\n","protect_epochs = training_config['epochs']\n","protect_lr_adam = results_adam_prot['lr']\n","protect_bz_adam = results_adam_prot['batch_size']\n","protect_beta1 = results_adam_prot['beta1']\n","protect_beta2 = results_adam_prot['beta2']\n","protect_weight_decay = results_adam_prot['weight_decay']\n","protect_epsilon = results_adam_prot['epsilon']\n","prot_train_loader, prot_test_loader = build_data_loaders(train_dataset, test_dataset, protect_bz)\n","adam_opt_proc = AdamOptimizer(net_naive.parameters(), lr=protect_lr_adam, beta1=protect_beta1,beta2=protect_beta2,weight_decay=protect_weight_decay,epsilon=protect_epsilon)\n","robust_net_adam = protect(robust_net, adam_opt_proc, training_config['loss_fun'], prot_train_loader, prot_test_loader, device=device, epochs=training_config['epochs'])"],"id":"16pWnK7TTC5H","execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-48-db2045aba439>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mrobust_net\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprot_train_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprot_test_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_data_loaders\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprotect_bz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0madam_opt_proc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAdamOptimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet_naive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbest_adam_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbest_adam_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'beta1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbest_adam_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'beta2'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mweight_decay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbest_adam_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'weight_decay'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbest_adam_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'epsilon'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mrobust_net_adam\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprotect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrobust_net\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madam_opt_proc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprot_train_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprot_test_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'epochs'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'protect_bz' is not defined"]}]},{"cell_type":"markdown","metadata":{"id":"Dy6ZxVp0TC5H"},"source":["### Nesterov\n","\n"],"id":"Dy6ZxVp0TC5H"},{"cell_type":"code","metadata":{"id":"zM_3v15STC5H"},"source":["robust_networks = dict()\n","batch_log_interval = 0\n","epsilon = 0.25\n","\n","for optimizer, optimizer_params in prot_optimizers.items():\n","    # Instantiate model\n","    net = Net().to(device)\n","    # Instantiate optimizer\n","    optimizer_params = optimizer_params.copy()\n","    batch_size = optimizer_params.pop('batch_size')\n","    optimizer_instance = optimizer(net.parameters(), **optimizer_params)\n","    # Instantiate data loaders\n","    train_loader, test_loader = build_data_loaders(train_dataset, test_dataset, batch_size)\n","    # Train robust model\n","    protect(\n","        model=net,\n","        optim=optimizer_instance,\n","        train_loader=train_loader,\n","        test_loader=test_loader,\n","        epsilon=epsilon,\n","        **training_config\n","    )\n","    # Save robust net\n","    robust_networks[optimizer] = net"],"id":"zM_3v15STC5H","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-xnntG3cggIS"},"source":[],"id":"-xnntG3cggIS","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4qVv9q6eTC5H"},"source":["## Attack robust models"],"id":"4qVv9q6eTC5H"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["accuracy_fgsm = dict()\n","losses_fgsm = dict()\n","\n","accuracy_pgd = dict()\n","losses_pgd = dict()\n","\n","for optimizer, optimizer_params in prot_optimizers.items():\n","    # Instantiate model\n","    net = robust_networks[optimizer]\n","    # Instantiate optimizer\n","    optimizer_params = optimizer_params.copy()\n","    batch_size = optimizer_params.pop('batch_size')\n","\n"]},{"cell_type":"markdown","metadata":{"id":"R6vqeaYzTC5I"},"source":["### Minibatch (for now, loop later)"],"id":"R6vqeaYzTC5I"},{"cell_type":"code","metadata":{"id":"OQdRN5UwTC5I"},"source":["accuracy_robust = []\n","losses_robust = []\n","epsilons = np.arange(0, 0.5, 0.05)\n","\n","# This should be the first term test_loader is used\n","for eps in epsilons:\n","    loss_attack, acc_attack = attack(robust_net, criterion, prot_test_loader, eps, device=device)\n","    accuracy_robust.append(acc_attack)\n","    losses_robust.append(loss_attack)"],"id":"OQdRN5UwTC5I","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iQc7A5jETC5I"},"source":["### Adam"],"id":"iQc7A5jETC5I"},{"cell_type":"code","metadata":{"id":"qCLBCNYTTC5I"},"source":["accuracy_robust_adam = []\n","losses_robust_adam = []\n","# This should be the first term test_loader is used\n","for eps in epsilons:\n","    loss_attack, acc_attack = attack(robust_net_adam, criterion, prot_test_loader, eps, device=device)\n","    accuracy_robust_adam.append(acc_attack)\n","    losses_robust_adam.append(loss_attack)"],"id":"qCLBCNYTTC5I","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tcc0rN-VTC5I"},"source":["## Comparison"],"id":"tcc0rN-VTC5I"},{"cell_type":"markdown","metadata":{"id":"Z_rGhjZxTC5I"},"source":["# Comparative analysis"],"id":"Z_rGhjZxTC5I"},{"cell_type":"markdown","metadata":{"id":"treK0pzuTC5I"},"source":["### Minibatch (for now)"],"id":"treK0pzuTC5I"},{"cell_type":"code","metadata":{"id":"yY6YSGTNTC5J"},"source":["plt.figure(figsize=(5,5))\n","plt.plot(epsilons, accuracy_naive, \"*-\", c='blue', label='Naive Model')\n","plt.plot(epsilons, accuracy_robust, \"*-\", c='orange', label='Robust Model')\n","\n","plt.yticks(np.arange(0, 1.1, step=0.1))\n","plt.xticks(np.arange(0, 0.5, step=0.05))\n","\n","plt.title(\"Accuracy vs Epsilon\")\n","plt.xlabel(\"Epsilon\")\n","plt.ylabel(\"Accuracy\")\n","plt.legend();"],"id":"yY6YSGTNTC5J","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"byYxhmiCTC5J"},"source":["Lots of plots\n","\n","* diff naive vs robust (algo as hue)"],"id":"byYxhmiCTC5J"}]}