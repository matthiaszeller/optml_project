{"nbformat":4,"nbformat_minor":5,"metadata":{"accelerator":"GPU","colab":{"name":"Pipeline.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python [conda env:ml]","language":"python","name":"conda-env-ml-py"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"},"metadata":{"interpreter":{"hash":"aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"}}},"cells":[{"cell_type":"code","metadata":{"id":"mechanical-vienna"},"source":["%load_ext autoreload\n","%autoreload 2"],"id":"mechanical-vienna","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"super-finland"},"source":["# guidelines\n","\n","TODO : import whenever needed, not centralized"],"id":"super-finland"},{"cell_type":"markdown","metadata":{"id":"coastal-sugar"},"source":["states https://pytorch.org/tutorials/beginner/saving_loading_models.html"],"id":"coastal-sugar"},{"cell_type":"markdown","metadata":{"id":"stable-latter"},"source":["# Introduction "],"id":"stable-latter"},{"cell_type":"markdown","metadata":{"id":"educated-soviet"},"source":["## Aim"],"id":"educated-soviet"},{"cell_type":"markdown","metadata":{"id":"electrical-density"},"source":["## Data"],"id":"electrical-density"},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8_URHgbeWjLB","executionInfo":{"status":"ok","timestamp":1623891269013,"user_tz":-120,"elapsed":21348,"user":{"displayName":"Baris Sevilmis","photoUrl":"","userId":"05631870087761794056"}},"outputId":"e351ca47-041d-4538-b293-6044685e800b"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"id":"8_URHgbeWjLB","execution_count":2,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iIYuAo6eXCTg","executionInfo":{"status":"ok","timestamp":1623891271652,"user_tz":-120,"elapsed":992,"user":{"displayName":"Baris Sevilmis","photoUrl":"","userId":"05631870087761794056"}},"outputId":"a9c12a99-6682-418f-c053-a1f0b842d09e"},"source":["#%cd /content/drive/MyDrive/Colab\\ Notebooks/\n","#%cd CS439/optml_project/\n","!ls"],"id":"iIYuAo6eXCTg","execution_count":3,"outputs":[{"output_type":"stream","text":["/content/drive/MyDrive/Colab Notebooks\n","/content/drive/MyDrive/Colab Notebooks/CS439/optml_project\n"," adversary.py\t        data_utils.py\t\t  Pipeline.ipynb   test1.txt\n"," adv_test.py\t        Hyperparam-tuning.ipynb   __pycache__\t   test2.txt\n"," alt_adv_test.py        Matt_notebook.ipynb\t  README.md\t   test.py\n"," Attack.ipynb\t       'MF Notebook.ipynb'\t  res\t\t   training.py\n"," Baris_Notebook.ipynb   Nesterov.ipynb\t\t  Research\n"," comp_results\t        net.py\t\t\t  test1a.txt\n"," data\t\t        optimizer.py\t\t  test1b.txt\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"foreign-chemical"},"source":["First load the dataset:"],"id":"foreign-chemical"},{"cell_type":"code","metadata":{"id":"aerial-riding","executionInfo":{"status":"ok","timestamp":1623891288068,"user_tz":-120,"elapsed":8801,"user":{"displayName":"Baris Sevilmis","photoUrl":"","userId":"05631870087761794056"}}},"source":["from data_utils import get_mnist\n","\n","train_dataset, test_dataset = get_mnist(normalize=True)"],"id":"aerial-riding","execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"possible-bulletin","executionInfo":{"status":"ok","timestamp":1623891288692,"user_tz":-120,"elapsed":636,"user":{"displayName":"Baris Sevilmis","photoUrl":"","userId":"05631870087761794056"}}},"source":["import numpy as np\n","#import random\n","import torch\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","import seaborn as sns"],"id":"possible-bulletin","execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"resident-mineral"},"source":["## Setup"],"id":"resident-mineral"},{"cell_type":"markdown","metadata":{"id":"maritime-globe"},"source":["Below one can find flags that will setup the notebook:"],"id":"maritime-globe"},{"cell_type":"code","metadata":{"id":"sixth-belfast","executionInfo":{"status":"ok","timestamp":1623891319857,"user_tz":-120,"elapsed":200,"user":{"displayName":"Baris Sevilmis","photoUrl":"","userId":"05631870087761794056"}}},"source":["# Whether to tune the hyperparameters in this notebook\n","# Note that this might take a long time (especially for Adam)\n","hyperparameter_tune = False\n","prot_hyperparameter_tune = False"],"id":"sixth-belfast","execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"suspected-madison","executionInfo":{"status":"ok","timestamp":1623891288698,"user_tz":-120,"elapsed":9,"user":{"displayName":"Baris Sevilmis","photoUrl":"","userId":"05631870087761794056"}},"outputId":"317070a6-98b3-4832-ab12-1f36cdd65ee3"},"source":["# Whether to use the GPU, if it's not available, this will be ignored\n","use_cuda = True\n","device = torch.device('cuda' if use_cuda and torch.cuda.is_available() else 'cpu')\n","print(\"Device chosen is {}\".format(device))"],"id":"suspected-madison","execution_count":7,"outputs":[{"output_type":"stream","text":["Device chosen is cuda\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"sophisticated-karaoke"},"source":["We setup the training parameters that we will use all along the notebook, in order to improve readability in downstream code:"],"id":"sophisticated-karaoke"},{"cell_type":"code","metadata":{"id":"hundred-swedish","executionInfo":{"status":"ok","timestamp":1623891288899,"user_tz":-120,"elapsed":208,"user":{"displayName":"Baris Sevilmis","photoUrl":"","userId":"05631870087761794056"}}},"source":["from training import accuracy\n","\n","training_config = {\n","    # Loss function\n","    'loss_fun': torch.nn.CrossEntropyLoss(),\n","    # Performance evaluation function\n","    'metric_fun': accuracy,\n","    # The device to train on\n","    'device': device,\n","    # Number of epochs\n","    'epochs': 10,\n","}\n","\n","test_config = training_config.copy()\n","test_config.pop('epochs');"],"id":"hundred-swedish","execution_count":8,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"flying-assessment"},"source":["Note that we will use a model with a 10-dimensional output, where each output is passed through softmax. When receiving an output \n","\n","$$Z = \\begin{bmatrix} \\mathbf z_1 & \\dots & \\mathbf z_B \\end{bmatrix}^\\top \\in \\mathbb R^{B \\times 10}$$\n","\n","with $B$ the batch size, we first retrieve the maximal component of each $\\mathbf z_i$:\n","\n","$$\\hat y_i = \\text{argmax}_{k = 1, \\ldots, 10} \\; z_{ik}, \\quad i = 1, \\ldots, B$$\n","\n","and then compute the accuracy:\n","\n","$$\\text{acc} = \\frac 1 B \\sum_{i=1}^B I\\left\\{ \\hat y_i = y_i \\right\\} $$\n","\n","with $I$ the indicator function and $y_i \\in \\{1, \\ldots, 10\\}$ the true target. "],"id":"flying-assessment"},{"cell_type":"code","metadata":{"id":"monetary-filter","executionInfo":{"status":"ok","timestamp":1623891289366,"user_tz":-120,"elapsed":471,"user":{"displayName":"Baris Sevilmis","photoUrl":"","userId":"05631870087761794056"}}},"source":["# View the source code\n","??accuracy"],"id":"monetary-filter","execution_count":9,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"touched-alfred"},"source":["# Model"],"id":"touched-alfred"},{"cell_type":"markdown","metadata":{"id":"dependent-alabama"},"source":["We use a simple standard model for the MNIST dataset (can be found [here](https://github.com/floydhub/mnist/blob/master/ConvNet.py))."],"id":"dependent-alabama"},{"cell_type":"code","metadata":{"id":"grave-dominican","executionInfo":{"status":"ok","timestamp":1623891290139,"user_tz":-120,"elapsed":776,"user":{"displayName":"Baris Sevilmis","photoUrl":"","userId":"05631870087761794056"}}},"source":["from net import Net\n","\n","??Net"],"id":"grave-dominican","execution_count":10,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"private-business"},"source":["# Hyperparameter tuning"],"id":"private-business"},{"cell_type":"code","metadata":{"id":"charming-lingerie","executionInfo":{"status":"ok","timestamp":1623891290154,"user_tz":-120,"elapsed":18,"user":{"displayName":"Baris Sevilmis","photoUrl":"","userId":"05631870087761794056"}}},"source":["from torch.optim import Optimizer\n","from training import tune_optimizer\n","from optimizer import AdamOptimizer, NesterovOptimizer, MiniBatchOptimizer\n","from data_utils import get_best_hyperparams"],"id":"charming-lingerie","execution_count":11,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"referenced-consultation"},"source":["If the `hyperparameter_tune` flag was set to `True` above, the following code will run hyperparameter tuning on all optimizers. Note that one can either run KFold cross validation (by providing `n_folds`) or use a simple train/test split (by providing `train_ratio`)."],"id":"referenced-consultation"},{"cell_type":"markdown","metadata":{"id":"vocal-funeral"},"source":["If the flag is set to `False`, the cell below will simply set up the hyperparameters that we carefully cross-validated:"],"id":"vocal-funeral"},{"cell_type":"code","metadata":{"id":"sticky-three","executionInfo":{"status":"ok","timestamp":1623891291129,"user_tz":-120,"elapsed":992,"user":{"displayName":"Baris Sevilmis","photoUrl":"","userId":"05631870087761794056"}}},"source":["optimizers = {\n","    AdamOptimizer: get_best_hyperparams('./res/adam_tuning_round3.json'),\n","    NesterovOptimizer: get_best_hyperparams('./res/nesterov_tuning_round2.json'),\n","    MiniBatchOptimizer: get_best_hyperparams('./res/minibatch_tuning_round2.json')\n","}"],"id":"sticky-three","execution_count":12,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"atlantic-cooking"},"source":["## Adam"],"id":"atlantic-cooking"},{"cell_type":"code","metadata":{"id":"developed-sending","executionInfo":{"status":"ok","timestamp":1623891291130,"user_tz":-120,"elapsed":12,"user":{"displayName":"Baris Sevilmis","photoUrl":"","userId":"05631870087761794056"}}},"source":["search_grid_adam = {\n","        'lr': np.linspace(0.001, 0.01, 3),\n","        'beta1':  np.linspace(0.1, 0.9, 2),\n","        'beta2': np.linspace(0.5, 0.999, 2),\n","        'batch_size': [32, 64, 128],\n","        'weight_decay': np.linspace(0.001, 0.1, 2),\n","        'epsilon': np.linspace(1e-10, 1e-8, 2),\n","    }\n","\n","if hyperparameter_tune:\n","    results_adam = tune_optimizer(\n","        model=Net().to(device),\n","        optim_fun=AdamOptimizer,\n","        xtrain=train_dataset.data,\n","        ytrain=train_dataset.targets,\n","        search_grid=search_grid_adam,\n","        nfolds=3,\n","        **training_config)\n","\n","else:\n","    results_adam = optimizers[AdamOptimizer]"],"id":"developed-sending","execution_count":13,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"falling-dividend"},"source":["## Nesterov"],"id":"falling-dividend"},{"cell_type":"code","metadata":{"id":"saved-delivery","executionInfo":{"status":"ok","timestamp":1623891291132,"user_tz":-120,"elapsed":13,"user":{"displayName":"Baris Sevilmis","photoUrl":"","userId":"05631870087761794056"}}},"source":["search_grid_nesterov = {\n","    'lr': np.logspace(0, 1),\n","    'batch_size': [32, 64, 128]\n","}\n","\n","if hyperparameter_tune:\n","    results_nesterov = tune_optimizer(\n","        model=Net().to(device),\n","        optim_fun=NesterovOptimizer,\n","        xtrain=train_dataset.data,\n","        ytrain=train_dataset.targets,\n","        search_grid=search_grid_nesterov,\n","        nfolds=3,\n","        **training_config\n","    )\n","\n","else:\n","    results_nesterov = optimizers[NesterovOptimizer]"],"id":"saved-delivery","execution_count":14,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"instrumental-opinion"},"source":["## Minibatch"],"id":"instrumental-opinion"},{"cell_type":"code","metadata":{"id":"absent-prayer","executionInfo":{"status":"ok","timestamp":1623891291132,"user_tz":-120,"elapsed":13,"user":{"displayName":"Baris Sevilmis","photoUrl":"","userId":"05631870087761794056"}}},"source":["search_grid_mini  = {\n","    'lr': np.linspace(0.00001, 0.01, 5),\n","    'batch_size': [32, 64, 128],\n","    'decreasing_lr': [0, 1],\n","}\n","if hyperparameter_tune:\n","    results_mini = tune_optimizer(\n","        model=Net().to(device),\n","        optim_fun=MiniBatchOptimizer,\n","        xtrain=train_dataset.data,\n","        ytrain=train_dataset.targets,\n","        search_grid=search_grid_mini,\n","        nfolds=3,\n","        **training_config\n","    )\n","\n","else:\n","    results_mini = optimizers[MiniBatchOptimizer]"],"id":"absent-prayer","execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"south-promise","executionInfo":{"status":"ok","timestamp":1623891291133,"user_tz":-120,"elapsed":13,"user":{"displayName":"Baris Sevilmis","photoUrl":"","userId":"05631870087761794056"}},"outputId":"bf4acede-f4b9-41a6-b780-321e1af735b8"},"source":["print(\"ADAM: Highest Test Accuracy {:.4f} with standart deviation of {:.4f}\".format(results_adam[\"metric_test\"], results_adam[\"metric_test_std\"]))\n","print(\"Hyperparameter set: Learning rate =  {:.4f}, Beta1 = {:.1f}, Beta2 = {:.3f}, Weight decay = {:.2f}, Epsilon = {:.8f},  Batch Size = {:.0f}\\n\".format(results_adam[\"lr\"], results_adam[\"beta1\"], results_adam[\"beta2\"], results_adam[\"weight_decay\"], results_adam[\"epsilon\"], results_adam['batch_size']))\n","print(\"NESTEROV: Highest Test Accuracy {:.4f} with standart deviation of {:.4f}\".format(results_nesterov[\"metric_test\"], results_nesterov[\"metric_test_std\"]))\n","print(\"Hyperparameter set: Learning rate =  {:.4f}, Batch Size = {:.0f}\\n\".format(results_nesterov[\"lr\"], results_nesterov[\"batch_size\"]))\n","print(\"MINIBATCH: Highest Test Accuracy {:.4f} with standart deviation of {:.4f}\".format(results_mini[\"metric_test\"], results_mini[\"metric_test_std\"]))\n","print(\"Hyperparameter set: Learning rate =  {:.4f}, Decreasing Learning rate {:.1f}, Batch Size = {:.0f}\\n\".format(results_mini[\"lr\"], results_mini[\"decreasing_lr\"], results_mini[\"batch_size\"]))\n"],"id":"south-promise","execution_count":16,"outputs":[{"output_type":"stream","text":["ADAM: Highest Test Accuracy 0.9868 with standart deviation of 0.0007\n","Hyperparameter set: Learning rate =  0.0001, Beta1 = 0.9, Beta2 = 0.999, Weight decay = 0.01, Epsilon = 0.00000001,  Batch Size = 32\n","\n","NESTEROV: Highest Test Accuracy 0.9876 with standart deviation of 0.0010\n","Hyperparameter set: Learning rate =  0.0001, Batch Size = 64\n","\n","MINIBATCH: Highest Test Accuracy 0.9886 with standart deviation of 0.0002\n","Hyperparameter set: Learning rate =  0.2639, Decreasing Learning rate 0.0, Batch Size = 128\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"better-archives"},"source":["# Attack on naive model\n","\n"],"id":"better-archives"},{"cell_type":"code","metadata":{"id":"better-agreement","executionInfo":{"status":"ok","timestamp":1623891336717,"user_tz":-120,"elapsed":574,"user":{"displayName":"Baris Sevilmis","photoUrl":"","userId":"05631870087761794056"}}},"source":["from data_utils import build_data_loaders\n","from training import training, testing\n","from adversary import attack, projected_attack"],"id":"better-agreement","execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"id":"saved-parameter","executionInfo":{"status":"ok","timestamp":1623891336718,"user_tz":-120,"elapsed":7,"user":{"displayName":"Baris Sevilmis","photoUrl":"","userId":"05631870087761794056"}}},"source":["optimizers = {\n","    AdamOptimizer: get_best_hyperparams('./res/adam_tuning_round3.json', get_performance=False),\n","    NesterovOptimizer: get_best_hyperparams('./res/nesterov_tuning_round2.json', get_performance=False),\n","    MiniBatchOptimizer: get_best_hyperparams('./res/minibatch_tuning_round2.json', get_performance=False)\n","}"],"id":"saved-parameter","execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"posted-portable","executionInfo":{"status":"ok","timestamp":1623891338326,"user_tz":-120,"elapsed":194,"user":{"displayName":"Baris Sevilmis","photoUrl":"","userId":"05631870087761794056"}},"outputId":"b253cb92-2f98-4484-8753-7a089e436492"},"source":["optimizers"],"id":"posted-portable","execution_count":20,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{optimizer.AdamOptimizer: {'batch_size': 32,\n","  'beta1': 0.9,\n","  'beta2': 0.999,\n","  'epsilon': 1e-08,\n","  'lr': 8e-05,\n","  'weight_decay': 0.01},\n"," optimizer.MiniBatchOptimizer: {'batch_size': 128,\n","  'decreasing_lr': False,\n","  'lr': 0.26389342601937466},\n"," optimizer.NesterovOptimizer: {'batch_size': 64, 'lr': 5e-05}}"]},"metadata":{"tags":[]},"execution_count":20}]},{"cell_type":"raw","metadata":{"executionInfo":{"elapsed":27,"status":"error","timestamp":1623615469045,"user":{"displayName":"Baris Sevilmis","photoUrl":"","userId":"05631870087761794056"},"user_tz":-120},"id":"accomplished-lawrence","jupyter":{"source_hidden":true},"outputId":"1ade6c5a-b1d0-4739-c1df-26c5777bdfdc","tags":[]},"source":["# NON LOOPY VERSION\n","naive_networks = dict()\n","data_naive = list()\n","batch_log_interval = -1\n","\n","for optimizer, optimizer_params in optimizers.items():\n","    optimizer_params = optimizer_params.copy()\n","    \n","    net = Net().to(device)\n","    # Instantiate data loaders with selected batch size\n","    batch_size = int(optimizer_params.pop('batch_size'))\n","    metric_test = optimizer_params.pop('metric_test')\n","    metric_test_std = optimizer_params.pop('metric_test_std')\n","    train_loader, test_loader = build_data_loaders(train_dataset, test_dataset, batch_size)\n","    # Instantiate optimizer\n","    optimizer_instance = optimizer(net.parameters(), **optimizer_params)\n","    print(f'--- {optimizer_instance}')\n","    # Train\n","    loss_train, acc_train = training(\n","        model=net, \n","        dataset=train_loader, \n","        optim=optimizer_instance,\n","        batch_log_interval=batch_log_interval,\n","        **training_config\n","    )\n","    # Test\n","    loss_test, acc_test = testing(\n","        model=net,\n","        dataset=test_loader,\n","        **test_config\n","    )\n","    # Log\n","    data_naive.append({\n","        'optimizer': str(optimizer_instance),\n","        'loss_train': loss_train,\n","        'acc_train': acc_train,\n","        'loss_test': loss_test,\n","        'acc_test': acc_test\n","    })\n","    # Save naive model\n","    naive_networks[optimizer] = net"],"id":"accomplished-lawrence"},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"intended-michigan","executionInfo":{"status":"ok","timestamp":1623891667535,"user_tz":-120,"elapsed":328127,"user":{"displayName":"Baris Sevilmis","photoUrl":"","userId":"05631870087761794056"}},"outputId":"b3c4dda3-2c2c-4c68-f0ad-c87a58dd43f0"},"source":["# Logging data structures\n","data_naive = list()\n","data_naive_attack = list()\n","\n","# Training / attack config\n","n_try = 3\n","batch_log_interval = -1\n","epsilons = np.arange(0, 0.6, 0.05)\n","\n","for optimizer, optimizer_params in optimizers.items():\n","    print(f'--- {optimizer.__name__}')\n","    # --------- SETUP OPTIMIZER\n","    optimizer_params = optimizer_params.copy()\n","    # Instantiate data loaders with selected batch size\n","    batch_size = int(optimizer_params.pop('batch_size'))\n","    train_loader, test_loader = build_data_loaders(train_dataset, test_dataset, batch_size)\n","    \n","    # --------- Train & Attack several times per optimizer\n","    for n in range(1, n_try + 1):\n","        net = Net().to(device)\n","        optimizer_instance = optimizer(net.parameters(), **optimizer_params)\n","        # --------- TRAIN MODEL\n","        loss_train, acc_train = training(\n","            model=net, \n","            dataset=train_loader, \n","            optim=optimizer_instance,\n","            batch_log_interval=batch_log_interval,\n","            **training_config\n","        )\n","        # --------- TEST MODEL\n","        loss_test, acc_test = testing(\n","            model=net,\n","            dataset=test_loader,\n","            **test_config\n","        )\n","        # Log\n","        data_naive.append({\n","            'optimizer': str(optimizer_instance),\n","            'n': n,\n","            'loss_train': loss_train,\n","            'acc_train': acc_train,\n","            'loss_test': loss_test,\n","            'acc_test': acc_test\n","        })\n","\n","        # --------- ATTACK MODEL\n","        print(f'Launching attacks', end=' ')\n","        for eps in epsilons:\n","            print('', end='.')\n","            loss_attack, acc_attack = attack(\n","                model=net,\n","                test_loader=test_loader,\n","                epsilon=eps,\n","                verbose=False,\n","                **test_config\n","            )\n","            # Log\n","            data_naive_attack.append({\n","                'optimizer': str(optimizer_instance),\n","                'n': n,\n","                'epsilon': eps,\n","                'loss': loss_attack,\n","                'acc': acc_attack\n","            })\n","\n","        print()"],"id":"intended-michigan","execution_count":21,"outputs":[{"output_type":"stream","text":["--- AdamOptimizer\n","Launching training on cuda . . . . . . . . . . training took 53.78 s\n","Avg test loss = 0.0343\tAvg test acc = 0.988\n","Launching attacks ............\n","Launching training on cuda . . . . . . . . . . training took 53.75 s\n","Avg test loss = 0.0331\tAvg test acc = 0.989\n","Launching attacks ............\n","Launching training on cuda . . . . . . . . . . training took 53.6 s\n","Avg test loss = 0.0312\tAvg test acc = 0.99\n","Launching attacks ............\n","--- NesterovOptimizer\n","Launching training on cuda . . . . . . . . . . training took 22.23 s\n","Avg test loss = 0.0243\tAvg test acc = 0.992\n","Launching attacks ............\n","Launching training on cuda . . . . . . . . . . training took 22.32 s\n","Avg test loss = 0.0326\tAvg test acc = 0.989\n","Launching attacks ............\n","Launching training on cuda . . . . . . . . . . training took 22.36 s\n","Avg test loss = 0.0345\tAvg test acc = 0.99\n","Launching attacks ............\n","--- MiniBatchOptimizer\n","Launching training on cuda . . . . . . . . . . training took 13.56 s\n","Avg test loss = 0.0387\tAvg test acc = 0.99\n","Launching attacks ............\n","Launching training on cuda . . . . . . . . . . training took 13.6 s\n","Avg test loss = 0.039\tAvg test acc = 0.989\n","Launching attacks ............\n","Launching training on cuda . . . . . . . . . . training took 13.62 s\n","Avg test loss = 0.0402\tAvg test acc = 0.99\n","Launching attacks ............\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"suffering-proposal"},"source":["### Training curves"],"id":"suffering-proposal"},{"cell_type":"code","metadata":{"id":"julian-anderson","colab":{"base_uri":"https://localhost:8080/","height":295},"executionInfo":{"status":"ok","timestamp":1623891668243,"user_tz":-120,"elapsed":717,"user":{"displayName":"Baris Sevilmis","photoUrl":"","userId":"05631870087761794056"}},"outputId":"ad42db05-f370-4410-9fbc-e8f311d5d2e5"},"source":["df_naive = pd.DataFrame(data_naive).sort_values(['optimizer', 'n'])\n","# Average training loss per epoch\n","df_naive.loss_train = df_naive.loss_train.apply(lambda s: np.mean(s, axis=1))\n","\n","colors = {'AdamOptimizer': 'r', 'MiniBatchOptimizer': 'b', 'NesterovOptimizer': 'm'}\n","for _, row in df_naive.iterrows():\n","    plt.plot(range(1, training_config['epochs'] + 1), row.loss_train, '-o', label=row.optimizer, color=colors[row.optimizer])\n","\n","plt.grid(alpha=.6)\n","plt.legend();\n","plt.yscale('log')\n","plt.xlabel('Epoch'); plt.ylabel('Training Loss')\n","plt.title('Training curves of naive models');"],"id":"julian-anderson","execution_count":22,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"generic-terrorism"},"source":["### Attack plots"],"id":"generic-terrorism"},{"cell_type":"code","metadata":{"id":"orange-consumer","colab":{"base_uri":"https://localhost:8080/","height":295},"executionInfo":{"status":"ok","timestamp":1623891668998,"user_tz":-120,"elapsed":759,"user":{"displayName":"Baris Sevilmis","photoUrl":"","userId":"05631870087761794056"}},"outputId":"101e1ee0-589d-49ce-eb90-92332d1d37c7"},"source":["df = pd.DataFrame(data_naive_attack).sort_values(['optimizer', 'epsilon'])\n","# Raw accuracy in function of attack stength\n","sns.lineplot(x='epsilon', y='acc', data=df, hue='optimizer', marker='o')\n","plt.grid(alpha=.6)\n","plt.ylabel('Accuracy');\n","plt.title('Attack on naive models');"],"id":"orange-consumer","execution_count":23,"outputs":[{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdd3RUxdvA8e/sZpPNpjdKQgklhZAKITSRJkWFgA0b0kTEhoqgYKH5oggIiKioiIgKFmyI6A9REAGlhN5rCBBKei9b5v1jN2uCBEKJKcznnByye+feO7Mb9tmZe+cZIaVEURRFuXFpqroCiqIoStVSgUBRFOUGpwKBoijKDU4FAkVRlBucCgSKoig3OBUIFEVRbnAqECg1jhBiiBBifVXX40oIIeYLIV6p6npcCSHEIiHE/1WwbKIQ4pbKrpNSOVQgUK6JEGKtECJDCOF0wfNlPhiEEIFCCCmEcPjva1n1pJQjpZSvVnU9FOViVCBQrpoQIhDoBEggvkoroyjKVVOBQLkWg4C/gUXA4JInhRCfAo2AH4UQuUKI54F1ts2ZtufaCyGaCSF+F0KkCSFShRCfCyE8Sx2noRDiWyFEiq3MvItVQggxQwixXgjhcZFtTkKIOUKIZNvPnJLeixCiixDilBDiOSHEeSHEGSHE0PIaa+v9vCqE2CCEyBFCrBJC+Jba/rUQ4qwQIksIsU4I0bLUNvswixBivxCiT6ltDrY2trI9bieE2CiEyBRC7BRCdLlEnRKFEGOFELuEEHlCiI+EEHWFED/b6rhaCOFVqny8EGKv7dhrhRAtSm2LEUJss+33JaC/4Fx9hBA7bPtuFEJEllOnOCHEViFEthDinBBiVnn1V6oJKaX6UT9X9QMcAR4HWgNGoG6pbYnALaUeB2LtOTiUeq450ANwAvywBos5tm1aYCcwG3DB+qF0k23bEGA91i8yHwL/Awzl1HEK1mBVx3aOjcCrtm1dAJOtjA64DcgHvMo51lrgKBAMONseTyu1fRjgZmvPHGBHqW2LgP+z/T4B+LzUttuB/bbfA4A0W100ttcnDfArp06JtvbVte17HtgGxNhes9+BibaywUCe7Zg64Hnbe+ho+zkBPGvbdrftPS2pc4zt2G1t781g27mdLny/gb+Ah2y/uwLtqvpvVf1c+kf1CJSrIoS4CWgMfCWlTMD6AfnAlRxDSnlESvmrlLJISpkCzAI62zbHAf7AWCllnpSyUEpZ+gKxDlgKeAN9pZT55ZzmQWCKlPK87RyTgYdKbTfathullCuBXCDkEtX+WEp5SEpZAHwFRJdqz0IpZY6UsgiYBERdrJcCLAHihRAG2+MHbG0BGAislFKulFJapJS/AluxBobyvC2lPCelPA38CWySUm6XUhYC32H9EAe4F/jJ9pobgZlYA1oHoB3W13SO7bVYBmwpdY4RwPtSyk1SSrOU8hOgyLbfhYxAcyGEr5QyV0r59yXqrlQDKhAoV2swsEpKmWp7vIRSw0MVYRvC+EIIcVoIkQ18BpQMtTQETkgpTeXs3hzoB0yWUhZf4jT+WL/pljhhe65E2gXnyMf6LbY8Zy9WVgihFUJME0IctbUl0VbG94L9kVIeAfYDfW3BIB7r6wfW4HqPbfglUwiRCdwE1L9Enc6V+r3gIo9L2lPmtZBSWoCTWHsS/sBpKWXpLJSlX7fGwHMX1KshZV/LEg9j7X0cEEJsKT0MplRPN+QdHMq1EUI4AwMArRCi5IPRCfAUQkRJKXdiHQYq7WJpbl+zPR8hpUwXQvQHSq4DnAQaCSEcygkG+4F3gJ+FEN2klAfLqW4y1g+xvbbHjWzPXW8PYA1Mt2ANAh5ABiDKKb8UuB/rl7F9tuAA1nZ/KqV8pBLqmAxElDwQQgisH+ansb4PAUIIUSoYNMLa0yup11Qp5dTLnURKeRi4XwihAe4ElgkhfKSUedevKcr1pHoEytXoD5iBMKxDI9FAC6zDEoNsZc4BTUvtkwJYLnjODetQTJYQIgAYW2rbZuAMME0I4SKE0AshOpauhJRyKfAisFoI0aycui4FXhZC+Nku7E7A2vO43tywDpWkAQasQe5SvgB6Ao/xT28AW936CiF62XoZettF7QbXoY5fAbcLIboLIXTAc7Y6b8Q6rm8CRgkhdEKIO7EOz5X4EBgphGgrrFyEELcLIdwuPIkQYqAQws/W48i0PW25DvVXKokKBMrVGIx1rDxJSnm25Afrt/kHhXWuwOtYP4AzhRBjbGP4U4ENtufaYR2vbwVkAT8B35acQEppBvpiHQJKAk5hHeMuwzZWPQX4XVhvZ73Q/2EdY98F7MZ6IbVCk6Su0GKsQymngX1YL+CWS0p5BuuHbwfgy1LPn8Tas3gRa/A8iTVAXvP/VVuvaSDwNpCK9fXtK6Ustg2v3Yn1Qnw61te69PuxFXgE63ucgfUi85ByTtUb2CuEyAXeAu6zXVNRqilRdkhQURRFudGoHoGiKMoNTgUCRVGUG5wKBIqiKDc4FQgURVFucDVuHoGvr68MDAy8qn2LiopwcnK6fMEaqja3T7Wt5qrN7atJbUtISEiVUvpdbFuNCwSBgYFs3br1qvY9dOgQwcHB17lG1Udtbp9qW81Vm9tXk9omhDhR3jY1NKQoinKDU4FAURTlBqcCgaIoyg2u0q4RCCEWAn2A81LK8ItsF1inn5fkgB8ipdxWWfVRlNrIaDRy6tQpCgsLq7oq5TIajezfv7+qq1EpqmPb9Ho9DRo0QKfTVXifyrxYvAhrXpLF5Wy/FQiy/bQF3rP9qyhKBZ06dQo3NzcCAwOxfreqfgoLC9Hr9ZcvWANVt7ZJKUlLS+PUqVM0adKkwvtV2tCQlHId1uRV5ekHLJZWf2NNYXypnOuKolygsLAQHx+fahsElP+WEAIfH58r7iFW5TWCAKyZFUucsj133ZlMJlJyzuBaT09KzhlMpvLWOlGUmkcFAaW0q/l7qBHzCIQQI7AulYe/vz+HDh2q8L6eXp5kiBRGrR1Ncl4y/i7+zO0yCy/pR2ZG5uUPUIOkpqZevlANpdp2cUajsVpfHwDrF7HqXserVV3bZjQar+hzsioDwWmsqyOVaGB77l+klB8AHwDExsbKK5nAkZJzhlH/swYBgOS8ZEatHc2r7SeydP3L1HWuQ0OPxgTXC6OZfzRevi0QDo5X26YqV1Mmt1wN1bZ/279/f7Uao76YaxlHnzNnDiNGjMBgsC7vfNttt7FkyRI8PT0rtP/y5cvZt28f48aNu6rzX051u0ZQQqfTXdHfVFUGguXAk0KIL7BeJM6yLdZxXRml0R4ESiTnJeOkM7CZc2QXp0DKXkhZCbvBYLFQzyTxtejwFS7UcfKlvlsDmvgEEdwgEjffEBzc6qHRlP/SmUwmMgpSMEojOqHDy9kPB4ca0flSlGplzpw5DBw40B4IVq5ceUX7x8fHEx8ff011MJlMtf7/b2XeProU6AL4CiFOARMBHYCUcj6wEuuto0ew3j46tDLqoRM6/F38ywQDfxd/6jvXYUqbJRxIOsi51D3k5p8k35xGIdnkafI45VDMLl02heRAznHI+RMSwctsxt9kxtekxQdnfBzcqetcnwY+TWlaPwz3Bm04JYovGIqaTTPP4Fr/x6QoFTFr1iwWLlwIwPDhw+nfvz+9e/emdevWbNu2jZYtW7J48WIWLFhAcnIyXbt2xdfXlzVr1thTzOTm5tK7d2/atWvHxo0badOmDUOHDmXixImcP3+ezz//nLi4OBYtWsTWrVuZN28e0dHR9jocPHiQX375hdjYWJ566in27NmD0Whk0qRJ9OvXj0WLFvHtt9+Sm5uL2Wzmjz/+qKqX6z9RaZ9MUsr7L7NdAk9U1vlLeDn7MbfLbEatfbbMB7O3cx26R/jTPSIK6zrsYDQbyS0uJK8wl6y8DE6mpbD7zCmSU49SUHCSAmMahWSRp8njrK6QTF0xZpEKllRI2Y04/z3zfOcxddPrFwxFPctnvT7Gy6UODpfoSShKbZeQkMDHH3/Mpk2bkFLStm1bOnfuzMGDB/noo4/o2LEjw4YN491332XMmDHMmjWLNWvW4Ovr+69jHTlyhK+//pqFCxfSpk0blixZwvr161m+fDmvvfYa33//fZnyO3bsAODHH39k+vTpdOjQgYkTJ9KtWzcWLlxIZmYmcXFx3HLLLQBs27aNXbt24e3tXfkvTBWr9Z9KDg4ONPMM5rNeizBKEzrhUO5QjU6rw8tZh5ezGw286tOyAfSOAou0UGwuptBYRE5RHhl5GWQXpHM2K5VjqSkkZZ4jJ+8MhcYUfPQ+Fx2KSi/KYMcHt9OgbgzeEbegb9oFFxUYlBvM+vXrueOOO3BxcQHgzjvv5M8//6Rhw4Z07NgRgIEDBzJ37lzGjBlzyWM1adKEiIgIAFq2bEn37t0RQhAREUFiYuJF9zl8+DBjx45lzZo16HQ6Vq1axfLly5k5cyZgHfNPSkoCoEePHjdEEIAbIBCANRj4udW/6kyBGqFB76BH76DH09mDhp7+9m1Gs5EicxFF5iKyi3Jx0V58KOpU/llG+5qoU/Q3Xdf9TqdfiggQ9ZENYvBo2R2npl0wuPih01R8NqCi1BYX3vJYkVsgS6d/1mg09scajeait4jn5uYyYMAAPvzwQ+rXt05ZklLyzTffEBISUqbspk2b7MHqRqByDV0jnVaHq6MrPs4+NPFsjLdzHeZ2mY2/izVY2G9X1XjR3acfWocQlrl68mQ9X+73M/Jexlo2r3oO8+wIzr7ZjqNfPMz5XUvJyknGaDFWcesU5frq1KkT33//Pfn5+eTl5fHdd9/RqVMnkpKS+OuvvwBYsmQJN910EwBubm7k5ORcl3MPGzaMoUOH0qlTJ/tzvXr14u2338Y6Ug3bt2+/LueqaW6IHsF/6eJDUb4USyNjOo/kdM4ZzudlsO/cbhLO7mGd2M+vrnkICaGFRm4/vYpbjnyHt0lyxqUJpkYxuIR2w6lpV9VjUGq8Vq1aMWTIEOLi4gDrxWIvLy9CQkJ45513GDZsGGFhYTz22GMAjBgxgt69e+Pv78+aNWuu+rwnTpxg2bJlHDp0yH6hesGCBbzyyis888wzREZGYrFYaNKkCStWrLj2htYwoiQS1hSxsbGyJi9MI6Uk35RPemE65/LOkVmQw9GME+w8v5PdabvINJ0HwKdIT4c8I/fmnyHSWIgZDedcm2BsGINzSBf0zW7BYPBFp9VhMZsx56aAqQgcnNC6+qHRaqu0nddbdXjvKsu1tG3//v20aNHiOtfo+rrcvfaJiYn06dOHPXv2/Ie1uj6q6zyCi/1dCCESpJSxFyuvegT/MSEELjoXXHQuNHBtQL4pnxDf5rT2DyffeCfJOefYnbKPHSnbWeF0lB+966A3O9M8x0Cv/CwG7PsWw/5lmNBw3rUJutYD8A7qiW7ZYMhMAs9GmAYsgbphtS4YKIpSOVQgqEIXCwpNPNNp5tWYW5t1I6soj31pB9h2bjsHHXazx9PEHNkUv4I6hGdruDP3DDfVC0euf5PU296g2OCNY3463uumYb71TTQe9aq6iYpyWYGBgTWyN1CbqEBQTVwsKKQXplPH4E17/9aYzCYOZx4j4dx2dqZuZ7Uhi9/QcE/qJvp1epKxf036Z57ETRNpZi6g0FiAXudc1U1TFKWaU4GgGiovKLg4utDCJ5iB3EtyzlkSzm+na5Ne9iAAtglsf0/m827z0M6JIaPNYDzaPobBuWK5WRRFufGoQFDNlRcUnLRO+LvVo5F7w4tOYMsotiBzNASvnUbexvc4G3UXLjeNxs2jYTlnUhTlRqUCQQ1yYVDIM+aRVZx18QlsxWd5I+BB/JPMjLD8RLstCyne9jkpob1x6jQWt7rhKo+9oiiAmlBWYwkhcHV0pb5LfeZ2m1tmAtuMzjNYfvQHTuu/4FTkdqb6D6d/8RR+LY7GZ+9yXN7vTPonfcg6toaadvuwUj19//33CCE4cODARbd36dKFq73t+0J79+6lW7duhISEEBQUxKuvvnrZv+PExESWLFlif7x161ZGjRp1RecdPnw4+/btu6o6V3cqENRwGqEhyCuIz2//nJ/if+KT3p+AhLuC7uTh8IfJMZ/lhPPbOMUeYEHAcLoVzeJzU3dcEjfjsbg/WfM7krVzKRazWrVNuXpLly7lpptuYunSpZV6noKCAuLj4xk3bhwHDx5k586dbNy4kXffffeS+10YCGJjY5k7d+4VnXvBggWEhYVdVb1LVNfVEVUgqAU0QoOvsy+FKYXUc61HqE8odV3q0qpuK6Z3nk6vwF4cyN1IstssQm86xfKAQXQsmsss092I80l4fDeS/LnRZG6Yg6k4r6qbo9Qwubm5rF+/no8++ogvvvgCsH5g33fffbRo0YIBAwZQUFBgL//YY48RGxtLy5YtmThxov35wMBAxo8fT3R0NLGxsWzbto1evXrRrFkz5s+fD1jTT3Ts2JGePXsCYDAYmDdvHtOmTQNg0qRJPPTQQ7Rv356goCA+/PBDAMaNG8eff/5JdHQ0s2fPZu3atfTp08e+z+DBg+nUqRONGzfm22+/5fnnnyciIoLevXtjNFpTvZT0apYvX050dDTR0dFERkbaF4lPSEigc+fOtG7dml69enHmzBn7fs888wyxsbG89dZblfY+XAt1jaAWctQ6EuQVhJ+zHwczDtK/WX+6NerG4n2L2ZD6NfV9NtKr2V38fewuFiTezh2a9TyR8yP+v06kcP0c8qLvx9DhWXRudaq6KcoVmPzjXvYlZ1/XY4b5uzOxb8tLlvnhhx/o3bs3wcHB+Pj4kJCQwB9//IHBYGD//v1s2bKF9u3b28tPnToVb29vzGYz3bt3Z9euXURGRgLQqFEjduzYwbPPPsuQIUPYsGEDhYWFhIeHM3LkSPbu3Uvr1q3LnL9Zs2bk5uaSnW1t+65du/j777/Jy8sjJiaG22+/nWnTpjFz5kx7+oi1a9eWOcbRo0dZs2YN+/bto3379nzzzTdMnz6dO+64g59++on+/fvby5Ze7Oauu+6iW7duGI1GnnrqKX744Qf8/Pz48ssveemll+zpLIqLi6/b0FhlUIGgFvPUe9KqbitOZZ/CnGvmudbPsTt1N5/t/4wfk+cS1SCWwaHxJBzowc2JXbhFs41nHX4g5K93MW79mKzQPuhvHoOTX2hVN0WpxpYuXcrTTz8NwH333cfSpUs5cuSIfQw+IiLC/kEP8NVXX/HBBx9gMpk4c+YM+/bts28v+YCNiIggNzcXNzc33NzccHJyIjOzYmuM9+vXD2dnZ5ydnenatSubN2++7NKWt956KzqdjoiICMxmM71797bXo7yU1tOnT8fZ2ZknnniCPXv2sGfPHnr06AGA2Wy2ZzgFuPfeeytU96qiAkEtp9PoaOLZBB+DD4fSDxHkGcT0m6fz8/Gf+f7I9+xL38ktIbfSqWVX1u9ry22JsbTiEGMdf6DN7mXIvd+R3fRmHG8ag75xB5AS8lPAVAwOjmDwA40aYawOLvfNvTKkp6fz+++/s3v3boQQmM1mhBDExMRctPzx48eZOXMmW7ZswcvLiyFDhpRZ/L10KukL00ybTCbCwsJYt25dmWMeO3YMV1dX3N3dgWtLaa3RaNDpdPZ9yktpvXr1ar7++mtWrVoFWHOItWzZ0p5B9ULVPaW1+h98g3B3dCemTgyN3BuRZ8yjV2AvZnWZRVy9OH4+sZxlp1+lXfRxxtzujggM4/7csdxSPIPfdR1wOboO/aLbyP9+JPLMdlhwC8wJt/57fh9YLFXdPKWKLFu2jIceeogTJ06QmJjIyZMnadKkCa1bt7ZfnN27dy+7du0CIDs7GxcXFzw8PDh37hw///zzFZ3vwQcfZP369axevRqwXosYNWoUzz//vL3MDz/8QGFhIWlpaaxdu5Y2bdpc13TWJ06c4IknnuDrr7/G2dk6cz8kJISUlBR7IDAajezdu/e6nO+/oHoENxCtRksj90Z46705knmEAgp4PPpxegb2ZNHeRSzc/x4hXiHc1eFBukf48dtuBx5NfBRveR/jPX6if4t+iK+HWJPbgfXfL+6H4avBtW6Vtk2pGkuXLuWFF14o89xdd93F9u3bKSgooEWLFgQHB9vH9aOiooiJiSE0NLTMqmQV5ezszA8//MBTTz3FE088gdls5qGHHuLJJ5+0l4mMjKRr166kpqbyyiuv4O/vj5+fH1qtlqioKIYMGVJuj6UiFi1aRFpaGv3790dKSUBAACtXrmTZsmWMGjWKrKwsTCYTzzzzDC1b/ve9tKuh0lDXIlfSPou0cDb3LMeyj6HT6DDoDKw9uZYvDnxBTnEOXRt25dZGd3IiRctvu/NISDTy12PB1Pmozb+OJZ/Zg/Cs3BnLtfm9u9HTUF9PkyZNwtXV9bLLXF4vKg21UqNphAZ/N3889Z4cyzpGekE6Nze4mbb127Ls0DJWJa7i7zN/c1fQ3TzZswuHzhahdzaAZ6N/egRgTXttMqGTEtRMZUWpkdQ1ghucQWegpU9LQrxDyC3OxWKxMLjlYKbfPJ0gryA+3b+Y1xJeweCRRLbWjbS+n1iDAYBnIyzx89CseJq0P2cijYWXPpmiVLJJkyb9Z72B2kT1CBSEENR1qYuHkwfHs46TUpBCHUMdxsWNY9v5bSzeu5jXN7/O7/XW0dD0IEMeWolGa8Fi1vDz30kMyjqL9+9TSU1OwOO2WTi6+1d1kxRFuQIqECh2egc9od6h+BX4cSTzCBZpoVWdVkT6RrLy+EoOpR+idytHRqwZbl/7YFbnt5iaP4/e+a/Q6cDPZKYeofD22bg37qhuK1WUGkL9T1XKEELga/ClVd1W+Bp8SStMQyLp17wfEzpMYMKGCWXWPhj9x9P0ifPmoaynmKEdhFvacRy/fJAzf7+NuSi3ilujKEpFqECgXJSj1pFgr2CifKMoNheTWZCJVmgvuvZBfU8dg29yZUFRL+43vkKxWUvd1ZNJXvkMBRlJ5ZxBUZTqQgUC5ZJK0lTUd62P2WK2p7su4e/iT05xNnfF+TIu3psTzs3pnPMaB3ShNNz5NdnLBpF6bC1YzFXTAKXSCSEYOHCg/bHJZMLPz8+e1G3FihX2pHDlSU5O5u677waseYA8PDzsSd1uueUWzp8/f8n9d+zYwcqVKy9bV1dX13K3ffDBB4SGhhIaGkpcXBzr16+/7PGWL19eJjX1hAkT7JPdKqJ0u6uSCgTKZek0Opp6NsXX2ZdZXWaVWftg6k1TmbZ5Gl8d+oLYJm68ek99Gjf0oE/WeD5z6Evd09vRf/coiVvfx1hQsVwxSs3i4uLCnj177BlGf/31VwICAuzb+/Tpw7hx4y55DH9/f5YtW2Z/3KlTJ3bs2MGuXbto06YN77zzziX3r2ggKM+KFSt4//33Wb9+PQcOHGD+/Pk88MADnD179pL7/fjjj2UCwZQpU7jlllsqfN4L2301pJRYrnF2vwoESoW5O7kT7BXMwt4LWd5/OR/0/AB3R3fqGOrww9EfmLdjHnU8tYzr50//1nom5t3Hk3I0uvxsGqyaTOLvE8hNPWzNV6TUKrfddhs//fQTYJ1tfP/999u3ffrpp/aZv0OGDGHUqFF06NCBpk2b2j8EExMTCQ8P/9dxpZTk5OTg5eUFwObNm2nfvj0xMTF06NCBgwcPUlxczIQJE/jyyy+Jjo7myy+/JDc3l6FDh9oT3n3zzTf2Y7700ktERUXRrl07zp07B8Abb7zBjBkz8PX1BaBVq1YMHjzYHoACAwPtqanj4uI4cuQIGzdu5KeffmLs2LFER0dz9OhRhgwZYm9TRdJql2738OHD7emt/fz8mDx5MgAzZsygTZs2REZG2tN2JyYmEhISwqBBgwgPD+fkyZPX9P6pu4aUK6LT6ghwDSC7OJs9KXtwcnDi4YiH8TP4sfTAUjIKM3gu9jkG3VyPJnXSWbgmhp75U/ncfTZBWz4hKf042R2eoX7jTggHx6puTu3y8zg4u/v6HrNeBNx66WEdsGYdnTJlCn369GHXrl0MGzaMP//886Jlz5w5Y//mHR8ff9GhkZK1A9LS0nBxceG1114DIDQ0lD///BMHBwdWr17Niy++yDfffMOUKVPYunUr8+bNA+CFF17Aw8OD3butr0dGRgYAeXl5tGvXjqlTp/L888/z4Ycf8vLLL180vXVsbCyffPKJ/XHJ8RYvXswzzzzDihUruP322+nXr1+5wzuXS6td2oIFCwBrLqPevXszZMgQVq1axeHDh9m8eTNSSuLj41m3bh2NGjXi8OHDfPLJJ7Rr1+6y78/lqB6BclXcHd2JqhOF0WykwFRAv+b9GBUzisOZh5mwYQLpRSl0DfNl4t110fv60D1rCr86dqLR0XU4rxzDwe0LKc5LqepmKNdJZGQkiYmJLF26lNtuu+2SZfv3749GoyEsLMz+jfxCJUNDJ0+eZOjQofakcllZWdxzzz2Eh4fz7LPPlpvYbfXq1TzxxBP2xyU9CkdHR/u1i9atW5ebYvpiSno5999/f7lZRi9UOq1227ZtcXNzw8/Pr9y02oWFhdxzzz28/fbbNG7cmFWrVrFq1SpiYmJo1aoVBw4c4PDhwwA0btz4ugQBUD0C5Rq46FyI9ItkV+ou8ox5dAjogJfei5lbZzJhwwTGthlLUP3mvHJPIz79/RQjDozkYedgxqd/guG31ziUfowG0Q/hWSdcpae4Hirwzb0yxcfHM2bMGNauXUtaWlq55Uqnl65IrrP4+HjuuusuAF555RW6du3Kd999R2JiIl26dLmiOpZOMa3Vau0ppsPCwkhISKBbt272sgkJCWWSxpVOZ12R1NZw+bTaFxo5ciR33nmn/TqDlJLx48fz6KOPlimXmJh4XVNbqx6Bck0MOgNRflEIBLnFubTwacGUjlNwcnBiyl9T2Hp2K14ujozo3ZhHOzvyhakLdxVPIt+sI+zvBaSsfY3Ewz9jLs6v6qYo12jYsGFMnDiRiIiI63rc9evX06xZM8DaIyi5EL1o0SJ7mQvTTPfo0aPMBeaSoaHyPP/887zwwgv2ALZjxw4WLVrE448/bi/z5Zdf2v8tWXHN1dX1uqW3fuedd8jJySlzYb1Xr0cjWM0AACAASURBVF4sXLiQ3FzrnJzTp09f9g6qq6ECgXLNnB2cifCNQCu05BbnEuAawJSOU2jo3pA3t77JL8d/Qa/Tcltrf8bHe5Lh2oDOOa+xy7ElQftXYlj7Bnt3LiY/+3RVN0W5Bg0aNLCvSnatSq4RREVF8emnn/Lmm28C1g/s8ePHExMTU+YbddeuXdm3b5/9YvHLL79MRkYG4eHhREVFsWbNmkueLz4+nmHDhtGhQwdCQ0N55JFH+Oyzz8qsMpaRkUFkZCRvvfUWs2fPBuCee+5hxowZxMTEcPTo0Wtq88yZM9m9e7f9gvH8+fPp2bMnDzzwAO3btyciIoK77777ugWe0io1DbUQojfwFqAFFkgpp12wvRHwCeBpKzNOSnnJe8BUGuryVXX7isxF7E3dS7G5GDcnN4rMRby97W22ntvKbU1uY2DYQDRoOJuRx8erT7HhhI4XXb9luOk7CtzrsT96AI2C++Ln3wo02jLHruq2VSaVhrr6CwwMZOvWrfa7ikpU17ZdaRrqSusRCCG0wDvArUAYcL8QIuyCYi8DX0kpY4D7gHcrqz5K5XPSOhHuG47eQU9WYRZOWidGx46md2BvVh5fyZyEORRbiqnn7cKo+GYMbG1iZsGdPGIei8jPIXrj+5xP+JDDB37AWHh9F2FXFKV8lTk0FAcckVIek1IWA18A/S4oIwF32+8eQDJKjeaodaSlb0vcHN3ILMxEIzQMCR/CoLBBbDm7hVf/epXsomxc9A7cdXNzxvZ0YLeuBbfkTuWkpj4tt3+Jc8Iidu7+jJyMY1XdHEUBrBdnL+wN1CaVeddQAFB6lsMpoO0FZSYBq4QQTwEuwEWn5AkhRgAjwDoT79ChQ1dVodTU1Kvar6aoTu1zkA5Y8i0km5PRO+hpp2uHU2MnFiUt4qU/XuLxpo9T16kuIe6ujOss+HQr9EyZxCzXT+hz9Hdc0s6wNdWEm3cIbh6NSEu/9MW+muxa3jej0Vhm8ffqyGQyVfs6Xq3q2jaj0XhFn5NVffvo/cAiKeWbQoj2wKdCiHApZZn50lLKD4APwHqN4FrGimvrOHOJ6tQ+k8XE4YzDpBWk4eXsRfeG3WnUoBHTt0znzaNvMrbNWEK8Q/DGmzGNc/lm7VGePvgwfzsFMSn7Y27aOZPjnZ+jgVcDmvjUwdHZDQx+tTK99bVcI6iOY9SlVddx9OuhurZNp9Nd0d9UZf6POg2UXsi2ge250h4GvgKQUv4F6IHa2/+6wThoHAj2CsbX4Et6QTpSSoK8gni146u4Orryf3//H38n/w2Ah5srD/ZsyTMd8/lJdiC+cDJ5deMIqhuNYel9OL7TGhbcgjy/D64xr4qiKGVVZiDYAgQJIZoIIRyxXgxefkGZJKA7gBCiBdZAoKab1iJajZZgr2DqudSzB4N6LvV4teOrNPVoypxtc/jx6I9IKXFycqBLXBgv36rF4uHL+ZteQyx/8p81kjOTEF/cj1QzkhXluqq0QCClNAFPAv8D9mO9O2ivEGKKECLeVuw54BEhxE5gKTBEVub9rEqV0AgNzTybEeAWQHpBOhZpwc3RjZfavUS7+u34fP/nLNyzELPFjEYrCA1qyvg+3jTy0v0TBEpkJmFRayNXK0IInnvuOfvjmTNnMmnSpCs+TmJiIkuWLLmONSvf999/T2RkJC1atCAiIoLvv//+svusXbuWjRs32h/Pnz+fzz///IrO26FDhyuu63+hUq8R2OYErLzguQmlft8HdKzMOijVg0ZoaOrRFI3QcDL7JF7OXjhqHRnVahR++/348diPpBak8nSrp9E76PGtVx80TuDZqGww8GyEES2ajBMIr8ZV1yDFzsnJiW+//Zbx48df0501JYHggQceqPA+JpMJB4cr+xjbuXMnY8aM4ddff6VJkyYcP36cHj160LRpUyIjI8vdb+3atbi6uto/zEeOHHnFF4pLB5KrZTab0Wq1ly94BWrfVTel2hJCEOgeSKBHIBkFGVikBY3Q8GDYgwwLH8aO8zuY/NdkMgqtdwhlaFzI7PeJNRiA9d/4eZg3f0jSiT8g7bhKaV0NODg4MGLECPts29JSUlK47777aNOmDW3atGHDhg0A/PHHH/YZtDExMfbUCiUzimfPno3ZbGbs2LH2FMzvv/8+YP1A7tSpE/Hx8YSFhVFYWGhPOR0TE2OfRdyuXbsySem6dOnC1q1bmTlzJi+++CJNmjQBoEmTJowfP54ZM2bYyz399NNER0cTHh7O5s2bSUxMZP78+cyePZvo6Gj+/PNPJk2aZG9zly5dePbZZ4mNjaVFixZs2bKFO++8k6CgIF5++WV7HUoWxpkwYYK9/QEBAQwdOhSAzz77jLi4OKKjo3n00Ucxm832/Z577jmioqIqnPDuSlT1XUPKDUYIQSP3RgghOJ51HE8nT7QaLT0De+Lr7Mtb297ilQ2v8ELcCzh56slzacrJW7/F09FCZrEGvxNrqPf3HHIateGsxoF6FiP4BqmkdcAbm9/gQPqB63rMUO9QXoh74bLlnnjiCSIjI+1ZQks8/fTTPPXUU3Tv3p2kpCR69erF/v37mTlzJu+88w4dO3YkNzcXvV7PtGnTmDlzJitWrACsK4Z5eHiwZcsWioqK6NixIz179gRg27Zt7NmzhyZNmvDmm28ihGD37t0cOHCAnj17cujQIe69916++uorJk+ezJkzZzhz5gyxsbHs3buXMWPGlKlnbGxsmdxE+fn57Nixg3Xr1jFs2DD27NnDyJEjcXV1te/722+/lTmGo6MjW7du5a233qJfv34kJCTg7e1Ns2bNePbZZ/Hx8bGXnTJlClOmTCEzM5NOnTrx5JNPsn//fr788ks2bNiATqfj8ccf5/PPP2fQoEHk5eXRtm1be6qN6031CJQq0dCtIc09mpNRmIHZtoxlq7qtmNh+IiaLiYkbJrLtXAI4puFex5diQx00BgNPH2zBfO6gXtIW2LqIjLM7IeWAupOoirm7uzNo0CDmzp1b5vnVq1czevRooqOjiY+PJzs7m9zcXDp27Mjo0aOZO3cumZmZFx3eWbVqFYsXLyY6Opq2bduSlpZmT8EcFxdn/0a/fv16+1KZoaGhNG7cmEOHDjFgwAD7IjFfffXVFS0JWZJy+uabbyY7O/uiKaMvVDrldMuWLalfvz5OTk40bdr0ogvHSCkZOHAgo0ePpnXr1vz2228kJCTQpk0boqOj+e233zh2zDqpUqvV2jOwVgbVI1CqjL+bPxqNhkMZh/Bw8sBB40BTz6a82vFV3tj8Bq9teo0J7SYQWy8Wjc6Mm7OW+yILGX/yDrQ6C48k/cBZjYbcNo/hajFBnbB/5Si6kVTkm3tleuaZZ2jVqpV9mAPAYrHwxx9/4OnpWabsuHHjuP3221m5ciUdO3bkf//737+OJ6Xk7bffplevXmWeX7t2bYVSMAcEBODj48OuXbv48ssv7auClaScjoqKspe9VMrpiz2+mCtNOT1p0iQaNGhgf72klAwePJjXX3/9X2X1ev11vy5QmuoRKFWqnks9wrzDyCrKwmg2AuBn8GNyx8n0adIHfzd/Hln1CPE/xvPIqkcICfZnam89M41385GIp17iX+RteZ/CjETr6lzmf/+HU/4b3t7eDBgwgI8++sj+XM+ePXn33X9SiO3YsQOAo0ePEhERwQsvvECbNm04cODAv1JJ9+rVi/feew+j0fp3cejQIfLy8v513k6dOtnv3jl06BBJSUmEhIQAcO+99zJ9+nSysrLsF4LHjBnD66+/bl+UJjExkddee63MnU8lKafXr1+Ph4cHHh4e/6rftfjxxx9ZvXp1mR5U9+7dWbZsmT3NdHp6OidOnLgu57scFQiUKudr8KWlT0uyi7MpNhcD1kVvRkSNYOKGiSTnWVNQJecl8+za0bSJDOXJtjm8UXQPi0Rf6iZuIGfL+xhzzkLydjAVV2VzbmjPPfdcmZQZc+fOZdu2bURGRhIWFmb/Vj5nzhzCw8OJjIxEp9Nx6623EhkZiVarJSoqitmzZzN8+HDCwsJo1aoV4eHhPProoxf9Zv34449jsViIiIjg3nvvZdGiRfZv5HfffTdffPEFAwYMsJePjo7mjTfeoG/fvoSGhtK3b1+mT59OdHS0vYxerycmJoaRI0faA1vfvn357rvv7BeLr8WsWbM4ffq0/cLwhAkTCAsL4//+7//o2bMnkZGR9OjRgzNnzlzTeSqqUtNQVwaVhrp8Nb19GQUZ7Enfg6vOFUetI646V/p81+df5VbcsYLM/HR+27iH97Z68Ir+CwZZfiKtWRc82z6JVu8G/jHg4HSRs1Q/Kg119dKlSxdmzpxJbOxFMzaXUV3bVm3SUCvKlfJy9iLSN5J8Yz5F5iIEAn8X/zJl/F38EQgcdI50bx/OiFbZTC64n881t+FzdC05W95DFufDqa1gLKiilihKzaICgVKteDh5EOEXQYGxgFxjLrO7zrYHA38XfyZ3nMyulF0AODg60qNDC4bHZDCh4AGWam/F8/Bv5G6eDxYTnNwCxf8eU1aUS1m7dm2FegO1ibprSKl23B3difKLYnfqbtyd3Pmw54eYTWY0Dhre3f4uvyb9ykvtXiLUOxSdk57eHVtiNu/lpV0PojFI7j30C/kaBwxtR1qDQUAr0Ltf/sQ1lJSywoupK7Xf1Qz3qx6BUi25OroS5RdFTnEO5/LPcSrpFLnGXPoH98fP2Y8ZW2ZwMtt6b7ajXs+tnVowKDydcXkDWebQE8OBnyja/CFoHeDUFii4/H3gNZFeryctLe2q/vMrtY+UkrS0tCu+bqF6BEq1ZdAZiPSNZHfqbvvdRO6O7oxvO54JGybw+ubXmdJxCr7OvuidDfS9uQUm837G7huExtXCnfuXUyw0OLZ91BoMAlqDwbuKW3V9NWjQgFOnTpGSUn0zshqNRnQ6XVVXo1JUx7bp9XoaNGhwRfuoQKBUawadgSi/KDYmbyTfmI9BZ8DP4Me4tuOYvHEyr296nckdJuPq6Ire4EK/ziGYLAcZfWAoWjdJv33fYxJaHOIesV5A9o8G1zpV3azrRqfT2WfYVlc1/W62S6ktbVNDQ0q1p3fQU9dQF7PFTKHJmu2xsXtjxrQZw/n880zfMt3eYzC4unFH52DuDk7j6ZxhLNd1w2HvN5i3fgR6D+s8gyy1NLailKYCgVIj6LQ6Wvq2pNBUaP/QD/MJ48mYJzmccZi3tr1lz1nk6u7O3V2C6N88jVE5D7PCsQva3V9j2boQnL3g3O5/r3OgKDcwFQiUGsPN0Y2WPi3JKcrBZLHOMG1bvy1Dw4eScC6Bj3Z/ZL9o6ubhwYAuTenTNI0nsx9hpWNnNLu+QG792BoMzu9XaawVxUZdI1BqFE+9J6E+oexP24+3szcaoaFnYE8yijL47vB3eOm9uCfkHgA8vLy5r4vEbEnkicRHmO9uodfOJUihQcQOhbRDoNJYK4oKBErNU8dQB6PZyNGso3jpvdAIDQOCB5BZmMk3h7/BU+9Jj8Y9APDy8eG+LhZMvycxMulRPvCQ9NjxGRKswSDjOEgz+IaARnWQlRuTCgRKjRTgFkCxpZiTOSfx1nsjhGB4xHCyirJYuHshHo4exNWPA8DXz48HOpswrznDiFMjWeAp6b7jM6RGi2g9BDJPWWci3+BprJUbl/oKpNRYge6B1HOpR2ahdbKYVqPl6dZP09yrOW9vf5v9afvtZevUq88DnevSKSCb4ZmPsVbfAbHtE2TCJ+DqCzlnVRpr5YalAoFSYwkhaObRDE+9J1mFWQA4aZ14vs3z+Bmss4+Tsv+5O6h+/QAG3uxDB/9shmY+zp/O7RHbFlmDgYsv5KfBmR0qjbVyw1GBQKnRtBotId4hGHQGcoqti4a4ObrxYtsXcdI6MW3zNFILbPnxBQQENGTgzZ60rZfD4Iwn2Ghoj0j4GJmw2DrruDAbkreBqagKW6Uo/y0VCJQaT6fR0cKnBQ7CgXxjPgC+zr6MbzueQlMhr216zR4kENAwIJBBN3nQum4uA9OfYJOhHSJhIXLbZ2DwAlOhLRionoFyY1CBQKkVnLROhPmElZl93Mi9EWPbjCUlP4XpW6ZTZLZ+yxcaaNg4kEEdXYjyy+P+9CfZ6tIOsXUB8tg68GwEBh/IPqWuGSg3BBUIlFrDoDMQ7hteZvZxC58WPBXzFEcyjvBWwj+zjzUaaBzYlCEd9YT75jMg7UkONR+M8I+Gxf1gXhvrv+f2qGCg1HoqECi1iqujq3X2cfE/s4/j6scxLGIY285vY8HuBfbZx1qtILBpc4Z0dKCFTz65MY/D8if/ST+RmQRfPQTZp9UMZKVWU4FAqXU89Z608G5BZmEmFmkBoEfjHtwZdCdrTq7hq0Nf2cs6aAXNmgYztL2Gxh6af+cgykxCmo0qN5FSq6lAoNRKfgY/mns2J6Mgwx4M7gm+h24Nu/Hd4e9YlbjKXtbBQUPzoBCcDc7W6wOleTbCpHWGlAOQfea/bIKi/GdUIFBqrQC3ABq6NySjMMO+nOPDEQ/Tum5rPt7zMX8n/20vq3PQkik8SOv7yT/BwLMRlvh55GScs95aenYX5KVVUWsUpfKoQKDUahebfTyq1SiCvIKYt2Me+9L22csaMfPiBhMJPb7m5ODN7OrxBRm/z8Xj67sh99w/6xnYJq8pSm2hAoFSq5XMPvbSe/1r9nFdQ11mbJnBiewTABhFOk92b87TK5Lp9P4RHl9xjqRWz2MxGTGvGAvFeeBogNPbrb8rSi2hAoFS62k1WoK9g8vMPnZ1dGV82/E4OzgzbdM0UvJTKDIX4uySwecjYvj9uY68c28QU/8u5hnxHOSnYlr5gvXuIa3WGgzU7GOllrhsIBBC9BVCqICh1Gg6jY4wnzAchAN5Ruu3eV9nX8bHjafYUszrm14npziHInMhuZZkCjSnSTcnE+Z1jJXZzZnm/AzajKOY/vcyaJ1AmuDMTjAbq7hlinLtKvIBfy9wWAgxXQgReiUHF0L0FkIcFEIcEUKMK6fMACHEPiHEXiHEkis5vqJcCUetI2E+YVgsFvvs44buDRkTO4aUghSmb55ufx6gjocr7aKb0zckjQ/TolnkPhKHM9sw/f4aOLlBUQ6c2wu2SWqKUlNdNhBIKQcCMcBRYJEQ4i8hxAghhNul9hNCaIF3gFuBMOB+IUTYBWWCgPFARyllS+CZq2uGolRMebOPR7UaxZHMI/x49EfcdG646lxxc3QjqG5durZuws2N05l87iZWeT+Iw/E1mNbPsy55mZcCKQfVhDOlRqvQkI+UMhtYBnwB1AfuALYJIZ66xG5xwBEp5TEpZbFt334XlHkEeEdKmWE7z/krrL+iXLGLzT5uU68NL7Z9kd5NevPIqkfo810fHln1CEZZTIuA+vSO9SeqbhYjkm9ju8/tOOz/FtP2JdacRFknIe1oFbdKUa5eRa4RxAshvgPWAjogTkp5KxAFPHeJXQOAk6Uen7I9V1owECyE2CCE+FsI0ftKKq8oV8tT70mYdxhZhVn2CWcd/DswccNEkvOSAUjOS+bZNc9i0DkRFOBL//a+NPXM557k+zju1QmHrR9iOviLdS2D9GNq9rFSY1Vkqcq7gNlSynWln5RS5gshHr4O5w8CugANgHVCiAgpZWbpQkKIEcAIAH9/fw4dOnRVJ0tNTb2mylZ3tbl9ldU2Q5GB5LPJODs4Y2hssAeBEsl5yZhNZgrPZ9NA48jAKD0fbLEQf344q7wyqbduBkkFjhTWaQUpu8E9FZxcr6gOtfl9g9rdvtrStooEgkmAfW69EMIZqCulTJRS/naJ/U4DDUs9bmB7rrRTwCYppRE4LoQ4hDUwbCldSEr5AfABQGxsrAwODq5AtS/uWvatCWpz+yqrbYlZiSTlJKF10OLv4l8mGPi7+KN10OLd0BsAjY8bd+uS+OxPDffmPsMK16k02DYdy+2zcGgUDIVpEBBonYl8BWrz+wa1u321oW0VuUbwNWAp9dhse+5ytgBBQogmQghH4D5g+QVlvsfaG0AI4Yt1qOhYBY6tKNdNY/fG1HepT1pBGrO7zsbfxR+wBoEpHadwLOufP8l6HnpaNAzg7rbFpJicGFw0liJHL8TP4zBnJVvvJkrebr2jSFFqiIoEAgfbxV4AbL87Xm4nKaUJeBL4H7Af+EpKuVcIMUUIEW8r9j8gTQixD1gDjJVSqmQuyn9KCEFTj6Y4ah0xmo182PNDVtyxgvk95rN472JeWv8SZ/PO2gpDQy8DoQ0D6N86n1257jyrHYdZaJA/jcFSkA0Oeji9DYrzq7ZhilJBFQkEKaU+uBFC9AMqNDAmpVwppQyWUjaTUk61PTdBSrnc9ruUUo6WUoZJKSOklF9cTSMU5VqVzD6WSJLzksk15pJvyqd/UH+klEzbNI3somxrWa2gWR03wgLr0zeqgF9S6/C6yzhEcQ6mn8YgLWYQwtozUMtdKjVARQLBSOBFIUSSEOIk8ALwaOVWS1H+exebfezv6s/YuLGkFaaVWe7S0UFDSF0Pwpv50LNFER+faczHvmNxyDlN8crxoHUEc7Ft9rFa4Uyp3ioyoeyolLId1klhLaSUHaSURyq/aory33PUOtLStyUWaSHfaB3aCfYKZlSrURzNPMrcbXPtt5u6ODkQWseL6GA97QPN/N+JFqz0fwqn1D0Urppsm32cbZt9bLnUaRWlSlVoQpkQ4nbgcWC0EGKCEGJC5VZLUaqOs4Mzkb6RmCwme8qJNvXaMCR8CAnnEvh4z8f25S69XB0JqlOHDpGCiHow6mgsmxo+jP7URgrWvmmdfZx7HlLV7GOl+qrIhLL5WPMNPQUI4B6gcSXXS1GqlEFnIMI3gkJToX04qFdgL/o268uvJ35l+dF/boCr7+5MY08/urc2E+ilYdCxbhwKuBPnIysp2LQQXHwgIwnSE6uoNYpyaRXpEXSQUg4CMqSUk4H2WG/zVJRazdXRlQi/CPKN+fa8RPeH3k9H/44sPbCUP0/9CYDQQGNfV+q7e9GnncRTr2HAyTtJrtcN512fUrDrB3D1hdRDkHXhVBpFqXoVCQQl6RjzhRD+gBFrviFFqfXcHd2J8I0gtzgXo9mIRmgYGTWSlj4tmb9zPrtTdwPgoBUE1fXEy9WZAZ20WNBy3/nBZPi2Rr9pLgWH14GLN5zbA7kpVdwqRSmrIoHgRyGEJzAD2AYkAipdtHLD8HDyIMwnjOyibEwWEzqtjtGxo/F39WfW1ln2Fc6cdBrC6vng4mxh0M3OnC3SMSz3cfI8gnBaN5XCU7vB2ROSd0BB5mXOqij/nUsGAtuCNL9JKTOllN9gvTYQKqVUF4uVG4qPsw9hPmFkFWVhtphx0bkwLm6cfYWz1ALr1BpXvQMt6tZF75LL0Js82ZHpzHPyWYqd6+Kw+iUKU0+A3hWSt0FRbhW3SlGsLhkIpJQWrGsKlDwuklKqlbuVG5KvwZdgr2AyCjOwSAs+zj6MixtHobmQaZun/bPymZsTzXzq4uaVzoPtfPnfeXemuTyP1OrR/vICRbnp1nkGyTvAWHiZsypK5avI0NBvQoi7hBCi0mujKNVcPZd6NPdsTkaBNRg0cm/EmNgxnMk9w8wtMzHalq5s6OVCfTdvGtRPpU+EN4uSfFlU5wWEuQh+GkuxsRikGc5sVyucKVWuIoHgUaxJ5oqEENlCiBwhRHYl10tRqq0AtwACPQJJL0jHIi209G3JY9GPsT99P+/tfA+LtCA00NzXA4POmdaheXRs6sHUww35udEYdAXnMf/0AkbhAMUFkHtOBQOlSlVkZrGblFIjpXSUUrrbHrv/F5VTlOqqoVtDGrs3JqMgAyklNwXcxAOhD7AxeSNL9lvvpXBwELSs70uxuZg+cRpa1ndl9IEQNjUbhT7zCMZtS5BejWnSsL51URuVikKpIpddj0AIcfPFnr9woRpFuZEIIWjs3hiLtHAq9xTeem/6NutLakEqK46twMfZh1ub3IreUUuUfwBbTiYxtHND3vrFxPD9rVjRcTJNQqLg0/7oMpPAsxEM+BTqhoO2IsuEKMr1U5G/uLGlftdjXYs4AehWKTVSlBpCCEGgRyAmaeJc3jm8nb0ZEj6EjMIMFu9djI/eh7j6cbg5OxBWtx77ziXxbK8QXl2eSE5gT1h+zz/LW2YmwVcPwaAfrUFBU6HsL4pyXVRkaKhvqZ8eQDiQUflVU5TqTyM0NPdsjp/Bj4zCDDRCw1OtnqK5V3Pe3v42B9MPAlDP3UCglw9niw4z7vbmeDuLf69xnJlkzViaelAlqVP+U1fzteMU0OJ6V0RRaiqN0BDkGYSXkxeZBZk4ah0Z22YsPs4+zNgyg9O5p0FAoI8nXgZX8kUiBmeD9Zt/aZ6NkA6OkHVSJalT/lMVSTr3thBiru1nHvAn1hnGiqLYaDVaQrxDcHdyJ7swG3dHd8bHjUcrtEzbNI3Mwkw0GmhR1weLNJKldSGz3yf/BAPPRhA/j/w9v4DB19o7SD2sgoHyn6hIj2Dr/7d33+FRldkDx7/vtHTSE5gUagpJCL0tSEdBFFgE27IuLMjqCoqubS2gqOsPcS0o61p2BQUUUVRQVECKonRCQg8hlBRKEpJAQnre3x83sKhRAiQZMjmf58njzJ07d85xgJP3vveeF2NOYBuwAXhEaz22TqMSogGymCxE+0fjZnXjdMlpgj2Cebjbw5wuPc3MLTMpKi/CajHRPsROcblm/PJCtg1eTNqfNrNt8GJWrViGx7ePULTxP0YxyD0EOQelGIg6V5PJ4o+BYq11BYBSyqyUctday4KsQvyM1WQl1j+Wndk7KSgtoLVPa6Z2msqsrbN4ZdsrPNT1IdxsFmwasgrKuOn9g+ffG+YzhB5RuXjunE+JApdu4+HUQWPZS//WDsxKOLsa3VkMuF3w3A1YVTfhCNHwWc1WYgNiMSszBaUFdAzuyMR2E0nMSuSd0z678QAAIABJREFUne+gtUZb8pjzh/aE+hp/tUJ93fi/0R1Y4T+WvNCBuCTNp3TLu+DuD9kpkHPIwVkJZ1aTEYGr1vp8dyytdYFSyr0OYxKiwXMxuxAXEEdiViJny84yIHwAOUU5fHLgE/xd/RkTNQYPjzzeGReHqjRjs7owZ3UKSxLO8mzXsQwFfBPnUwZYu4yDnGTjklJfWRNK1L6aFIJCpVQnrfV2AKVUZ6CobsMSouFztbjSLqAdSdlJFJUXMTpyNDnFVcXAzZ8B4QOoUEXs2X+YSh9fbuocQUJaHk9vU3j1HEsvDX6J8ylHY+kyHk7uM04T/fxqIyGuUE1ODU0FFiulvldKrQcWAZPrNiwhnMO5JS9Ly0spqShhYruJtA9szzs73yHhZAJms6JZkyYUVeSTVnCY6TfE4Ofpwt83u7EjbCw5IQOwJC6gYutccPc1ioGsciZqWU1uKNsCRAN3A3cBbbXW2+o6MCGchYfVg3aBxvrHlbqSqZ2nEu4VzsrDK7GZbIS3CGNQmzhslhJySjOYMSIOm8XCQ5s9SG55B9khAzEnzqdy61xjYZsTuyE/09FpCSdSk/sI7gE8tNa7tNa7AE+l1F/rPjQhnIeXzYu4gDgKygowKzMzes3gng73MPnbyQxfNpxJK+8kItgPbSqglCyeHh5LcYXmwS2epLW5gyz7QEyJC6jcOq+qGOyCM8cdnZZwEjU5NXSn1vr8unpa61zgzroLSQjn5O3iTZxfHGdKz+Dv6s+TPzxJZqHxm31mYSYPrH2ATqHhHD2TiotrAU8OiyGroJyHtzfhRPS5YjAfvW2uUQyOJULBSccmJZxCTQqB+cJFaZRSZsBWdyEJ4bx83XyJ8YuhXJefLwLnZBZmohS0DwnhQN5+gn3KeWRIFAezi3g80ZfstneQZR+A2rEAvfVdcPWBzAQoyHJQNsJZ1KQQfA0sUkoNVEoNBD4AvqrbsIRwXgHuAbiZ3bB72H+y3e5hp6KyAm83V9rbm7Ln1F4im1m5d0AEiRkFPLc3gFOx48gKGYhKXAjb54Krt1EMCrMdk4xwCjUpBI8AqzEmiu8CdvLTG8yEEJco2COYV/q/cr4Y2D3szOg1gxe3vsjxwuP4ergT29SfXdk76d7ak/G/a8H61HxmH2xKXsyfOGkfCDsWwra54OIFGdvh7CnHJiUarIveR6C1rlRKbQJaAzcDAcAndR2YEM7MpExE+UXx7pB3KSopwmq1cuT0EXac3MHunN080eMJ7F52yisr2Jm1kyFx7ckvKmNJQgY+7qGMbzceBQQmfmAcsNOfIGMbhHYBN1+H5iYanl8dESilIpVS05VS+4DXgKMAWuv+WuvX6ytAIZyVSZmwe9rJycjhcP5hvF28ebLnk5RXlvP0hqdJP5NOM28fQv3cSMrZzW3d7AyMDmLB1uMsyWlObtx4suwDIfED2D4PbJ6Qvg2K8i7+4UJc4LdODe3DWIXsBq11b631a4CssC1ELfNx9SHSL5K8kjyaeTRjWs9pKBQzNszgyOkjNPfzJ7iJiV05e7mrb0u6tvDljfVprC5qQ067CWSHVBWDbXPB5g4ZW6E439FpiQbktwrBKOAYsEYp9XbVRLH6jf2FEJepqUdTYv1jKSgrIMAtgGk9p2ExWXhmwzMcyj9E64AgvN3L2Xcqmb8NjqBtsya8+O0htlZEkhUz0SgGSR/CtnlgcTNOExWfdnRaooH41UKgtf5Ma30rxl3FazBaTQQppd5QSl1bXwEK0Vj4u/nTPrA9pRWl+Lj4ML3ndFwtrjy78VlSclOICmqKq2sBqfmHeXxoNKG+bjz3zUH2WaM5ETORU6FVxWD7PDDbjGJQUnDxDxaNXk1aTBRqrRdqrW8EQoEEjCuJLkopNUQptV8plaKUevQ39rtJKaWVUl1qHLkQTsjL5kX7wPYoFO4Wd6b3nI6H1YPnNj3H/tz9tA2yY7KeIv1sOtNvjMHL1cL05QdI94glo+1EcsMGQ9IioxiYrJC+FUoLHZ2WuMpd0prFWutcrfVbWuuBF9u36sazOcBQIAa4TSkVU81+XsB9wKZLiUUIZ+VudSc+MB5XiytWk5Wnej6Fj4sP/9j0D/ac2kNMsJ1y0wlyS7J4ZkQcSime/PIAOT7xHI36M3lhgyHpI0iYByazFANxUZezeH1NdQNStNapWutS4ENgRDX7PQPMBIrrMBYhGhSb2UZcQBx+rn4ATOsxjUC3QGZunsmeU7uJC7ZTqNMo0fk8dWMsZ4rLmfblAc4GdiA1cgL5zauKwfb3jNbVGduhVBYVFNWryXoElysESLvgeTrQ/cIdlFKdgDCt9ZdKqYd+7UBKqUnAJAC73U5ycvJlBZSd7dx3Xzpzfo01N5M2YSm2cLr0NJPDJzM7dTYzN89kUotJtPWI4UTeATzM/tzXw48Xf8hi2tLdPNIriHz7ONqWQ9OdH3GqsITsyNvh5HpoEgJmaz1m13i/u4akLgvBb1JKmYCXgHEX21dr/RbwFkCXLl10ZGTkZX/ulby3IXDm/Bprblpr0s6kcej0IZ60P8kLW17gzcNvcn/n+2lrj2Pf8WxaB0bzoIc/M7/ex78TS3jsuq6keVjxsJrwS/0cPw8bdBgL5jwI6QxW13rMrvF+dw1FXZ4aygDCLngeWrXtHC8gDlirlDoM9ACWyoSxED+llCK8STjRvtFUVlbycNeHaeHdgpe3vczO7B1EBvlxrCiZqGau3N2vNVuP5PL6uqNYQjuyr80Ezra6DnYuhsPrwTMI8tPgzDGorHR0auIqUZeFYAsQoZRqqZSyAbcCS8+9qLXO11oHaK1baK1bABuB4VrrrXUYkxANVrBHMO0C2oGGB7s8SBufNsxOmE1iznZaB3qSfnY/PVp584fu4azef5L3NmViDe3MrpYTKe46BVpeA/NHwetd4D/XGgvcSDEQ1GEh0FqXYyxp+Q2wF/hIa71bKTVDKTW8rj5XCGfm6+ZLh6AOWEwW7u10L9F+0cxJmENidgLh/i6kFx5gaFwgN7RrxqcJGXyedAJbWCfKOt4BSydD3lHjQHlHYdHtxshANHp1OSJAa71cax2ptW6ttX6uats0rfXSavbtJ6MBIS7O0+ZJ+8D2uFvcubv93cQFxPHvxH+TmL2NYF9IK0zltu6h9IkI4N0fD7Mm+RQ2m+1/ReCcvKPGZaV5R0FrxyQjrgp1WgiEEHXDzeJGfGA8fq5+TGo3ifaB7Xl759sk5mzF37uE9IIj3NWnFR3DfHhtzQHySk3gE/7Tg/iEQ2U5nNwLWclymqgRk0IgRANlM9uI8Y+hqWdTxsWNo0twF97d9S47srbg41VARmEaD1wbSZsgT6YsTaN49Pz/FQOfcBgxB5Y/CNkpkHcEjidBRZljkxIOIYVAiAbMYrIQ6RtJyyYt+WPbP9KtaTfe3/s+W7N+xNMzj5Nnj/P3IW3JyCvhuc1QdMc3lN2bRPEdX1NUWmGsebzicUhZYaxylrEVyoocnZaoZw67j0AIUTtMykRL75a4mF34Q/QfsJgsfLj/Q8oqy+gc0Iv8Ygsvjo5HKxj8dhLpuUWE+rrxr9s70nzwP/HeOAs2vw05qdD9Lji6CUI6gWsTR6cm6okUAiGcgFKKEK8QbGYbJpMJkzLxyYFPKKsso0dQf/y9mvHnudtJzzV+20/PLeKvCxOYO64LxV0fJtg7zFjTID8NBjwBaZugWQfwDHRwZqI+SCEQwokEugfS0dwRszJjVmaWHlxKWWUZUd4dzxeBc9JzizCbTOxRbSiNnUiodyhqw2uw7D4YON24kigo+peTzMLpSCEQwsl4u3jTKbgTZpMZkzLx1aGvMONGiG8fMnL/19sx1NeN3LNl+Hq6ceBsGKXNR9PSsymm71+A5Q9B7/uNYlBaBAERYJIpRWclhUAIJ+Rh9aBTUCdcTC6YlZkvDi1hfP9gOvldh7sLnC2BADc/nvxsD74eNu7p15q0El9KAwYTMSQQy/ez4LsXoN0YiB0N5UUQHFvvDetE/ZBCIISTcrW4Eh8Yz3jTeFp4t6B7s05M/+GvZBZmYvew83K/VxkcE8QL3yRzPL+Yx65vy8lyV0rduxFz3UysG2cbPYpyD0PPKVBeDM3ag9XN0amJWiZjPSGcmNVsJTYgllFtRjH9h+lkFmYCkFmYyf1r72Noey8evi6KlJMF/G3xDs4UlXO63ExiZQQlfadBt79AZgKseAxyDkLaZlkL2QlJIRDCyZlNZswm8/kicE5mYSbaVEqMvQn/+H0cpeWVPPxJEgdPFlKqFQlFQZztPhkGTIOSM8a8wbEEoxgUOkcffmGQQiBEI2Az27B72H+yze5h52z5GVxcTuPnaWPmTfE0beLKjC92s2Z/FgDbTrlxOm4sXP+S0cJ65VNw4Gtj+cuf9y4SDZYUAiEaAT9XP2YPmH2+GNg97Dzb61me3/QPlqX9Fy/PU1jMMP3GGLq19OPt71OZt+EIFqXYfqKCU+GDYfhrEN7DuPlsy9uQmSg9ipyETBYL0QiYlIkI3wgWDFtAaUUpFpOFEwUnsJltLEtdRtqZNP7SbgqUNOfuvq0J8XHnk+3pZOYV8cDgKHYcLyauaSeChr0CP7wESYsgPx163W+0pAiOkSuKGjAZEQjRSJiUiQC3AOyedoLcg4gJiOHJ7k8yKmIUiVmJzNj0BKf0Fpq4wbD4pkwZ0Ibdmad57NOdFJVUsOt4Aem2cBj0NFzzkHE10YrH4OgGyNgGZcUXjUFcnaQQCNFImU1mWvm2YkqHKdzX6T7OlJ7h2c0z2Jz7Kc18oGOYD9NujOF0cRmPLNlJRm4RycfPkFrihf7dZBg6C5QZVj4ByV8bbSnkiqIGSQqBEI1cgHsAt0XfxoxeMwh0C+T1Ha8zN/klwgLKaRngwYzhsfi6W3lq2R62HcnlcM5ZkvNNVLa7GUa9Bf4RsP5l2D4PjvwoVxQ1QFIIhBC4W90ZEDaAWX1n0b1pd5YfWs60TQ/SpEkWYX5u/P36aOJDvZmz9iCfJ2SQfqqIvVkllDe/Bkb9ByKug12fwPf/hEPfQ16ao1MSl0AKgRACME4VxfjH8Hzv57kl8hb2ntrL/esmk0sCLQPduKdfa4a1a8rniZm8se4gabln2Zl5htKAaBg+G7reacwVrHwSDqySK4oaECkEQoifCPQI5IEuD/BI10coqSjh7+sf5YeTnxDV1J3RncOY0LsF24/m8vzyfRzOLiQpLY9i10AYOA2ufQ6K8415g7RNkHeElr4WKDghReEqJpePCiF+wd3qzpioMbTybsWzm57l1YRXOZB3gKkdH8XN1hR/TxfmrE7h6WV7mDoogtLKStqH+uDR9c/g2xwSFhjtq98bjjXvqPH41g8gKEa6mF6F5BsRQlTLYrLQ3d6dfw38F71DerP80HKmrr2LQN8C+kQE8viwaFytZp79ci8/puSw/Ugup8tNEDkErnsWlk7+393HeUfhw9ug8KRjkxLVkkIghPhNYU3CeLHvi4yLGcf+3P1MWPEn8vUuercJ5LHr2xLV1IvX16TwaUIGWw+fIudsGZgsv2xBkXfU6FlUnO+YRMSvkkIghLgoD6sH93a+l2d6PUN5ZTlT1kxh9bHF9Grjx4PXRtI/KoglCRm8/d0hNh/OoRTrL1c28wk3isHOjyE7BSrKHZOM+AWZIxBC1IjVZOWGVjfQ2qc1j33/GP/c9k/25+7n4c5P4OXaiuAmLizaksbJM8W4XB9F31sWYl50u/GPv0843PQOrHoW0n6E2FHQ4Q9g7wBuPo5OrdGTEYEQosaUUsT4x/Dude8yMGwgX6R+wV++HU8z/1L+3LsFUwa0ISOviAc/3sWPpwMpGbeCsilJlI1fSWVQPFxzP4T1gJ0fwbIpsP09GR1cBaQQCCEuma+bL7P6zmJyh8kcyDvAbV/ewmmdzO3dwnlsaFvahTTBZLYw8M29RMzaRf9/72H/qTIqW/aD0f811jgoOwsrp8GKx+HgGijKc3RajZYUAiHEZbGarUyKn8QrfV8B4M6Vd7Iq8xN+3ymEJ4bF8MgnSaTnFgGQnlvEne9tJedsKXgFw++mwO0fQdRQSP4GPvsLbJgjowMHkUIghLhsSin6hvfl/evfp7V3a2ZumcnzW6ZjsVSeLwLnpOcWUVBcTmFJOVhsENIZRv4Lhv0TrB7w3QuwdIrRwE5GB/VKJouFEFeseZPmvD/0fZ7e8DTLUpeRmneEQXETublLKD4eJvIKK/l4Sy5puUWsT8mmT0QgoX7umN18ofM4aNHH6FO0azF8mgQd/whdJoBfSzDLP1N1Tf4PCyFqhZvVjeeveZ64gDhWHl7JpIEePPnDZDILM7F72Hlp6Kt8sD6TDzZnMDgmmNu6htEhzBdvdysERsCwFyHyWlj3Amx6Aw6vh9/dB5GD5cqiOiaFQAhRa5RSjI0ZyzWh1zBpxSQyCzMByCzM5IG19zGn/7sczSnm613H2XzoFLd0DWVkBzstA7ywuXhC7O8hrDv8+JrR1nrpX6HdGOg5BQIiZHRQR2SOQAhR66wm6/kicE5mYSZuNph+YyyPX98WL1cLb6xN5W+Lk1i6I4OTp4vRAN4hMPhpuOUDaNYediww2lMkzJe5gzoihUAIUetsZht2D/tPttk97KTmH+RQ0UZu7RbGyzd34PZu4aRmFfLokp0888Ueth09RVFpBVhcoE0/48qifo9BUS58eb/RvygzSa4sqmV1WgiUUkOUUvuVUilKqUeref0BpdQepVSSUupbpVTzuoxHCFE//Fz9mD1g9vliYPewM6vvLD7c9yH3r72fu74dh9ntKPcPjuCF0fF0beHLsqRj3D0/gTe/O0h67lkqKzW4+8E1f4M7PodW/WHvMlg4Gja+YRQHUSvqrBAopczAHGAoEAPcppSK+dluCUAXrXU88DHwQl3FI4SoPyZlIsI3ggXDFvDl8C9ZMGwBcQFx/F+f/2N87HhS81MZ+9VYnt3yCDFhZfxjVDsevi4Km1nxyqoDTF6YwNe7jnG6uMyYF7B3gJvnwfUvgjIZ6x0sHgdpm2V0UAvqckTQDUjRWqdqrUuBD4ERF+6gtV6jtT5b9XQjEFqH8Qgh6pFJmQhwC6A4q5gAtwBMyoSXzYsHujzAkhFLuKHVDXyf8T2jlo1gQcorjOzsy+zbOjKmcwh7j51m6qJEnvp8F3szT1NWUQkuXsYlpeO+hLibjCUx598E62YacwcFJ4wlMmURnEtWl1PwIcCFC5emA91/Y/8JwFfVvaCUmgRMArDb7SQnJ19WQNnZzr2otjPnJ7k1XL+W37igcQzyHMTCowv5aP9HLE1Zyij7KEZHDqGzXwCLdp5mSUImPySf4PZ4H/q29sbdZjbeHPsgNr++NN3xCq6pq6ls1Q/TZ3edb3BXPmY+meXeFJeUOiS3huaquBZLKTUW6AL0re51rfVbwFsAXbp00ZGRkZf9WVfy3obAmfOT3BquX8sviij6tu/Lj5k/MmfHHBakLWBF9gruaT+Fl+IHsSzpOAs2HuHlDTmsP1bJlAFt6NbSH1erGdrGQNehkHsY05IJP1kEx7J4LOETV4FnC4fl1pDU5amhDCDsguehVdt+Qik1CHgcGK61LqnDeIQQVyGLyUKf0D7MGzKPaT2nYTPbeGrjNB748Q7atTnBG2M7MbKDnR1peUx6fxszlu0mPacQrTV4BUGTptUvglNaCJUVjkmqganLQrAFiFBKtVRK2YBbgaUX7qCU6gi8iVEEZA07IRoxV4srYyLHsOiGRfyl3V/ILsrm3rV3M2ffQ9x+jZVZY9oTGezFws1p3PL2JhZuOlrVt8il+kVwTu6FjydA+jaZUL6IOisEWutyYDLwDbAX+EhrvVspNUMpNbxqt1mAJ7BYKbVDKbX0Vw4nhGgkvF28uafjPXw47ENGtRlFUlYSE1fdzob815g+ws6UAW0oLqvg8c92Mem9rSSfcUXf+sH/ioFPOIyeCwdWwd7P4b/XwsKbjVbX5XU7Z9BQ1ekcgdZ6ObD8Z9umXfB4UF1+vhCiYVJKEeIVwrSe07g16lbeSHqDb458zaq0ldwccSuzb7+VBRtO8s2eE4x8YwPP/z6WoeNWYKosQ5ttmD0DMQVEGG2ut/4HDq6Gg99CaDfocTdEXQ9WV0enedW4KiaLhRCiOmaTmbYBbZnVdxZbjm/hzcQ3mb/vPZbZPuePcRPo33YAPxzIIcDLjQFvGusfhPq68fYdXYgK9sIUeS206A3Hd8GWt2H/cvh4PARGQ9c7of0txmWpjZwUAiHEVc/F7ELvkN50DOrIisMr+O+u//J64kuEeC5iQvx9zN1QzrQRYedbXr+8ah9P39iOZj5uYHOH8G7GTWmnUmHLO7D7U1j+N/jhFeh0B3SdAO7+jk7TYaTXkBCiwfCwejCyzUjmDZnHPe3voaSihM8OzWfCQMU/d01mwuqR/HPXZMb3c+NUYQnTPt9FalaB0a7CYoOgaBg6Eyatgz4PgVKw5jl4vSt8/XfIS3d0ig4hIwIhRIOilMLPzY874+9kWOth5Bef4W/r7v9Jy+unNj3IGwPm8t6GI3yw+SjXtAlkfK8W9Gjtj9VsBp9Q6P84dL8bdi6C7fNh479g2zyIGQG9p0JApFEoGgEpBEKIBslsMhPmFYaJzGpbXpfqM0y7sQXr9heyPiWb1ftPEt3Ui1u7hTG6Uyierlbw8Icef4UOY40lMre8A4kfwM7FxiI5vR8AeycwOffJE+fOTgjh9Fws1be8zihMY07qHXg3X8SjI10Z0zmE7IISnlq6hz6z1vL00t0cySk03uDaBOJvNrqcjl0CrfpB8jfwn0Ew70ZIWeXUN6dJIRBCNGjVtbx+pf8rVFZU0im4Ez9kruXlPfey1zyN2wYd5q/9Qghu4sK7Px5m0EvrmDB3Cz+mZBvzCFY3aDMAbvsAJqyC2Jsgc5vR3O6tfpC4CMrLjKZ2BSdo6WtxiiZ3cmpICNGgXdjyurSiFJvZhp+rH1F+UXSzd+Ng3kGWpy7nu4zvmLt/Nq5mV3rF9ee6jtey42ATvk/J5tt9xmmjsd2bc1PnENxsVgjpCKPegtzDsGEO7F4Cn04y1kTofR98/GesVU3uuPUDCIppsKeQlNba0TFcki5duuitW7de1nuTk5OdokHUr3Hm/CS3hutqyK+0opScohy+y/iOFYdXkHAygbLKMlp7R9DD/wayTsSxbl8+2QWl+HnY+H1HO3/u1YoQXzfjAFrDmePGzWmhXWH5gz/tb+QTDhNXgWewYxKsAaXUNq11l+pekxGBEMLp2cw2mnk24+bImxnWchip+al8nvI569LXsSD1ZdwsbvTpOQjP0n5sTXbhP+sPM2/DEfpFBjLxmlZ0b+mHatIMBjwBuUeqb3JXcBJKCsC/tWOSvAJSCIQQjYZSCk+bJ/GB8cT4x3BX/F2sSV/DV4e+Yk3GV5TrZUS0iGZs3BDSjkbxXXI2q/Yap43+9LsWjOoYgovV1RgB/HxEkHsYFo2F4DiIGQnxt4Bv+K/GcjVpmCe0hBDiCllMFgI9Ark56mbmDJzD+0PfZ3TEaPJKcvg8/RX22R5kSL8fuKGzIrughL8v2UnP//uWL1JKKb954U+a3JXfvJDKJmHGZajFebDmWXg1Ht7sC+tfhdPHHJvsRciIQAjR6Llb3YkLjCMmIIZ7i+9l1dFVfJn6Jd8d+4IK/TlR7WL5nWkgB1JbYbVamZWguP2PyzGZK6msMLFwYz4T+7QlcMTrUFoARzfDro8hdS2smgbfPmXcjxD7e2Ok4Bno6JR/QgqBEEJUMSkTvm6+jIkaw4g2IziYf5CP9n3E2vS17C+ajWegF6kld9KvfWcmrZlIZmEmdg87T3V/kYKSUopKywn394KIgcZlqCUFkLYRdlYVhRWPw8onjS6ocaOg3Rhw93N02lIIhBCiOjazjbZ+bZnWcxpTS6ey4sgKvjj4BVEBzXlq40O/aGkxp/9c+s/aTpifG71bB9C/bRB92gTgGjEYIgZD8Rk4+iMkLYZD6+Crh43+RuE9od1oY7Tg5uOQXKUQCCHEb1BK4e3izZjIMYxsM5JjBceqbWlRXJnLgI45ZBxvxuJt6XywJQ2b2UT7MG/6RgUyqG0w0ZHXQeR1RlE4vN7oc3Toe/hiqnFJaotrIG40xAw37nauJ1IIhBCihqwmK+5Wd+we9p8UA7uHnZNFx9lSPAuLr4X2zdviTTsK81pzMMPMlm9yefGbZIKbuNCzlT8DooPpGzkQ7+ihxumj1LWw8yOjKKSugS+nQst+xkgh+gawusPZLGOFNYsN3ANr9eY1KQRCCHEJzrW0uHf1vefnCGYPmI2fix/Tekxj07FN7M7ZTXLBQlDg2dKL33l0wFLSlpys5izfVcZnOzKxmBSx9ib0iQxkYHQv4kdfj6msEFJWw67FxoghZSWE9YBB0+HTvxiXrNbBncxSCIQQ4hJc2NLibPFZ3F3d8XP1w6RMjIkaw5ioMRSXF3P0zFFWHV7Fjqwd7MlJIr/0e/CE5vEhBFniKSuMJC1T89rqfF5bnYKvu5XurfzpH9WRAddfR6CtDA6sBM+g/xUBMP774W21eiezFAIhhLhEJmUiwC2A5LRkwiN/edOYq8WVSN9IIn0j0VpztuwsSdlJrElbQ1JWEntzV1FW+RWmZmbi20ThXhHLmdzWrNtfzte7jmNSEBnsRe820TzUwwOXau5k1uWl1NZqCVIIhBCiDiml8LB50NPek572nlRUVpBbksv69PVsOLaBXdm72F20GFyhSbQH0a7tMBVFc/JEc/6z/gz3dGuPNfoGTnX6A6XuftjOnsJv+wIqlBVrLcUohUAIIeqR2WQmwC2AkREjGRkxkrLKMtJPp/Pt0W/ZdnIbu7N3k1uxEQKgRUhT5h8dTb8BD/Pgdw+fn5N4deBLBJqaUFurLEshEEIIB7KarLT0aclEn4lMZCLF5cXszt7NqiPINjZVAAAF/klEQVSrSMpOIjYo4nwRAONS1fvWPcDcIe8D7rUSgxQCIYS4irhaXOnctDOdm3ZGa01GQfVLcWrKa+0zpemcEEJcpZRSuFpcql2K02a21drnSCEQQoirWHVLcc4eMBs/19rrUSSnhoQQ4ir2a0txmpTcWSyEEI3GufsW6uz4dXZkIYQQDYIUAiGEaOSkEAghRCMnhUAIIRo5KQRCCNHIKa21o2O4JEqpLODIZb49AMiuxXCuNs6cn+TWcDlzfg0pt+Za68DqXmhwheBKKKW2aq27ODqOuuLM+UluDZcz5+csucmpISGEaOSkEAghRCPX2ArBW44OoI45c36SW8PlzPk5RW6Nao5ACCHELzW2EYEQQoifkUIghBCNnFMWAqXUEKXUfqVUilLq0Wped1FKLap6fZNSqkX9R3l5apBbH6XUdqVUuVJqtCNivBI1yO8BpdQepVSSUupbpVRzR8R5OWqQ211KqZ1KqR1KqfVKqRhHxHk5LpbbBfvdpJTSSqkGdcllDb67cUqprKrvbodSaqIj4rxsWmun+gHMwEGgFWADEoGYn+3zV+DfVY9vBRY5Ou5azK0FEA+8B4x2dMx1kF9/wL3q8d1O9t01ueDxcOBrR8ddW7lV7ecFfAdsBLo4Ou5a/u7GAa87OtbL/XHGEUE3IEVrnaq1LgU+BEb8bJ8RwLyqxx8DA5VSqh5jvFwXzU1rfVhrnQRUOiLAK1ST/NZorc9WPd0IhNZzjJerJrmdvuCpB9BQruSoyd85gGeAmUBxfQZXC2qaX4PljIUgBEi74Hl61bZq99FalwP5gH+9RHdlapJbQ3ap+U0AvqrTiGpPjXJTSt2jlDoIvADcW0+xXamL5qaU6gSEaa2/rM/AaklN/1zeVHXK8mOlVFj9hFY7nLEQiEZAKTUW6ALMcnQstUlrPUdr3Rp4BHjC0fHUBqWUCXgJ+JujY6lDy4AWWut4YCX/O+PQIDhjIcgALqzGoVXbqt1HKWUBvIGceonuytQkt4asRvkppQYBjwPDtdYl9RTblbrU7+5DYGSdRlR7LpabFxAHrFVKHQZ6AEsb0ITxRb87rXXOBX8W3wE611NstcIZC8EWIEIp1VIpZcOYDF76s32WAn+qejwaWK2rZnyucjXJrSG7aH5KqY7AmxhF4KQDYrxcNckt4oKnw4AD9RjflfjN3LTW+VrrAK11C611C4y5neFa662OCfeS1eS7a3bB0+HA3nqM78o5era6Ln6A64FkjJn+x6u2zcD4wwfgCiwGUoDNQCtHx1yLuXXFOIdZiDHK2e3omGs5v1XACWBH1c9SR8dci7m9CuyuymsNEOvomGsrt5/tu5YGdNVQDb+756u+u8Sq7y7a0TFfyo+0mBBCiEbOGU8NCSGEuARSCIQQopGTQiCEEI2cFAIhhGjkpBAIIUQjJ4VAiFqilBp+rjOlUuoppdSDjo5JiJqwODoAIZyF1nopznWDn2gkZEQgRBWl1Fil1OaqfvJvKqXMSqkCpdTLSqndVesfBFbte+8F6yJ8WLVtnFLq9WqO20EptbFq30+VUr5V29cqpWZWfWayUuqa+s1YCIMUAiEApVRb4Bagl9a6A1AB/AGjHfRWrXUssA6YXvWWR4GO2mgydtdFDv8e8EjVvjsvOAaARWvdDZj6s+1C1Bs5NSSEYSBGo7AtVUtTuAEnMdZ1WFS1z3xgSdXjJGCBUuoz4LNfO6hSyhvw0Vqvq9o0D6O9yTnnjrcNY1EhIeqdjAiEMChgnta6Q9VPlNb6qWr2O9eTZRgwB+iEUTwu95eqcx0rK5BfzISDSCEQwvAtMFopFQSglPKrWg/ZhNGhFuB2YH1Vf/0wrfUajHUDvAHP6g6qtc4Hci84//9HjFNMQlw15DcQIQCt9R6l1BPAiqp/6MuAezC6uHareu0kxjyCGZhfddpHAbO11nm/sdrpn4B/K6XcgVRgfN1mI8Slke6jQvwGpVSB1rra3/aFcBZyakgIIRo5GREIIUQjJyMCIYRo5KQQCCFEIyeFQAghGjkpBEII0chJIRBCiEbu/wHLeh8qlF/ijQAAAABJRU5ErkJggg==\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"meaning-amount","executionInfo":{"status":"ok","timestamp":1623891669213,"user_tz":-120,"elapsed":4,"user":{"displayName":"Baris Sevilmis","photoUrl":"","userId":"05631870087761794056"}}},"source":["df.T.to_json('res/log_attack_naive.json', indent=2)"],"id":"meaning-amount","execution_count":24,"outputs":[]},{"cell_type":"raw","metadata":{"id":"moral-married"},"source":["# THIS DOESNT WORK, PIVOTING -> several values (1 per run), want to keep list of values or compute std \n","# Difference in accuracy w.r.t. to no attack (epsilon = 0)\n","df_delta = df.pivot_table(index='epsilon', columns='optimizer', values='acc')\n","df_delta -= df_delta.loc[0]\n","df_delta = df_delta.unstack().rename('acc').reset_index()\n","sns.lineplot(x='epsilon', y='acc', data=df_delta, hue='optimizer', marker='o')\n","plt.grid(alpha=.6)\n","plt.ylabel('Difference in accuracy'); plt.xlabel('Attack strength $\\epsilon$');"],"id":"moral-married"},{"cell_type":"raw","metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1623616171457,"user":{"displayName":"Baris Sevilmis","photoUrl":"","userId":"05631870087761794056"},"user_tz":-120},"id":"stock-header","tags":[]},"source":["# NON LOOPY VERSION FOR ATTACK\n","data_naive_attack = list()\n","epsilons = np.arange(0, 0.6, 0.05)\n","\n","for optimizer, network in naive_networks.items():\n","    name = optimizer_names[optimizer]\n","    print(f'\\n{name:<10}', end='')\n","    \n","    for eps in epsilons:\n","        print('', end='.')\n","        loss_attack, acc_attack = attack(\n","            model=network,\n","            test_loader=test_loader,\n","            epsilon=eps,\n","            verbose=False,\n","            **test_config\n","        )\n","        # Log\n","        data_naive_attack.append({\n","            'optimizer': name,\n","            'epsilon': eps,\n","            'loss': loss_attack,\n","            'acc': acc_attack\n","        })"],"id":"stock-header"},{"cell_type":"raw","metadata":{"tags":[],"id":"later-poster"},"source":["# Plots before loops version\n","_, ax = plt.subplots(2, 1, figsize=(7, 6), sharex=True)\n","plt.axes(ax[0])\n","df = pd.DataFrame(data_naive_attack).sort_values(['optimizer', 'epsilon'])\n","\n","# Raw accuracy in function of attack stength\n","sns.lineplot(x='epsilon', y='acc', data=df, hue='optimizer', marker='o')\n","plt.grid(alpha=.6)\n","plt.ylabel('Accuracy');\n","plt.title('Attack on naive models')\n","\n","# Difference in accuracy w.r.t. to no attack (epsilon = 0)\n","plt.axes(ax[1])\n","df_delta = df.pivot(index='epsilon', columns='optimizer', values='acc')\n","df_delta -= df_delta.loc[0]\n","df_delta = df_delta.unstack().rename('acc').reset_index()\n","sns.lineplot(x='epsilon', y='acc', data=df_delta, hue='optimizer', marker='o')\n","plt.grid(alpha=.6)\n","plt.ylabel('Difference in accuracy'); plt.xlabel('Attack strength $\\epsilon$');"],"id":"later-poster"},{"cell_type":"markdown","metadata":{"id":"cloudy-warren"},"source":["# Attack on robust model"],"id":"cloudy-warren"},{"cell_type":"markdown","metadata":{"id":"apart-preference"},"source":["## Hyperparameter optimization on robust models\n","\n","- If the `prot_hyperparameter_tune` flag was set to `True` above, the following code will run hyperparameter tuning on all optimizers for robust models. Note that one can either run KFold cross validation (by providing `n_folds`) or use a simple train/test split (by providing `train_ratio`).\n"],"id":"apart-preference"},{"cell_type":"raw","metadata":{"executionInfo":{"elapsed":228,"status":"error","timestamp":1623617263506,"user":{"displayName":"Baris Sevilmis","photoUrl":"","userId":"05631870087761794056"},"user_tz":-120},"id":"economic-shock","outputId":"f6b4fdd5-0490-47a7-88f7-80319364fa38"},"source":["prot_optimizers = {\n","    AdamOptimizer: get_best_hyperparams('./res/prot_adam_tuning.json',get_performance=False),\n","    NesterovOptimizer: get_best_hyperparams('./res/prot_nesterov_tuning.json', get_performance=False),\n","    MiniBatchOptimizer: get_best_hyperparams('./res/prot_minibatch_tuning.json', get_performance=False)\n","}"],"id":"economic-shock"},{"cell_type":"code","metadata":{"id":"F49mhli4ZS0I","executionInfo":{"status":"ok","timestamp":1623891786914,"user_tz":-120,"elapsed":223,"user":{"displayName":"Baris Sevilmis","photoUrl":"","userId":"05631870087761794056"}}},"source":["from adversary import protected_training"],"id":"F49mhli4ZS0I","execution_count":25,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"exciting-motor"},"source":["### Adam"],"id":"exciting-motor"},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cordless-anchor","outputId":"2553320f-8c9a-4c3f-abe0-4964847f3f78"},"source":["search_grid_adam = {\n","        'lr': np.linspace(0.001, 0.01, 3),\n","        'beta1':  np.linspace(0.1, 0.9, 2),\n","        'beta2': np.linspace(0.5, 0.999, 2),\n","        'batch_size': [32, 64, 128],\n","        'weight_decay': np.linspace(0.001, 0.1, 2),\n","        'epsilon': np.linspace(1e-10, 1e-8, 2),\n","    }\n","\n","if prot_hyperparameter_tune:\n","    results_adam_prot = tune_optimizer(\n","        model=Net().to(device),\n","        optim_fun=AdamOptimizer,\n","        xtrain=train_dataset.data,\n","        ytrain=train_dataset.targets,\n","        search_grid=search_grid_adam,\n","        nfolds=3,\n","        func=protected_training,\n","        **training_config)\n","\n","else:\n","    results_adam_prot = optimizers[AdamOptimizer]"],"id":"cordless-anchor","execution_count":null,"outputs":[{"output_type":"stream","text":["Launching hyperparameter tuning:\n","\tlr = [0.001  0.0055 0.01  ]\n","\tbeta1 = [0.1 0.9]\n","\tbeta2 = [0.5   0.999]\n","\tbatch_size = [32, 64, 128]\n","\tweight_decay = [0.001 0.1  ]\n","\tepsilon = [1.e-10 1.e-08]\n","{'lr': 0.001, 'beta1': 0.1, 'beta2': 0.5, 'batch_size': 32, 'weight_decay': 0.001, 'epsilon': 1e-10}\n","epoch 0\tavg epoch loss = 0.441\tavg epoch acc = 0.9597\n","epoch 1\tavg epoch loss = 0.3262\tavg epoch acc = 0.9797\n","epoch 2\tavg epoch loss = 0.3371\tavg epoch acc = 0.98\n","epoch 3\tavg epoch loss = 0.3328\tavg epoch acc = 0.9797\n","epoch 4\tavg epoch loss = 0.3411\tavg epoch acc = 0.9792\n","epoch 5\tavg epoch loss = 0.3529\tavg epoch acc = 0.9792\n","epoch 6\tavg epoch loss = 0.3711\tavg epoch acc = 0.979\n","epoch 7\tavg epoch loss = 0.4003\tavg epoch acc = 0.9789\n","epoch 8\tavg epoch loss = 0.4001\tavg epoch acc = 0.9781\n","epoch 9\tavg epoch loss = 0.4229\tavg epoch acc = 0.977\n","training took 54.34 s\n","Avg test loss = 0.128\tAvg test acc = 0.965\n","epoch 0\tavg epoch loss = 0.4492\tavg epoch acc = 0.9565\n","epoch 1\tavg epoch loss = 0.3184\tavg epoch acc = 0.9795\n","epoch 2\tavg epoch loss = 0.3301\tavg epoch acc = 0.978\n","epoch 3\tavg epoch loss = 0.336\tavg epoch acc = 0.9758\n","epoch 4\tavg epoch loss = 0.3483\tavg epoch acc = 0.9759\n","epoch 5\tavg epoch loss = 0.3723\tavg epoch acc = 0.9757\n","epoch 6\tavg epoch loss = 0.3873\tavg epoch acc = 0.9764\n","epoch 7\tavg epoch loss = 0.4083\tavg epoch acc = 0.9756\n","epoch 8\tavg epoch loss = 0.4121\tavg epoch acc = 0.9748\n","epoch 9\tavg epoch loss = 0.42\tavg epoch acc = 0.9733\n","training took 53.95 s\n","Avg test loss = 0.152\tAvg test acc = 0.959\n","epoch 0\tavg epoch loss = 0.4488\tavg epoch acc = 0.956\n","epoch 1\tavg epoch loss = 0.3179\tavg epoch acc = 0.9792\n","epoch 2\tavg epoch loss = 0.3215\tavg epoch acc = 0.979\n","epoch 3\tavg epoch loss = 0.324\tavg epoch acc = 0.9781\n","epoch 4\tavg epoch loss = 0.3352\tavg epoch acc = 0.9776\n","epoch 5\tavg epoch loss = 0.3491\tavg epoch acc = 0.9772\n","epoch 6\tavg epoch loss = 0.3598\tavg epoch acc = 0.9769\n","epoch 7\tavg epoch loss = 0.3671\tavg epoch acc = 0.9765\n","epoch 8\tavg epoch loss = 0.3697\tavg epoch acc = 0.9763\n","epoch 9\tavg epoch loss = 0.3823\tavg epoch acc = 0.9764\n","training took 54.26 s\n","Avg test loss = 0.16\tAvg test acc = 0.975\n","{'lr': 0.001, 'beta1': 0.1, 'beta2': 0.5, 'batch_size': 32, 'weight_decay': 0.001, 'epsilon': 1e-08}\n","epoch 0\tavg epoch loss = 0.4475\tavg epoch acc = 0.9581\n","epoch 1\tavg epoch loss = 0.3149\tavg epoch acc = 0.9802\n","epoch 2\tavg epoch loss = 0.3259\tavg epoch acc = 0.9793\n","epoch 3\tavg epoch loss = 0.3283\tavg epoch acc = 0.9787\n","epoch 4\tavg epoch loss = 0.3509\tavg epoch acc = 0.9773\n","epoch 5\tavg epoch loss = 0.3613\tavg epoch acc = 0.9779\n","epoch 6\tavg epoch loss = 0.3945\tavg epoch acc = 0.9782\n","epoch 7\tavg epoch loss = 0.3976\tavg epoch acc = 0.9777\n","epoch 8\tavg epoch loss = 0.4088\tavg epoch acc = 0.9775\n","epoch 9\tavg epoch loss = 0.4193\tavg epoch acc = 0.9778\n","training took 54.37 s\n","Avg test loss = 0.115\tAvg test acc = 0.972\n","epoch 0\tavg epoch loss = 0.4416\tavg epoch acc = 0.9582\n","epoch 1\tavg epoch loss = 0.3039\tavg epoch acc = 0.9797\n","epoch 2\tavg epoch loss = 0.316\tavg epoch acc = 0.9794\n","epoch 3\tavg epoch loss = 0.3198\tavg epoch acc = 0.9796\n","epoch 4\tavg epoch loss = 0.3247\tavg epoch acc = 0.9788\n","epoch 5\tavg epoch loss = 0.3485\tavg epoch acc = 0.979\n","epoch 6\tavg epoch loss = 0.3566\tavg epoch acc = 0.9791\n","epoch 7\tavg epoch loss = 0.369\tavg epoch acc = 0.9788\n","epoch 8\tavg epoch loss = 0.3801\tavg epoch acc = 0.9795\n","epoch 9\tavg epoch loss = 0.4011\tavg epoch acc = 0.9785\n","training took 54.32 s\n","Avg test loss = 0.109\tAvg test acc = 0.971\n","epoch 0\tavg epoch loss = 0.45\tavg epoch acc = 0.9582\n","epoch 1\tavg epoch loss = 0.3376\tavg epoch acc = 0.9788\n","epoch 2\tavg epoch loss = 0.3378\tavg epoch acc = 0.9791\n","epoch 3\tavg epoch loss = 0.3301\tavg epoch acc = 0.9778\n","epoch 4\tavg epoch loss = 0.3445\tavg epoch acc = 0.9776\n","epoch 5\tavg epoch loss = 0.3591\tavg epoch acc = 0.9776\n","epoch 6\tavg epoch loss = 0.3735\tavg epoch acc = 0.9778\n","epoch 7\tavg epoch loss = 0.3784\tavg epoch acc = 0.9786\n","epoch 8\tavg epoch loss = 0.3966\tavg epoch acc = 0.9773\n","epoch 9\tavg epoch loss = 0.4034\tavg epoch acc = 0.9768\n","training took 54.4 s\n","Avg test loss = 0.123\tAvg test acc = 0.973\n","{'lr': 0.001, 'beta1': 0.1, 'beta2': 0.5, 'batch_size': 32, 'weight_decay': 0.1, 'epsilon': 1e-10}\n","epoch 0\tavg epoch loss = 0.4358\tavg epoch acc = 0.9582\n","epoch 1\tavg epoch loss = 0.2713\tavg epoch acc = 0.982\n","epoch 2\tavg epoch loss = 0.2622\tavg epoch acc = 0.9825\n","epoch 3\tavg epoch loss = 0.2682\tavg epoch acc = 0.9814\n","epoch 4\tavg epoch loss = 0.284\tavg epoch acc = 0.9809\n","epoch 5\tavg epoch loss = 0.2856\tavg epoch acc = 0.9807\n","epoch 6\tavg epoch loss = 0.2899\tavg epoch acc = 0.9809\n","epoch 7\tavg epoch loss = 0.2955\tavg epoch acc = 0.9803\n","epoch 8\tavg epoch loss = 0.2956\tavg epoch acc = 0.9812\n","epoch 9\tavg epoch loss = 0.2978\tavg epoch acc = 0.981\n","training took 53.82 s\n","Avg test loss = 0.091\tAvg test acc = 0.973\n","epoch 0\tavg epoch loss = 0.4398\tavg epoch acc = 0.9573\n","epoch 1\tavg epoch loss = 0.2831\tavg epoch acc = 0.9805\n","epoch 2\tavg epoch loss = 0.2781\tavg epoch acc = 0.9803\n","epoch 3\tavg epoch loss = 0.2831\tavg epoch acc = 0.9793\n","epoch 4\tavg epoch loss = 0.2893\tavg epoch acc = 0.9794\n","epoch 5\tavg epoch loss = 0.2946\tavg epoch acc = 0.98\n","epoch 6\tavg epoch loss = 0.2916\tavg epoch acc = 0.9807\n","epoch 7\tavg epoch loss = 0.2964\tavg epoch acc = 0.9801\n","epoch 8\tavg epoch loss = 0.2972\tavg epoch acc = 0.9799\n","epoch 9\tavg epoch loss = 0.2949\tavg epoch acc = 0.9806\n","training took 54.01 s\n","Avg test loss = 0.118\tAvg test acc = 0.972\n","epoch 0\tavg epoch loss = 0.4457\tavg epoch acc = 0.9577\n","epoch 1\tavg epoch loss = 0.2885\tavg epoch acc = 0.9806\n","epoch 2\tavg epoch loss = 0.2785\tavg epoch acc = 0.9815\n","epoch 3\tavg epoch loss = 0.288\tavg epoch acc = 0.9807\n","epoch 4\tavg epoch loss = 0.2981\tavg epoch acc = 0.9808\n","epoch 5\tavg epoch loss = 0.3058\tavg epoch acc = 0.9808\n","epoch 6\tavg epoch loss = 0.3126\tavg epoch acc = 0.9804\n","epoch 7\tavg epoch loss = 0.3161\tavg epoch acc = 0.9805\n","epoch 8\tavg epoch loss = 0.3174\tavg epoch acc = 0.9803\n","epoch 9\tavg epoch loss = 0.3143\tavg epoch acc = 0.98\n","training took 53.86 s\n","Avg test loss = 0.0891\tAvg test acc = 0.976\n","{'lr': 0.001, 'beta1': 0.1, 'beta2': 0.5, 'batch_size': 32, 'weight_decay': 0.1, 'epsilon': 1e-08}\n","epoch 0\tavg epoch loss = 0.4379\tavg epoch acc = 0.9588\n","epoch 1\tavg epoch loss = 0.2816\tavg epoch acc = 0.9802\n","epoch 2\tavg epoch loss = 0.2665\tavg epoch acc = 0.9803\n","epoch 3\tavg epoch loss = 0.2723\tavg epoch acc = 0.9805\n","epoch 4\tavg epoch loss = 0.2839\tavg epoch acc = 0.9807\n","epoch 5\tavg epoch loss = 0.2932\tavg epoch acc = 0.9814\n","epoch 6\tavg epoch loss = 0.2921\tavg epoch acc = 0.981\n","epoch 7\tavg epoch loss = 0.3028\tavg epoch acc = 0.9812\n","epoch 8\tavg epoch loss = 0.3026\tavg epoch acc = 0.9805\n","epoch 9\tavg epoch loss = 0.304\tavg epoch acc = 0.9806\n","training took 53.69 s\n","Avg test loss = 0.103\tAvg test acc = 0.973\n","epoch 0\tavg epoch loss = 0.443\tavg epoch acc = 0.9569\n","epoch 1\tavg epoch loss = 0.2922\tavg epoch acc = 0.9793\n","epoch 2\tavg epoch loss = 0.2799\tavg epoch acc = 0.9787\n","epoch 3\tavg epoch loss = 0.2743\tavg epoch acc = 0.9788\n","epoch 4\tavg epoch loss = 0.2826\tavg epoch acc = 0.9788\n","epoch 5\tavg epoch loss = 0.2898\tavg epoch acc = 0.9796\n","epoch 6\tavg epoch loss = 0.2975\tavg epoch acc = 0.9794\n","epoch 7\tavg epoch loss = 0.2993\tavg epoch acc = 0.9806\n","epoch 8\tavg epoch loss = 0.3054\tavg epoch acc = 0.9804\n","epoch 9\tavg epoch loss = 0.3051\tavg epoch acc = 0.9804\n","training took 53.88 s\n","Avg test loss = 0.105\tAvg test acc = 0.973\n","epoch 0\tavg epoch loss = 0.4377\tavg epoch acc = 0.9575\n","epoch 1\tavg epoch loss = 0.2764\tavg epoch acc = 0.9799\n","epoch 2\tavg epoch loss = 0.2719\tavg epoch acc = 0.9808\n","epoch 3\tavg epoch loss = 0.2727\tavg epoch acc = 0.9804\n","epoch 4\tavg epoch loss = 0.2758\tavg epoch acc = 0.9806\n","epoch 5\tavg epoch loss = 0.2785\tavg epoch acc = 0.9806\n","epoch 6\tavg epoch loss = 0.2861\tavg epoch acc = 0.9803\n","epoch 7\tavg epoch loss = 0.2942\tavg epoch acc = 0.9809\n","epoch 8\tavg epoch loss = 0.2978\tavg epoch acc = 0.9801\n","epoch 9\tavg epoch loss = 0.2963\tavg epoch acc = 0.9807\n","training took 53.88 s\n","Avg test loss = 0.113\tAvg test acc = 0.972\n","{'lr': 0.001, 'beta1': 0.1, 'beta2': 0.5, 'batch_size': 64, 'weight_decay': 0.001, 'epsilon': 1e-10}\n","epoch 0\tavg epoch loss = 0.474\tavg epoch acc = 0.949\n","epoch 1\tavg epoch loss = 0.2398\tavg epoch acc = 0.9838\n","epoch 2\tavg epoch loss = 0.2192\tavg epoch acc = 0.9861\n","epoch 3\tavg epoch loss = 0.221\tavg epoch acc = 0.9865\n","epoch 4\tavg epoch loss = 0.2205\tavg epoch acc = 0.9864\n","epoch 5\tavg epoch loss = 0.2162\tavg epoch acc = 0.9857\n","epoch 6\tavg epoch loss = 0.2187\tavg epoch acc = 0.986\n","epoch 7\tavg epoch loss = 0.2237\tavg epoch acc = 0.986\n","epoch 8\tavg epoch loss = 0.2241\tavg epoch acc = 0.9862\n","epoch 9\tavg epoch loss = 0.2288\tavg epoch acc = 0.9864\n","training took 27.9 s\n","Avg test loss = 0.0884\tAvg test acc = 0.983\n","epoch 0\tavg epoch loss = 0.4791\tavg epoch acc = 0.9481\n","epoch 1\tavg epoch loss = 0.2388\tavg epoch acc = 0.9838\n","epoch 2\tavg epoch loss = 0.2186\tavg epoch acc = 0.986\n","epoch 3\tavg epoch loss = 0.2278\tavg epoch acc = 0.9869\n","epoch 4\tavg epoch loss = 0.2298\tavg epoch acc = 0.9871\n","epoch 5\tavg epoch loss = 0.2285\tavg epoch acc = 0.9865\n","epoch 6\tavg epoch loss = 0.232\tavg epoch acc = 0.986\n","epoch 7\tavg epoch loss = 0.2337\tavg epoch acc = 0.9857\n","epoch 8\tavg epoch loss = 0.2384\tavg epoch acc = 0.9853\n","epoch 9\tavg epoch loss = 0.244\tavg epoch acc = 0.985\n","training took 27.83 s\n","Avg test loss = 0.085\tAvg test acc = 0.98\n","epoch 0\tavg epoch loss = 0.4794\tavg epoch acc = 0.9482\n","epoch 1\tavg epoch loss = 0.2429\tavg epoch acc = 0.9829\n","epoch 2\tavg epoch loss = 0.2163\tavg epoch acc = 0.986\n","epoch 3\tavg epoch loss = 0.2219\tavg epoch acc = 0.9859\n","epoch 4\tavg epoch loss = 0.2306\tavg epoch acc = 0.9858\n","epoch 5\tavg epoch loss = 0.229\tavg epoch acc = 0.9856\n","epoch 6\tavg epoch loss = 0.2268\tavg epoch acc = 0.9857\n","epoch 7\tavg epoch loss = 0.2334\tavg epoch acc = 0.9848\n","epoch 8\tavg epoch loss = 0.2325\tavg epoch acc = 0.9856\n","epoch 9\tavg epoch loss = 0.23\tavg epoch acc = 0.9859\n","training took 28.0 s\n","Avg test loss = 0.104\tAvg test acc = 0.978\n","{'lr': 0.001, 'beta1': 0.1, 'beta2': 0.5, 'batch_size': 64, 'weight_decay': 0.001, 'epsilon': 1e-08}\n","epoch 0\tavg epoch loss = 0.4804\tavg epoch acc = 0.9476\n","epoch 1\tavg epoch loss = 0.2424\tavg epoch acc = 0.9841\n","epoch 2\tavg epoch loss = 0.22\tavg epoch acc = 0.986\n","epoch 3\tavg epoch loss = 0.2255\tavg epoch acc = 0.9866\n","epoch 4\tavg epoch loss = 0.2235\tavg epoch acc = 0.9877\n","epoch 5\tavg epoch loss = 0.222\tavg epoch acc = 0.9877\n","epoch 6\tavg epoch loss = 0.2209\tavg epoch acc = 0.9876\n","epoch 7\tavg epoch loss = 0.2176\tavg epoch acc = 0.9873\n","epoch 8\tavg epoch loss = 0.2197\tavg epoch acc = 0.9876\n","epoch 9\tavg epoch loss = 0.2234\tavg epoch acc = 0.988\n","training took 28.16 s\n","Avg test loss = 0.0717\tAvg test acc = 0.98\n","epoch 0\tavg epoch loss = 0.4748\tavg epoch acc = 0.9485\n","epoch 1\tavg epoch loss = 0.2422\tavg epoch acc = 0.9839\n","epoch 2\tavg epoch loss = 0.2226\tavg epoch acc = 0.9856\n","epoch 3\tavg epoch loss = 0.2241\tavg epoch acc = 0.9857\n","epoch 4\tavg epoch loss = 0.2223\tavg epoch acc = 0.9859\n","epoch 5\tavg epoch loss = 0.2221\tavg epoch acc = 0.9858\n","epoch 6\tavg epoch loss = 0.2204\tavg epoch acc = 0.9858\n","epoch 7\tavg epoch loss = 0.2248\tavg epoch acc = 0.986\n","epoch 8\tavg epoch loss = 0.2342\tavg epoch acc = 0.9868\n","epoch 9\tavg epoch loss = 0.2384\tavg epoch acc = 0.9857\n","training took 27.81 s\n","Avg test loss = 0.078\tAvg test acc = 0.982\n","epoch 0\tavg epoch loss = 0.474\tavg epoch acc = 0.9488\n","epoch 1\tavg epoch loss = 0.2344\tavg epoch acc = 0.9842\n","epoch 2\tavg epoch loss = 0.2121\tavg epoch acc = 0.986\n","epoch 3\tavg epoch loss = 0.2098\tavg epoch acc = 0.9869\n","epoch 4\tavg epoch loss = 0.2105\tavg epoch acc = 0.9865\n","epoch 5\tavg epoch loss = 0.2102\tavg epoch acc = 0.9857\n","epoch 6\tavg epoch loss = 0.2094\tavg epoch acc = 0.9857\n","epoch 7\tavg epoch loss = 0.2192\tavg epoch acc = 0.9857\n","epoch 8\tavg epoch loss = 0.2216\tavg epoch acc = 0.9859\n","epoch 9\tavg epoch loss = 0.2256\tavg epoch acc = 0.9868\n","training took 28.01 s\n","Avg test loss = 0.0893\tAvg test acc = 0.982\n","{'lr': 0.001, 'beta1': 0.1, 'beta2': 0.5, 'batch_size': 64, 'weight_decay': 0.1, 'epsilon': 1e-10}\n","epoch 0\tavg epoch loss = 0.4765\tavg epoch acc = 0.9484\n","epoch 1\tavg epoch loss = 0.2329\tavg epoch acc = 0.9838\n","epoch 2\tavg epoch loss = 0.198\tavg epoch acc = 0.9861\n","epoch 3\tavg epoch loss = 0.1865\tavg epoch acc = 0.9868\n","epoch 4\tavg epoch loss = 0.1829\tavg epoch acc = 0.9871\n","epoch 5\tavg epoch loss = 0.1843\tavg epoch acc = 0.9869\n","epoch 6\tavg epoch loss = 0.1854\tavg epoch acc = 0.9871\n","epoch 7\tavg epoch loss = 0.1874\tavg epoch acc = 0.9873\n","epoch 8\tavg epoch loss = 0.1908\tavg epoch acc = 0.9872\n","epoch 9\tavg epoch loss = 0.1901\tavg epoch acc = 0.9877\n","training took 27.9 s\n","Avg test loss = 0.0708\tAvg test acc = 0.982\n","epoch 0\tavg epoch loss = 0.4814\tavg epoch acc = 0.9474\n","epoch 1\tavg epoch loss = 0.2378\tavg epoch acc = 0.983\n","epoch 2\tavg epoch loss = 0.203\tavg epoch acc = 0.986\n","epoch 3\tavg epoch loss = 0.1959\tavg epoch acc = 0.9866\n","epoch 4\tavg epoch loss = 0.196\tavg epoch acc = 0.9864\n","epoch 5\tavg epoch loss = 0.1977\tavg epoch acc = 0.9864\n","epoch 6\tavg epoch loss = 0.1999\tavg epoch acc = 0.9869\n","epoch 7\tavg epoch loss = 0.1979\tavg epoch acc = 0.9865\n","epoch 8\tavg epoch loss = 0.2007\tavg epoch acc = 0.987\n","epoch 9\tavg epoch loss = 0.2035\tavg epoch acc = 0.9873\n","training took 27.94 s\n","Avg test loss = 0.0641\tAvg test acc = 0.982\n","epoch 0\tavg epoch loss = 0.4736\tavg epoch acc = 0.9488\n","epoch 1\tavg epoch loss = 0.2369\tavg epoch acc = 0.9826\n","epoch 2\tavg epoch loss = 0.2033\tavg epoch acc = 0.9853\n","epoch 3\tavg epoch loss = 0.1957\tavg epoch acc = 0.9858\n","epoch 4\tavg epoch loss = 0.193\tavg epoch acc = 0.9861\n","epoch 5\tavg epoch loss = 0.1932\tavg epoch acc = 0.9861\n","epoch 6\tavg epoch loss = 0.1917\tavg epoch acc = 0.9866\n","epoch 7\tavg epoch loss = 0.1902\tavg epoch acc = 0.9867\n","epoch 8\tavg epoch loss = 0.1944\tavg epoch acc = 0.9867\n","epoch 9\tavg epoch loss = 0.1966\tavg epoch acc = 0.9873\n","training took 27.75 s\n","Avg test loss = 0.0627\tAvg test acc = 0.983\n","{'lr': 0.001, 'beta1': 0.1, 'beta2': 0.5, 'batch_size': 64, 'weight_decay': 0.1, 'epsilon': 1e-08}\n","epoch 0\tavg epoch loss = 0.4727\tavg epoch acc = 0.9482\n","epoch 1\tavg epoch loss = 0.2347\tavg epoch acc = 0.9823\n","epoch 2\tavg epoch loss = 0.2011\tavg epoch acc = 0.9857\n","epoch 3\tavg epoch loss = 0.1932\tavg epoch acc = 0.9865\n","epoch 4\tavg epoch loss = 0.1875\tavg epoch acc = 0.9865\n","epoch 5\tavg epoch loss = 0.1875\tavg epoch acc = 0.9869\n","epoch 6\tavg epoch loss = 0.1858\tavg epoch acc = 0.9867\n","epoch 7\tavg epoch loss = 0.1905\tavg epoch acc = 0.9867\n","epoch 8\tavg epoch loss = 0.1923\tavg epoch acc = 0.9873\n","epoch 9\tavg epoch loss = 0.1968\tavg epoch acc = 0.9871\n","training took 28.13 s\n","Avg test loss = 0.0625\tAvg test acc = 0.982\n","epoch 0\tavg epoch loss = 0.4731\tavg epoch acc = 0.9484\n","epoch 1\tavg epoch loss = 0.2306\tavg epoch acc = 0.983\n","epoch 2\tavg epoch loss = 0.1956\tavg epoch acc = 0.9863\n","epoch 3\tavg epoch loss = 0.1899\tavg epoch acc = 0.9875\n","epoch 4\tavg epoch loss = 0.19\tavg epoch acc = 0.9876\n","epoch 5\tavg epoch loss = 0.1883\tavg epoch acc = 0.9871\n","epoch 6\tavg epoch loss = 0.189\tavg epoch acc = 0.9876\n","epoch 7\tavg epoch loss = 0.1889\tavg epoch acc = 0.9876\n","epoch 8\tavg epoch loss = 0.194\tavg epoch acc = 0.9879\n","epoch 9\tavg epoch loss = 0.1923\tavg epoch acc = 0.9879\n","training took 27.89 s\n","Avg test loss = 0.0665\tAvg test acc = 0.985\n","epoch 0\tavg epoch loss = 0.4798\tavg epoch acc = 0.9484\n","epoch 1\tavg epoch loss = 0.2392\tavg epoch acc = 0.9831\n","epoch 2\tavg epoch loss = 0.2036\tavg epoch acc = 0.9857\n","epoch 3\tavg epoch loss = 0.1903\tavg epoch acc = 0.9867\n","epoch 4\tavg epoch loss = 0.1847\tavg epoch acc = 0.9875\n","epoch 5\tavg epoch loss = 0.1832\tavg epoch acc = 0.9875\n","epoch 6\tavg epoch loss = 0.1838\tavg epoch acc = 0.9879\n","epoch 7\tavg epoch loss = 0.1865\tavg epoch acc = 0.9874\n","epoch 8\tavg epoch loss = 0.1888\tavg epoch acc = 0.9881\n","epoch 9\tavg epoch loss = 0.1919\tavg epoch acc = 0.9883\n","training took 27.93 s\n","Avg test loss = 0.059\tAvg test acc = 0.985\n","{'lr': 0.001, 'beta1': 0.1, 'beta2': 0.5, 'batch_size': 128, 'weight_decay': 0.001, 'epsilon': 1e-10}\n","epoch 0\tavg epoch loss = 0.5795\tavg epoch acc = 0.9309\n","epoch 1\tavg epoch loss = 0.2473\tavg epoch acc = 0.9826\n","epoch 2\tavg epoch loss = 0.1864\tavg epoch acc = 0.9875\n","epoch 3\tavg epoch loss = 0.156\tavg epoch acc = 0.99\n","epoch 4\tavg epoch loss = 0.1408\tavg epoch acc = 0.9914\n","epoch 5\tavg epoch loss = 0.1369\tavg epoch acc = 0.992\n","epoch 6\tavg epoch loss = 0.1332\tavg epoch acc = 0.992\n","epoch 7\tavg epoch loss = 0.1297\tavg epoch acc = 0.9928\n","epoch 8\tavg epoch loss = 0.1273\tavg epoch acc = 0.993\n","epoch 9\tavg epoch loss = 0.1286\tavg epoch acc = 0.9931\n","training took 17.27 s\n","Avg test loss = 0.0852\tAvg test acc = 0.985\n","epoch 0\tavg epoch loss = 0.5644\tavg epoch acc = 0.9335\n","epoch 1\tavg epoch loss = 0.2421\tavg epoch acc = 0.9828\n","epoch 2\tavg epoch loss = 0.1847\tavg epoch acc = 0.9884\n","epoch 3\tavg epoch loss = 0.1581\tavg epoch acc = 0.9909\n","epoch 4\tavg epoch loss = 0.1462\tavg epoch acc = 0.9919\n","epoch 5\tavg epoch loss = 0.1397\tavg epoch acc = 0.9924\n","epoch 6\tavg epoch loss = 0.1371\tavg epoch acc = 0.9925\n","epoch 7\tavg epoch loss = 0.1364\tavg epoch acc = 0.9931\n","epoch 8\tavg epoch loss = 0.1339\tavg epoch acc = 0.9927\n","epoch 9\tavg epoch loss = 0.1355\tavg epoch acc = 0.9928\n","training took 17.23 s\n","Avg test loss = 0.0594\tAvg test acc = 0.986\n","epoch 0\tavg epoch loss = 0.5813\tavg epoch acc = 0.9284\n","epoch 1\tavg epoch loss = 0.2488\tavg epoch acc = 0.9825\n","epoch 2\tavg epoch loss = 0.1897\tavg epoch acc = 0.9872\n","epoch 3\tavg epoch loss = 0.1635\tavg epoch acc = 0.9896\n","epoch 4\tavg epoch loss = 0.1495\tavg epoch acc = 0.9907\n","epoch 5\tavg epoch loss = 0.1434\tavg epoch acc = 0.9914\n","epoch 6\tavg epoch loss = 0.1397\tavg epoch acc = 0.9921\n","epoch 7\tavg epoch loss = 0.1374\tavg epoch acc = 0.9926\n","epoch 8\tavg epoch loss = 0.1372\tavg epoch acc = 0.9927\n","epoch 9\tavg epoch loss = 0.1365\tavg epoch acc = 0.9925\n","training took 17.34 s\n","Avg test loss = 0.051\tAvg test acc = 0.986\n","{'lr': 0.001, 'beta1': 0.1, 'beta2': 0.5, 'batch_size': 128, 'weight_decay': 0.001, 'epsilon': 1e-08}\n","epoch 0\tavg epoch loss = 0.573\tavg epoch acc = 0.9297\n","epoch 1\tavg epoch loss = 0.2438\tavg epoch acc = 0.9832\n","epoch 2\tavg epoch loss = 0.1861\tavg epoch acc = 0.9884\n","epoch 3\tavg epoch loss = 0.1571\tavg epoch acc = 0.9908\n","epoch 4\tavg epoch loss = 0.1416\tavg epoch acc = 0.992\n","epoch 5\tavg epoch loss = 0.1316\tavg epoch acc = 0.9929\n","epoch 6\tavg epoch loss = 0.1268\tavg epoch acc = 0.9931\n","epoch 7\tavg epoch loss = 0.1254\tavg epoch acc = 0.9932\n","epoch 8\tavg epoch loss = 0.1205\tavg epoch acc = 0.9933\n","epoch 9\tavg epoch loss = 0.1195\tavg epoch acc = 0.9932\n","training took 17.34 s\n","Avg test loss = 0.095\tAvg test acc = 0.986\n","epoch 0\tavg epoch loss = 0.5775\tavg epoch acc = 0.9299\n","epoch 1\tavg epoch loss = 0.2461\tavg epoch acc = 0.9827\n","epoch 2\tavg epoch loss = 0.1879\tavg epoch acc = 0.9876\n","epoch 3\tavg epoch loss = 0.1638\tavg epoch acc = 0.99\n","epoch 4\tavg epoch loss = 0.1517\tavg epoch acc = 0.9911\n","epoch 5\tavg epoch loss = 0.1474\tavg epoch acc = 0.9916\n","epoch 6\tavg epoch loss = 0.1463\tavg epoch acc = 0.992\n","epoch 7\tavg epoch loss = 0.1431\tavg epoch acc = 0.9922\n","epoch 8\tavg epoch loss = 0.1417\tavg epoch acc = 0.9925\n","epoch 9\tavg epoch loss = 0.143\tavg epoch acc = 0.9925\n","training took 17.3 s\n","Avg test loss = 0.0675\tAvg test acc = 0.984\n","epoch 0\tavg epoch loss = 0.5748\tavg epoch acc = 0.9314\n","epoch 1\tavg epoch loss = 0.2412\tavg epoch acc = 0.983\n","epoch 2\tavg epoch loss = 0.1814\tavg epoch acc = 0.9879\n","epoch 3\tavg epoch loss = 0.1536\tavg epoch acc = 0.9905\n","epoch 4\tavg epoch loss = 0.1404\tavg epoch acc = 0.9922\n","epoch 5\tavg epoch loss = 0.1343\tavg epoch acc = 0.9929\n","epoch 6\tavg epoch loss = 0.1321\tavg epoch acc = 0.9932\n","epoch 7\tavg epoch loss = 0.1303\tavg epoch acc = 0.9933\n","epoch 8\tavg epoch loss = 0.1322\tavg epoch acc = 0.9935\n","epoch 9\tavg epoch loss = 0.131\tavg epoch acc = 0.9939\n","training took 17.27 s\n","Avg test loss = 0.0568\tAvg test acc = 0.986\n","{'lr': 0.001, 'beta1': 0.1, 'beta2': 0.5, 'batch_size': 128, 'weight_decay': 0.1, 'epsilon': 1e-10}\n","epoch 0\tavg epoch loss = 0.5814\tavg epoch acc = 0.9297\n","epoch 1\tavg epoch loss = 0.2496\tavg epoch acc = 0.9826\n","epoch 2\tavg epoch loss = 0.1875\tavg epoch acc = 0.9876\n","epoch 3\tavg epoch loss = 0.1571\tavg epoch acc = 0.9897\n","epoch 4\tavg epoch loss = 0.1408\tavg epoch acc = 0.9909\n","epoch 5\tavg epoch loss = 0.1316\tavg epoch acc = 0.9917\n","epoch 6\tavg epoch loss = 0.1277\tavg epoch acc = 0.9922\n","epoch 7\tavg epoch loss = 0.1253\tavg epoch acc = 0.9926\n","epoch 8\tavg epoch loss = 0.1245\tavg epoch acc = 0.9927\n","epoch 9\tavg epoch loss = 0.1233\tavg epoch acc = 0.9929\n","training took 17.38 s\n","Avg test loss = 0.0561\tAvg test acc = 0.986\n","epoch 0\tavg epoch loss = 0.5681\tavg epoch acc = 0.9306\n","epoch 1\tavg epoch loss = 0.2416\tavg epoch acc = 0.9827\n","epoch 2\tavg epoch loss = 0.1823\tavg epoch acc = 0.9881\n","epoch 3\tavg epoch loss = 0.154\tavg epoch acc = 0.9902\n","epoch 4\tavg epoch loss = 0.1364\tavg epoch acc = 0.9917\n","epoch 5\tavg epoch loss = 0.1273\tavg epoch acc = 0.9924\n","epoch 6\tavg epoch loss = 0.1223\tavg epoch acc = 0.9927\n","epoch 7\tavg epoch loss = 0.1194\tavg epoch acc = 0.993\n","epoch 8\tavg epoch loss = 0.1184\tavg epoch acc = 0.9935\n","epoch 9\tavg epoch loss = 0.1144\tavg epoch acc = 0.9937\n","training took 17.31 s\n","Avg test loss = 0.0427\tAvg test acc = 0.988\n","epoch 0\tavg epoch loss = 0.5816\tavg epoch acc = 0.93\n","epoch 1\tavg epoch loss = 0.2474\tavg epoch acc = 0.983\n","epoch 2\tavg epoch loss = 0.1865\tavg epoch acc = 0.9878\n","epoch 3\tavg epoch loss = 0.1574\tavg epoch acc = 0.9899\n","epoch 4\tavg epoch loss = 0.1415\tavg epoch acc = 0.9911\n","epoch 5\tavg epoch loss = 0.1338\tavg epoch acc = 0.992\n","epoch 6\tavg epoch loss = 0.1282\tavg epoch acc = 0.9922\n","epoch 7\tavg epoch loss = 0.1248\tavg epoch acc = 0.9922\n","epoch 8\tavg epoch loss = 0.1242\tavg epoch acc = 0.9925\n","epoch 9\tavg epoch loss = 0.1225\tavg epoch acc = 0.9925\n","training took 17.25 s\n","Avg test loss = 0.0669\tAvg test acc = 0.985\n","{'lr': 0.001, 'beta1': 0.1, 'beta2': 0.5, 'batch_size': 128, 'weight_decay': 0.1, 'epsilon': 1e-08}\n","epoch 0\tavg epoch loss = 0.5778\tavg epoch acc = 0.9299\n","epoch 1\tavg epoch loss = 0.2491\tavg epoch acc = 0.9818\n","epoch 2\tavg epoch loss = 0.1885\tavg epoch acc = 0.987\n","epoch 3\tavg epoch loss = 0.1587\tavg epoch acc = 0.9896\n","epoch 4\tavg epoch loss = 0.1429\tavg epoch acc = 0.9908\n","epoch 5\tavg epoch loss = 0.1354\tavg epoch acc = 0.9912\n","epoch 6\tavg epoch loss = 0.1295\tavg epoch acc = 0.9919\n","epoch 7\tavg epoch loss = 0.1265\tavg epoch acc = 0.9925\n","epoch 8\tavg epoch loss = 0.1251\tavg epoch acc = 0.9922\n","epoch 9\tavg epoch loss = 0.1223\tavg epoch acc = 0.9925\n","training took 17.35 s\n","Avg test loss = 0.0526\tAvg test acc = 0.984\n","epoch 0\tavg epoch loss = 0.5756\tavg epoch acc = 0.9312\n","epoch 1\tavg epoch loss = 0.2425\tavg epoch acc = 0.9833\n","epoch 2\tavg epoch loss = 0.1796\tavg epoch acc = 0.9884\n","epoch 3\tavg epoch loss = 0.1509\tavg epoch acc = 0.9905\n","epoch 4\tavg epoch loss = 0.1336\tavg epoch acc = 0.9918\n","epoch 5\tavg epoch loss = 0.124\tavg epoch acc = 0.9927\n","epoch 6\tavg epoch loss = 0.1193\tavg epoch acc = 0.9933\n","epoch 7\tavg epoch loss = 0.1179\tavg epoch acc = 0.9938\n","epoch 8\tavg epoch loss = 0.1144\tavg epoch acc = 0.9937\n","epoch 9\tavg epoch loss = 0.1121\tavg epoch acc = 0.994\n","training took 17.34 s\n","Avg test loss = 0.0491\tAvg test acc = 0.986\n","epoch 0\tavg epoch loss = 0.5716\tavg epoch acc = 0.9288\n","epoch 1\tavg epoch loss = 0.2442\tavg epoch acc = 0.9829\n","epoch 2\tavg epoch loss = 0.1834\tavg epoch acc = 0.9882\n","epoch 3\tavg epoch loss = 0.1538\tavg epoch acc = 0.991\n","epoch 4\tavg epoch loss = 0.1384\tavg epoch acc = 0.9919\n","epoch 5\tavg epoch loss = 0.1296\tavg epoch acc = 0.992\n","epoch 6\tavg epoch loss = 0.1225\tavg epoch acc = 0.9929\n","epoch 7\tavg epoch loss = 0.119\tavg epoch acc = 0.993\n","epoch 8\tavg epoch loss = 0.1176\tavg epoch acc = 0.9935\n","epoch 9\tavg epoch loss = 0.1144\tavg epoch acc = 0.9935\n","training took 17.24 s\n","Avg test loss = 0.062\tAvg test acc = 0.988\n","{'lr': 0.001, 'beta1': 0.1, 'beta2': 0.999, 'batch_size': 32, 'weight_decay': 0.001, 'epsilon': 1e-10}\n","epoch 0\tavg epoch loss = 0.7846\tavg epoch acc = 0.8677\n","epoch 1\tavg epoch loss = 0.2516\tavg epoch acc = 0.9823\n","epoch 2\tavg epoch loss = 0.1845\tavg epoch acc = 0.9881\n","epoch 3\tavg epoch loss = 0.1433\tavg epoch acc = 0.9911\n","epoch 4\tavg epoch loss = 0.1179\tavg epoch acc = 0.9938\n","epoch 5\tavg epoch loss = 0.0974\tavg epoch acc = 0.9954\n","epoch 6\tavg epoch loss = 0.08117\tavg epoch acc = 0.9969\n","epoch 7\tavg epoch loss = 0.07626\tavg epoch acc = 0.9976\n","epoch 8\tavg epoch loss = 0.0594\tavg epoch acc = 0.9981\n","epoch 9\tavg epoch loss = 0.05762\tavg epoch acc = 0.9986\n","training took 54.03 s\n","Avg test loss = 0.04\tAvg test acc = 0.99\n","epoch 0\tavg epoch loss = 0.7759\tavg epoch acc = 0.8697\n","epoch 1\tavg epoch loss = 0.2503\tavg epoch acc = 0.9826\n","epoch 2\tavg epoch loss = 0.1797\tavg epoch acc = 0.9889\n","epoch 3\tavg epoch loss = 0.1477\tavg epoch acc = 0.9915\n","epoch 4\tavg epoch loss = 0.116\tavg epoch acc = 0.9942\n","epoch 5\tavg epoch loss = 0.09541\tavg epoch acc = 0.9959\n","epoch 6\tavg epoch loss = 0.07868\tavg epoch acc = 0.9967\n","epoch 7\tavg epoch loss = 0.06723\tavg epoch acc = 0.998\n","epoch 8\tavg epoch loss = 0.06287\tavg epoch acc = 0.9982\n","epoch 9\tavg epoch loss = 0.05854\tavg epoch acc = 0.9987\n","training took 53.87 s\n","Avg test loss = 0.0396\tAvg test acc = 0.99\n","epoch 0\tavg epoch loss = 0.7777\tavg epoch acc = 0.8689\n","epoch 1\tavg epoch loss = 0.2581\tavg epoch acc = 0.9813\n","epoch 2\tavg epoch loss = 0.1872\tavg epoch acc = 0.9872\n","epoch 3\tavg epoch loss = 0.1484\tavg epoch acc = 0.9909\n","epoch 4\tavg epoch loss = 0.1233\tavg epoch acc = 0.9929\n","epoch 5\tavg epoch loss = 0.1021\tavg epoch acc = 0.9948\n","epoch 6\tavg epoch loss = 0.08698\tavg epoch acc = 0.9961\n","epoch 7\tavg epoch loss = 0.07302\tavg epoch acc = 0.9972\n","epoch 8\tavg epoch loss = 0.06488\tavg epoch acc = 0.9978\n","epoch 9\tavg epoch loss = 0.05705\tavg epoch acc = 0.9985\n","training took 53.69 s\n","Avg test loss = 0.037\tAvg test acc = 0.992\n","{'lr': 0.001, 'beta1': 0.1, 'beta2': 0.999, 'batch_size': 32, 'weight_decay': 0.001, 'epsilon': 1e-08}\n","epoch 0\tavg epoch loss = 0.7838\tavg epoch acc = 0.8671\n","epoch 1\tavg epoch loss = 0.2525\tavg epoch acc = 0.9823\n","epoch 2\tavg epoch loss = 0.1897\tavg epoch acc = 0.9878\n","epoch 3\tavg epoch loss = 0.1433\tavg epoch acc = 0.9914\n","epoch 4\tavg epoch loss = 0.117\tavg epoch acc = 0.9938\n","epoch 5\tavg epoch loss = 0.09862\tavg epoch acc = 0.9952\n","epoch 6\tavg epoch loss = 0.08219\tavg epoch acc = 0.997\n","epoch 7\tavg epoch loss = 0.0702\tavg epoch acc = 0.9974\n","epoch 8\tavg epoch loss = 0.06429\tavg epoch acc = 0.9979\n","epoch 9\tavg epoch loss = 0.06062\tavg epoch acc = 0.9986\n","training took 53.75 s\n","Avg test loss = 0.0404\tAvg test acc = 0.989\n","epoch 0\tavg epoch loss = 0.7799\tavg epoch acc = 0.8707\n","epoch 1\tavg epoch loss = 0.2529\tavg epoch acc = 0.9822\n","epoch 2\tavg epoch loss = 0.1837\tavg epoch acc = 0.9884\n","epoch 3\tavg epoch loss = 0.1424\tavg epoch acc = 0.9917\n","epoch 4\tavg epoch loss = 0.1176\tavg epoch acc = 0.9938\n","epoch 5\tavg epoch loss = 0.09396\tavg epoch acc = 0.9958\n","epoch 6\tavg epoch loss = 0.08258\tavg epoch acc = 0.9968\n","epoch 7\tavg epoch loss = 0.06854\tavg epoch acc = 0.9976\n","epoch 8\tavg epoch loss = 0.06149\tavg epoch acc = 0.9982\n","epoch 9\tavg epoch loss = 0.05459\tavg epoch acc = 0.9987\n","training took 53.89 s\n","Avg test loss = 0.0535\tAvg test acc = 0.987\n","epoch 0\tavg epoch loss = 0.7759\tavg epoch acc = 0.8673\n","epoch 1\tavg epoch loss = 0.2495\tavg epoch acc = 0.9819\n","epoch 2\tavg epoch loss = 0.183\tavg epoch acc = 0.9879\n","epoch 3\tavg epoch loss = 0.1513\tavg epoch acc = 0.9904\n","epoch 4\tavg epoch loss = 0.1169\tavg epoch acc = 0.9937\n","epoch 5\tavg epoch loss = 0.09366\tavg epoch acc = 0.9952\n","epoch 6\tavg epoch loss = 0.08517\tavg epoch acc = 0.9969\n","epoch 7\tavg epoch loss = 0.07349\tavg epoch acc = 0.9977\n","epoch 8\tavg epoch loss = 0.06403\tavg epoch acc = 0.9982\n","epoch 9\tavg epoch loss = 0.05052\tavg epoch acc = 0.9986\n","training took 53.56 s\n","Avg test loss = 0.0592\tAvg test acc = 0.99\n","{'lr': 0.001, 'beta1': 0.1, 'beta2': 0.999, 'batch_size': 32, 'weight_decay': 0.1, 'epsilon': 1e-10}\n","epoch 0\tavg epoch loss = 0.7827\tavg epoch acc = 0.8668\n","epoch 1\tavg epoch loss = 0.251\tavg epoch acc = 0.9823\n","epoch 2\tavg epoch loss = 0.1822\tavg epoch acc = 0.9876\n","epoch 3\tavg epoch loss = 0.1458\tavg epoch acc = 0.9907\n","epoch 4\tavg epoch loss = 0.1228\tavg epoch acc = 0.993\n","epoch 5\tavg epoch loss = 0.1049\tavg epoch acc = 0.9944\n","epoch 6\tavg epoch loss = 0.09187\tavg epoch acc = 0.9956\n","epoch 7\tavg epoch loss = 0.08224\tavg epoch acc = 0.9966\n","epoch 8\tavg epoch loss = 0.07619\tavg epoch acc = 0.9968\n","epoch 9\tavg epoch loss = 0.06795\tavg epoch acc = 0.9975\n","training took 53.78 s\n","Avg test loss = 0.044\tAvg test acc = 0.987\n","epoch 0\tavg epoch loss = 0.7849\tavg epoch acc = 0.869\n","epoch 1\tavg epoch loss = 0.2582\tavg epoch acc = 0.9807\n","epoch 2\tavg epoch loss = 0.1887\tavg epoch acc = 0.9866\n","epoch 3\tavg epoch loss = 0.1489\tavg epoch acc = 0.9902\n","epoch 4\tavg epoch loss = 0.127\tavg epoch acc = 0.9924\n","epoch 5\tavg epoch loss = 0.1071\tavg epoch acc = 0.9941\n","epoch 6\tavg epoch loss = 0.09229\tavg epoch acc = 0.9951\n","epoch 7\tavg epoch loss = 0.08512\tavg epoch acc = 0.9959\n","epoch 8\tavg epoch loss = 0.07598\tavg epoch acc = 0.9964\n","epoch 9\tavg epoch loss = 0.06907\tavg epoch acc = 0.9974\n","training took 53.72 s\n","Avg test loss = 0.0561\tAvg test acc = 0.985\n","epoch 0\tavg epoch loss = 0.7743\tavg epoch acc = 0.8685\n","epoch 1\tavg epoch loss = 0.2487\tavg epoch acc = 0.9826\n","epoch 2\tavg epoch loss = 0.1847\tavg epoch acc = 0.9873\n","epoch 3\tavg epoch loss = 0.1503\tavg epoch acc = 0.9904\n","epoch 4\tavg epoch loss = 0.1239\tavg epoch acc = 0.9927\n","epoch 5\tavg epoch loss = 0.1028\tavg epoch acc = 0.9945\n","epoch 6\tavg epoch loss = 0.09365\tavg epoch acc = 0.9952\n","epoch 7\tavg epoch loss = 0.08395\tavg epoch acc = 0.9959\n","epoch 8\tavg epoch loss = 0.07325\tavg epoch acc = 0.9967\n","epoch 9\tavg epoch loss = 0.06889\tavg epoch acc = 0.9972\n","training took 53.69 s\n","Avg test loss = 0.0528\tAvg test acc = 0.985\n","{'lr': 0.001, 'beta1': 0.1, 'beta2': 0.999, 'batch_size': 32, 'weight_decay': 0.1, 'epsilon': 1e-08}\n","epoch 0\tavg epoch loss = 0.7737\tavg epoch acc = 0.8691\n","epoch 1\tavg epoch loss = 0.2497\tavg epoch acc = 0.9816\n","epoch 2\tavg epoch loss = 0.1861\tavg epoch acc = 0.9875\n","epoch 3\tavg epoch loss = 0.1462\tavg epoch acc = 0.9905\n","epoch 4\tavg epoch loss = 0.12\tavg epoch acc = 0.9929\n","epoch 5\tavg epoch loss = 0.1057\tavg epoch acc = 0.9946\n","epoch 6\tavg epoch loss = 0.09262\tavg epoch acc = 0.9955\n","epoch 7\tavg epoch loss = 0.08052\tavg epoch acc = 0.9964\n","epoch 8\tavg epoch loss = 0.07244\tavg epoch acc = 0.9973\n","epoch 9\tavg epoch loss = 0.06289\tavg epoch acc = 0.9977\n","training took 53.68 s\n","Avg test loss = 0.06\tAvg test acc = 0.984\n","epoch 0\tavg epoch loss = 0.787\tavg epoch acc = 0.869\n","epoch 1\tavg epoch loss = 0.2556\tavg epoch acc = 0.9817\n","epoch 2\tavg epoch loss = 0.1886\tavg epoch acc = 0.9866\n","epoch 3\tavg epoch loss = 0.1502\tavg epoch acc = 0.9901\n","epoch 4\tavg epoch loss = 0.1299\tavg epoch acc = 0.9918\n","epoch 5\tavg epoch loss = 0.1062\tavg epoch acc = 0.9942\n","epoch 6\tavg epoch loss = 0.09441\tavg epoch acc = 0.9953\n","epoch 7\tavg epoch loss = 0.0912\tavg epoch acc = 0.9962\n","epoch 8\tavg epoch loss = 0.07437\tavg epoch acc = 0.9971\n","epoch 9\tavg epoch loss = 0.07083\tavg epoch acc = 0.9972\n","training took 53.84 s\n","Avg test loss = 0.04\tAvg test acc = 0.988\n","epoch 0\tavg epoch loss = 0.7801\tavg epoch acc = 0.8664\n","epoch 1\tavg epoch loss = 0.2529\tavg epoch acc = 0.9809\n","epoch 2\tavg epoch loss = 0.185\tavg epoch acc = 0.9871\n","epoch 3\tavg epoch loss = 0.15\tavg epoch acc = 0.9902\n","epoch 4\tavg epoch loss = 0.1217\tavg epoch acc = 0.9926\n","epoch 5\tavg epoch loss = 0.1084\tavg epoch acc = 0.9939\n","epoch 6\tavg epoch loss = 0.09503\tavg epoch acc = 0.9952\n","epoch 7\tavg epoch loss = 0.08015\tavg epoch acc = 0.9964\n","epoch 8\tavg epoch loss = 0.07727\tavg epoch acc = 0.9966\n","epoch 9\tavg epoch loss = 0.06792\tavg epoch acc = 0.9973\n","training took 54.25 s\n","Avg test loss = 0.0325\tAvg test acc = 0.99\n","{'lr': 0.001, 'beta1': 0.1, 'beta2': 0.999, 'batch_size': 64, 'weight_decay': 0.001, 'epsilon': 1e-10}\n","epoch 0\tavg epoch loss = 1.094\tavg epoch acc = 0.7902\n","epoch 1\tavg epoch loss = 0.3231\tavg epoch acc = 0.9768\n","epoch 2\tavg epoch loss = 0.2277\tavg epoch acc = 0.985\n","epoch 3\tavg epoch loss = 0.1786\tavg epoch acc = 0.9895\n","epoch 4\tavg epoch loss = 0.146\tavg epoch acc = 0.9918\n","epoch 5\tavg epoch loss = 0.1241\tavg epoch acc = 0.9935\n","epoch 6\tavg epoch loss = 0.1029\tavg epoch acc = 0.9956\n","epoch 7\tavg epoch loss = 0.09337\tavg epoch acc = 0.9962\n","epoch 8\tavg epoch loss = 0.08197\tavg epoch acc = 0.9971\n","epoch 9\tavg epoch loss = 0.07382\tavg epoch acc = 0.9977\n","training took 27.94 s\n","Avg test loss = 0.0396\tAvg test acc = 0.99\n","epoch 0\tavg epoch loss = 1.101\tavg epoch acc = 0.7908\n","epoch 1\tavg epoch loss = 0.3296\tavg epoch acc = 0.9764\n","epoch 2\tavg epoch loss = 0.2327\tavg epoch acc = 0.9856\n","epoch 3\tavg epoch loss = 0.1837\tavg epoch acc = 0.9889\n","epoch 4\tavg epoch loss = 0.1473\tavg epoch acc = 0.992\n","epoch 5\tavg epoch loss = 0.1267\tavg epoch acc = 0.9932\n","epoch 6\tavg epoch loss = 0.1078\tavg epoch acc = 0.9952\n","epoch 7\tavg epoch loss = 0.08871\tavg epoch acc = 0.9964\n","epoch 8\tavg epoch loss = 0.07923\tavg epoch acc = 0.997\n","epoch 9\tavg epoch loss = 0.07117\tavg epoch acc = 0.9977\n","training took 27.87 s\n","Avg test loss = 0.042\tAvg test acc = 0.991\n","epoch 0\tavg epoch loss = 1.092\tavg epoch acc = 0.7912\n","epoch 1\tavg epoch loss = 0.3246\tavg epoch acc = 0.976\n","epoch 2\tavg epoch loss = 0.2283\tavg epoch acc = 0.9846\n","epoch 3\tavg epoch loss = 0.1806\tavg epoch acc = 0.9887\n","epoch 4\tavg epoch loss = 0.1485\tavg epoch acc = 0.9915\n","epoch 5\tavg epoch loss = 0.1268\tavg epoch acc = 0.9933\n","epoch 6\tavg epoch loss = 0.1065\tavg epoch acc = 0.9948\n","epoch 7\tavg epoch loss = 0.09237\tavg epoch acc = 0.9962\n","epoch 8\tavg epoch loss = 0.07828\tavg epoch acc = 0.9971\n","epoch 9\tavg epoch loss = 0.07091\tavg epoch acc = 0.9976\n","training took 27.85 s\n","Avg test loss = 0.0609\tAvg test acc = 0.985\n","{'lr': 0.001, 'beta1': 0.1, 'beta2': 0.999, 'batch_size': 64, 'weight_decay': 0.001, 'epsilon': 1e-08}\n","epoch 0\tavg epoch loss = 1.092\tavg epoch acc = 0.7924\n","epoch 1\tavg epoch loss = 0.3225\tavg epoch acc = 0.9764\n","epoch 2\tavg epoch loss = 0.2273\tavg epoch acc = 0.985\n","epoch 3\tavg epoch loss = 0.1796\tavg epoch acc = 0.9891\n","epoch 4\tavg epoch loss = 0.1471\tavg epoch acc = 0.9918\n","epoch 5\tavg epoch loss = 0.1214\tavg epoch acc = 0.994\n","epoch 6\tavg epoch loss = 0.1027\tavg epoch acc = 0.9956\n","epoch 7\tavg epoch loss = 0.09482\tavg epoch acc = 0.9962\n","epoch 8\tavg epoch loss = 0.0741\tavg epoch acc = 0.9973\n","epoch 9\tavg epoch loss = 0.0681\tavg epoch acc = 0.9977\n","training took 27.88 s\n","Avg test loss = 0.0463\tAvg test acc = 0.989\n","epoch 0\tavg epoch loss = 1.098\tavg epoch acc = 0.7885\n","epoch 1\tavg epoch loss = 0.32\tavg epoch acc = 0.9769\n","epoch 2\tavg epoch loss = 0.2264\tavg epoch acc = 0.985\n","epoch 3\tavg epoch loss = 0.1777\tavg epoch acc = 0.9893\n","epoch 4\tavg epoch loss = 0.1462\tavg epoch acc = 0.9919\n","epoch 5\tavg epoch loss = 0.1223\tavg epoch acc = 0.9938\n","epoch 6\tavg epoch loss = 0.1107\tavg epoch acc = 0.9951\n","epoch 7\tavg epoch loss = 0.09735\tavg epoch acc = 0.996\n","epoch 8\tavg epoch loss = 0.07813\tavg epoch acc = 0.9973\n","epoch 9\tavg epoch loss = 0.06851\tavg epoch acc = 0.9979\n","training took 27.78 s\n","Avg test loss = 0.0443\tAvg test acc = 0.988\n","epoch 0\tavg epoch loss = 1.09\tavg epoch acc = 0.7935\n","epoch 1\tavg epoch loss = 0.3166\tavg epoch acc = 0.9777\n","epoch 2\tavg epoch loss = 0.2236\tavg epoch acc = 0.9862\n","epoch 3\tavg epoch loss = 0.1735\tavg epoch acc = 0.99\n","epoch 4\tavg epoch loss = 0.1419\tavg epoch acc = 0.9923\n","epoch 5\tavg epoch loss = 0.1194\tavg epoch acc = 0.9942\n","epoch 6\tavg epoch loss = 0.1049\tavg epoch acc = 0.9955\n","epoch 7\tavg epoch loss = 0.09191\tavg epoch acc = 0.9964\n","epoch 8\tavg epoch loss = 0.07402\tavg epoch acc = 0.9974\n","epoch 9\tavg epoch loss = 0.07021\tavg epoch acc = 0.9979\n","training took 27.97 s\n","Avg test loss = 0.043\tAvg test acc = 0.988\n","{'lr': 0.001, 'beta1': 0.1, 'beta2': 0.999, 'batch_size': 64, 'weight_decay': 0.1, 'epsilon': 1e-10}\n","epoch 0\tavg epoch loss = 1.096\tavg epoch acc = 0.7899\n","epoch 1\tavg epoch loss = 0.322\tavg epoch acc = 0.9765\n","epoch 2\tavg epoch loss = 0.2279\tavg epoch acc = 0.9842\n","epoch 3\tavg epoch loss = 0.1825\tavg epoch acc = 0.9879\n","epoch 4\tavg epoch loss = 0.1553\tavg epoch acc = 0.9903\n","epoch 5\tavg epoch loss = 0.1299\tavg epoch acc = 0.9925\n","epoch 6\tavg epoch loss = 0.1132\tavg epoch acc = 0.9939\n","epoch 7\tavg epoch loss = 0.1012\tavg epoch acc = 0.9949\n","epoch 8\tavg epoch loss = 0.08611\tavg epoch acc = 0.9962\n","epoch 9\tavg epoch loss = 0.08278\tavg epoch acc = 0.9965\n","training took 27.76 s\n","Avg test loss = 0.041\tAvg test acc = 0.99\n","epoch 0\tavg epoch loss = 1.097\tavg epoch acc = 0.791\n","epoch 1\tavg epoch loss = 0.3283\tavg epoch acc = 0.9758\n","epoch 2\tavg epoch loss = 0.2324\tavg epoch acc = 0.9841\n","epoch 3\tavg epoch loss = 0.1831\tavg epoch acc = 0.9881\n","epoch 4\tavg epoch loss = 0.1505\tavg epoch acc = 0.9909\n","epoch 5\tavg epoch loss = 0.1298\tavg epoch acc = 0.9928\n","epoch 6\tavg epoch loss = 0.1116\tavg epoch acc = 0.9942\n","epoch 7\tavg epoch loss = 0.09878\tavg epoch acc = 0.9955\n","epoch 8\tavg epoch loss = 0.08884\tavg epoch acc = 0.9962\n","epoch 9\tavg epoch loss = 0.07378\tavg epoch acc = 0.9971\n","training took 27.94 s\n","Avg test loss = 0.0376\tAvg test acc = 0.989\n","epoch 0\tavg epoch loss = 1.096\tavg epoch acc = 0.7914\n","epoch 1\tavg epoch loss = 0.3157\tavg epoch acc = 0.9766\n","epoch 2\tavg epoch loss = 0.2251\tavg epoch acc = 0.9848\n","epoch 3\tavg epoch loss = 0.1764\tavg epoch acc = 0.9887\n","epoch 4\tavg epoch loss = 0.1511\tavg epoch acc = 0.991\n","epoch 5\tavg epoch loss = 0.1232\tavg epoch acc = 0.9933\n","epoch 6\tavg epoch loss = 0.1057\tavg epoch acc = 0.9947\n","epoch 7\tavg epoch loss = 0.09415\tavg epoch acc = 0.9957\n","epoch 8\tavg epoch loss = 0.08863\tavg epoch acc = 0.9962\n","epoch 9\tavg epoch loss = 0.07553\tavg epoch acc = 0.997\n","training took 27.82 s\n","Avg test loss = 0.0514\tAvg test acc = 0.984\n","{'lr': 0.001, 'beta1': 0.1, 'beta2': 0.999, 'batch_size': 64, 'weight_decay': 0.1, 'epsilon': 1e-08}\n","epoch 0\tavg epoch loss = 1.097\tavg epoch acc = 0.7919\n","epoch 1\tavg epoch loss = 0.3265\tavg epoch acc = 0.9759\n","epoch 2\tavg epoch loss = 0.2296\tavg epoch acc = 0.9847\n","epoch 3\tavg epoch loss = 0.184\tavg epoch acc = 0.9885\n","epoch 4\tavg epoch loss = 0.1513\tavg epoch acc = 0.9909\n","epoch 5\tavg epoch loss = 0.1301\tavg epoch acc = 0.9928\n","epoch 6\tavg epoch loss = 0.116\tavg epoch acc = 0.9938\n","epoch 7\tavg epoch loss = 0.09643\tavg epoch acc = 0.9955\n","epoch 8\tavg epoch loss = 0.08494\tavg epoch acc = 0.9962\n","epoch 9\tavg epoch loss = 0.0802\tavg epoch acc = 0.9967\n","training took 27.71 s\n","Avg test loss = 0.0424\tAvg test acc = 0.987\n","epoch 0\tavg epoch loss = 1.099\tavg epoch acc = 0.7901\n","epoch 1\tavg epoch loss = 0.3227\tavg epoch acc = 0.9769\n","epoch 2\tavg epoch loss = 0.2266\tavg epoch acc = 0.9852\n","epoch 3\tavg epoch loss = 0.1795\tavg epoch acc = 0.989\n","epoch 4\tavg epoch loss = 0.1501\tavg epoch acc = 0.9912\n","epoch 5\tavg epoch loss = 0.1281\tavg epoch acc = 0.9931\n","epoch 6\tavg epoch loss = 0.1096\tavg epoch acc = 0.9941\n","epoch 7\tavg epoch loss = 0.0962\tavg epoch acc = 0.9954\n","epoch 8\tavg epoch loss = 0.08497\tavg epoch acc = 0.9963\n","epoch 9\tavg epoch loss = 0.07856\tavg epoch acc = 0.9971\n","training took 27.86 s\n","Avg test loss = 0.0389\tAvg test acc = 0.988\n","epoch 0\tavg epoch loss = 1.094\tavg epoch acc = 0.7912\n","epoch 1\tavg epoch loss = 0.3174\tavg epoch acc = 0.9774\n","epoch 2\tavg epoch loss = 0.2253\tavg epoch acc = 0.9849\n","epoch 3\tavg epoch loss = 0.1768\tavg epoch acc = 0.9889\n","epoch 4\tavg epoch loss = 0.1444\tavg epoch acc = 0.9917\n","epoch 5\tavg epoch loss = 0.1232\tavg epoch acc = 0.9933\n","epoch 6\tavg epoch loss = 0.1046\tavg epoch acc = 0.995\n","epoch 7\tavg epoch loss = 0.09298\tavg epoch acc = 0.996\n","epoch 8\tavg epoch loss = 0.08368\tavg epoch acc = 0.9969\n","epoch 9\tavg epoch loss = 0.07711\tavg epoch acc = 0.9972\n","training took 27.83 s\n","Avg test loss = 0.0424\tAvg test acc = 0.989\n","{'lr': 0.001, 'beta1': 0.1, 'beta2': 0.999, 'batch_size': 128, 'weight_decay': 0.001, 'epsilon': 1e-10}\n","epoch 0\tavg epoch loss = 1.583\tavg epoch acc = 0.6575\n","epoch 1\tavg epoch loss = 0.4796\tavg epoch acc = 0.9619\n","epoch 2\tavg epoch loss = 0.3161\tavg epoch acc = 0.9779\n","epoch 3\tavg epoch loss = 0.2444\tavg epoch acc = 0.9844\n","epoch 4\tavg epoch loss = 0.2006\tavg epoch acc = 0.9879\n","epoch 5\tavg epoch loss = 0.1712\tavg epoch acc = 0.9905\n","epoch 6\tavg epoch loss = 0.1484\tavg epoch acc = 0.9925\n","epoch 7\tavg epoch loss = 0.1287\tavg epoch acc = 0.9938\n","epoch 8\tavg epoch loss = 0.1139\tavg epoch acc = 0.9949\n","epoch 9\tavg epoch loss = 0.09832\tavg epoch acc = 0.9961\n","training took 17.23 s\n","Avg test loss = 0.0747\tAvg test acc = 0.979\n","epoch 0\tavg epoch loss = 1.579\tavg epoch acc = 0.6557\n","epoch 1\tavg epoch loss = 0.4824\tavg epoch acc = 0.9615\n","epoch 2\tavg epoch loss = 0.3221\tavg epoch acc = 0.978\n","epoch 3\tavg epoch loss = 0.2516\tavg epoch acc = 0.9842\n","epoch 4\tavg epoch loss = 0.207\tavg epoch acc = 0.9877\n","epoch 5\tavg epoch loss = 0.1735\tavg epoch acc = 0.9906\n","epoch 6\tavg epoch loss = 0.1484\tavg epoch acc = 0.9925\n","epoch 7\tavg epoch loss = 0.128\tavg epoch acc = 0.9942\n","epoch 8\tavg epoch loss = 0.114\tavg epoch acc = 0.9952\n","epoch 9\tavg epoch loss = 0.1086\tavg epoch acc = 0.9954\n","training took 17.19 s\n","Avg test loss = 0.0417\tAvg test acc = 0.989\n","epoch 0\tavg epoch loss = 1.571\tavg epoch acc = 0.6597\n","epoch 1\tavg epoch loss = 0.4815\tavg epoch acc = 0.9621\n","epoch 2\tavg epoch loss = 0.3178\tavg epoch acc = 0.9781\n","epoch 3\tavg epoch loss = 0.2469\tavg epoch acc = 0.9844\n","epoch 4\tavg epoch loss = 0.2036\tavg epoch acc = 0.9875\n","epoch 5\tavg epoch loss = 0.1716\tavg epoch acc = 0.9901\n","epoch 6\tavg epoch loss = 0.1467\tavg epoch acc = 0.9919\n","epoch 7\tavg epoch loss = 0.1294\tavg epoch acc = 0.9935\n","epoch 8\tavg epoch loss = 0.1175\tavg epoch acc = 0.9944\n","epoch 9\tavg epoch loss = 0.09904\tavg epoch acc = 0.9955\n","training took 17.26 s\n","Avg test loss = 0.107\tAvg test acc = 0.963\n","{'lr': 0.001, 'beta1': 0.1, 'beta2': 0.999, 'batch_size': 128, 'weight_decay': 0.001, 'epsilon': 1e-08}\n","epoch 0\tavg epoch loss = 1.571\tavg epoch acc = 0.6606\n","epoch 1\tavg epoch loss = 0.481\tavg epoch acc = 0.9623\n","epoch 2\tavg epoch loss = 0.3193\tavg epoch acc = 0.9778\n","epoch 3\tavg epoch loss = 0.2492\tavg epoch acc = 0.9837\n","epoch 4\tavg epoch loss = 0.2062\tavg epoch acc = 0.9871\n","epoch 5\tavg epoch loss = 0.1745\tavg epoch acc = 0.9901\n","epoch 6\tavg epoch loss = 0.1519\tavg epoch acc = 0.992\n","epoch 7\tavg epoch loss = 0.13\tavg epoch acc = 0.9939\n","epoch 8\tavg epoch loss = 0.1119\tavg epoch acc = 0.9952\n","epoch 9\tavg epoch loss = 0.1128\tavg epoch acc = 0.9956\n","training took 17.27 s\n","Avg test loss = 0.0539\tAvg test acc = 0.985\n","epoch 0\tavg epoch loss = 1.577\tavg epoch acc = 0.6573\n","epoch 1\tavg epoch loss = 0.4801\tavg epoch acc = 0.9617\n","epoch 2\tavg epoch loss = 0.3213\tavg epoch acc = 0.9773\n","epoch 3\tavg epoch loss = 0.2505\tavg epoch acc = 0.9831\n","epoch 4\tavg epoch loss = 0.2071\tavg epoch acc = 0.9872\n","epoch 5\tavg epoch loss = 0.1739\tavg epoch acc = 0.99\n","epoch 6\tavg epoch loss = 0.1505\tavg epoch acc = 0.9918\n","epoch 7\tavg epoch loss = 0.1312\tavg epoch acc = 0.9934\n","epoch 8\tavg epoch loss = 0.1152\tavg epoch acc = 0.9948\n","epoch 9\tavg epoch loss = 0.0997\tavg epoch acc = 0.9959\n","training took 17.29 s\n","Avg test loss = 0.0409\tAvg test acc = 0.988\n","epoch 0\tavg epoch loss = 1.583\tavg epoch acc = 0.6554\n","epoch 1\tavg epoch loss = 0.4868\tavg epoch acc = 0.961\n","epoch 2\tavg epoch loss = 0.321\tavg epoch acc = 0.9781\n","epoch 3\tavg epoch loss = 0.2479\tavg epoch acc = 0.9843\n","epoch 4\tavg epoch loss = 0.2048\tavg epoch acc = 0.9876\n","epoch 5\tavg epoch loss = 0.172\tavg epoch acc = 0.9904\n","epoch 6\tavg epoch loss = 0.1467\tavg epoch acc = 0.9924\n","epoch 7\tavg epoch loss = 0.1283\tavg epoch acc = 0.9938\n","epoch 8\tavg epoch loss = 0.1149\tavg epoch acc = 0.9945\n","epoch 9\tavg epoch loss = 0.09911\tavg epoch acc = 0.9959\n","training took 17.17 s\n","Avg test loss = 0.073\tAvg test acc = 0.977\n","{'lr': 0.001, 'beta1': 0.1, 'beta2': 0.999, 'batch_size': 128, 'weight_decay': 0.1, 'epsilon': 1e-10}\n","epoch 0\tavg epoch loss = 1.575\tavg epoch acc = 0.6587\n","epoch 1\tavg epoch loss = 0.4812\tavg epoch acc = 0.9613\n","epoch 2\tavg epoch loss = 0.3187\tavg epoch acc = 0.9779\n","epoch 3\tavg epoch loss = 0.2479\tavg epoch acc = 0.9843\n","epoch 4\tavg epoch loss = 0.2044\tavg epoch acc = 0.9876\n","epoch 5\tavg epoch loss = 0.1737\tavg epoch acc = 0.9899\n","epoch 6\tavg epoch loss = 0.1491\tavg epoch acc = 0.992\n","epoch 7\tavg epoch loss = 0.1301\tavg epoch acc = 0.9937\n","epoch 8\tavg epoch loss = 0.1142\tavg epoch acc = 0.9948\n","epoch 9\tavg epoch loss = 0.1041\tavg epoch acc = 0.9957\n","training took 17.22 s\n","Avg test loss = 0.067\tAvg test acc = 0.978\n","epoch 0\tavg epoch loss = 1.584\tavg epoch acc = 0.6551\n","epoch 1\tavg epoch loss = 0.4841\tavg epoch acc = 0.9617\n","epoch 2\tavg epoch loss = 0.318\tavg epoch acc = 0.9779\n","epoch 3\tavg epoch loss = 0.2471\tavg epoch acc = 0.9833\n","epoch 4\tavg epoch loss = 0.2036\tavg epoch acc = 0.9873\n","epoch 5\tavg epoch loss = 0.1735\tavg epoch acc = 0.9898\n","epoch 6\tavg epoch loss = 0.1491\tavg epoch acc = 0.9917\n","epoch 7\tavg epoch loss = 0.1289\tavg epoch acc = 0.9929\n","epoch 8\tavg epoch loss = 0.1128\tavg epoch acc = 0.9943\n","epoch 9\tavg epoch loss = 0.1016\tavg epoch acc = 0.9952\n","training took 17.24 s\n","Avg test loss = 0.0566\tAvg test acc = 0.984\n","epoch 0\tavg epoch loss = 1.582\tavg epoch acc = 0.6545\n","epoch 1\tavg epoch loss = 0.4762\tavg epoch acc = 0.9629\n","epoch 2\tavg epoch loss = 0.3187\tavg epoch acc = 0.9785\n","epoch 3\tavg epoch loss = 0.2505\tavg epoch acc = 0.9836\n","epoch 4\tavg epoch loss = 0.207\tavg epoch acc = 0.9866\n","epoch 5\tavg epoch loss = 0.1758\tavg epoch acc = 0.9896\n","epoch 6\tavg epoch loss = 0.1531\tavg epoch acc = 0.9915\n","epoch 7\tavg epoch loss = 0.137\tavg epoch acc = 0.9929\n","epoch 8\tavg epoch loss = 0.1194\tavg epoch acc = 0.994\n","epoch 9\tavg epoch loss = 0.1045\tavg epoch acc = 0.9951\n","training took 17.27 s\n","Avg test loss = 0.055\tAvg test acc = 0.981\n","{'lr': 0.001, 'beta1': 0.1, 'beta2': 0.999, 'batch_size': 128, 'weight_decay': 0.1, 'epsilon': 1e-08}\n","epoch 0\tavg epoch loss = 1.58\tavg epoch acc = 0.6586\n","epoch 1\tavg epoch loss = 0.4799\tavg epoch acc = 0.9613\n","epoch 2\tavg epoch loss = 0.3193\tavg epoch acc = 0.9772\n","epoch 3\tavg epoch loss = 0.2485\tavg epoch acc = 0.9837\n","epoch 4\tavg epoch loss = 0.2047\tavg epoch acc = 0.9874\n","epoch 5\tavg epoch loss = 0.1723\tavg epoch acc = 0.9901\n","epoch 6\tavg epoch loss = 0.1491\tavg epoch acc = 0.9917\n","epoch 7\tavg epoch loss = 0.1316\tavg epoch acc = 0.9934\n","epoch 8\tavg epoch loss = 0.1163\tavg epoch acc = 0.9948\n","epoch 9\tavg epoch loss = 0.1021\tavg epoch acc = 0.9958\n","training took 17.25 s\n","Avg test loss = 0.0437\tAvg test acc = 0.989\n","epoch 0\tavg epoch loss = 1.581\tavg epoch acc = 0.6558\n","epoch 1\tavg epoch loss = 0.4877\tavg epoch acc = 0.9613\n","epoch 2\tavg epoch loss = 0.3217\tavg epoch acc = 0.9779\n","epoch 3\tavg epoch loss = 0.2496\tavg epoch acc = 0.9843\n","epoch 4\tavg epoch loss = 0.2059\tavg epoch acc = 0.9877\n","epoch 5\tavg epoch loss = 0.175\tavg epoch acc = 0.9907\n","epoch 6\tavg epoch loss = 0.1505\tavg epoch acc = 0.9924\n","epoch 7\tavg epoch loss = 0.1318\tavg epoch acc = 0.9934\n","epoch 8\tavg epoch loss = 0.1184\tavg epoch acc = 0.9945\n","epoch 9\tavg epoch loss = 0.1039\tavg epoch acc = 0.9955\n","training took 17.32 s\n","Avg test loss = 0.151\tAvg test acc = 0.949\n","epoch 0\tavg epoch loss = 1.577\tavg epoch acc = 0.6557\n","epoch 1\tavg epoch loss = 0.4815\tavg epoch acc = 0.9624\n","epoch 2\tavg epoch loss = 0.3187\tavg epoch acc = 0.9777\n","epoch 3\tavg epoch loss = 0.2478\tavg epoch acc = 0.9838\n","epoch 4\tavg epoch loss = 0.2052\tavg epoch acc = 0.9872\n","epoch 5\tavg epoch loss = 0.1744\tavg epoch acc = 0.9898\n","epoch 6\tavg epoch loss = 0.1496\tavg epoch acc = 0.9918\n","epoch 7\tavg epoch loss = 0.131\tavg epoch acc = 0.9932\n","epoch 8\tavg epoch loss = 0.1149\tavg epoch acc = 0.9943\n","epoch 9\tavg epoch loss = 0.0991\tavg epoch acc = 0.9955\n","training took 17.3 s\n","Avg test loss = 0.106\tAvg test acc = 0.965\n","{'lr': 0.001, 'beta1': 0.9, 'beta2': 0.5, 'batch_size': 32, 'weight_decay': 0.001, 'epsilon': 1e-10}\n","epoch 0\tavg epoch loss = 7.264e+08\tavg epoch acc = 0.0986\n","epoch 1\tavg epoch loss = 7.946e+08\tavg epoch acc = 0.0997\n","epoch 2\tavg epoch loss = 7.776e+08\tavg epoch acc = 0.0997\n","epoch 3\tavg epoch loss = 7.619e+08\tavg epoch acc = 0.0997\n","epoch 4\tavg epoch loss = 7.471e+08\tavg epoch acc = 0.0997\n","epoch 5\tavg epoch loss = 7.326e+08\tavg epoch acc = 0.0997\n","epoch 6\tavg epoch loss = 7.187e+08\tavg epoch acc = 0.0997\n","epoch 7\tavg epoch loss = 7.052e+08\tavg epoch acc = 0.0997\n","epoch 8\tavg epoch loss = 6.932e+08\tavg epoch acc = 0.0997\n","epoch 9\tavg epoch loss = 6.823e+08\tavg epoch acc = 0.0997\n","training took 53.98 s\n","Avg test loss = 6.78e+08\tAvg test acc = 0.0965\n","epoch 0\tavg epoch loss = 1.391e+12\tavg epoch acc = 0.09928\n","epoch 1\tavg epoch loss = nan\tavg epoch acc = 0.09835\n","epoch 2\tavg epoch loss = nan\tavg epoch acc = 0.09932\n","epoch 3\tavg epoch loss = nan\tavg epoch acc = 0.09932\n","epoch 4\tavg epoch loss = nan\tavg epoch acc = 0.09932\n","epoch 5\tavg epoch loss = nan\tavg epoch acc = 0.09932\n","epoch 6\tavg epoch loss = nan\tavg epoch acc = 0.09932\n","epoch 7\tavg epoch loss = nan\tavg epoch acc = 0.09932\n","epoch 8\tavg epoch loss = nan\tavg epoch acc = 0.09932\n","epoch 9\tavg epoch loss = nan\tavg epoch acc = 0.09932\n","training took 54.02 s\n","Avg test loss = nan\tAvg test acc = 0.0975\n","epoch 0\tavg epoch loss = 6.273e+05\tavg epoch acc = 0.09575\n","epoch 1\tavg epoch loss = 2.3e+05\tavg epoch acc = 0.09863\n","epoch 2\tavg epoch loss = 3.191e+04\tavg epoch acc = 0.09835\n","epoch 3\tavg epoch loss = 5.203e+03\tavg epoch acc = 0.0975\n","epoch 4\tavg epoch loss = 2.731e+03\tavg epoch acc = 0.0995\n","epoch 5\tavg epoch loss = 1.332e+03\tavg epoch acc = 0.1036\n","epoch 6\tavg epoch loss = 310.4\tavg epoch acc = 0.1032\n","epoch 7\tavg epoch loss = 12.72\tavg epoch acc = 0.09957\n","epoch 8\tavg epoch loss = 14.21\tavg epoch acc = 0.0993\n","epoch 9\tavg epoch loss = 13.47\tavg epoch acc = 0.09992\n","training took 54.3 s\n","Avg test loss = 12.0\tAvg test acc = 0.1\n","{'lr': 0.001, 'beta1': 0.9, 'beta2': 0.5, 'batch_size': 32, 'weight_decay': 0.001, 'epsilon': 1e-08}\n","epoch 0\tavg epoch loss = nan\tavg epoch acc = 0.09907\n","epoch 1\tavg epoch loss = nan\tavg epoch acc = 0.0988\n","epoch 2\tavg epoch loss = nan\tavg epoch acc = 0.0988\n","epoch 3\tavg epoch loss = nan\tavg epoch acc = 0.0988\n","epoch 4\tavg epoch loss = nan\tavg epoch acc = 0.0988\n","epoch 5\tavg epoch loss = nan\tavg epoch acc = 0.0988\n","epoch 6\tavg epoch loss = nan\tavg epoch acc = 0.0988\n","epoch 7\tavg epoch loss = nan\tavg epoch acc = 0.0988\n","epoch 8\tavg epoch loss = nan\tavg epoch acc = 0.0988\n","epoch 9\tavg epoch loss = nan\tavg epoch acc = 0.0988\n","training took 53.86 s\n","Avg test loss = nan\tAvg test acc = 0.0985\n","epoch 0\tavg epoch loss = 6.628e+07\tavg epoch acc = 0.1009\n","epoch 1\tavg epoch loss = 2.863e+07\tavg epoch acc = 0.1002\n","epoch 2\tavg epoch loss = 2.502e+07\tavg epoch acc = 0.1002\n","epoch 3\tavg epoch loss = 2.173e+07\tavg epoch acc = 0.1002\n","epoch 4\tavg epoch loss = 1.893e+07\tavg epoch acc = 0.1002\n","epoch 5\tavg epoch loss = 1.693e+07\tavg epoch acc = 0.1007\n","epoch 6\tavg epoch loss = 1.553e+07\tavg epoch acc = 0.1011\n","epoch 7\tavg epoch loss = 1.425e+07\tavg epoch acc = 0.09917\n","epoch 8\tavg epoch loss = 1.298e+07\tavg epoch acc = 0.1002\n","epoch 9\tavg epoch loss = 1.181e+07\tavg epoch acc = 0.09957\n","training took 53.82 s\n","Avg test loss = 1.15e+07\tAvg test acc = 0.0979\n","epoch 0\tavg epoch loss = 2.422e+33\tavg epoch acc = 0.09165\n","epoch 1\tavg epoch loss = 2.591e+17\tavg epoch acc = 0.09008\n","epoch 2\tavg epoch loss = 2.584e+17\tavg epoch acc = 0.09008\n","epoch 3\tavg epoch loss = 2.577e+17\tavg epoch acc = 0.09008\n","epoch 4\tavg epoch loss = 2.571e+17\tavg epoch acc = 0.09008\n","epoch 5\tavg epoch loss = 2.564e+17\tavg epoch acc = 0.09008\n","epoch 6\tavg epoch loss = 2.558e+17\tavg epoch acc = 0.09008\n","epoch 7\tavg epoch loss = 2.551e+17\tavg epoch acc = 0.09008\n","epoch 8\tavg epoch loss = 2.544e+17\tavg epoch acc = 0.09008\n","epoch 9\tavg epoch loss = 2.538e+17\tavg epoch acc = 0.09008\n","training took 54.05 s\n","Avg test loss = 2.53e+17\tAvg test acc = 0.0909\n","{'lr': 0.001, 'beta1': 0.9, 'beta2': 0.5, 'batch_size': 32, 'weight_decay': 0.1, 'epsilon': 1e-10}\n","epoch 0\tavg epoch loss = nan\tavg epoch acc = 0.09498\n","epoch 1\tavg epoch loss = nan\tavg epoch acc = 0.0982\n","epoch 2\tavg epoch loss = nan\tavg epoch acc = 0.0982\n","epoch 3\tavg epoch loss = nan\tavg epoch acc = 0.0982\n","epoch 4\tavg epoch loss = nan\tavg epoch acc = 0.0982\n","epoch 5\tavg epoch loss = nan\tavg epoch acc = 0.0982\n","epoch 6\tavg epoch loss = nan\tavg epoch acc = 0.0982\n","epoch 7\tavg epoch loss = nan\tavg epoch acc = 0.0982\n","epoch 8\tavg epoch loss = nan\tavg epoch acc = 0.0982\n","epoch 9\tavg epoch loss = nan\tavg epoch acc = 0.0982\n","training took 54.36 s\n","Avg test loss = nan\tAvg test acc = 0.0998\n","epoch 0\tavg epoch loss = nan\tavg epoch acc = 0.1019\n","epoch 1\tavg epoch loss = nan\tavg epoch acc = 0.09932\n","epoch 2\tavg epoch loss = nan\tavg epoch acc = 0.09932\n","epoch 3\tavg epoch loss = nan\tavg epoch acc = 0.09932\n","epoch 4\tavg epoch loss = nan\tavg epoch acc = 0.09932\n","epoch 5\tavg epoch loss = nan\tavg epoch acc = 0.09932\n","epoch 6\tavg epoch loss = nan\tavg epoch acc = 0.09932\n","epoch 7\tavg epoch loss = nan\tavg epoch acc = 0.09932\n","epoch 8\tavg epoch loss = nan\tavg epoch acc = 0.09932\n","epoch 9\tavg epoch loss = nan\tavg epoch acc = 0.09932\n","training took 53.98 s\n","Avg test loss = nan\tAvg test acc = 0.0975\n","epoch 0\tavg epoch loss = 1.832e+09\tavg epoch acc = 0.09685\n","epoch 1\tavg epoch loss = 9.222e+06\tavg epoch acc = 0.0973\n","epoch 2\tavg epoch loss = 4.555e+06\tavg epoch acc = 0.0974\n","epoch 3\tavg epoch loss = 3.096e+06\tavg epoch acc = 0.0973\n","epoch 4\tavg epoch loss = 2.086e+06\tavg epoch acc = 0.09855\n","epoch 5\tavg epoch loss = 1.429e+06\tavg epoch acc = 0.1002\n","epoch 6\tavg epoch loss = 1.046e+06\tavg epoch acc = 0.1008\n","epoch 7\tavg epoch loss = 7.591e+05\tavg epoch acc = 0.09935\n","epoch 8\tavg epoch loss = 5.448e+05\tavg epoch acc = 0.0994\n","epoch 9\tavg epoch loss = 3.885e+05\tavg epoch acc = 0.09942\n","training took 54.1 s\n","Avg test loss = 3.25e+05\tAvg test acc = 0.099\n","{'lr': 0.001, 'beta1': 0.9, 'beta2': 0.5, 'batch_size': 32, 'weight_decay': 0.1, 'epsilon': 1e-08}\n","epoch 0\tavg epoch loss = 1.95e+07\tavg epoch acc = 0.09807\n","epoch 1\tavg epoch loss = 9.148e+06\tavg epoch acc = 0.09803\n","epoch 2\tavg epoch loss = 5.305e+06\tavg epoch acc = 0.1027\n","epoch 3\tavg epoch loss = 2.973e+06\tavg epoch acc = 0.1027\n","epoch 4\tavg epoch loss = 1.684e+06\tavg epoch acc = 0.0964\n","epoch 5\tavg epoch loss = 1.096e+06\tavg epoch acc = 0.09505\n","epoch 6\tavg epoch loss = 7.586e+05\tavg epoch acc = 0.0955\n","epoch 7\tavg epoch loss = 5.605e+05\tavg epoch acc = 0.09757\n","epoch 8\tavg epoch loss = 4.151e+05\tavg epoch acc = 0.0963\n","epoch 9\tavg epoch loss = 3.061e+05\tavg epoch acc = 0.09905\n","training took 54.31 s\n","Avg test loss = 2.62e+05\tAvg test acc = 0.0993\n","epoch 0\tavg epoch loss = nan\tavg epoch acc = 0.1019\n","epoch 1\tavg epoch loss = nan\tavg epoch acc = 0.09698\n","epoch 2\tavg epoch loss = nan\tavg epoch acc = 0.09698\n","epoch 3\tavg epoch loss = nan\tavg epoch acc = 0.09698\n","epoch 4\tavg epoch loss = nan\tavg epoch acc = 0.09698\n","epoch 5\tavg epoch loss = nan\tavg epoch acc = 0.09698\n","epoch 6\tavg epoch loss = nan\tavg epoch acc = 0.09698\n","epoch 7\tavg epoch loss = nan\tavg epoch acc = 0.09698\n","epoch 8\tavg epoch loss = nan\tavg epoch acc = 0.09698\n","epoch 9\tavg epoch loss = nan\tavg epoch acc = 0.09698\n","training took 54.3 s\n","Avg test loss = nan\tAvg test acc = 0.102\n","epoch 0\tavg epoch loss = nan\tavg epoch acc = 0.1129\n","epoch 1\tavg epoch loss = nan\tavg epoch acc = 0.1013\n","epoch 2\tavg epoch loss = nan\tavg epoch acc = 0.1013\n","epoch 3\tavg epoch loss = nan\tavg epoch acc = 0.1013\n","epoch 4\tavg epoch loss = nan\tavg epoch acc = 0.1013\n","epoch 5\tavg epoch loss = nan\tavg epoch acc = 0.1013\n","epoch 6\tavg epoch loss = nan\tavg epoch acc = 0.1013\n","epoch 7\tavg epoch loss = nan\tavg epoch acc = 0.1013\n","epoch 8\tavg epoch loss = nan\tavg epoch acc = 0.1013\n","epoch 9\tavg epoch loss = nan\tavg epoch acc = 0.1013\n","training took 53.99 s\n","Avg test loss = nan\tAvg test acc = 0.0935\n","{'lr': 0.001, 'beta1': 0.9, 'beta2': 0.5, 'batch_size': 64, 'weight_decay': 0.001, 'epsilon': 1e-10}\n","epoch 0\tavg epoch loss = 2.106e+30\tavg epoch acc = 0.0985\n","epoch 1\tavg epoch loss = nan\tavg epoch acc = 0.09857\n","epoch 2\tavg epoch loss = nan\tavg epoch acc = 0.0989\n","epoch 3\tavg epoch loss = nan\tavg epoch acc = 0.0989\n","epoch 4\tavg epoch loss = nan\tavg epoch acc = 0.0989\n","epoch 5\tavg epoch loss = nan\tavg epoch acc = 0.0989\n","epoch 6\tavg epoch loss = nan\tavg epoch acc = 0.0989\n","epoch 7\tavg epoch loss = nan\tavg epoch acc = 0.0989\n","epoch 8\tavg epoch loss = nan\tavg epoch acc = 0.0989\n","epoch 9\tavg epoch loss = nan\tavg epoch acc = 0.0989\n","training took 28.12 s\n","Avg test loss = nan\tAvg test acc = 0.0984\n","epoch 0\tavg epoch loss = 1.892e+24\tavg epoch acc = 0.1005\n","epoch 1\tavg epoch loss = 2.5e+28\tavg epoch acc = 0.08443\n","epoch 2\tavg epoch loss = 1.883e+31\tavg epoch acc = 0.09085\n","epoch 3\tavg epoch loss = 2.88e+32\tavg epoch acc = 0.1037\n","epoch 4\tavg epoch loss = 1.323e+33\tavg epoch acc = 0.1186\n","epoch 5\tavg epoch loss = 3.171e+33\tavg epoch acc = 0.1231\n","epoch 6\tavg epoch loss = 8.811e+33\tavg epoch acc = 0.12\n","epoch 7\tavg epoch loss = nan\tavg epoch acc = 0.09938\n","epoch 8\tavg epoch loss = nan\tavg epoch acc = 0.0981\n","epoch 9\tavg epoch loss = nan\tavg epoch acc = 0.0981\n","training took 28.01 s\n","Avg test loss = nan\tAvg test acc = 0.0999\n","epoch 0\tavg epoch loss = nan\tavg epoch acc = 0.09592\n","epoch 1\tavg epoch loss = nan\tavg epoch acc = 0.09915\n","epoch 2\tavg epoch loss = nan\tavg epoch acc = 0.09915\n","epoch 3\tavg epoch loss = nan\tavg epoch acc = 0.09915\n","epoch 4\tavg epoch loss = nan\tavg epoch acc = 0.09915\n","epoch 5\tavg epoch loss = nan\tavg epoch acc = 0.09915\n","epoch 6\tavg epoch loss = nan\tavg epoch acc = 0.09915\n","epoch 7\tavg epoch loss = nan\tavg epoch acc = 0.09915\n","epoch 8\tavg epoch loss = nan\tavg epoch acc = 0.09915\n","epoch 9\tavg epoch loss = nan\tavg epoch acc = 0.09915\n","training took 28.14 s\n","Avg test loss = nan\tAvg test acc = 0.0979\n","{'lr': 0.001, 'beta1': 0.9, 'beta2': 0.5, 'batch_size': 64, 'weight_decay': 0.001, 'epsilon': 1e-08}\n","epoch 0\tavg epoch loss = 2.288e+14\tavg epoch acc = 0.1042\n","epoch 1\tavg epoch loss = 1.179e+10\tavg epoch acc = 0.1123\n","epoch 2\tavg epoch loss = 1.172e+10\tavg epoch acc = 0.1123\n","epoch 3\tavg epoch loss = 1.165e+10\tavg epoch acc = 0.1123\n","epoch 4\tavg epoch loss = 1.159e+10\tavg epoch acc = 0.1123\n","epoch 5\tavg epoch loss = 1.152e+10\tavg epoch acc = 0.1123\n","epoch 6\tavg epoch loss = 1.145e+10\tavg epoch acc = 0.1123\n","epoch 7\tavg epoch loss = 1.139e+10\tavg epoch acc = 0.1123\n","epoch 8\tavg epoch loss = 1.132e+10\tavg epoch acc = 0.1123\n","epoch 9\tavg epoch loss = 1.126e+10\tavg epoch acc = 0.1123\n","training took 28.26 s\n","Avg test loss = 1.13e+10\tAvg test acc = 0.113\n","epoch 0\tavg epoch loss = 1.54e+11\tavg epoch acc = 0.09925\n","epoch 1\tavg epoch loss = 3.503e+06\tavg epoch acc = 0.09845\n","epoch 2\tavg epoch loss = 3.047e+06\tavg epoch acc = 0.09845\n","epoch 3\tavg epoch loss = 2.599e+06\tavg epoch acc = 0.09845\n","epoch 4\tavg epoch loss = 2.155e+06\tavg epoch acc = 0.09845\n","epoch 5\tavg epoch loss = 1.715e+06\tavg epoch acc = 0.09845\n","epoch 6\tavg epoch loss = 1.451e+06\tavg epoch acc = 0.09845\n","epoch 7\tavg epoch loss = 1.406e+06\tavg epoch acc = 0.09845\n","epoch 8\tavg epoch loss = 1.366e+06\tavg epoch acc = 0.09845\n","epoch 9\tavg epoch loss = 1.326e+06\tavg epoch acc = 0.09845\n","training took 28.15 s\n","Avg test loss = 1.3e+06\tAvg test acc = 0.0992\n","epoch 0\tavg epoch loss = 1.91e+20\tavg epoch acc = 0.09423\n","epoch 1\tavg epoch loss = 5.983e+32\tavg epoch acc = 0.08993\n","epoch 2\tavg epoch loss = nan\tavg epoch acc = 0.09903\n","epoch 3\tavg epoch loss = nan\tavg epoch acc = 0.1\n","epoch 4\tavg epoch loss = nan\tavg epoch acc = 0.1\n","epoch 5\tavg epoch loss = nan\tavg epoch acc = 0.1\n","epoch 6\tavg epoch loss = nan\tavg epoch acc = 0.1\n","epoch 7\tavg epoch loss = nan\tavg epoch acc = 0.1\n","epoch 8\tavg epoch loss = nan\tavg epoch acc = 0.1\n","epoch 9\tavg epoch loss = nan\tavg epoch acc = 0.1\n","training took 28.28 s\n","Avg test loss = nan\tAvg test acc = 0.0962\n","{'lr': 0.001, 'beta1': 0.9, 'beta2': 0.5, 'batch_size': 64, 'weight_decay': 0.1, 'epsilon': 1e-10}\n","epoch 0\tavg epoch loss = 2.836e+07\tavg epoch acc = 0.0991\n","epoch 1\tavg epoch loss = 1.42e+07\tavg epoch acc = 0.0996\n","epoch 2\tavg epoch loss = 1.127e+07\tavg epoch acc = 0.1002\n","epoch 3\tavg epoch loss = 8.849e+06\tavg epoch acc = 0.1007\n","epoch 4\tavg epoch loss = 6.881e+06\tavg epoch acc = 0.09928\n","epoch 5\tavg epoch loss = 5.254e+06\tavg epoch acc = 0.09907\n","epoch 6\tavg epoch loss = 3.885e+06\tavg epoch acc = 0.0981\n","epoch 7\tavg epoch loss = 2.732e+06\tavg epoch acc = 0.1007\n","epoch 8\tavg epoch loss = 1.792e+06\tavg epoch acc = 0.1025\n","epoch 9\tavg epoch loss = 1.418e+06\tavg epoch acc = 0.1044\n","training took 27.99 s\n","Avg test loss = 1.35e+06\tAvg test acc = 0.1\n","epoch 0\tavg epoch loss = 2.974e+30\tavg epoch acc = 0.1018\n","epoch 1\tavg epoch loss = nan\tavg epoch acc = 0.1005\n","epoch 2\tavg epoch loss = nan\tavg epoch acc = 0.0997\n","epoch 3\tavg epoch loss = nan\tavg epoch acc = 0.0997\n","epoch 4\tavg epoch loss = nan\tavg epoch acc = 0.0997\n","epoch 5\tavg epoch loss = nan\tavg epoch acc = 0.0997\n","epoch 6\tavg epoch loss = nan\tavg epoch acc = 0.0997\n","epoch 7\tavg epoch loss = nan\tavg epoch acc = 0.0997\n","epoch 8\tavg epoch loss = nan\tavg epoch acc = 0.0997\n","epoch 9\tavg epoch loss = nan\tavg epoch acc = 0.0997\n","training took 27.93 s\n","Avg test loss = nan\tAvg test acc = 0.0969\n","epoch 0\tavg epoch loss = 1.958e+07\tavg epoch acc = 0.1006\n","epoch 1\tavg epoch loss = 9.94e+06\tavg epoch acc = 0.1008\n","epoch 2\tavg epoch loss = 7.337e+06\tavg epoch acc = 0.1004\n","epoch 3\tavg epoch loss = 5.45e+06\tavg epoch acc = 0.1025\n","epoch 4\tavg epoch loss = 4.226e+06\tavg epoch acc = 0.1001\n","epoch 5\tavg epoch loss = 3.334e+06\tavg epoch acc = 0.099\n","epoch 6\tavg epoch loss = 2.688e+06\tavg epoch acc = 0.1004\n","epoch 7\tavg epoch loss = 2.151e+06\tavg epoch acc = 0.1011\n","epoch 8\tavg epoch loss = 1.69e+06\tavg epoch acc = 0.101\n","epoch 9\tavg epoch loss = 1.336e+06\tavg epoch acc = 0.1007\n","training took 28.25 s\n","Avg test loss = 1.2e+06\tAvg test acc = 0.105\n","{'lr': 0.001, 'beta1': 0.9, 'beta2': 0.5, 'batch_size': 64, 'weight_decay': 0.1, 'epsilon': 1e-08}\n","epoch 0\tavg epoch loss = 4.368e+09\tavg epoch acc = 0.0989\n","epoch 1\tavg epoch loss = 8.949e+06\tavg epoch acc = 0.09892\n","epoch 2\tavg epoch loss = 6.825e+06\tavg epoch acc = 0.1016\n","epoch 3\tavg epoch loss = 5.265e+06\tavg epoch acc = 0.1013\n","epoch 4\tavg epoch loss = 3.945e+06\tavg epoch acc = 0.1001\n","epoch 5\tavg epoch loss = 2.903e+06\tavg epoch acc = 0.1001\n","epoch 6\tavg epoch loss = 2.086e+06\tavg epoch acc = 0.1004\n","epoch 7\tavg epoch loss = 1.398e+06\tavg epoch acc = 0.1008\n","epoch 8\tavg epoch loss = 8.448e+05\tavg epoch acc = 0.1009\n","epoch 9\tavg epoch loss = 4.177e+05\tavg epoch acc = 0.09925\n","training took 27.94 s\n","Avg test loss = 2.98e+05\tAvg test acc = 0.0988\n","epoch 0\tavg epoch loss = 1.722e+07\tavg epoch acc = 0.1122\n","epoch 1\tavg epoch loss = 8.991e+06\tavg epoch acc = 0.1055\n","epoch 2\tavg epoch loss = 7.155e+06\tavg epoch acc = 0.1059\n","epoch 3\tavg epoch loss = 5.585e+06\tavg epoch acc = 0.1044\n","epoch 4\tavg epoch loss = 4.247e+06\tavg epoch acc = 0.1057\n","epoch 5\tavg epoch loss = 3.138e+06\tavg epoch acc = 0.1045\n","epoch 6\tavg epoch loss = 2.412e+06\tavg epoch acc = 0.1018\n","epoch 7\tavg epoch loss = 1.839e+06\tavg epoch acc = 0.1037\n","epoch 8\tavg epoch loss = 1.437e+06\tavg epoch acc = 0.102\n","epoch 9\tavg epoch loss = 1.125e+06\tavg epoch acc = 0.1007\n","training took 27.86 s\n","Avg test loss = 9.83e+05\tAvg test acc = 0.0988\n","epoch 0\tavg epoch loss = 6.769e+07\tavg epoch acc = 0.09755\n","epoch 1\tavg epoch loss = 1.552e+07\tavg epoch acc = 0.09773\n","epoch 2\tavg epoch loss = 1.162e+07\tavg epoch acc = 0.09773\n","epoch 3\tavg epoch loss = 8.325e+06\tavg epoch acc = 0.09773\n","epoch 4\tavg epoch loss = 5.747e+06\tavg epoch acc = 0.09972\n","epoch 5\tavg epoch loss = 4.014e+06\tavg epoch acc = 0.1004\n","epoch 6\tavg epoch loss = 2.617e+06\tavg epoch acc = 0.1012\n","epoch 7\tavg epoch loss = 1.835e+06\tavg epoch acc = 0.1007\n","epoch 8\tavg epoch loss = 1.334e+06\tavg epoch acc = 0.09965\n","epoch 9\tavg epoch loss = 9.881e+05\tavg epoch acc = 0.1007\n","training took 28.41 s\n","Avg test loss = 8.43e+05\tAvg test acc = 0.0966\n","{'lr': 0.001, 'beta1': 0.9, 'beta2': 0.5, 'batch_size': 128, 'weight_decay': 0.001, 'epsilon': 1e-10}\n","epoch 0\tavg epoch loss = 8.842e+07\tavg epoch acc = 0.09999\n","epoch 1\tavg epoch loss = 9.862e+07\tavg epoch acc = 0.1\n","epoch 2\tavg epoch loss = 9.795e+07\tavg epoch acc = 0.1\n","epoch 3\tavg epoch loss = 9.729e+07\tavg epoch acc = 0.1\n","epoch 4\tavg epoch loss = 9.671e+07\tavg epoch acc = 0.1\n","epoch 5\tavg epoch loss = 9.623e+07\tavg epoch acc = 0.1\n","epoch 6\tavg epoch loss = 9.584e+07\tavg epoch acc = 0.1\n","epoch 7\tavg epoch loss = 9.549e+07\tavg epoch acc = 0.1\n","epoch 8\tavg epoch loss = 9.518e+07\tavg epoch acc = 0.1\n","epoch 9\tavg epoch loss = 9.49e+07\tavg epoch acc = 0.1\n","training took 17.21 s\n","Avg test loss = 9.5e+07\tAvg test acc = 0.0976\n","epoch 0\tavg epoch loss = 5.068e+05\tavg epoch acc = 0.09355\n","epoch 1\tavg epoch loss = 5.667e+05\tavg epoch acc = 0.09113\n","epoch 2\tavg epoch loss = 4.568e+05\tavg epoch acc = 0.09113\n","epoch 3\tavg epoch loss = 3.476e+05\tavg epoch acc = 0.09113\n","epoch 4\tavg epoch loss = 2.391e+05\tavg epoch acc = 0.09113\n","epoch 5\tavg epoch loss = 1.598e+05\tavg epoch acc = 0.09113\n","epoch 6\tavg epoch loss = 1.2e+05\tavg epoch acc = 0.09113\n","epoch 7\tavg epoch loss = 9.095e+04\tavg epoch acc = 0.09452\n","epoch 8\tavg epoch loss = 7.433e+04\tavg epoch acc = 0.09477\n","epoch 9\tavg epoch loss = 5.831e+04\tavg epoch acc = 0.09475\n","training took 17.27 s\n","Avg test loss = 5e+04\tAvg test acc = 0.112\n","epoch 0\tavg epoch loss = 2.527e+05\tavg epoch acc = 0.101\n","epoch 1\tavg epoch loss = 2.739e+05\tavg epoch acc = 0.09814\n","epoch 2\tavg epoch loss = 2.385e+05\tavg epoch acc = 0.09822\n","epoch 3\tavg epoch loss = 2.073e+05\tavg epoch acc = 0.09789\n","epoch 4\tavg epoch loss = 1.784e+05\tavg epoch acc = 0.09904\n","epoch 5\tavg epoch loss = 1.512e+05\tavg epoch acc = 0.09959\n","epoch 6\tavg epoch loss = 1.27e+05\tavg epoch acc = 0.09812\n","epoch 7\tavg epoch loss = 1.052e+05\tavg epoch acc = 0.09744\n","epoch 8\tavg epoch loss = 9.025e+04\tavg epoch acc = 0.09834\n","epoch 9\tavg epoch loss = 7.784e+04\tavg epoch acc = 0.09792\n","training took 17.29 s\n","Avg test loss = 7.25e+04\tAvg test acc = 0.0998\n","{'lr': 0.001, 'beta1': 0.9, 'beta2': 0.5, 'batch_size': 128, 'weight_decay': 0.001, 'epsilon': 1e-08}\n","epoch 0\tavg epoch loss = 1.508e+17\tavg epoch acc = 0.09824\n","epoch 1\tavg epoch loss = 6.641e+11\tavg epoch acc = 0.09852\n","epoch 2\tavg epoch loss = 8.191e+11\tavg epoch acc = 0.09839\n","epoch 3\tavg epoch loss = 8.179e+11\tavg epoch acc = 0.09839\n","epoch 4\tavg epoch loss = 8.166e+11\tavg epoch acc = 0.09839\n","epoch 5\tavg epoch loss = 8.154e+11\tavg epoch acc = 0.09839\n","epoch 6\tavg epoch loss = 8.142e+11\tavg epoch acc = 0.09839\n","epoch 7\tavg epoch loss = 8.13e+11\tavg epoch acc = 0.09839\n","epoch 8\tavg epoch loss = 8.118e+11\tavg epoch acc = 0.09839\n","epoch 9\tavg epoch loss = 8.106e+11\tavg epoch acc = 0.09839\n","training took 17.33 s\n","Avg test loss = 7.98e+11\tAvg test acc = 0.101\n","epoch 0\tavg epoch loss = 1.166e+09\tavg epoch acc = 0.09812\n","epoch 1\tavg epoch loss = 3.212e+08\tavg epoch acc = 0.09869\n","epoch 2\tavg epoch loss = 3.186e+08\tavg epoch acc = 0.09869\n","epoch 3\tavg epoch loss = 3.16e+08\tavg epoch acc = 0.09869\n","epoch 4\tavg epoch loss = 3.134e+08\tavg epoch acc = 0.09869\n","epoch 5\tavg epoch loss = 3.108e+08\tavg epoch acc = 0.09869\n","epoch 6\tavg epoch loss = 3.083e+08\tavg epoch acc = 0.09869\n","epoch 7\tavg epoch loss = 3.058e+08\tavg epoch acc = 0.09869\n","epoch 8\tavg epoch loss = 3.033e+08\tavg epoch acc = 0.09869\n","epoch 9\tavg epoch loss = 3.007e+08\tavg epoch acc = 0.09869\n","training took 17.32 s\n","Avg test loss = 3e+08\tAvg test acc = 0.0984\n","epoch 0\tavg epoch loss = 2.443e+12\tavg epoch acc = 0.09627\n","epoch 1\tavg epoch loss = 6.445e+19\tavg epoch acc = 0.1011\n","epoch 2\tavg epoch loss = 5.117e+26\tavg epoch acc = 0.1101\n","epoch 3\tavg epoch loss = nan\tavg epoch acc = 0.101\n","epoch 4\tavg epoch loss = nan\tavg epoch acc = 0.09767\n","epoch 5\tavg epoch loss = nan\tavg epoch acc = 0.09767\n","epoch 6\tavg epoch loss = nan\tavg epoch acc = 0.09767\n","epoch 7\tavg epoch loss = nan\tavg epoch acc = 0.09767\n","epoch 8\tavg epoch loss = nan\tavg epoch acc = 0.09767\n","epoch 9\tavg epoch loss = nan\tavg epoch acc = 0.09767\n","training took 17.32 s\n","Avg test loss = nan\tAvg test acc = 0.101\n","{'lr': 0.001, 'beta1': 0.9, 'beta2': 0.5, 'batch_size': 128, 'weight_decay': 0.1, 'epsilon': 1e-10}\n","epoch 0\tavg epoch loss = nan\tavg epoch acc = 0.101\n","epoch 1\tavg epoch loss = nan\tavg epoch acc = 0.09922\n","epoch 2\tavg epoch loss = nan\tavg epoch acc = 0.09922\n","epoch 3\tavg epoch loss = nan\tavg epoch acc = 0.09922\n","epoch 4\tavg epoch loss = nan\tavg epoch acc = 0.09922\n","epoch 5\tavg epoch loss = nan\tavg epoch acc = 0.09922\n","epoch 6\tavg epoch loss = nan\tavg epoch acc = 0.09922\n","epoch 7\tavg epoch loss = nan\tavg epoch acc = 0.09922\n","epoch 8\tavg epoch loss = nan\tavg epoch acc = 0.09922\n","epoch 9\tavg epoch loss = nan\tavg epoch acc = 0.09922\n","training took 17.33 s\n","Avg test loss = nan\tAvg test acc = 0.0979\n","epoch 0\tavg epoch loss = 2.147e+18\tavg epoch acc = 0.09849\n","epoch 1\tavg epoch loss = 4.861e+13\tavg epoch acc = 0.09021\n","epoch 2\tavg epoch loss = 4.564e+13\tavg epoch acc = 0.09021\n","epoch 3\tavg epoch loss = 4.286e+13\tavg epoch acc = 0.09021\n","epoch 4\tavg epoch loss = 4.024e+13\tavg epoch acc = 0.09021\n","epoch 5\tavg epoch loss = 3.778e+13\tavg epoch acc = 0.09021\n","epoch 6\tavg epoch loss = 3.547e+13\tavg epoch acc = 0.09021\n","epoch 7\tavg epoch loss = 3.331e+13\tavg epoch acc = 0.09021\n","epoch 8\tavg epoch loss = 3.127e+13\tavg epoch acc = 0.09021\n","epoch 9\tavg epoch loss = 2.936e+13\tavg epoch acc = 0.09021\n","training took 17.33 s\n","Avg test loss = 2.85e+13\tAvg test acc = 0.0908\n","epoch 0\tavg epoch loss = 2.998e+23\tavg epoch acc = 0.09822\n","epoch 1\tavg epoch loss = nan\tavg epoch acc = 0.09627\n","epoch 2\tavg epoch loss = nan\tavg epoch acc = 0.1002\n","epoch 3\tavg epoch loss = nan\tavg epoch acc = 0.1002\n","epoch 4\tavg epoch loss = nan\tavg epoch acc = 0.1002\n","epoch 5\tavg epoch loss = nan\tavg epoch acc = 0.1002\n","epoch 6\tavg epoch loss = nan\tavg epoch acc = 0.1002\n","epoch 7\tavg epoch loss = nan\tavg epoch acc = 0.1002\n","epoch 8\tavg epoch loss = nan\tavg epoch acc = 0.1002\n","epoch 9\tavg epoch loss = nan\tavg epoch acc = 0.1002\n","training took 17.41 s\n","Avg test loss = nan\tAvg test acc = 0.0956\n","{'lr': 0.001, 'beta1': 0.9, 'beta2': 0.5, 'batch_size': 128, 'weight_decay': 0.1, 'epsilon': 1e-08}\n","epoch 0\tavg epoch loss = 2.667e+07\tavg epoch acc = 0.1007\n","epoch 1\tavg epoch loss = 1.201e+07\tavg epoch acc = 0.09957\n","epoch 2\tavg epoch loss = 1.076e+07\tavg epoch acc = 0.101\n","epoch 3\tavg epoch loss = 9.697e+06\tavg epoch acc = 0.101\n","epoch 4\tavg epoch loss = 8.72e+06\tavg epoch acc = 0.09817\n","epoch 5\tavg epoch loss = 7.825e+06\tavg epoch acc = 0.09919\n","epoch 6\tavg epoch loss = 7.004e+06\tavg epoch acc = 0.09762\n","epoch 7\tavg epoch loss = 6.25e+06\tavg epoch acc = 0.09849\n","epoch 8\tavg epoch loss = 5.557e+06\tavg epoch acc = 0.09979\n","epoch 9\tavg epoch loss = 4.952e+06\tavg epoch acc = 0.1002\n","training took 17.27 s\n","Avg test loss = 4.74e+06\tAvg test acc = 0.0959\n","epoch 0\tavg epoch loss = 2.875e+07\tavg epoch acc = 0.102\n","epoch 1\tavg epoch loss = 1.487e+07\tavg epoch acc = 0.1022\n","epoch 2\tavg epoch loss = 1.275e+07\tavg epoch acc = 0.1022\n","epoch 3\tavg epoch loss = 1.08e+07\tavg epoch acc = 0.1022\n","epoch 4\tavg epoch loss = 9.147e+06\tavg epoch acc = 0.1008\n","epoch 5\tavg epoch loss = 7.904e+06\tavg epoch acc = 0.1005\n","epoch 6\tavg epoch loss = 6.768e+06\tavg epoch acc = 0.1014\n","epoch 7\tavg epoch loss = 5.72e+06\tavg epoch acc = 0.1022\n","epoch 8\tavg epoch loss = 4.756e+06\tavg epoch acc = 0.1005\n","epoch 9\tavg epoch loss = 3.896e+06\tavg epoch acc = 0.1002\n","training took 17.22 s\n","Avg test loss = 3.57e+06\tAvg test acc = 0.0985\n","epoch 0\tavg epoch loss = 3.919e+16\tavg epoch acc = 0.1001\n","epoch 1\tavg epoch loss = 5.353e+29\tavg epoch acc = 0.1006\n","epoch 2\tavg epoch loss = 4.195e+33\tavg epoch acc = 0.1009\n","epoch 3\tavg epoch loss = 1.625e+18\tavg epoch acc = 0.09952\n","epoch 4\tavg epoch loss = 1.652e+18\tavg epoch acc = 0.09944\n","epoch 5\tavg epoch loss = 1.551e+18\tavg epoch acc = 0.09944\n","epoch 6\tavg epoch loss = 1.456e+18\tavg epoch acc = 0.09944\n","epoch 7\tavg epoch loss = 1.368e+18\tavg epoch acc = 0.09944\n","epoch 8\tavg epoch loss = 1.284e+18\tavg epoch acc = 0.09944\n","epoch 9\tavg epoch loss = 1.206e+18\tavg epoch acc = 0.09944\n","training took 17.35 s\n","Avg test loss = 1.16e+18\tAvg test acc = 0.0991\n","{'lr': 0.001, 'beta1': 0.9, 'beta2': 0.999, 'batch_size': 32, 'weight_decay': 0.001, 'epsilon': 1e-10}\n","epoch 0\tavg epoch loss = 0.823\tavg epoch acc = 0.8622\n","epoch 1\tavg epoch loss = 0.2713\tavg epoch acc = 0.9808\n","epoch 2\tavg epoch loss = 0.1984\tavg epoch acc = 0.9873\n","epoch 3\tavg epoch loss = 0.1573\tavg epoch acc = 0.9905\n","epoch 4\tavg epoch loss = 0.1227\tavg epoch acc = 0.9929\n","epoch 5\tavg epoch loss = 0.1106\tavg epoch acc = 0.9948\n","epoch 6\tavg epoch loss = 0.08934\tavg epoch acc = 0.9962\n","epoch 7\tavg epoch loss = 0.07391\tavg epoch acc = 0.9971\n","epoch 8\tavg epoch loss = 0.06675\tavg epoch acc = 0.9979\n","epoch 9\tavg epoch loss = 0.05973\tavg epoch acc = 0.9984\n","training took 54.19 s\n","Avg test loss = 0.0433\tAvg test acc = 0.99\n","epoch 0\tavg epoch loss = 0.8133\tavg epoch acc = 0.8646\n","epoch 1\tavg epoch loss = 0.2636\tavg epoch acc = 0.9811\n","epoch 2\tavg epoch loss = 0.1915\tavg epoch acc = 0.9872\n","epoch 3\tavg epoch loss = 0.1508\tavg epoch acc = 0.9912\n","epoch 4\tavg epoch loss = 0.1237\tavg epoch acc = 0.9934\n","epoch 5\tavg epoch loss = 0.1019\tavg epoch acc = 0.9951\n","epoch 6\tavg epoch loss = 0.08331\tavg epoch acc = 0.9968\n","epoch 7\tavg epoch loss = 0.08066\tavg epoch acc = 0.997\n","epoch 8\tavg epoch loss = 0.06919\tavg epoch acc = 0.9978\n","epoch 9\tavg epoch loss = 0.0561\tavg epoch acc = 0.9984\n","training took 54.09 s\n","Avg test loss = 0.0511\tAvg test acc = 0.988\n","epoch 0\tavg epoch loss = 0.8097\tavg epoch acc = 0.8652\n","epoch 1\tavg epoch loss = 0.2622\tavg epoch acc = 0.9822\n","epoch 2\tavg epoch loss = 0.1947\tavg epoch acc = 0.9876\n","epoch 3\tavg epoch loss = 0.1491\tavg epoch acc = 0.991\n","epoch 4\tavg epoch loss = 0.1222\tavg epoch acc = 0.9932\n","epoch 5\tavg epoch loss = 0.1028\tavg epoch acc = 0.9951\n","epoch 6\tavg epoch loss = 0.08912\tavg epoch acc = 0.9965\n","epoch 7\tavg epoch loss = 0.07959\tavg epoch acc = 0.9973\n","epoch 8\tavg epoch loss = 0.06903\tavg epoch acc = 0.998\n","epoch 9\tavg epoch loss = 0.05866\tavg epoch acc = 0.9986\n","training took 53.75 s\n","Avg test loss = 0.0527\tAvg test acc = 0.989\n","{'lr': 0.001, 'beta1': 0.9, 'beta2': 0.999, 'batch_size': 32, 'weight_decay': 0.001, 'epsilon': 1e-08}\n","epoch 0\tavg epoch loss = 0.8175\tavg epoch acc = 0.8656\n","epoch 1\tavg epoch loss = 0.2675\tavg epoch acc = 0.9804\n","epoch 2\tavg epoch loss = 0.1951\tavg epoch acc = 0.9869\n","epoch 3\tavg epoch loss = 0.1595\tavg epoch acc = 0.9899\n","epoch 4\tavg epoch loss = 0.1273\tavg epoch acc = 0.9927\n","epoch 5\tavg epoch loss = 0.105\tavg epoch acc = 0.9948\n","epoch 6\tavg epoch loss = 0.09312\tavg epoch acc = 0.9955\n","epoch 7\tavg epoch loss = 0.07579\tavg epoch acc = 0.9972\n","epoch 8\tavg epoch loss = 0.06684\tavg epoch acc = 0.9974\n","epoch 9\tavg epoch loss = 0.05967\tavg epoch acc = 0.998\n","training took 54.02 s\n","Avg test loss = 0.0393\tAvg test acc = 0.99\n","epoch 0\tavg epoch loss = 0.8105\tavg epoch acc = 0.8619\n","epoch 1\tavg epoch loss = 0.2634\tavg epoch acc = 0.981\n","epoch 2\tavg epoch loss = 0.1911\tavg epoch acc = 0.9874\n","epoch 3\tavg epoch loss = 0.1488\tavg epoch acc = 0.9911\n","epoch 4\tavg epoch loss = 0.1233\tavg epoch acc = 0.9936\n","epoch 5\tavg epoch loss = 0.1048\tavg epoch acc = 0.9953\n","epoch 6\tavg epoch loss = 0.08912\tavg epoch acc = 0.997\n","epoch 7\tavg epoch loss = 0.07813\tavg epoch acc = 0.9974\n","epoch 8\tavg epoch loss = 0.06739\tavg epoch acc = 0.998\n","epoch 9\tavg epoch loss = 0.06782\tavg epoch acc = 0.9983\n","training took 54.03 s\n","Avg test loss = 0.0512\tAvg test acc = 0.99\n","epoch 0\tavg epoch loss = 0.8132\tavg epoch acc = 0.8648\n","epoch 1\tavg epoch loss = 0.2612\tavg epoch acc = 0.9812\n","epoch 2\tavg epoch loss = 0.1906\tavg epoch acc = 0.9877\n","epoch 3\tavg epoch loss = 0.155\tavg epoch acc = 0.9909\n","epoch 4\tavg epoch loss = 0.121\tavg epoch acc = 0.993\n","epoch 5\tavg epoch loss = 0.09905\tavg epoch acc = 0.9949\n","epoch 6\tavg epoch loss = 0.08752\tavg epoch acc = 0.9963\n","epoch 7\tavg epoch loss = 0.0723\tavg epoch acc = 0.9975\n","epoch 8\tavg epoch loss = 0.06444\tavg epoch acc = 0.9982\n","epoch 9\tavg epoch loss = 0.0555\tavg epoch acc = 0.9984\n","training took 53.94 s\n","Avg test loss = 0.0416\tAvg test acc = 0.99\n","{'lr': 0.001, 'beta1': 0.9, 'beta2': 0.999, 'batch_size': 32, 'weight_decay': 0.1, 'epsilon': 1e-10}\n","epoch 0\tavg epoch loss = 0.8143\tavg epoch acc = 0.8631\n","epoch 1\tavg epoch loss = 0.2651\tavg epoch acc = 0.9805\n","epoch 2\tavg epoch loss = 0.1954\tavg epoch acc = 0.9866\n","epoch 3\tavg epoch loss = 0.1613\tavg epoch acc = 0.9899\n","epoch 4\tavg epoch loss = 0.1354\tavg epoch acc = 0.9925\n","epoch 5\tavg epoch loss = 0.1185\tavg epoch acc = 0.9939\n","epoch 6\tavg epoch loss = 0.1051\tavg epoch acc = 0.9948\n","epoch 7\tavg epoch loss = 0.09226\tavg epoch acc = 0.9958\n","epoch 8\tavg epoch loss = 0.0865\tavg epoch acc = 0.9965\n","epoch 9\tavg epoch loss = 0.07647\tavg epoch acc = 0.997\n","training took 54.05 s\n","Avg test loss = 0.0407\tAvg test acc = 0.989\n","epoch 0\tavg epoch loss = 0.8126\tavg epoch acc = 0.8649\n","epoch 1\tavg epoch loss = 0.263\tavg epoch acc = 0.9818\n","epoch 2\tavg epoch loss = 0.1967\tavg epoch acc = 0.9862\n","epoch 3\tavg epoch loss = 0.1532\tavg epoch acc = 0.9906\n","epoch 4\tavg epoch loss = 0.1324\tavg epoch acc = 0.9924\n","epoch 5\tavg epoch loss = 0.1105\tavg epoch acc = 0.994\n","epoch 6\tavg epoch loss = 0.0981\tavg epoch acc = 0.995\n","epoch 7\tavg epoch loss = 0.09045\tavg epoch acc = 0.9958\n","epoch 8\tavg epoch loss = 0.08368\tavg epoch acc = 0.9962\n","epoch 9\tavg epoch loss = 0.06993\tavg epoch acc = 0.9971\n","training took 54.12 s\n","Avg test loss = 0.0503\tAvg test acc = 0.986\n","epoch 0\tavg epoch loss = 0.8165\tavg epoch acc = 0.8638\n","epoch 1\tavg epoch loss = 0.2674\tavg epoch acc = 0.9808\n","epoch 2\tavg epoch loss = 0.1963\tavg epoch acc = 0.9867\n","epoch 3\tavg epoch loss = 0.1566\tavg epoch acc = 0.9895\n","epoch 4\tavg epoch loss = 0.1278\tavg epoch acc = 0.9926\n","epoch 5\tavg epoch loss = 0.1117\tavg epoch acc = 0.9936\n","epoch 6\tavg epoch loss = 0.09761\tavg epoch acc = 0.9949\n","epoch 7\tavg epoch loss = 0.09428\tavg epoch acc = 0.9955\n","epoch 8\tavg epoch loss = 0.07921\tavg epoch acc = 0.9966\n","epoch 9\tavg epoch loss = 0.07139\tavg epoch acc = 0.9972\n","training took 53.89 s\n","Avg test loss = 0.0413\tAvg test acc = 0.988\n","{'lr': 0.001, 'beta1': 0.9, 'beta2': 0.999, 'batch_size': 32, 'weight_decay': 0.1, 'epsilon': 1e-08}\n","epoch 0\tavg epoch loss = 0.8137\tavg epoch acc = 0.8634\n","epoch 1\tavg epoch loss = 0.2668\tavg epoch acc = 0.9806\n","epoch 2\tavg epoch loss = 0.1993\tavg epoch acc = 0.9859\n","epoch 3\tavg epoch loss = 0.1604\tavg epoch acc = 0.9892\n","epoch 4\tavg epoch loss = 0.1381\tavg epoch acc = 0.9917\n","epoch 5\tavg epoch loss = 0.1143\tavg epoch acc = 0.9931\n","epoch 6\tavg epoch loss = 0.09892\tavg epoch acc = 0.9946\n","epoch 7\tavg epoch loss = 0.089\tavg epoch acc = 0.9956\n","epoch 8\tavg epoch loss = 0.08138\tavg epoch acc = 0.9962\n","epoch 9\tavg epoch loss = 0.0786\tavg epoch acc = 0.997\n","training took 54.34 s\n","Avg test loss = 0.0388\tAvg test acc = 0.989\n","epoch 0\tavg epoch loss = 0.8131\tavg epoch acc = 0.8638\n","epoch 1\tavg epoch loss = 0.2624\tavg epoch acc = 0.9809\n","epoch 2\tavg epoch loss = 0.1919\tavg epoch acc = 0.9865\n","epoch 3\tavg epoch loss = 0.1548\tavg epoch acc = 0.9895\n","epoch 4\tavg epoch loss = 0.1301\tavg epoch acc = 0.9921\n","epoch 5\tavg epoch loss = 0.1103\tavg epoch acc = 0.9936\n","epoch 6\tavg epoch loss = 0.09798\tavg epoch acc = 0.9951\n","epoch 7\tavg epoch loss = 0.08774\tavg epoch acc = 0.9959\n","epoch 8\tavg epoch loss = 0.07751\tavg epoch acc = 0.9965\n","epoch 9\tavg epoch loss = 0.07246\tavg epoch acc = 0.9972\n","training took 54.35 s\n","Avg test loss = 0.0445\tAvg test acc = 0.987\n","epoch 0\tavg epoch loss = 0.8183\tavg epoch acc = 0.8621\n","epoch 1\tavg epoch loss = 0.2674\tavg epoch acc = 0.9808\n","epoch 2\tavg epoch loss = 0.1989\tavg epoch acc = 0.9863\n","epoch 3\tavg epoch loss = 0.1562\tavg epoch acc = 0.9901\n","epoch 4\tavg epoch loss = 0.1314\tavg epoch acc = 0.9917\n","epoch 5\tavg epoch loss = 0.1122\tavg epoch acc = 0.9934\n","epoch 6\tavg epoch loss = 0.1005\tavg epoch acc = 0.9942\n","epoch 7\tavg epoch loss = 0.08744\tavg epoch acc = 0.9956\n","epoch 8\tavg epoch loss = 0.07729\tavg epoch acc = 0.9962\n","epoch 9\tavg epoch loss = 0.07119\tavg epoch acc = 0.9968\n","training took 53.78 s\n","Avg test loss = 0.0395\tAvg test acc = 0.989\n","{'lr': 0.001, 'beta1': 0.9, 'beta2': 0.999, 'batch_size': 64, 'weight_decay': 0.001, 'epsilon': 1e-10}\n","epoch 0\tavg epoch loss = 1.134\tavg epoch acc = 0.7861\n","epoch 1\tavg epoch loss = 0.3325\tavg epoch acc = 0.976\n","epoch 2\tavg epoch loss = 0.238\tavg epoch acc = 0.9843\n","epoch 3\tavg epoch loss = 0.1852\tavg epoch acc = 0.9891\n","epoch 4\tavg epoch loss = 0.1544\tavg epoch acc = 0.9912\n","epoch 5\tavg epoch loss = 0.1304\tavg epoch acc = 0.9932\n","epoch 6\tavg epoch loss = 0.1169\tavg epoch acc = 0.9949\n","epoch 7\tavg epoch loss = 0.102\tavg epoch acc = 0.9962\n","epoch 8\tavg epoch loss = 0.0876\tavg epoch acc = 0.9969\n","epoch 9\tavg epoch loss = 0.08265\tavg epoch acc = 0.9975\n","training took 27.97 s\n","Avg test loss = 0.0359\tAvg test acc = 0.991\n","epoch 0\tavg epoch loss = 1.135\tavg epoch acc = 0.7834\n","epoch 1\tavg epoch loss = 0.3336\tavg epoch acc = 0.976\n","epoch 2\tavg epoch loss = 0.237\tavg epoch acc = 0.9843\n","epoch 3\tavg epoch loss = 0.1868\tavg epoch acc = 0.9885\n","epoch 4\tavg epoch loss = 0.1521\tavg epoch acc = 0.9912\n","epoch 5\tavg epoch loss = 0.1321\tavg epoch acc = 0.9929\n","epoch 6\tavg epoch loss = 0.1122\tavg epoch acc = 0.9944\n","epoch 7\tavg epoch loss = 0.1008\tavg epoch acc = 0.9953\n","epoch 8\tavg epoch loss = 0.08335\tavg epoch acc = 0.9969\n","epoch 9\tavg epoch loss = 0.07763\tavg epoch acc = 0.9973\n","training took 27.87 s\n","Avg test loss = 0.0395\tAvg test acc = 0.99\n","epoch 0\tavg epoch loss = 1.144\tavg epoch acc = 0.7823\n","epoch 1\tavg epoch loss = 0.3301\tavg epoch acc = 0.9756\n","epoch 2\tavg epoch loss = 0.2329\tavg epoch acc = 0.9842\n","epoch 3\tavg epoch loss = 0.1839\tavg epoch acc = 0.9884\n","epoch 4\tavg epoch loss = 0.1524\tavg epoch acc = 0.9915\n","epoch 5\tavg epoch loss = 0.1285\tavg epoch acc = 0.994\n","epoch 6\tavg epoch loss = 0.1064\tavg epoch acc = 0.9958\n","epoch 7\tavg epoch loss = 0.09217\tavg epoch acc = 0.9964\n","epoch 8\tavg epoch loss = 0.08324\tavg epoch acc = 0.9971\n","epoch 9\tavg epoch loss = 0.07148\tavg epoch acc = 0.9976\n","training took 28.01 s\n","Avg test loss = 0.0353\tAvg test acc = 0.991\n","{'lr': 0.001, 'beta1': 0.9, 'beta2': 0.999, 'batch_size': 64, 'weight_decay': 0.001, 'epsilon': 1e-08}\n","epoch 0\tavg epoch loss = 1.14\tavg epoch acc = 0.7845\n","epoch 1\tavg epoch loss = 0.3355\tavg epoch acc = 0.9755\n","epoch 2\tavg epoch loss = 0.2378\tavg epoch acc = 0.9839\n","epoch 3\tavg epoch loss = 0.1909\tavg epoch acc = 0.9877\n","epoch 4\tavg epoch loss = 0.1569\tavg epoch acc = 0.9907\n","epoch 5\tavg epoch loss = 0.133\tavg epoch acc = 0.9929\n","epoch 6\tavg epoch loss = 0.11\tavg epoch acc = 0.9941\n","epoch 7\tavg epoch loss = 0.1012\tavg epoch acc = 0.9958\n","epoch 8\tavg epoch loss = 0.09376\tavg epoch acc = 0.9963\n","epoch 9\tavg epoch loss = 0.07236\tavg epoch acc = 0.9971\n","training took 27.78 s\n","Avg test loss = 0.0341\tAvg test acc = 0.99\n","epoch 0\tavg epoch loss = 1.138\tavg epoch acc = 0.7854\n","epoch 1\tavg epoch loss = 0.3376\tavg epoch acc = 0.9752\n","epoch 2\tavg epoch loss = 0.2374\tavg epoch acc = 0.9843\n","epoch 3\tavg epoch loss = 0.1874\tavg epoch acc = 0.9885\n","epoch 4\tavg epoch loss = 0.155\tavg epoch acc = 0.9914\n","epoch 5\tavg epoch loss = 0.1292\tavg epoch acc = 0.9937\n","epoch 6\tavg epoch loss = 0.1147\tavg epoch acc = 0.9949\n","epoch 7\tavg epoch loss = 0.09953\tavg epoch acc = 0.9961\n","epoch 8\tavg epoch loss = 0.08853\tavg epoch acc = 0.9969\n","epoch 9\tavg epoch loss = 0.07813\tavg epoch acc = 0.9974\n","training took 27.69 s\n","Avg test loss = 0.0435\tAvg test acc = 0.99\n","epoch 0\tavg epoch loss = 1.142\tavg epoch acc = 0.7823\n","epoch 1\tavg epoch loss = 0.3332\tavg epoch acc = 0.9756\n","epoch 2\tavg epoch loss = 0.2344\tavg epoch acc = 0.9845\n","epoch 3\tavg epoch loss = 0.1869\tavg epoch acc = 0.9885\n","epoch 4\tavg epoch loss = 0.1532\tavg epoch acc = 0.9917\n","epoch 5\tavg epoch loss = 0.1339\tavg epoch acc = 0.9931\n","epoch 6\tavg epoch loss = 0.112\tavg epoch acc = 0.995\n","epoch 7\tavg epoch loss = 0.09682\tavg epoch acc = 0.9963\n","epoch 8\tavg epoch loss = 0.08297\tavg epoch acc = 0.997\n","epoch 9\tavg epoch loss = 0.07227\tavg epoch acc = 0.998\n","training took 27.88 s\n","Avg test loss = 0.0458\tAvg test acc = 0.99\n","{'lr': 0.001, 'beta1': 0.9, 'beta2': 0.999, 'batch_size': 64, 'weight_decay': 0.1, 'epsilon': 1e-10}\n","epoch 0\tavg epoch loss = 1.141\tavg epoch acc = 0.7824\n","epoch 1\tavg epoch loss = 0.3342\tavg epoch acc = 0.9754\n","epoch 2\tavg epoch loss = 0.2354\tavg epoch acc = 0.9846\n","epoch 3\tavg epoch loss = 0.1881\tavg epoch acc = 0.9877\n","epoch 4\tavg epoch loss = 0.159\tavg epoch acc = 0.9906\n","epoch 5\tavg epoch loss = 0.1359\tavg epoch acc = 0.9925\n","epoch 6\tavg epoch loss = 0.1127\tavg epoch acc = 0.994\n","epoch 7\tavg epoch loss = 0.09905\tavg epoch acc = 0.9953\n","epoch 8\tavg epoch loss = 0.0894\tavg epoch acc = 0.9962\n","epoch 9\tavg epoch loss = 0.07956\tavg epoch acc = 0.9966\n","training took 27.87 s\n","Avg test loss = 0.0342\tAvg test acc = 0.99\n","epoch 0\tavg epoch loss = 1.135\tavg epoch acc = 0.7852\n","epoch 1\tavg epoch loss = 0.3329\tavg epoch acc = 0.9755\n","epoch 2\tavg epoch loss = 0.2351\tavg epoch acc = 0.9839\n","epoch 3\tavg epoch loss = 0.1879\tavg epoch acc = 0.9882\n","epoch 4\tavg epoch loss = 0.161\tavg epoch acc = 0.9903\n","epoch 5\tavg epoch loss = 0.1355\tavg epoch acc = 0.9924\n","epoch 6\tavg epoch loss = 0.1171\tavg epoch acc = 0.994\n","epoch 7\tavg epoch loss = 0.1032\tavg epoch acc = 0.9949\n","epoch 8\tavg epoch loss = 0.09083\tavg epoch acc = 0.996\n","epoch 9\tavg epoch loss = 0.08884\tavg epoch acc = 0.9963\n","training took 27.81 s\n","Avg test loss = 0.0376\tAvg test acc = 0.99\n","epoch 0\tavg epoch loss = 1.15\tavg epoch acc = 0.7821\n","epoch 1\tavg epoch loss = 0.3382\tavg epoch acc = 0.9754\n","epoch 2\tavg epoch loss = 0.2373\tavg epoch acc = 0.9846\n","epoch 3\tavg epoch loss = 0.1899\tavg epoch acc = 0.9886\n","epoch 4\tavg epoch loss = 0.1557\tavg epoch acc = 0.9916\n","epoch 5\tavg epoch loss = 0.1341\tavg epoch acc = 0.993\n","epoch 6\tavg epoch loss = 0.1131\tavg epoch acc = 0.9945\n","epoch 7\tavg epoch loss = 0.1011\tavg epoch acc = 0.9955\n","epoch 8\tavg epoch loss = 0.08951\tavg epoch acc = 0.9964\n","epoch 9\tavg epoch loss = 0.084\tavg epoch acc = 0.9969\n","training took 27.98 s\n","Avg test loss = 0.0404\tAvg test acc = 0.989\n","{'lr': 0.001, 'beta1': 0.9, 'beta2': 0.999, 'batch_size': 64, 'weight_decay': 0.1, 'epsilon': 1e-08}\n","epoch 0\tavg epoch loss = 1.14\tavg epoch acc = 0.7822\n","epoch 1\tavg epoch loss = 0.3365\tavg epoch acc = 0.9752\n","epoch 2\tavg epoch loss = 0.2387\tavg epoch acc = 0.9835\n","epoch 3\tavg epoch loss = 0.1907\tavg epoch acc = 0.9876\n","epoch 4\tavg epoch loss = 0.1604\tavg epoch acc = 0.9901\n","epoch 5\tavg epoch loss = 0.1412\tavg epoch acc = 0.9919\n","epoch 6\tavg epoch loss = 0.1187\tavg epoch acc = 0.9939\n","epoch 7\tavg epoch loss = 0.1031\tavg epoch acc = 0.9951\n","epoch 8\tavg epoch loss = 0.09958\tavg epoch acc = 0.9958\n","epoch 9\tavg epoch loss = 0.08757\tavg epoch acc = 0.9963\n","training took 28.14 s\n","Avg test loss = 0.0373\tAvg test acc = 0.989\n","epoch 0\tavg epoch loss = 1.139\tavg epoch acc = 0.7847\n","epoch 1\tavg epoch loss = 0.3396\tavg epoch acc = 0.9748\n","epoch 2\tavg epoch loss = 0.2383\tavg epoch acc = 0.9841\n","epoch 3\tavg epoch loss = 0.1917\tavg epoch acc = 0.9877\n","epoch 4\tavg epoch loss = 0.1554\tavg epoch acc = 0.9908\n","epoch 5\tavg epoch loss = 0.1343\tavg epoch acc = 0.9927\n","epoch 6\tavg epoch loss = 0.1117\tavg epoch acc = 0.9944\n","epoch 7\tavg epoch loss = 0.09775\tavg epoch acc = 0.9954\n","epoch 8\tavg epoch loss = 0.08857\tavg epoch acc = 0.996\n","epoch 9\tavg epoch loss = 0.07813\tavg epoch acc = 0.9969\n","training took 27.91 s\n","Avg test loss = 0.0391\tAvg test acc = 0.989\n","epoch 0\tavg epoch loss = 1.14\tavg epoch acc = 0.7815\n","epoch 1\tavg epoch loss = 0.3309\tavg epoch acc = 0.976\n","epoch 2\tavg epoch loss = 0.2329\tavg epoch acc = 0.9843\n","epoch 3\tavg epoch loss = 0.1883\tavg epoch acc = 0.9884\n","epoch 4\tavg epoch loss = 0.1561\tavg epoch acc = 0.9907\n","epoch 5\tavg epoch loss = 0.1356\tavg epoch acc = 0.9928\n","epoch 6\tavg epoch loss = 0.1189\tavg epoch acc = 0.9938\n","epoch 7\tavg epoch loss = 0.1068\tavg epoch acc = 0.995\n","epoch 8\tavg epoch loss = 0.08855\tavg epoch acc = 0.9959\n","epoch 9\tavg epoch loss = 0.08301\tavg epoch acc = 0.9966\n","training took 28.01 s\n","Avg test loss = 0.0411\tAvg test acc = 0.989\n","{'lr': 0.001, 'beta1': 0.9, 'beta2': 0.999, 'batch_size': 128, 'weight_decay': 0.001, 'epsilon': 1e-10}\n","epoch 0\tavg epoch loss = 1.645\tavg epoch acc = 0.6455\n","epoch 1\tavg epoch loss = 0.4899\tavg epoch acc = 0.9628\n","epoch 2\tavg epoch loss = 0.3178\tavg epoch acc = 0.9784\n","epoch 3\tavg epoch loss = 0.2459\tavg epoch acc = 0.9846\n","epoch 4\tavg epoch loss = 0.2041\tavg epoch acc = 0.9878\n","epoch 5\tavg epoch loss = 0.1731\tavg epoch acc = 0.9901\n","epoch 6\tavg epoch loss = 0.1494\tavg epoch acc = 0.9919\n","epoch 7\tavg epoch loss = 0.131\tavg epoch acc = 0.9935\n","epoch 8\tavg epoch loss = 0.1172\tavg epoch acc = 0.9947\n","epoch 9\tavg epoch loss = 0.1188\tavg epoch acc = 0.9949\n","training took 17.32 s\n","Avg test loss = 0.0369\tAvg test acc = 0.99\n","epoch 0\tavg epoch loss = 1.635\tavg epoch acc = 0.655\n","epoch 1\tavg epoch loss = 0.4847\tavg epoch acc = 0.9628\n","epoch 2\tavg epoch loss = 0.3186\tavg epoch acc = 0.9781\n","epoch 3\tavg epoch loss = 0.2465\tavg epoch acc = 0.9837\n","epoch 4\tavg epoch loss = 0.2039\tavg epoch acc = 0.9878\n","epoch 5\tavg epoch loss = 0.1742\tavg epoch acc = 0.9902\n","epoch 6\tavg epoch loss = 0.1535\tavg epoch acc = 0.9921\n","epoch 7\tavg epoch loss = 0.136\tavg epoch acc = 0.9934\n","epoch 8\tavg epoch loss = 0.1167\tavg epoch acc = 0.9947\n","epoch 9\tavg epoch loss = 0.1053\tavg epoch acc = 0.9953\n","training took 17.31 s\n","Avg test loss = 0.0329\tAvg test acc = 0.99\n","epoch 0\tavg epoch loss = 1.635\tavg epoch acc = 0.6498\n","epoch 1\tavg epoch loss = 0.4864\tavg epoch acc = 0.9623\n","epoch 2\tavg epoch loss = 0.3218\tavg epoch acc = 0.9775\n","epoch 3\tavg epoch loss = 0.2491\tavg epoch acc = 0.9838\n","epoch 4\tavg epoch loss = 0.2045\tavg epoch acc = 0.9875\n","epoch 5\tavg epoch loss = 0.1728\tavg epoch acc = 0.9906\n","epoch 6\tavg epoch loss = 0.1492\tavg epoch acc = 0.9926\n","epoch 7\tavg epoch loss = 0.1328\tavg epoch acc = 0.9943\n","epoch 8\tavg epoch loss = 0.1171\tavg epoch acc = 0.9954\n","epoch 9\tavg epoch loss = 0.1121\tavg epoch acc = 0.9955\n","training took 17.25 s\n","Avg test loss = 0.0419\tAvg test acc = 0.99\n","{'lr': 0.001, 'beta1': 0.9, 'beta2': 0.999, 'batch_size': 128, 'weight_decay': 0.001, 'epsilon': 1e-08}\n","epoch 0\tavg epoch loss = 1.629\tavg epoch acc = 0.6517\n","epoch 1\tavg epoch loss = 0.4891\tavg epoch acc = 0.9627\n","epoch 2\tavg epoch loss = 0.3203\tavg epoch acc = 0.9794\n","epoch 3\tavg epoch loss = 0.247\tavg epoch acc = 0.9853\n","epoch 4\tavg epoch loss = 0.2052\tavg epoch acc = 0.9885\n","epoch 5\tavg epoch loss = 0.1743\tavg epoch acc = 0.9909\n","epoch 6\tavg epoch loss = 0.1508\tavg epoch acc = 0.9925\n","epoch 7\tavg epoch loss = 0.132\tavg epoch acc = 0.994\n","epoch 8\tavg epoch loss = 0.1213\tavg epoch acc = 0.9946\n","epoch 9\tavg epoch loss = 0.1063\tavg epoch acc = 0.9956\n","training took 17.29 s\n","Avg test loss = 0.0402\tAvg test acc = 0.99\n","epoch 0\tavg epoch loss = 1.637\tavg epoch acc = 0.6534\n","epoch 1\tavg epoch loss = 0.4876\tavg epoch acc = 0.9637\n","epoch 2\tavg epoch loss = 0.3233\tavg epoch acc = 0.9779\n","epoch 3\tavg epoch loss = 0.2514\tavg epoch acc = 0.9838\n","epoch 4\tavg epoch loss = 0.2064\tavg epoch acc = 0.9876\n","epoch 5\tavg epoch loss = 0.1747\tavg epoch acc = 0.9904\n","epoch 6\tavg epoch loss = 0.1528\tavg epoch acc = 0.9917\n","epoch 7\tavg epoch loss = 0.1334\tavg epoch acc = 0.9932\n","epoch 8\tavg epoch loss = 0.1246\tavg epoch acc = 0.9941\n","epoch 9\tavg epoch loss = 0.1126\tavg epoch acc = 0.9952\n","training took 17.3 s\n","Avg test loss = 0.0357\tAvg test acc = 0.99\n","epoch 0\tavg epoch loss = 1.64\tavg epoch acc = 0.6466\n","epoch 1\tavg epoch loss = 0.4839\tavg epoch acc = 0.9626\n","epoch 2\tavg epoch loss = 0.3145\tavg epoch acc = 0.9787\n","epoch 3\tavg epoch loss = 0.2418\tavg epoch acc = 0.985\n","epoch 4\tavg epoch loss = 0.1977\tavg epoch acc = 0.9889\n","epoch 5\tavg epoch loss = 0.1667\tavg epoch acc = 0.9913\n","epoch 6\tavg epoch loss = 0.1432\tavg epoch acc = 0.9927\n","epoch 7\tavg epoch loss = 0.1275\tavg epoch acc = 0.994\n","epoch 8\tavg epoch loss = 0.1104\tavg epoch acc = 0.9953\n","epoch 9\tavg epoch loss = 0.1025\tavg epoch acc = 0.9959\n","training took 17.23 s\n","Avg test loss = 0.0375\tAvg test acc = 0.989\n","{'lr': 0.001, 'beta1': 0.9, 'beta2': 0.999, 'batch_size': 128, 'weight_decay': 0.1, 'epsilon': 1e-10}\n","epoch 0\tavg epoch loss = 1.633\tavg epoch acc = 0.6481\n","epoch 1\tavg epoch loss = 0.4876\tavg epoch acc = 0.9627\n","epoch 2\tavg epoch loss = 0.3238\tavg epoch acc = 0.978\n","epoch 3\tavg epoch loss = 0.2513\tavg epoch acc = 0.984\n","epoch 4\tavg epoch loss = 0.2083\tavg epoch acc = 0.9874\n","epoch 5\tavg epoch loss = 0.1771\tavg epoch acc = 0.99\n","epoch 6\tavg epoch loss = 0.1558\tavg epoch acc = 0.992\n","epoch 7\tavg epoch loss = 0.1372\tavg epoch acc = 0.9931\n","epoch 8\tavg epoch loss = 0.1202\tavg epoch acc = 0.9943\n","epoch 9\tavg epoch loss = 0.1106\tavg epoch acc = 0.9951\n","training took 17.25 s\n","Avg test loss = 0.0333\tAvg test acc = 0.99\n","epoch 0\tavg epoch loss = 1.64\tavg epoch acc = 0.6535\n","epoch 1\tavg epoch loss = 0.4928\tavg epoch acc = 0.9618\n","epoch 2\tavg epoch loss = 0.3263\tavg epoch acc = 0.9772\n","epoch 3\tavg epoch loss = 0.2515\tavg epoch acc = 0.9835\n","epoch 4\tavg epoch loss = 0.2073\tavg epoch acc = 0.9874\n","epoch 5\tavg epoch loss = 0.1751\tavg epoch acc = 0.9904\n","epoch 6\tavg epoch loss = 0.1517\tavg epoch acc = 0.9919\n","epoch 7\tavg epoch loss = 0.1366\tavg epoch acc = 0.9931\n","epoch 8\tavg epoch loss = 0.1195\tavg epoch acc = 0.9942\n","epoch 9\tavg epoch loss = 0.1063\tavg epoch acc = 0.9955\n","training took 17.28 s\n","Avg test loss = 0.036\tAvg test acc = 0.989\n","epoch 0\tavg epoch loss = 1.64\tavg epoch acc = 0.6506\n","epoch 1\tavg epoch loss = 0.4815\tavg epoch acc = 0.9624\n","epoch 2\tavg epoch loss = 0.3152\tavg epoch acc = 0.9789\n","epoch 3\tavg epoch loss = 0.2445\tavg epoch acc = 0.9845\n","epoch 4\tavg epoch loss = 0.201\tavg epoch acc = 0.9881\n","epoch 5\tavg epoch loss = 0.1688\tavg epoch acc = 0.9909\n","epoch 6\tavg epoch loss = 0.1449\tavg epoch acc = 0.9928\n","epoch 7\tavg epoch loss = 0.132\tavg epoch acc = 0.9938\n","epoch 8\tavg epoch loss = 0.1216\tavg epoch acc = 0.9945\n","epoch 9\tavg epoch loss = 0.1069\tavg epoch acc = 0.9953\n","training took 17.24 s\n","Avg test loss = 0.0362\tAvg test acc = 0.989\n","{'lr': 0.001, 'beta1': 0.9, 'beta2': 0.999, 'batch_size': 128, 'weight_decay': 0.1, 'epsilon': 1e-08}\n","epoch 0\tavg epoch loss = 1.631\tavg epoch acc = 0.652\n","epoch 1\tavg epoch loss = 0.4811\tavg epoch acc = 0.9627\n","epoch 2\tavg epoch loss = 0.3117\tavg epoch acc = 0.9781\n","epoch 3\tavg epoch loss = 0.2411\tavg epoch acc = 0.9844\n","epoch 4\tavg epoch loss = 0.1999\tavg epoch acc = 0.9883\n","epoch 5\tavg epoch loss = 0.1702\tavg epoch acc = 0.9908\n","epoch 6\tavg epoch loss = 0.1488\tavg epoch acc = 0.9924\n","epoch 7\tavg epoch loss = 0.133\tavg epoch acc = 0.9937\n","epoch 8\tavg epoch loss = 0.1185\tavg epoch acc = 0.9941\n","epoch 9\tavg epoch loss = 0.1034\tavg epoch acc = 0.9954\n","training took 17.4 s\n","Avg test loss = 0.0381\tAvg test acc = 0.991\n","epoch 0\tavg epoch loss = 1.639\tavg epoch acc = 0.6524\n","epoch 1\tavg epoch loss = 0.4964\tavg epoch acc = 0.9607\n","epoch 2\tavg epoch loss = 0.3297\tavg epoch acc = 0.9776\n","epoch 3\tavg epoch loss = 0.2572\tavg epoch acc = 0.9831\n","epoch 4\tavg epoch loss = 0.213\tavg epoch acc = 0.9867\n","epoch 5\tavg epoch loss = 0.1808\tavg epoch acc = 0.9896\n","epoch 6\tavg epoch loss = 0.1562\tavg epoch acc = 0.9917\n","epoch 7\tavg epoch loss = 0.1392\tavg epoch acc = 0.9931\n","epoch 8\tavg epoch loss = 0.1246\tavg epoch acc = 0.9939\n","epoch 9\tavg epoch loss = 0.1114\tavg epoch acc = 0.9951\n","training took 17.29 s\n","Avg test loss = 0.0311\tAvg test acc = 0.991\n","epoch 0\tavg epoch loss = 1.641\tavg epoch acc = 0.647\n","epoch 1\tavg epoch loss = 0.4854\tavg epoch acc = 0.9635\n","epoch 2\tavg epoch loss = 0.3181\tavg epoch acc = 0.9784\n","epoch 3\tavg epoch loss = 0.2468\tavg epoch acc = 0.9843\n","epoch 4\tavg epoch loss = 0.2038\tavg epoch acc = 0.9882\n","epoch 5\tavg epoch loss = 0.1733\tavg epoch acc = 0.9905\n","epoch 6\tavg epoch loss = 0.1521\tavg epoch acc = 0.9921\n","epoch 7\tavg epoch loss = 0.1332\tavg epoch acc = 0.9935\n","epoch 8\tavg epoch loss = 0.1235\tavg epoch acc = 0.9941\n","epoch 9\tavg epoch loss = 0.1055\tavg epoch acc = 0.9955\n","training took 17.31 s\n","Avg test loss = 0.036\tAvg test acc = 0.989\n","{'lr': 0.0055000000000000005, 'beta1': 0.1, 'beta2': 0.5, 'batch_size': 32, 'weight_decay': 0.001, 'epsilon': 1e-10}\n","epoch 0\tavg epoch loss = 0.6674\tavg epoch acc = 0.9428\n","epoch 1\tavg epoch loss = 0.6573\tavg epoch acc = 0.9539\n","epoch 2\tavg epoch loss = 0.6803\tavg epoch acc = 0.9488\n","epoch 3\tavg epoch loss = 0.7525\tavg epoch acc = 0.9444\n","epoch 4\tavg epoch loss = 0.7988\tavg epoch acc = 0.9437\n","epoch 5\tavg epoch loss = 0.7713\tavg epoch acc = 0.9416\n","epoch 6\tavg epoch loss = 0.8233\tavg epoch acc = 0.9356\n","epoch 7\tavg epoch loss = 0.8275\tavg epoch acc = 0.9314\n","epoch 8\tavg epoch loss = 0.9277\tavg epoch acc = 0.9273\n","epoch 9\tavg epoch loss = 0.8405\tavg epoch acc = 0.9297\n","training took 54.09 s\n","Avg test loss = 0.382\tAvg test acc = 0.939\n","epoch 0\tavg epoch loss = 0.6559\tavg epoch acc = 0.9433\n","epoch 1\tavg epoch loss = 0.676\tavg epoch acc = 0.9569\n","epoch 2\tavg epoch loss = 0.7417\tavg epoch acc = 0.9519\n","epoch 3\tavg epoch loss = 0.7453\tavg epoch acc = 0.9503\n","epoch 4\tavg epoch loss = 0.7774\tavg epoch acc = 0.9457\n","epoch 5\tavg epoch loss = 0.801\tavg epoch acc = 0.9457\n","epoch 6\tavg epoch loss = 0.7458\tavg epoch acc = 0.9464\n","epoch 7\tavg epoch loss = 0.7071\tavg epoch acc = 0.9408\n","epoch 8\tavg epoch loss = 0.8256\tavg epoch acc = 0.9369\n","epoch 9\tavg epoch loss = 0.8477\tavg epoch acc = 0.9344\n","training took 53.93 s\n","Avg test loss = 0.368\tAvg test acc = 0.938\n","epoch 0\tavg epoch loss = 0.6736\tavg epoch acc = 0.9438\n","epoch 1\tavg epoch loss = 0.6813\tavg epoch acc = 0.9583\n","epoch 2\tavg epoch loss = 0.7545\tavg epoch acc = 0.9515\n","epoch 3\tavg epoch loss = 0.7046\tavg epoch acc = 0.9503\n","epoch 4\tavg epoch loss = 0.7504\tavg epoch acc = 0.9453\n","epoch 5\tavg epoch loss = 0.792\tavg epoch acc = 0.9478\n","epoch 6\tavg epoch loss = 0.8423\tavg epoch acc = 0.943\n","epoch 7\tavg epoch loss = 0.9028\tavg epoch acc = 0.9428\n","epoch 8\tavg epoch loss = 0.9419\tavg epoch acc = 0.9412\n","epoch 9\tavg epoch loss = 0.9946\tavg epoch acc = 0.9344\n","training took 54.32 s\n","Avg test loss = 0.329\tAvg test acc = 0.943\n","{'lr': 0.0055000000000000005, 'beta1': 0.1, 'beta2': 0.5, 'batch_size': 32, 'weight_decay': 0.001, 'epsilon': 1e-08}\n","epoch 0\tavg epoch loss = 0.6689\tavg epoch acc = 0.9418\n","epoch 1\tavg epoch loss = 0.6698\tavg epoch acc = 0.9569\n","epoch 2\tavg epoch loss = 0.6773\tavg epoch acc = 0.9511\n","epoch 3\tavg epoch loss = 0.6918\tavg epoch acc = 0.9502\n","epoch 4\tavg epoch loss = 0.7274\tavg epoch acc = 0.9471\n","epoch 5\tavg epoch loss = 0.7753\tavg epoch acc = 0.9459\n","epoch 6\tavg epoch loss = 0.8385\tavg epoch acc = 0.9415\n","epoch 7\tavg epoch loss = 0.8121\tavg epoch acc = 0.9413\n","epoch 8\tavg epoch loss = 0.787\tavg epoch acc = 0.9433\n","epoch 9\tavg epoch loss = 0.7483\tavg epoch acc = 0.9428\n","training took 54.17 s\n","Avg test loss = 0.34\tAvg test acc = 0.934\n","epoch 0\tavg epoch loss = 0.6632\tavg epoch acc = 0.9456\n","epoch 1\tavg epoch loss = 0.6877\tavg epoch acc = 0.9584\n","epoch 2\tavg epoch loss = 0.7299\tavg epoch acc = 0.9562\n","epoch 3\tavg epoch loss = 0.7484\tavg epoch acc = 0.9518\n","epoch 4\tavg epoch loss = 0.7378\tavg epoch acc = 0.9529\n","epoch 5\tavg epoch loss = 0.8104\tavg epoch acc = 0.9493\n","epoch 6\tavg epoch loss = 0.7566\tavg epoch acc = 0.9488\n","epoch 7\tavg epoch loss = 0.831\tavg epoch acc = 0.9491\n","epoch 8\tavg epoch loss = 0.8799\tavg epoch acc = 0.9437\n","epoch 9\tavg epoch loss = 0.8834\tavg epoch acc = 0.9406\n","training took 53.99 s\n","Avg test loss = 0.543\tAvg test acc = 0.94\n","epoch 0\tavg epoch loss = 0.6706\tavg epoch acc = 0.9455\n","epoch 1\tavg epoch loss = 0.695\tavg epoch acc = 0.958\n","epoch 2\tavg epoch loss = 0.7347\tavg epoch acc = 0.9551\n","epoch 3\tavg epoch loss = 0.7167\tavg epoch acc = 0.9507\n","epoch 4\tavg epoch loss = 0.7798\tavg epoch acc = 0.9459\n","epoch 5\tavg epoch loss = 0.7508\tavg epoch acc = 0.9407\n","epoch 6\tavg epoch loss = 0.7145\tavg epoch acc = 0.9435\n","epoch 7\tavg epoch loss = 0.7786\tavg epoch acc = 0.9375\n","epoch 8\tavg epoch loss = 0.8163\tavg epoch acc = 0.9397\n","epoch 9\tavg epoch loss = 0.7983\tavg epoch acc = 0.9356\n","training took 54.04 s\n","Avg test loss = 0.261\tAvg test acc = 0.932\n","{'lr': 0.0055000000000000005, 'beta1': 0.1, 'beta2': 0.5, 'batch_size': 32, 'weight_decay': 0.1, 'epsilon': 1e-10}\n","epoch 0\tavg epoch loss = 0.6168\tavg epoch acc = 0.9434\n","epoch 1\tavg epoch loss = 0.5539\tavg epoch acc = 0.9624\n","epoch 2\tavg epoch loss = 0.5617\tavg epoch acc = 0.9604\n","epoch 3\tavg epoch loss = 0.5317\tavg epoch acc = 0.9608\n","epoch 4\tavg epoch loss = 0.5242\tavg epoch acc = 0.9601\n","epoch 5\tavg epoch loss = 0.5133\tavg epoch acc = 0.9597\n","epoch 6\tavg epoch loss = 0.5104\tavg epoch acc = 0.9595\n","epoch 7\tavg epoch loss = 0.5191\tavg epoch acc = 0.9603\n","epoch 8\tavg epoch loss = 0.5187\tavg epoch acc = 0.9583\n","epoch 9\tavg epoch loss = 0.5128\tavg epoch acc = 0.9593\n","training took 54.09 s\n","Avg test loss = 0.203\tAvg test acc = 0.95\n","epoch 0\tavg epoch loss = 0.6408\tavg epoch acc = 0.9437\n","epoch 1\tavg epoch loss = 0.5869\tavg epoch acc = 0.9602\n","epoch 2\tavg epoch loss = 0.5682\tavg epoch acc = 0.9596\n","epoch 3\tavg epoch loss = 0.5756\tavg epoch acc = 0.9598\n","epoch 4\tavg epoch loss = 0.5497\tavg epoch acc = 0.96\n","epoch 5\tavg epoch loss = 0.5664\tavg epoch acc = 0.9612\n","epoch 6\tavg epoch loss = 0.5448\tavg epoch acc = 0.9597\n","epoch 7\tavg epoch loss = 0.5379\tavg epoch acc = 0.9599\n","epoch 8\tavg epoch loss = 0.5349\tavg epoch acc = 0.9589\n","epoch 9\tavg epoch loss = 0.5277\tavg epoch acc = 0.9591\n","training took 54.06 s\n","Avg test loss = 0.21\tAvg test acc = 0.947\n","epoch 0\tavg epoch loss = 0.6389\tavg epoch acc = 0.9439\n","epoch 1\tavg epoch loss = 0.5861\tavg epoch acc = 0.9588\n","epoch 2\tavg epoch loss = 0.5494\tavg epoch acc = 0.9605\n","epoch 3\tavg epoch loss = 0.5472\tavg epoch acc = 0.9586\n","epoch 4\tavg epoch loss = 0.5433\tavg epoch acc = 0.9568\n","epoch 5\tavg epoch loss = 0.5296\tavg epoch acc = 0.9581\n","epoch 6\tavg epoch loss = 0.5267\tavg epoch acc = 0.9578\n","epoch 7\tavg epoch loss = 0.5264\tavg epoch acc = 0.9578\n","epoch 8\tavg epoch loss = 0.5196\tavg epoch acc = 0.9578\n","epoch 9\tavg epoch loss = 0.5383\tavg epoch acc = 0.9584\n","training took 54.19 s\n","Avg test loss = 0.183\tAvg test acc = 0.942\n","{'lr': 0.0055000000000000005, 'beta1': 0.1, 'beta2': 0.5, 'batch_size': 32, 'weight_decay': 0.1, 'epsilon': 1e-08}\n","epoch 0\tavg epoch loss = 0.6333\tavg epoch acc = 0.9429\n","epoch 1\tavg epoch loss = 0.5717\tavg epoch acc = 0.9602\n","epoch 2\tavg epoch loss = 0.5569\tavg epoch acc = 0.9613\n","epoch 3\tavg epoch loss = 0.5382\tavg epoch acc = 0.9611\n","epoch 4\tavg epoch loss = 0.5295\tavg epoch acc = 0.9615\n","epoch 5\tavg epoch loss = 0.5154\tavg epoch acc = 0.9604\n","epoch 6\tavg epoch loss = 0.5008\tavg epoch acc = 0.9599\n","epoch 7\tavg epoch loss = 0.5053\tavg epoch acc = 0.9605\n","epoch 8\tavg epoch loss = 0.5083\tavg epoch acc = 0.9595\n","epoch 9\tavg epoch loss = 0.5154\tavg epoch acc = 0.9581\n","training took 53.86 s\n","Avg test loss = 0.237\tAvg test acc = 0.951\n","epoch 0\tavg epoch loss = 0.6186\tavg epoch acc = 0.9437\n","epoch 1\tavg epoch loss = 0.5762\tavg epoch acc = 0.9614\n","epoch 2\tavg epoch loss = 0.5255\tavg epoch acc = 0.9613\n","epoch 3\tavg epoch loss = 0.5097\tavg epoch acc = 0.9616\n","epoch 4\tavg epoch loss = 0.5012\tavg epoch acc = 0.9617\n","epoch 5\tavg epoch loss = 0.493\tavg epoch acc = 0.9611\n","epoch 6\tavg epoch loss = 0.4912\tavg epoch acc = 0.9617\n","epoch 7\tavg epoch loss = 0.5023\tavg epoch acc = 0.9619\n","epoch 8\tavg epoch loss = 0.5102\tavg epoch acc = 0.9612\n","epoch 9\tavg epoch loss = 0.5137\tavg epoch acc = 0.9606\n","training took 54.05 s\n","Avg test loss = 0.21\tAvg test acc = 0.932\n","epoch 0\tavg epoch loss = 0.6424\tavg epoch acc = 0.9415\n","epoch 1\tavg epoch loss = 0.5389\tavg epoch acc = 0.9614\n","epoch 2\tavg epoch loss = 0.552\tavg epoch acc = 0.9605\n","epoch 3\tavg epoch loss = 0.5418\tavg epoch acc = 0.9603\n","epoch 4\tavg epoch loss = 0.5145\tavg epoch acc = 0.9615\n","epoch 5\tavg epoch loss = 0.507\tavg epoch acc = 0.9591\n","epoch 6\tavg epoch loss = 0.4928\tavg epoch acc = 0.9603\n","epoch 7\tavg epoch loss = 0.4909\tavg epoch acc = 0.9601\n","epoch 8\tavg epoch loss = 0.4834\tavg epoch acc = 0.9604\n","epoch 9\tavg epoch loss = 0.4741\tavg epoch acc = 0.9608\n","training took 54.07 s\n","Avg test loss = 0.184\tAvg test acc = 0.952\n","{'lr': 0.0055000000000000005, 'beta1': 0.1, 'beta2': 0.5, 'batch_size': 64, 'weight_decay': 0.001, 'epsilon': 1e-10}\n","epoch 0\tavg epoch loss = 0.5524\tavg epoch acc = 0.9432\n","epoch 1\tavg epoch loss = 0.4407\tavg epoch acc = 0.9724\n","epoch 2\tavg epoch loss = 0.4606\tavg epoch acc = 0.9728\n","epoch 3\tavg epoch loss = 0.4816\tavg epoch acc = 0.9717\n","epoch 4\tavg epoch loss = 0.5135\tavg epoch acc = 0.9707\n","epoch 5\tavg epoch loss = 0.5198\tavg epoch acc = 0.9677\n","epoch 6\tavg epoch loss = 0.527\tavg epoch acc = 0.9655\n","epoch 7\tavg epoch loss = 0.5459\tavg epoch acc = 0.9643\n","epoch 8\tavg epoch loss = 0.5552\tavg epoch acc = 0.9646\n","epoch 9\tavg epoch loss = 0.5432\tavg epoch acc = 0.9659\n","training took 28.05 s\n","Avg test loss = 0.217\tAvg test acc = 0.952\n","epoch 0\tavg epoch loss = 0.5437\tavg epoch acc = 0.9428\n","epoch 1\tavg epoch loss = 0.461\tavg epoch acc = 0.9725\n","epoch 2\tavg epoch loss = 0.4898\tavg epoch acc = 0.9693\n","epoch 3\tavg epoch loss = 0.5021\tavg epoch acc = 0.969\n","epoch 4\tavg epoch loss = 0.515\tavg epoch acc = 0.9655\n","epoch 5\tavg epoch loss = 0.5305\tavg epoch acc = 0.9669\n","epoch 6\tavg epoch loss = 0.5297\tavg epoch acc = 0.9665\n","epoch 7\tavg epoch loss = 0.5648\tavg epoch acc = 0.9676\n","epoch 8\tavg epoch loss = 0.5577\tavg epoch acc = 0.9646\n","epoch 9\tavg epoch loss = 0.5174\tavg epoch acc = 0.9647\n","training took 27.8 s\n","Avg test loss = 0.21\tAvg test acc = 0.953\n","epoch 0\tavg epoch loss = 0.5665\tavg epoch acc = 0.9395\n","epoch 1\tavg epoch loss = 0.466\tavg epoch acc = 0.9716\n","epoch 2\tavg epoch loss = 0.4809\tavg epoch acc = 0.9724\n","epoch 3\tavg epoch loss = 0.5049\tavg epoch acc = 0.9713\n","epoch 4\tavg epoch loss = 0.5266\tavg epoch acc = 0.9706\n","epoch 5\tavg epoch loss = 0.5866\tavg epoch acc = 0.9704\n","epoch 6\tavg epoch loss = 0.5836\tavg epoch acc = 0.9692\n","epoch 7\tavg epoch loss = 0.5824\tavg epoch acc = 0.9679\n","epoch 8\tavg epoch loss = 0.5778\tavg epoch acc = 0.9686\n","epoch 9\tavg epoch loss = 0.5876\tavg epoch acc = 0.9676\n","training took 27.87 s\n","Avg test loss = 0.214\tAvg test acc = 0.956\n","{'lr': 0.0055000000000000005, 'beta1': 0.1, 'beta2': 0.5, 'batch_size': 64, 'weight_decay': 0.001, 'epsilon': 1e-08}\n","epoch 0\tavg epoch loss = 0.5485\tavg epoch acc = 0.9421\n","epoch 1\tavg epoch loss = 0.4367\tavg epoch acc = 0.9744\n","epoch 2\tavg epoch loss = 0.4656\tavg epoch acc = 0.9736\n","epoch 3\tavg epoch loss = 0.4854\tavg epoch acc = 0.9732\n","epoch 4\tavg epoch loss = 0.4972\tavg epoch acc = 0.9709\n","epoch 5\tavg epoch loss = 0.4955\tavg epoch acc = 0.9696\n","epoch 6\tavg epoch loss = 0.5086\tavg epoch acc = 0.9675\n","epoch 7\tavg epoch loss = 0.5002\tavg epoch acc = 0.9669\n","epoch 8\tavg epoch loss = 0.5221\tavg epoch acc = 0.9667\n","epoch 9\tavg epoch loss = 0.52\tavg epoch acc = 0.9667\n","training took 28.17 s\n","Avg test loss = 0.558\tAvg test acc = 0.899\n","epoch 0\tavg epoch loss = 0.5617\tavg epoch acc = 0.9413\n","epoch 1\tavg epoch loss = 0.4422\tavg epoch acc = 0.9736\n","epoch 2\tavg epoch loss = 0.4639\tavg epoch acc = 0.9736\n","epoch 3\tavg epoch loss = 0.4867\tavg epoch acc = 0.9733\n","epoch 4\tavg epoch loss = 0.4903\tavg epoch acc = 0.9725\n","epoch 5\tavg epoch loss = 0.4712\tavg epoch acc = 0.9726\n","epoch 6\tavg epoch loss = 0.4795\tavg epoch acc = 0.9715\n","epoch 7\tavg epoch loss = 0.5071\tavg epoch acc = 0.9715\n","epoch 8\tavg epoch loss = 0.5357\tavg epoch acc = 0.9706\n","epoch 9\tavg epoch loss = 0.5203\tavg epoch acc = 0.9719\n","training took 27.91 s\n","Avg test loss = 0.251\tAvg test acc = 0.937\n","epoch 0\tavg epoch loss = 0.5575\tavg epoch acc = 0.941\n","epoch 1\tavg epoch loss = 0.4556\tavg epoch acc = 0.9703\n","epoch 2\tavg epoch loss = 0.4661\tavg epoch acc = 0.971\n","epoch 3\tavg epoch loss = 0.4951\tavg epoch acc = 0.9694\n","epoch 4\tavg epoch loss = 0.5136\tavg epoch acc = 0.9681\n","epoch 5\tavg epoch loss = 0.5189\tavg epoch acc = 0.9677\n","epoch 6\tavg epoch loss = 0.5228\tavg epoch acc = 0.9674\n","epoch 7\tavg epoch loss = 0.5308\tavg epoch acc = 0.9686\n","epoch 8\tavg epoch loss = 0.4939\tavg epoch acc = 0.9679\n","epoch 9\tavg epoch loss = 0.5286\tavg epoch acc = 0.9671\n","training took 27.91 s\n","Avg test loss = 0.142\tAvg test acc = 0.967\n","{'lr': 0.0055000000000000005, 'beta1': 0.1, 'beta2': 0.5, 'batch_size': 64, 'weight_decay': 0.1, 'epsilon': 1e-10}\n","epoch 0\tavg epoch loss = 0.5486\tavg epoch acc = 0.9399\n","epoch 1\tavg epoch loss = 0.4097\tavg epoch acc = 0.972\n","epoch 2\tavg epoch loss = 0.4262\tavg epoch acc = 0.9725\n","epoch 3\tavg epoch loss = 0.4249\tavg epoch acc = 0.9733\n","epoch 4\tavg epoch loss = 0.4054\tavg epoch acc = 0.9725\n","epoch 5\tavg epoch loss = 0.4244\tavg epoch acc = 0.9736\n","epoch 6\tavg epoch loss = 0.4021\tavg epoch acc = 0.9746\n","epoch 7\tavg epoch loss = 0.3975\tavg epoch acc = 0.9746\n","epoch 8\tavg epoch loss = 0.4015\tavg epoch acc = 0.9738\n","epoch 9\tavg epoch loss = 0.4002\tavg epoch acc = 0.9733\n","training took 28.02 s\n","Avg test loss = 0.156\tAvg test acc = 0.955\n","epoch 0\tavg epoch loss = 0.5467\tavg epoch acc = 0.9398\n","epoch 1\tavg epoch loss = 0.4058\tavg epoch acc = 0.9726\n","epoch 2\tavg epoch loss = 0.4059\tavg epoch acc = 0.9735\n","epoch 3\tavg epoch loss = 0.4128\tavg epoch acc = 0.9735\n","epoch 4\tavg epoch loss = 0.417\tavg epoch acc = 0.9735\n","epoch 5\tavg epoch loss = 0.4092\tavg epoch acc = 0.9729\n","epoch 6\tavg epoch loss = 0.4109\tavg epoch acc = 0.9726\n","epoch 7\tavg epoch loss = 0.3928\tavg epoch acc = 0.9725\n","epoch 8\tavg epoch loss = 0.3898\tavg epoch acc = 0.9734\n","epoch 9\tavg epoch loss = 0.3903\tavg epoch acc = 0.9737\n","training took 27.9 s\n","Avg test loss = 0.168\tAvg test acc = 0.958\n","epoch 0\tavg epoch loss = 0.5509\tavg epoch acc = 0.94\n","epoch 1\tavg epoch loss = 0.415\tavg epoch acc = 0.9704\n","epoch 2\tavg epoch loss = 0.4209\tavg epoch acc = 0.9725\n","epoch 3\tavg epoch loss = 0.3979\tavg epoch acc = 0.9734\n","epoch 4\tavg epoch loss = 0.4036\tavg epoch acc = 0.9735\n","epoch 5\tavg epoch loss = 0.3947\tavg epoch acc = 0.9739\n","epoch 6\tavg epoch loss = 0.3966\tavg epoch acc = 0.9723\n","epoch 7\tavg epoch loss = 0.387\tavg epoch acc = 0.9725\n","epoch 8\tavg epoch loss = 0.3906\tavg epoch acc = 0.973\n","epoch 9\tavg epoch loss = 0.3862\tavg epoch acc = 0.9732\n","training took 28.12 s\n","Avg test loss = 0.123\tAvg test acc = 0.967\n","{'lr': 0.0055000000000000005, 'beta1': 0.1, 'beta2': 0.5, 'batch_size': 64, 'weight_decay': 0.1, 'epsilon': 1e-08}\n","epoch 0\tavg epoch loss = 0.5588\tavg epoch acc = 0.9405\n","epoch 1\tavg epoch loss = 0.4133\tavg epoch acc = 0.9719\n","epoch 2\tavg epoch loss = 0.398\tavg epoch acc = 0.9733\n","epoch 3\tavg epoch loss = 0.4031\tavg epoch acc = 0.9739\n","epoch 4\tavg epoch loss = 0.3992\tavg epoch acc = 0.9738\n","epoch 5\tavg epoch loss = 0.3933\tavg epoch acc = 0.9727\n","epoch 6\tavg epoch loss = 0.39\tavg epoch acc = 0.9736\n","epoch 7\tavg epoch loss = 0.3766\tavg epoch acc = 0.9734\n","epoch 8\tavg epoch loss = 0.375\tavg epoch acc = 0.974\n","epoch 9\tavg epoch loss = 0.3799\tavg epoch acc = 0.9745\n","training took 28.25 s\n","Avg test loss = 0.139\tAvg test acc = 0.957\n","epoch 0\tavg epoch loss = 0.5428\tavg epoch acc = 0.94\n","epoch 1\tavg epoch loss = 0.4284\tavg epoch acc = 0.9719\n","epoch 2\tavg epoch loss = 0.4132\tavg epoch acc = 0.9724\n","epoch 3\tavg epoch loss = 0.4049\tavg epoch acc = 0.9719\n","epoch 4\tavg epoch loss = 0.4063\tavg epoch acc = 0.9719\n","epoch 5\tavg epoch loss = 0.4089\tavg epoch acc = 0.9727\n","epoch 6\tavg epoch loss = 0.4051\tavg epoch acc = 0.9721\n","epoch 7\tavg epoch loss = 0.3981\tavg epoch acc = 0.9721\n","epoch 8\tavg epoch loss = 0.3979\tavg epoch acc = 0.9716\n","epoch 9\tavg epoch loss = 0.3986\tavg epoch acc = 0.9715\n","training took 27.97 s\n","Avg test loss = 0.141\tAvg test acc = 0.958\n","epoch 0\tavg epoch loss = 0.5635\tavg epoch acc = 0.9394\n","epoch 1\tavg epoch loss = 0.435\tavg epoch acc = 0.9716\n","epoch 2\tavg epoch loss = 0.4425\tavg epoch acc = 0.971\n","epoch 3\tavg epoch loss = 0.4203\tavg epoch acc = 0.9709\n","epoch 4\tavg epoch loss = 0.4244\tavg epoch acc = 0.9718\n","epoch 5\tavg epoch loss = 0.42\tavg epoch acc = 0.9711\n","epoch 6\tavg epoch loss = 0.4244\tavg epoch acc = 0.971\n","epoch 7\tavg epoch loss = 0.4068\tavg epoch acc = 0.9714\n","epoch 8\tavg epoch loss = 0.4014\tavg epoch acc = 0.9711\n","epoch 9\tavg epoch loss = 0.4117\tavg epoch acc = 0.9715\n","training took 27.95 s\n","Avg test loss = 0.141\tAvg test acc = 0.957\n","{'lr': 0.0055000000000000005, 'beta1': 0.1, 'beta2': 0.5, 'batch_size': 128, 'weight_decay': 0.001, 'epsilon': 1e-10}\n","epoch 0\tavg epoch loss = 0.5925\tavg epoch acc = 0.9204\n","epoch 1\tavg epoch loss = 0.3229\tavg epoch acc = 0.9776\n","epoch 2\tavg epoch loss = 0.3222\tavg epoch acc = 0.98\n","epoch 3\tavg epoch loss = 0.3362\tavg epoch acc = 0.9818\n","epoch 4\tavg epoch loss = 0.3388\tavg epoch acc = 0.9826\n","epoch 5\tavg epoch loss = 0.3409\tavg epoch acc = 0.9837\n","epoch 6\tavg epoch loss = 0.3524\tavg epoch acc = 0.983\n","epoch 7\tavg epoch loss = 0.3839\tavg epoch acc = 0.9826\n","epoch 8\tavg epoch loss = 0.3672\tavg epoch acc = 0.9844\n","epoch 9\tavg epoch loss = 0.3554\tavg epoch acc = 0.9827\n","training took 17.32 s\n","Avg test loss = 0.108\tAvg test acc = 0.974\n","epoch 0\tavg epoch loss = 0.5697\tavg epoch acc = 0.9253\n","epoch 1\tavg epoch loss = 0.3187\tavg epoch acc = 0.9782\n","epoch 2\tavg epoch loss = 0.3232\tavg epoch acc = 0.9813\n","epoch 3\tavg epoch loss = 0.3257\tavg epoch acc = 0.9816\n","epoch 4\tavg epoch loss = 0.3293\tavg epoch acc = 0.9826\n","epoch 5\tavg epoch loss = 0.3416\tavg epoch acc = 0.9833\n","epoch 6\tavg epoch loss = 0.3283\tavg epoch acc = 0.9829\n","epoch 7\tavg epoch loss = 0.3231\tavg epoch acc = 0.984\n","epoch 8\tavg epoch loss = 0.3411\tavg epoch acc = 0.9847\n","epoch 9\tavg epoch loss = 0.3275\tavg epoch acc = 0.9843\n","training took 17.33 s\n","Avg test loss = 0.12\tAvg test acc = 0.972\n","epoch 0\tavg epoch loss = 0.5658\tavg epoch acc = 0.9286\n","epoch 1\tavg epoch loss = 0.3193\tavg epoch acc = 0.9784\n","epoch 2\tavg epoch loss = 0.3145\tavg epoch acc = 0.9821\n","epoch 3\tavg epoch loss = 0.3213\tavg epoch acc = 0.9834\n","epoch 4\tavg epoch loss = 0.3329\tavg epoch acc = 0.9826\n","epoch 5\tavg epoch loss = 0.3449\tavg epoch acc = 0.9838\n","epoch 6\tavg epoch loss = 0.3324\tavg epoch acc = 0.9832\n","epoch 7\tavg epoch loss = 0.3472\tavg epoch acc = 0.9833\n","epoch 8\tavg epoch loss = 0.3529\tavg epoch acc = 0.9824\n","epoch 9\tavg epoch loss = 0.3666\tavg epoch acc = 0.9816\n","training took 17.35 s\n","Avg test loss = 0.131\tAvg test acc = 0.974\n","{'lr': 0.0055000000000000005, 'beta1': 0.1, 'beta2': 0.5, 'batch_size': 128, 'weight_decay': 0.001, 'epsilon': 1e-08}\n","epoch 0\tavg epoch loss = 0.5846\tavg epoch acc = 0.924\n","epoch 1\tavg epoch loss = 0.3091\tavg epoch acc = 0.9785\n","epoch 2\tavg epoch loss = 0.3018\tavg epoch acc = 0.9813\n","epoch 3\tavg epoch loss = 0.2993\tavg epoch acc = 0.984\n","epoch 4\tavg epoch loss = 0.3044\tavg epoch acc = 0.9844\n","epoch 5\tavg epoch loss = 0.3151\tavg epoch acc = 0.9841\n","epoch 6\tavg epoch loss = 0.3358\tavg epoch acc = 0.984\n","epoch 7\tavg epoch loss = 0.3226\tavg epoch acc = 0.9845\n","epoch 8\tavg epoch loss = 0.3636\tavg epoch acc = 0.9834\n","epoch 9\tavg epoch loss = 0.3506\tavg epoch acc = 0.9823\n","training took 17.43 s\n","Avg test loss = 0.137\tAvg test acc = 0.965\n","epoch 0\tavg epoch loss = 0.5797\tavg epoch acc = 0.9244\n","epoch 1\tavg epoch loss = 0.3173\tavg epoch acc = 0.9788\n","epoch 2\tavg epoch loss = 0.3209\tavg epoch acc = 0.981\n","epoch 3\tavg epoch loss = 0.3212\tavg epoch acc = 0.9823\n","epoch 4\tavg epoch loss = 0.3285\tavg epoch acc = 0.9833\n","epoch 5\tavg epoch loss = 0.3524\tavg epoch acc = 0.9837\n","epoch 6\tavg epoch loss = 0.3672\tavg epoch acc = 0.9838\n","epoch 7\tavg epoch loss = 0.3526\tavg epoch acc = 0.9843\n","epoch 8\tavg epoch loss = 0.3404\tavg epoch acc = 0.9849\n","epoch 9\tavg epoch loss = 0.3451\tavg epoch acc = 0.984\n","training took 17.44 s\n","Avg test loss = 0.505\tAvg test acc = 0.835\n","epoch 0\tavg epoch loss = 0.5774\tavg epoch acc = 0.9239\n","epoch 1\tavg epoch loss = 0.3188\tavg epoch acc = 0.9787\n","epoch 2\tavg epoch loss = 0.3177\tavg epoch acc = 0.9812\n","epoch 3\tavg epoch loss = 0.32\tavg epoch acc = 0.9829\n","epoch 4\tavg epoch loss = 0.3367\tavg epoch acc = 0.982\n","epoch 5\tavg epoch loss = 0.3352\tavg epoch acc = 0.9831\n","epoch 6\tavg epoch loss = 0.3534\tavg epoch acc = 0.9839\n","epoch 7\tavg epoch loss = 0.3526\tavg epoch acc = 0.9832\n","epoch 8\tavg epoch loss = 0.3735\tavg epoch acc = 0.9818\n","epoch 9\tavg epoch loss = 0.3676\tavg epoch acc = 0.9816\n","training took 17.25 s\n","Avg test loss = 0.152\tAvg test acc = 0.959\n","{'lr': 0.0055000000000000005, 'beta1': 0.1, 'beta2': 0.5, 'batch_size': 128, 'weight_decay': 0.1, 'epsilon': 1e-10}\n","epoch 0\tavg epoch loss = 0.5728\tavg epoch acc = 0.9226\n","epoch 1\tavg epoch loss = 0.3218\tavg epoch acc = 0.9772\n","epoch 2\tavg epoch loss = 0.3013\tavg epoch acc = 0.9807\n","epoch 3\tavg epoch loss = 0.3064\tavg epoch acc = 0.9821\n","epoch 4\tavg epoch loss = 0.3029\tavg epoch acc = 0.9823\n","epoch 5\tavg epoch loss = 0.301\tavg epoch acc = 0.9827\n","epoch 6\tavg epoch loss = 0.3003\tavg epoch acc = 0.9826\n","epoch 7\tavg epoch loss = 0.2934\tavg epoch acc = 0.983\n","epoch 8\tavg epoch loss = 0.2984\tavg epoch acc = 0.9826\n","epoch 9\tavg epoch loss = 0.2961\tavg epoch acc = 0.9832\n","training took 17.33 s\n","Avg test loss = 0.128\tAvg test acc = 0.964\n","epoch 0\tavg epoch loss = 0.5872\tavg epoch acc = 0.9204\n","epoch 1\tavg epoch loss = 0.3167\tavg epoch acc = 0.9774\n","epoch 2\tavg epoch loss = 0.3084\tavg epoch acc = 0.9806\n","epoch 3\tavg epoch loss = 0.3156\tavg epoch acc = 0.9816\n","epoch 4\tavg epoch loss = 0.3025\tavg epoch acc = 0.9816\n","epoch 5\tavg epoch loss = 0.2912\tavg epoch acc = 0.9828\n","epoch 6\tavg epoch loss = 0.2918\tavg epoch acc = 0.9829\n","epoch 7\tavg epoch loss = 0.289\tavg epoch acc = 0.9827\n","epoch 8\tavg epoch loss = 0.2905\tavg epoch acc = 0.9823\n","epoch 9\tavg epoch loss = 0.2885\tavg epoch acc = 0.9828\n","training took 17.26 s\n","Avg test loss = 0.0892\tAvg test acc = 0.976\n","epoch 0\tavg epoch loss = 0.5819\tavg epoch acc = 0.9247\n","epoch 1\tavg epoch loss = 0.305\tavg epoch acc = 0.9773\n","epoch 2\tavg epoch loss = 0.3033\tavg epoch acc = 0.9802\n","epoch 3\tavg epoch loss = 0.2947\tavg epoch acc = 0.9811\n","epoch 4\tavg epoch loss = 0.3003\tavg epoch acc = 0.9816\n","epoch 5\tavg epoch loss = 0.3022\tavg epoch acc = 0.9822\n","epoch 6\tavg epoch loss = 0.2909\tavg epoch acc = 0.9825\n","epoch 7\tavg epoch loss = 0.3\tavg epoch acc = 0.9812\n","epoch 8\tavg epoch loss = 0.2944\tavg epoch acc = 0.9818\n","epoch 9\tavg epoch loss = 0.2944\tavg epoch acc = 0.9827\n","training took 17.28 s\n","Avg test loss = 0.126\tAvg test acc = 0.97\n","{'lr': 0.0055000000000000005, 'beta1': 0.1, 'beta2': 0.5, 'batch_size': 128, 'weight_decay': 0.1, 'epsilon': 1e-08}\n","epoch 0\tavg epoch loss = 0.5556\tavg epoch acc = 0.9284\n","epoch 1\tavg epoch loss = 0.3089\tavg epoch acc = 0.9777\n","epoch 2\tavg epoch loss = 0.2987\tavg epoch acc = 0.9805\n","epoch 3\tavg epoch loss = 0.2892\tavg epoch acc = 0.9823\n","epoch 4\tavg epoch loss = 0.294\tavg epoch acc = 0.9827\n","epoch 5\tavg epoch loss = 0.2941\tavg epoch acc = 0.983\n","epoch 6\tavg epoch loss = 0.2914\tavg epoch acc = 0.9834\n","epoch 7\tavg epoch loss = 0.2808\tavg epoch acc = 0.9828\n","epoch 8\tavg epoch loss = 0.2939\tavg epoch acc = 0.9827\n","epoch 9\tavg epoch loss = 0.2837\tavg epoch acc = 0.9825\n","training took 17.29 s\n","Avg test loss = 0.155\tAvg test acc = 0.961\n","epoch 0\tavg epoch loss = 0.5754\tavg epoch acc = 0.9227\n","epoch 1\tavg epoch loss = 0.3145\tavg epoch acc = 0.9782\n","epoch 2\tavg epoch loss = 0.297\tavg epoch acc = 0.9812\n","epoch 3\tavg epoch loss = 0.3054\tavg epoch acc = 0.9822\n","epoch 4\tavg epoch loss = 0.2994\tavg epoch acc = 0.9819\n","epoch 5\tavg epoch loss = 0.2996\tavg epoch acc = 0.983\n","epoch 6\tavg epoch loss = 0.2946\tavg epoch acc = 0.9829\n","epoch 7\tavg epoch loss = 0.2963\tavg epoch acc = 0.984\n","epoch 8\tavg epoch loss = 0.2781\tavg epoch acc = 0.9836\n","epoch 9\tavg epoch loss = 0.2847\tavg epoch acc = 0.9837\n","training took 17.27 s\n","Avg test loss = 0.0986\tAvg test acc = 0.974\n","epoch 0\tavg epoch loss = 0.5781\tavg epoch acc = 0.9233\n","epoch 1\tavg epoch loss = 0.3108\tavg epoch acc = 0.9784\n","epoch 2\tavg epoch loss = 0.3034\tavg epoch acc = 0.982\n","epoch 3\tavg epoch loss = 0.3035\tavg epoch acc = 0.9821\n","epoch 4\tavg epoch loss = 0.2981\tavg epoch acc = 0.9825\n","epoch 5\tavg epoch loss = 0.2962\tavg epoch acc = 0.983\n","epoch 6\tavg epoch loss = 0.292\tavg epoch acc = 0.9831\n","epoch 7\tavg epoch loss = 0.2895\tavg epoch acc = 0.9827\n","epoch 8\tavg epoch loss = 0.2942\tavg epoch acc = 0.9831\n","epoch 9\tavg epoch loss = 0.2899\tavg epoch acc = 0.9829\n","training took 17.25 s\n","Avg test loss = 0.226\tAvg test acc = 0.934\n","{'lr': 0.0055000000000000005, 'beta1': 0.1, 'beta2': 0.999, 'batch_size': 32, 'weight_decay': 0.001, 'epsilon': 1e-10}\n","epoch 0\tavg epoch loss = 0.5683\tavg epoch acc = 0.9204\n","epoch 1\tavg epoch loss = 0.3072\tavg epoch acc = 0.9745\n","epoch 2\tavg epoch loss = 0.3066\tavg epoch acc = 0.9784\n","epoch 3\tavg epoch loss = 0.2882\tavg epoch acc = 0.9811\n","epoch 4\tavg epoch loss = 0.2812\tavg epoch acc = 0.9844\n","epoch 5\tavg epoch loss = 0.2646\tavg epoch acc = 0.9856\n","epoch 6\tavg epoch loss = 0.2703\tavg epoch acc = 0.9867\n","epoch 7\tavg epoch loss = 0.2566\tavg epoch acc = 0.9877\n","epoch 8\tavg epoch loss = 0.2463\tavg epoch acc = 0.9882\n","epoch 9\tavg epoch loss = 0.2525\tavg epoch acc = 0.9872\n","training took 54.11 s\n","Avg test loss = 0.081\tAvg test acc = 0.977\n","epoch 0\tavg epoch loss = 0.5882\tavg epoch acc = 0.9173\n","epoch 1\tavg epoch loss = 0.2995\tavg epoch acc = 0.9744\n","epoch 2\tavg epoch loss = 0.2894\tavg epoch acc = 0.9778\n","epoch 3\tavg epoch loss = 1.18\tavg epoch acc = 0.6723\n","epoch 4\tavg epoch loss = 0.8463\tavg epoch acc = 0.7597\n","epoch 5\tavg epoch loss = 0.2606\tavg epoch acc = 0.9821\n","epoch 6\tavg epoch loss = 0.2295\tavg epoch acc = 0.9849\n","epoch 7\tavg epoch loss = 0.2616\tavg epoch acc = 0.9853\n","epoch 8\tavg epoch loss = 0.2085\tavg epoch acc = 0.9889\n","epoch 9\tavg epoch loss = 0.2329\tavg epoch acc = 0.9878\n","training took 53.78 s\n","Avg test loss = 0.0864\tAvg test acc = 0.975\n","epoch 0\tavg epoch loss = 0.5664\tavg epoch acc = 0.9184\n","epoch 1\tavg epoch loss = 0.2949\tavg epoch acc = 0.9762\n","epoch 2\tavg epoch loss = 0.4631\tavg epoch acc = 0.9682\n","epoch 3\tavg epoch loss = 2.311\tavg epoch acc = 0.1082\n","epoch 4\tavg epoch loss = 2.303\tavg epoch acc = 0.111\n","epoch 5\tavg epoch loss = 2.302\tavg epoch acc = 0.1123\n","epoch 6\tavg epoch loss = 2.302\tavg epoch acc = 0.1119\n","epoch 7\tavg epoch loss = 2.302\tavg epoch acc = 0.1117\n","epoch 8\tavg epoch loss = 2.302\tavg epoch acc = 0.1118\n","epoch 9\tavg epoch loss = 2.302\tavg epoch acc = 0.1118\n","training took 54.03 s\n","Avg test loss = 2.3\tAvg test acc = 0.106\n","{'lr': 0.0055000000000000005, 'beta1': 0.1, 'beta2': 0.999, 'batch_size': 32, 'weight_decay': 0.001, 'epsilon': 1e-08}\n","epoch 0\tavg epoch loss = 0.5774\tavg epoch acc = 0.9175\n","epoch 1\tavg epoch loss = 0.3069\tavg epoch acc = 0.9758\n","epoch 2\tavg epoch loss = 0.3307\tavg epoch acc = 0.9749\n","epoch 3\tavg epoch loss = 0.2765\tavg epoch acc = 0.9808\n","epoch 4\tavg epoch loss = 0.2915\tavg epoch acc = 0.9825\n","epoch 5\tavg epoch loss = 0.2895\tavg epoch acc = 0.9811\n","epoch 6\tavg epoch loss = 0.2485\tavg epoch acc = 0.9858\n","epoch 7\tavg epoch loss = 0.2463\tavg epoch acc = 0.9871\n","epoch 8\tavg epoch loss = 0.238\tavg epoch acc = 0.9879\n","epoch 9\tavg epoch loss = 0.2324\tavg epoch acc = 0.9889\n","training took 54.13 s\n","Avg test loss = 0.135\tAvg test acc = 0.971\n","epoch 0\tavg epoch loss = 0.5732\tavg epoch acc = 0.9193\n","epoch 1\tavg epoch loss = 0.3017\tavg epoch acc = 0.974\n","epoch 2\tavg epoch loss = 0.2991\tavg epoch acc = 0.9762\n","epoch 3\tavg epoch loss = 0.323\tavg epoch acc = 0.9778\n","epoch 4\tavg epoch loss = 0.3062\tavg epoch acc = 0.9801\n","epoch 5\tavg epoch loss = 0.2699\tavg epoch acc = 0.9835\n","epoch 6\tavg epoch loss = 0.2583\tavg epoch acc = 0.9856\n","epoch 7\tavg epoch loss = 0.2546\tavg epoch acc = 0.9861\n","epoch 8\tavg epoch loss = 0.2295\tavg epoch acc = 0.988\n","epoch 9\tavg epoch loss = 0.2405\tavg epoch acc = 0.9878\n","training took 53.7 s\n","Avg test loss = 0.114\tAvg test acc = 0.974\n","epoch 0\tavg epoch loss = 0.5659\tavg epoch acc = 0.9212\n","epoch 1\tavg epoch loss = 0.3018\tavg epoch acc = 0.9758\n","epoch 2\tavg epoch loss = 0.2864\tavg epoch acc = 0.9796\n","epoch 3\tavg epoch loss = 0.2964\tavg epoch acc = 0.9801\n","epoch 4\tavg epoch loss = 0.264\tavg epoch acc = 0.9841\n","epoch 5\tavg epoch loss = 0.2589\tavg epoch acc = 0.9862\n","epoch 6\tavg epoch loss = 0.2411\tavg epoch acc = 0.9876\n","epoch 7\tavg epoch loss = 0.3181\tavg epoch acc = 0.9856\n","epoch 8\tavg epoch loss = 0.2443\tavg epoch acc = 0.9893\n","epoch 9\tavg epoch loss = 0.2597\tavg epoch acc = 0.9885\n","training took 54.01 s\n","Avg test loss = 0.175\tAvg test acc = 0.969\n","{'lr': 0.0055000000000000005, 'beta1': 0.1, 'beta2': 0.999, 'batch_size': 32, 'weight_decay': 0.1, 'epsilon': 1e-10}\n","epoch 0\tavg epoch loss = 0.5607\tavg epoch acc = 0.9183\n","epoch 1\tavg epoch loss = 0.3054\tavg epoch acc = 0.974\n","epoch 2\tavg epoch loss = 0.3359\tavg epoch acc = 0.97\n","epoch 3\tavg epoch loss = 0.2846\tavg epoch acc = 0.977\n","epoch 4\tavg epoch loss = 0.2792\tavg epoch acc = 0.977\n","epoch 5\tavg epoch loss = 0.2649\tavg epoch acc = 0.9778\n","epoch 6\tavg epoch loss = 0.2883\tavg epoch acc = 0.9774\n","epoch 7\tavg epoch loss = 0.2759\tavg epoch acc = 0.9786\n","epoch 8\tavg epoch loss = 0.2666\tavg epoch acc = 0.9784\n","epoch 9\tavg epoch loss = 0.2704\tavg epoch acc = 0.9787\n","training took 54.05 s\n","Avg test loss = 0.108\tAvg test acc = 0.969\n","epoch 0\tavg epoch loss = 0.5714\tavg epoch acc = 0.9201\n","epoch 1\tavg epoch loss = 0.3756\tavg epoch acc = 0.9556\n","epoch 2\tavg epoch loss = 0.3064\tavg epoch acc = 0.9725\n","epoch 3\tavg epoch loss = 0.3051\tavg epoch acc = 0.9738\n","epoch 4\tavg epoch loss = 0.2912\tavg epoch acc = 0.9757\n","epoch 5\tavg epoch loss = 0.3105\tavg epoch acc = 0.9737\n","epoch 6\tavg epoch loss = 0.3116\tavg epoch acc = 0.9744\n","epoch 7\tavg epoch loss = 0.2716\tavg epoch acc = 0.9781\n","epoch 8\tavg epoch loss = 0.271\tavg epoch acc = 0.9776\n","epoch 9\tavg epoch loss = 0.2762\tavg epoch acc = 0.9775\n","training took 53.83 s\n","Avg test loss = 0.0958\tAvg test acc = 0.971\n","epoch 0\tavg epoch loss = 0.574\tavg epoch acc = 0.9187\n","epoch 1\tavg epoch loss = 0.3046\tavg epoch acc = 0.9732\n","epoch 2\tavg epoch loss = 0.3385\tavg epoch acc = 0.9685\n","epoch 3\tavg epoch loss = 0.3653\tavg epoch acc = 0.964\n","epoch 4\tavg epoch loss = 0.2761\tavg epoch acc = 0.9757\n","epoch 5\tavg epoch loss = 0.2893\tavg epoch acc = 0.9759\n","epoch 6\tavg epoch loss = 0.2661\tavg epoch acc = 0.9787\n","epoch 7\tavg epoch loss = 0.2647\tavg epoch acc = 0.9787\n","epoch 8\tavg epoch loss = 0.2759\tavg epoch acc = 0.9776\n","epoch 9\tavg epoch loss = 0.251\tavg epoch acc = 0.98\n","training took 54.09 s\n","Avg test loss = 0.162\tAvg test acc = 0.953\n","{'lr': 0.0055000000000000005, 'beta1': 0.1, 'beta2': 0.999, 'batch_size': 32, 'weight_decay': 0.1, 'epsilon': 1e-08}\n","epoch 0\tavg epoch loss = 0.5754\tavg epoch acc = 0.9173\n","epoch 1\tavg epoch loss = 0.3035\tavg epoch acc = 0.9724\n","epoch 2\tavg epoch loss = 0.4482\tavg epoch acc = 0.9506\n","epoch 3\tavg epoch loss = 0.2913\tavg epoch acc = 0.9738\n","epoch 4\tavg epoch loss = 0.2908\tavg epoch acc = 0.9748\n","epoch 5\tavg epoch loss = 0.2763\tavg epoch acc = 0.9772\n","epoch 6\tavg epoch loss = 1.078\tavg epoch acc = 0.7619\n","epoch 7\tavg epoch loss = 0.5508\tavg epoch acc = 0.9305\n","epoch 8\tavg epoch loss = 0.4541\tavg epoch acc = 0.9484\n","epoch 9\tavg epoch loss = 0.4184\tavg epoch acc = 0.9535\n","training took 53.9 s\n","Avg test loss = 0.27\tAvg test acc = 0.907\n","epoch 0\tavg epoch loss = 0.5771\tavg epoch acc = 0.9191\n","epoch 1\tavg epoch loss = 0.3111\tavg epoch acc = 0.9727\n","epoch 2\tavg epoch loss = 0.3135\tavg epoch acc = 0.9719\n","epoch 3\tavg epoch loss = 0.3065\tavg epoch acc = 0.9735\n","epoch 4\tavg epoch loss = 0.2957\tavg epoch acc = 0.9759\n","epoch 5\tavg epoch loss = 0.2681\tavg epoch acc = 0.9789\n","epoch 6\tavg epoch loss = 0.275\tavg epoch acc = 0.9787\n","epoch 7\tavg epoch loss = 0.2557\tavg epoch acc = 0.9806\n","epoch 8\tavg epoch loss = 0.2708\tavg epoch acc = 0.9794\n","epoch 9\tavg epoch loss = 1.224\tavg epoch acc = 0.6089\n","training took 53.85 s\n","Avg test loss = 2.31\tAvg test acc = 0.0997\n","epoch 0\tavg epoch loss = 0.5672\tavg epoch acc = 0.9218\n","epoch 1\tavg epoch loss = 0.3126\tavg epoch acc = 0.972\n","epoch 2\tavg epoch loss = 0.3111\tavg epoch acc = 0.9724\n","epoch 3\tavg epoch loss = 0.2828\tavg epoch acc = 0.9765\n","epoch 4\tavg epoch loss = 0.2834\tavg epoch acc = 0.9768\n","epoch 5\tavg epoch loss = 0.2918\tavg epoch acc = 0.9757\n","epoch 6\tavg epoch loss = 0.2715\tavg epoch acc = 0.978\n","epoch 7\tavg epoch loss = 0.2893\tavg epoch acc = 0.9764\n","epoch 8\tavg epoch loss = 0.2583\tavg epoch acc = 0.979\n","epoch 9\tavg epoch loss = 0.2642\tavg epoch acc = 0.9789\n","training took 54.0 s\n","Avg test loss = 0.0989\tAvg test acc = 0.969\n","{'lr': 0.0055000000000000005, 'beta1': 0.1, 'beta2': 0.999, 'batch_size': 64, 'weight_decay': 0.001, 'epsilon': 1e-10}\n","epoch 0\tavg epoch loss = 0.7269\tavg epoch acc = 0.8863\n","epoch 1\tavg epoch loss = 0.2647\tavg epoch acc = 0.9794\n","epoch 2\tavg epoch loss = 0.2491\tavg epoch acc = 0.9812\n","epoch 3\tavg epoch loss = 0.3211\tavg epoch acc = 0.9711\n","epoch 4\tavg epoch loss = 0.2064\tavg epoch acc = 0.9866\n","epoch 5\tavg epoch loss = 0.2441\tavg epoch acc = 0.986\n","epoch 6\tavg epoch loss = 2.589\tavg epoch acc = 0.1086\n","epoch 7\tavg epoch loss = 2.302\tavg epoch acc = 0.1121\n","epoch 8\tavg epoch loss = 2.302\tavg epoch acc = 0.1123\n","epoch 9\tavg epoch loss = 2.302\tavg epoch acc = 0.1125\n","training took 28.12 s\n","Avg test loss = 2.3\tAvg test acc = 0.103\n","epoch 0\tavg epoch loss = 0.7365\tavg epoch acc = 0.8833\n","epoch 1\tavg epoch loss = 0.2792\tavg epoch acc = 0.9771\n","epoch 2\tavg epoch loss = 0.2247\tavg epoch acc = 0.9833\n","epoch 3\tavg epoch loss = 0.233\tavg epoch acc = 0.984\n","epoch 4\tavg epoch loss = 0.4754\tavg epoch acc = 0.9603\n","epoch 5\tavg epoch loss = 0.1975\tavg epoch acc = 0.9881\n","epoch 6\tavg epoch loss = 0.1879\tavg epoch acc = 0.9892\n","epoch 7\tavg epoch loss = 0.2186\tavg epoch acc = 0.9889\n","epoch 8\tavg epoch loss = 0.169\tavg epoch acc = 0.9922\n","epoch 9\tavg epoch loss = 0.2061\tavg epoch acc = 0.9908\n","training took 27.93 s\n","Avg test loss = 0.102\tAvg test acc = 0.974\n","epoch 0\tavg epoch loss = 0.7283\tavg epoch acc = 0.8862\n","epoch 1\tavg epoch loss = 0.2712\tavg epoch acc = 0.9785\n","epoch 2\tavg epoch loss = 0.2381\tavg epoch acc = 0.9821\n","epoch 3\tavg epoch loss = 0.2092\tavg epoch acc = 0.9854\n","epoch 4\tavg epoch loss = 0.2254\tavg epoch acc = 0.9853\n","epoch 5\tavg epoch loss = 0.1847\tavg epoch acc = 0.9901\n","epoch 6\tavg epoch loss = 0.2096\tavg epoch acc = 0.9891\n","epoch 7\tavg epoch loss = 1.805\tavg epoch acc = 0.4426\n","epoch 8\tavg epoch loss = 2.304\tavg epoch acc = 0.1089\n","epoch 9\tavg epoch loss = 2.303\tavg epoch acc = 0.1156\n","training took 27.93 s\n","Avg test loss = 2.3\tAvg test acc = 0.104\n","{'lr': 0.0055000000000000005, 'beta1': 0.1, 'beta2': 0.999, 'batch_size': 64, 'weight_decay': 0.001, 'epsilon': 1e-08}\n","epoch 0\tavg epoch loss = 0.7276\tavg epoch acc = 0.8845\n","epoch 1\tavg epoch loss = 0.2688\tavg epoch acc = 0.9777\n","epoch 2\tavg epoch loss = 0.2311\tavg epoch acc = 0.9816\n","epoch 3\tavg epoch loss = 0.2274\tavg epoch acc = 0.9829\n","epoch 4\tavg epoch loss = 0.2135\tavg epoch acc = 0.9859\n","epoch 5\tavg epoch loss = 0.212\tavg epoch acc = 0.987\n","epoch 6\tavg epoch loss = 0.3034\tavg epoch acc = 0.9791\n","epoch 7\tavg epoch loss = 0.1808\tavg epoch acc = 0.9904\n","epoch 8\tavg epoch loss = 0.1636\tavg epoch acc = 0.9922\n","epoch 9\tavg epoch loss = 0.1642\tavg epoch acc = 0.9928\n","training took 28.11 s\n","Avg test loss = 0.0633\tAvg test acc = 0.982\n","epoch 0\tavg epoch loss = 0.7213\tavg epoch acc = 0.888\n","epoch 1\tavg epoch loss = 0.2848\tavg epoch acc = 0.9776\n","epoch 2\tavg epoch loss = 0.2279\tavg epoch acc = 0.9831\n","epoch 3\tavg epoch loss = 0.2479\tavg epoch acc = 0.9821\n","epoch 4\tavg epoch loss = 0.1996\tavg epoch acc = 0.9872\n","epoch 5\tavg epoch loss = 0.21\tavg epoch acc = 0.988\n","epoch 6\tavg epoch loss = 0.2167\tavg epoch acc = 0.9889\n","epoch 7\tavg epoch loss = 0.2165\tavg epoch acc = 0.9891\n","epoch 8\tavg epoch loss = 0.206\tavg epoch acc = 0.9903\n","epoch 9\tavg epoch loss = 0.203\tavg epoch acc = 0.9909\n","training took 28.4 s\n","Avg test loss = 0.116\tAvg test acc = 0.969\n","epoch 0\tavg epoch loss = 0.7311\tavg epoch acc = 0.8821\n","epoch 1\tavg epoch loss = 0.27\tavg epoch acc = 0.9796\n","epoch 2\tavg epoch loss = 0.2323\tavg epoch acc = 0.9838\n","epoch 3\tavg epoch loss = 0.212\tavg epoch acc = 0.9861\n","epoch 4\tavg epoch loss = 0.2015\tavg epoch acc = 0.9873\n","epoch 5\tavg epoch loss = 0.2271\tavg epoch acc = 0.9863\n","epoch 6\tavg epoch loss = 0.2023\tavg epoch acc = 0.9894\n","epoch 7\tavg epoch loss = 1.984\tavg epoch acc = 0.296\n","epoch 8\tavg epoch loss = 2.304\tavg epoch acc = 0.1117\n","epoch 9\tavg epoch loss = 2.302\tavg epoch acc = 0.1127\n","training took 27.91 s\n","Avg test loss = 2.3\tAvg test acc = 0.107\n","{'lr': 0.0055000000000000005, 'beta1': 0.1, 'beta2': 0.999, 'batch_size': 64, 'weight_decay': 0.1, 'epsilon': 1e-10}\n","epoch 0\tavg epoch loss = 0.7379\tavg epoch acc = 0.8858\n","epoch 1\tavg epoch loss = 0.2814\tavg epoch acc = 0.9775\n","epoch 2\tavg epoch loss = 0.2365\tavg epoch acc = 0.9821\n","epoch 3\tavg epoch loss = 0.9585\tavg epoch acc = 0.7246\n","epoch 4\tavg epoch loss = 0.4194\tavg epoch acc = 0.9568\n","epoch 5\tavg epoch loss = 0.2504\tavg epoch acc = 0.9785\n","epoch 6\tavg epoch loss = 0.2337\tavg epoch acc = 0.9801\n","epoch 7\tavg epoch loss = 0.2439\tavg epoch acc = 0.9816\n","epoch 8\tavg epoch loss = 0.2388\tavg epoch acc = 0.9818\n","epoch 9\tavg epoch loss = 0.2142\tavg epoch acc = 0.9845\n","training took 28.14 s\n","Avg test loss = 0.123\tAvg test acc = 0.957\n","epoch 0\tavg epoch loss = 0.7274\tavg epoch acc = 0.8836\n","epoch 1\tavg epoch loss = 0.2735\tavg epoch acc = 0.9775\n","epoch 2\tavg epoch loss = 0.2395\tavg epoch acc = 0.9808\n","epoch 3\tavg epoch loss = 0.5945\tavg epoch acc = 0.9128\n","epoch 4\tavg epoch loss = 0.2943\tavg epoch acc = 0.9739\n","epoch 5\tavg epoch loss = 0.2327\tavg epoch acc = 0.981\n","epoch 6\tavg epoch loss = 0.2162\tavg epoch acc = 0.9824\n","epoch 7\tavg epoch loss = 0.2122\tavg epoch acc = 0.983\n","epoch 8\tavg epoch loss = 0.2192\tavg epoch acc = 0.9834\n","epoch 9\tavg epoch loss = 0.2306\tavg epoch acc = 0.9826\n","training took 27.93 s\n","Avg test loss = 0.162\tAvg test acc = 0.946\n","epoch 0\tavg epoch loss = 0.7348\tavg epoch acc = 0.8859\n","epoch 1\tavg epoch loss = 0.2832\tavg epoch acc = 0.9775\n","epoch 2\tavg epoch loss = 0.2352\tavg epoch acc = 0.9815\n","epoch 3\tavg epoch loss = 0.5133\tavg epoch acc = 0.902\n","epoch 4\tavg epoch loss = 0.2422\tavg epoch acc = 0.9803\n","epoch 5\tavg epoch loss = 0.2313\tavg epoch acc = 0.9816\n","epoch 6\tavg epoch loss = 0.2361\tavg epoch acc = 0.9819\n","epoch 7\tavg epoch loss = 1.166\tavg epoch acc = 0.9107\n","epoch 8\tavg epoch loss = 0.2648\tavg epoch acc = 0.9726\n","epoch 9\tavg epoch loss = 0.2203\tavg epoch acc = 0.9774\n","training took 27.92 s\n","Avg test loss = 0.102\tAvg test acc = 0.967\n","{'lr': 0.0055000000000000005, 'beta1': 0.1, 'beta2': 0.999, 'batch_size': 64, 'weight_decay': 0.1, 'epsilon': 1e-08}\n","epoch 0\tavg epoch loss = 0.7255\tavg epoch acc = 0.8861\n","epoch 1\tavg epoch loss = 0.2734\tavg epoch acc = 0.9774\n","epoch 2\tavg epoch loss = 0.2257\tavg epoch acc = 0.9814\n","epoch 3\tavg epoch loss = 0.3123\tavg epoch acc = 0.9703\n","epoch 4\tavg epoch loss = 0.2584\tavg epoch acc = 0.9793\n","epoch 5\tavg epoch loss = 0.2127\tavg epoch acc = 0.9841\n","epoch 6\tavg epoch loss = 0.3667\tavg epoch acc = 0.9478\n","epoch 7\tavg epoch loss = 0.2309\tavg epoch acc = 0.9821\n","epoch 8\tavg epoch loss = 0.2012\tavg epoch acc = 0.9853\n","epoch 9\tavg epoch loss = 1.802\tavg epoch acc = 0.634\n","training took 28.15 s\n","Avg test loss = 0.173\tAvg test acc = 0.942\n","epoch 0\tavg epoch loss = 0.7308\tavg epoch acc = 0.8859\n","epoch 1\tavg epoch loss = 0.2736\tavg epoch acc = 0.9772\n","epoch 2\tavg epoch loss = 0.2299\tavg epoch acc = 0.9822\n","epoch 3\tavg epoch loss = 0.2149\tavg epoch acc = 0.9829\n","epoch 4\tavg epoch loss = 0.2374\tavg epoch acc = 0.9814\n","epoch 5\tavg epoch loss = 0.8218\tavg epoch acc = 0.8818\n","epoch 6\tavg epoch loss = 0.2548\tavg epoch acc = 0.9781\n","epoch 7\tavg epoch loss = 0.2175\tavg epoch acc = 0.9821\n","epoch 8\tavg epoch loss = 0.2091\tavg epoch acc = 0.9839\n","epoch 9\tavg epoch loss = 0.2075\tavg epoch acc = 0.9842\n","training took 27.88 s\n","Avg test loss = 0.0887\tAvg test acc = 0.972\n","epoch 0\tavg epoch loss = 0.7207\tavg epoch acc = 0.8849\n","epoch 1\tavg epoch loss = 0.2763\tavg epoch acc = 0.9777\n","epoch 2\tavg epoch loss = 0.236\tavg epoch acc = 0.9817\n","epoch 3\tavg epoch loss = 0.2299\tavg epoch acc = 0.983\n","epoch 4\tavg epoch loss = 0.2432\tavg epoch acc = 0.9808\n","epoch 5\tavg epoch loss = 1.911\tavg epoch acc = 0.2966\n","epoch 6\tavg epoch loss = 0.7566\tavg epoch acc = 0.8786\n","epoch 7\tavg epoch loss = 0.2741\tavg epoch acc = 0.9757\n","epoch 8\tavg epoch loss = 0.2651\tavg epoch acc = 0.9773\n","epoch 9\tavg epoch loss = 0.2265\tavg epoch acc = 0.9816\n","training took 28.09 s\n","Avg test loss = 0.0735\tAvg test acc = 0.977\n","{'lr': 0.0055000000000000005, 'beta1': 0.1, 'beta2': 0.999, 'batch_size': 128, 'weight_decay': 0.001, 'epsilon': 1e-10}\n","epoch 0\tavg epoch loss = 1.005\tavg epoch acc = 0.8196\n","epoch 1\tavg epoch loss = 0.338\tavg epoch acc = 0.9732\n","epoch 2\tavg epoch loss = 0.2427\tavg epoch acc = 0.9824\n","epoch 3\tavg epoch loss = 0.2005\tavg epoch acc = 0.9869\n","epoch 4\tavg epoch loss = 0.1716\tavg epoch acc = 0.9892\n","epoch 5\tavg epoch loss = 0.1869\tavg epoch acc = 0.9898\n","epoch 6\tavg epoch loss = 0.1853\tavg epoch acc = 0.9893\n","epoch 7\tavg epoch loss = 0.1371\tavg epoch acc = 0.9929\n","epoch 8\tavg epoch loss = 0.526\tavg epoch acc = 0.9053\n","epoch 9\tavg epoch loss = 0.5564\tavg epoch acc = 0.9231\n","training took 17.39 s\n","Avg test loss = 0.137\tAvg test acc = 0.955\n","epoch 0\tavg epoch loss = 1.001\tavg epoch acc = 0.8187\n","epoch 1\tavg epoch loss = 0.329\tavg epoch acc = 0.9745\n","epoch 2\tavg epoch loss = 0.2396\tavg epoch acc = 0.9818\n","epoch 3\tavg epoch loss = 0.841\tavg epoch acc = 0.897\n","epoch 4\tavg epoch loss = 0.2378\tavg epoch acc = 0.9788\n","epoch 5\tavg epoch loss = 0.1938\tavg epoch acc = 0.9838\n","epoch 6\tavg epoch loss = 0.1635\tavg epoch acc = 0.9871\n","epoch 7\tavg epoch loss = 0.1522\tavg epoch acc = 0.9885\n","epoch 8\tavg epoch loss = 0.1477\tavg epoch acc = 0.9899\n","epoch 9\tavg epoch loss = 0.2078\tavg epoch acc = 0.9847\n","training took 17.28 s\n","Avg test loss = 0.0786\tAvg test acc = 0.976\n","epoch 0\tavg epoch loss = 1.003\tavg epoch acc = 0.8217\n","epoch 1\tavg epoch loss = 0.3249\tavg epoch acc = 0.9753\n","epoch 2\tavg epoch loss = 0.2356\tavg epoch acc = 0.9842\n","epoch 3\tavg epoch loss = 0.1955\tavg epoch acc = 0.988\n","epoch 4\tavg epoch loss = 0.1871\tavg epoch acc = 0.9885\n","epoch 5\tavg epoch loss = 0.1442\tavg epoch acc = 0.9919\n","epoch 6\tavg epoch loss = 0.1477\tavg epoch acc = 0.9922\n","epoch 7\tavg epoch loss = 0.1516\tavg epoch acc = 0.9925\n","epoch 8\tavg epoch loss = 0.9665\tavg epoch acc = 0.7759\n","epoch 9\tavg epoch loss = 0.2882\tavg epoch acc = 0.975\n","training took 17.34 s\n","Avg test loss = 0.257\tAvg test acc = 0.923\n","{'lr': 0.0055000000000000005, 'beta1': 0.1, 'beta2': 0.999, 'batch_size': 128, 'weight_decay': 0.001, 'epsilon': 1e-08}\n","epoch 0\tavg epoch loss = 1.014\tavg epoch acc = 0.8168\n","epoch 1\tavg epoch loss = 0.3402\tavg epoch acc = 0.974\n","epoch 2\tavg epoch loss = 0.2452\tavg epoch acc = 0.9826\n","epoch 3\tavg epoch loss = 0.199\tavg epoch acc = 0.9869\n","epoch 4\tavg epoch loss = 0.1774\tavg epoch acc = 0.9889\n","epoch 5\tavg epoch loss = 0.1674\tavg epoch acc = 0.9904\n","epoch 6\tavg epoch loss = 0.1598\tavg epoch acc = 0.9914\n","epoch 7\tavg epoch loss = 0.1431\tavg epoch acc = 0.9932\n","epoch 8\tavg epoch loss = 1.791\tavg epoch acc = 0.4277\n","epoch 9\tavg epoch loss = 2.303\tavg epoch acc = 0.1171\n","training took 17.29 s\n","Avg test loss = 2.3\tAvg test acc = 0.12\n","epoch 0\tavg epoch loss = 0.9902\tavg epoch acc = 0.8236\n","epoch 1\tavg epoch loss = 0.3229\tavg epoch acc = 0.9752\n","epoch 2\tavg epoch loss = 0.226\tavg epoch acc = 0.9837\n","epoch 3\tavg epoch loss = 0.1816\tavg epoch acc = 0.9865\n","epoch 4\tavg epoch loss = 0.1651\tavg epoch acc = 0.9893\n","epoch 5\tavg epoch loss = 0.1849\tavg epoch acc = 0.9875\n","epoch 6\tavg epoch loss = 0.6186\tavg epoch acc = 0.913\n","epoch 7\tavg epoch loss = 0.173\tavg epoch acc = 0.9876\n","epoch 8\tavg epoch loss = 0.1828\tavg epoch acc = 0.9878\n","epoch 9\tavg epoch loss = 0.142\tavg epoch acc = 0.9922\n","training took 17.31 s\n","Avg test loss = 0.0749\tAvg test acc = 0.977\n","epoch 0\tavg epoch loss = 0.9984\tavg epoch acc = 0.8232\n","epoch 1\tavg epoch loss = 0.3329\tavg epoch acc = 0.974\n","epoch 2\tavg epoch loss = 0.2482\tavg epoch acc = 0.9823\n","epoch 3\tavg epoch loss = 0.1927\tavg epoch acc = 0.9869\n","epoch 4\tavg epoch loss = 0.1834\tavg epoch acc = 0.988\n","epoch 5\tavg epoch loss = 0.1537\tavg epoch acc = 0.9915\n","epoch 6\tavg epoch loss = 0.6819\tavg epoch acc = 0.901\n","epoch 7\tavg epoch loss = 0.2128\tavg epoch acc = 0.9832\n","epoch 8\tavg epoch loss = 0.1992\tavg epoch acc = 0.9861\n","epoch 9\tavg epoch loss = 0.1587\tavg epoch acc = 0.9901\n","training took 17.5 s\n","Avg test loss = 0.336\tAvg test acc = 0.922\n","{'lr': 0.0055000000000000005, 'beta1': 0.1, 'beta2': 0.999, 'batch_size': 128, 'weight_decay': 0.1, 'epsilon': 1e-10}\n","epoch 0\tavg epoch loss = 0.9982\tavg epoch acc = 0.8222\n","epoch 1\tavg epoch loss = 0.3316\tavg epoch acc = 0.9736\n","epoch 2\tavg epoch loss = 0.2409\tavg epoch acc = 0.9821\n","epoch 3\tavg epoch loss = 0.1957\tavg epoch acc = 0.9864\n","epoch 4\tavg epoch loss = 0.2647\tavg epoch acc = 0.9772\n","epoch 5\tavg epoch loss = 0.1822\tavg epoch acc = 0.9876\n","epoch 6\tavg epoch loss = 0.1574\tavg epoch acc = 0.9902\n","epoch 7\tavg epoch loss = 1.118\tavg epoch acc = 0.8819\n","epoch 8\tavg epoch loss = 0.3442\tavg epoch acc = 0.9654\n","epoch 9\tavg epoch loss = 0.2407\tavg epoch acc = 0.9772\n","training took 17.46 s\n","Avg test loss = 0.263\tAvg test acc = 0.93\n","epoch 0\tavg epoch loss = 1.011\tavg epoch acc = 0.8167\n","epoch 1\tavg epoch loss = 0.3385\tavg epoch acc = 0.9728\n","epoch 2\tavg epoch loss = 0.2612\tavg epoch acc = 0.979\n","epoch 3\tavg epoch loss = 0.1979\tavg epoch acc = 0.9856\n","epoch 4\tavg epoch loss = 0.229\tavg epoch acc = 0.9817\n","epoch 5\tavg epoch loss = 0.1669\tavg epoch acc = 0.9885\n","epoch 6\tavg epoch loss = 0.912\tavg epoch acc = 0.8097\n","epoch 7\tavg epoch loss = 0.2308\tavg epoch acc = 0.9805\n","epoch 8\tavg epoch loss = 0.1672\tavg epoch acc = 0.9871\n","epoch 9\tavg epoch loss = 0.1623\tavg epoch acc = 0.9879\n","training took 17.37 s\n","Avg test loss = 0.106\tAvg test acc = 0.966\n","epoch 0\tavg epoch loss = 0.9939\tavg epoch acc = 0.8228\n","epoch 1\tavg epoch loss = 0.3263\tavg epoch acc = 0.975\n","epoch 2\tavg epoch loss = 0.24\tavg epoch acc = 0.982\n","epoch 3\tavg epoch loss = 0.1934\tavg epoch acc = 0.9862\n","epoch 4\tavg epoch loss = 0.171\tavg epoch acc = 0.9886\n","epoch 5\tavg epoch loss = 0.1923\tavg epoch acc = 0.986\n","epoch 6\tavg epoch loss = 0.1628\tavg epoch acc = 0.9897\n","epoch 7\tavg epoch loss = 0.1493\tavg epoch acc = 0.9911\n","epoch 8\tavg epoch loss = 0.1369\tavg epoch acc = 0.9924\n","epoch 9\tavg epoch loss = 0.3321\tavg epoch acc = 0.9649\n","training took 17.32 s\n","Avg test loss = 0.308\tAvg test acc = 0.909\n","{'lr': 0.0055000000000000005, 'beta1': 0.1, 'beta2': 0.999, 'batch_size': 128, 'weight_decay': 0.1, 'epsilon': 1e-08}\n","epoch 0\tavg epoch loss = 1.008\tavg epoch acc = 0.8204\n","epoch 1\tavg epoch loss = 0.336\tavg epoch acc = 0.9733\n","epoch 2\tavg epoch loss = 0.2367\tavg epoch acc = 0.982\n","epoch 3\tavg epoch loss = 0.2009\tavg epoch acc = 0.9851\n","epoch 4\tavg epoch loss = 0.2101\tavg epoch acc = 0.9858\n","epoch 5\tavg epoch loss = 0.1891\tavg epoch acc = 0.9867\n","epoch 6\tavg epoch loss = 0.1562\tavg epoch acc = 0.9905\n","epoch 7\tavg epoch loss = 0.351\tavg epoch acc = 0.9616\n","epoch 8\tavg epoch loss = 0.1627\tavg epoch acc = 0.989\n","epoch 9\tavg epoch loss = 2.84\tavg epoch acc = 0.1149\n","training took 17.43 s\n","Avg test loss = 2.3\tAvg test acc = 0.115\n","epoch 0\tavg epoch loss = 0.9969\tavg epoch acc = 0.8199\n","epoch 1\tavg epoch loss = 0.3256\tavg epoch acc = 0.9738\n","epoch 2\tavg epoch loss = 0.2411\tavg epoch acc = 0.9823\n","epoch 3\tavg epoch loss = 0.2216\tavg epoch acc = 0.9831\n","epoch 4\tavg epoch loss = 0.1847\tavg epoch acc = 0.9872\n","epoch 5\tavg epoch loss = 0.1718\tavg epoch acc = 0.9884\n","epoch 6\tavg epoch loss = 0.9964\tavg epoch acc = 0.7984\n","epoch 7\tavg epoch loss = 0.2719\tavg epoch acc = 0.9744\n","epoch 8\tavg epoch loss = 0.2096\tavg epoch acc = 0.9829\n","epoch 9\tavg epoch loss = 0.2107\tavg epoch acc = 0.9838\n","training took 17.31 s\n","Avg test loss = 0.0967\tAvg test acc = 0.968\n","epoch 0\tavg epoch loss = 0.9997\tavg epoch acc = 0.821\n","epoch 1\tavg epoch loss = 0.3321\tavg epoch acc = 0.9734\n","epoch 2\tavg epoch loss = 0.2328\tavg epoch acc = 0.9831\n","epoch 3\tavg epoch loss = 0.1922\tavg epoch acc = 0.9862\n","epoch 4\tavg epoch loss = 0.5825\tavg epoch acc = 0.9108\n","epoch 5\tavg epoch loss = 0.2197\tavg epoch acc = 0.9825\n","epoch 6\tavg epoch loss = 0.1732\tavg epoch acc = 0.9883\n","epoch 7\tavg epoch loss = 0.1692\tavg epoch acc = 0.989\n","epoch 8\tavg epoch loss = 0.1753\tavg epoch acc = 0.9883\n","epoch 9\tavg epoch loss = 1.497\tavg epoch acc = 0.5198\n","training took 17.35 s\n","Avg test loss = 2.3\tAvg test acc = 0.111\n","{'lr': 0.0055000000000000005, 'beta1': 0.9, 'beta2': 0.5, 'batch_size': 32, 'weight_decay': 0.001, 'epsilon': 1e-10}\n","epoch 0\tavg epoch loss = 2.702e+07\tavg epoch acc = 0.09795\n","epoch 1\tavg epoch loss = 1.791e+06\tavg epoch acc = 0.09885\n","epoch 2\tavg epoch loss = 3.34e+05\tavg epoch acc = 0.1018\n","epoch 3\tavg epoch loss = 4.228e+04\tavg epoch acc = 0.0997\n","epoch 4\tavg epoch loss = 1.205e+04\tavg epoch acc = 0.09922\n","epoch 5\tavg epoch loss = 4.676e+03\tavg epoch acc = 0.1007\n","epoch 6\tavg epoch loss = 1.079e+03\tavg epoch acc = 0.1014\n","epoch 7\tavg epoch loss = 300.6\tavg epoch acc = 0.1003\n","epoch 8\tavg epoch loss = 276.3\tavg epoch acc = 0.1011\n","epoch 9\tavg epoch loss = 281.0\tavg epoch acc = 0.09882\n","training took 54.01 s\n","Avg test loss = 1.54e+02\tAvg test acc = 0.0898\n","epoch 0\tavg epoch loss = 1.42e+18\tavg epoch acc = 0.1009\n","epoch 1\tavg epoch loss = 5.468e+16\tavg epoch acc = 0.0998\n","epoch 2\tavg epoch loss = 5.393e+16\tavg epoch acc = 0.0998\n","epoch 3\tavg epoch loss = 5.32e+16\tavg epoch acc = 0.0998\n","epoch 4\tavg epoch loss = 5.247e+16\tavg epoch acc = 0.0998\n","epoch 5\tavg epoch loss = 5.175e+16\tavg epoch acc = 0.0998\n","epoch 6\tavg epoch loss = 5.105e+16\tavg epoch acc = 0.0998\n","epoch 7\tavg epoch loss = 5.035e+16\tavg epoch acc = 0.0998\n","epoch 8\tavg epoch loss = 4.966e+16\tavg epoch acc = 0.0998\n","epoch 9\tavg epoch loss = 4.898e+16\tavg epoch acc = 0.0998\n","training took 53.89 s\n","Avg test loss = 4.87e+16\tAvg test acc = 0.0983\n","epoch 0\tavg epoch loss = 9.559e+08\tavg epoch acc = 0.1019\n","epoch 1\tavg epoch loss = 2.198e+06\tavg epoch acc = 0.1003\n","epoch 2\tavg epoch loss = 8.21e+05\tavg epoch acc = 0.0975\n","epoch 3\tavg epoch loss = 4.022e+05\tavg epoch acc = 0.09673\n","epoch 4\tavg epoch loss = 2.482e+05\tavg epoch acc = 0.1005\n","epoch 5\tavg epoch loss = 1.672e+05\tavg epoch acc = 0.1003\n","epoch 6\tavg epoch loss = 1.284e+05\tavg epoch acc = 0.1016\n","epoch 7\tavg epoch loss = 9.347e+04\tavg epoch acc = 0.09992\n","epoch 8\tavg epoch loss = 6.061e+04\tavg epoch acc = 0.1027\n","epoch 9\tavg epoch loss = 2.929e+04\tavg epoch acc = 0.1009\n","training took 54.06 s\n","Avg test loss = 1.86e+04\tAvg test acc = 0.096\n","{'lr': 0.0055000000000000005, 'beta1': 0.9, 'beta2': 0.5, 'batch_size': 32, 'weight_decay': 0.001, 'epsilon': 1e-08}\n","epoch 0\tavg epoch loss = 2.768e+16\tavg epoch acc = 0.1017\n","epoch 1\tavg epoch loss = 2.53e+14\tavg epoch acc = 0.1017\n","epoch 2\tavg epoch loss = 2.495e+14\tavg epoch acc = 0.1017\n","epoch 3\tavg epoch loss = 2.461e+14\tavg epoch acc = 0.1017\n","epoch 4\tavg epoch loss = 2.427e+14\tavg epoch acc = 0.1017\n","epoch 5\tavg epoch loss = 2.393e+14\tavg epoch acc = 0.1017\n","epoch 6\tavg epoch loss = 2.36e+14\tavg epoch acc = 0.1017\n","epoch 7\tavg epoch loss = 2.328e+14\tavg epoch acc = 0.1017\n","epoch 8\tavg epoch loss = 2.295e+14\tavg epoch acc = 0.1017\n","epoch 9\tavg epoch loss = 2.264e+14\tavg epoch acc = 0.1017\n","training took 54.28 s\n","Avg test loss = 2.23e+14\tAvg test acc = 0.103\n","epoch 0\tavg epoch loss = 3.94e+07\tavg epoch acc = 0.09588\n","epoch 1\tavg epoch loss = 9.773e+05\tavg epoch acc = 0.09817\n","epoch 2\tavg epoch loss = 5.822e+05\tavg epoch acc = 0.0993\n","epoch 3\tavg epoch loss = 4.201e+05\tavg epoch acc = 0.1012\n","epoch 4\tavg epoch loss = 2.718e+05\tavg epoch acc = 0.1001\n","epoch 5\tavg epoch loss = 1.489e+05\tavg epoch acc = 0.0973\n","epoch 6\tavg epoch loss = 9.428e+04\tavg epoch acc = 0.09835\n","epoch 7\tavg epoch loss = 5.859e+04\tavg epoch acc = 0.1\n","epoch 8\tavg epoch loss = 2.605e+04\tavg epoch acc = 0.1023\n","epoch 9\tavg epoch loss = 2.706e+03\tavg epoch acc = 0.1035\n","training took 54.08 s\n","Avg test loss = 4.57e+02\tAvg test acc = 0.104\n","epoch 0\tavg epoch loss = 3.052e+09\tavg epoch acc = 0.09922\n","epoch 1\tavg epoch loss = 3.193e+09\tavg epoch acc = 0.09805\n","epoch 2\tavg epoch loss = 3.112e+09\tavg epoch acc = 0.09805\n","epoch 3\tavg epoch loss = 3.037e+09\tavg epoch acc = 0.09805\n","epoch 4\tavg epoch loss = 2.965e+09\tavg epoch acc = 0.09805\n","epoch 5\tavg epoch loss = 2.894e+09\tavg epoch acc = 0.09805\n","epoch 6\tavg epoch loss = 2.824e+09\tavg epoch acc = 0.09805\n","epoch 7\tavg epoch loss = 2.755e+09\tavg epoch acc = 0.09805\n","epoch 8\tavg epoch loss = 2.687e+09\tavg epoch acc = 0.09805\n","epoch 9\tavg epoch loss = 2.621e+09\tavg epoch acc = 0.09805\n","training took 54.33 s\n","Avg test loss = 2.6e+09\tAvg test acc = 0.0964\n","{'lr': 0.0055000000000000005, 'beta1': 0.9, 'beta2': 0.5, 'batch_size': 32, 'weight_decay': 0.1, 'epsilon': 1e-10}\n","epoch 0\tavg epoch loss = 1.611e+14\tavg epoch acc = 0.09588\n","epoch 1\tavg epoch loss = 2.628e+12\tavg epoch acc = 0.09673\n","epoch 2\tavg epoch loss = 6.615e+11\tavg epoch acc = 0.09673\n","epoch 3\tavg epoch loss = 1.658e+11\tavg epoch acc = 0.09673\n","epoch 4\tavg epoch loss = 4.128e+10\tavg epoch acc = 0.09673\n","epoch 5\tavg epoch loss = 1.016e+10\tavg epoch acc = 0.09673\n","epoch 6\tavg epoch loss = 2.461e+09\tavg epoch acc = 0.09673\n","epoch 7\tavg epoch loss = 5.758e+08\tavg epoch acc = 0.09673\n","epoch 8\tavg epoch loss = 1.254e+08\tavg epoch acc = 0.0985\n","epoch 9\tavg epoch loss = 2.822e+07\tavg epoch acc = 0.09903\n","training took 55.78 s\n","Avg test loss = 1.29e+07\tAvg test acc = 0.0979\n","epoch 0\tavg epoch loss = 2.499e+22\tavg epoch acc = 0.0927\n","epoch 1\tavg epoch loss = 2.9e+13\tavg epoch acc = 0.09043\n","epoch 2\tavg epoch loss = 7.328e+12\tavg epoch acc = 0.09043\n","epoch 3\tavg epoch loss = 1.85e+12\tavg epoch acc = 0.09043\n","epoch 4\tavg epoch loss = 4.669e+11\tavg epoch acc = 0.09043\n","epoch 5\tavg epoch loss = 1.176e+11\tavg epoch acc = 0.09043\n","epoch 6\tavg epoch loss = 2.954e+10\tavg epoch acc = 0.09043\n","epoch 7\tavg epoch loss = 7.374e+09\tavg epoch acc = 0.09043\n","epoch 8\tavg epoch loss = 1.818e+09\tavg epoch acc = 0.09043\n","epoch 9\tavg epoch loss = 4.367e+08\tavg epoch acc = 0.09043\n","training took 55.46 s\n","Avg test loss = 1.93e+08\tAvg test acc = 0.0902\n","epoch 0\tavg epoch loss = 1.96e+11\tavg epoch acc = 0.1028\n","epoch 1\tavg epoch loss = 2.637e+10\tavg epoch acc = 0.1039\n","epoch 2\tavg epoch loss = 5.95e+09\tavg epoch acc = 0.1001\n","epoch 3\tavg epoch loss = 1.169e+09\tavg epoch acc = 0.09897\n","epoch 4\tavg epoch loss = 2.179e+08\tavg epoch acc = 0.09782\n","epoch 5\tavg epoch loss = 8.06e+07\tavg epoch acc = 0.0973\n","epoch 6\tavg epoch loss = 3.909e+07\tavg epoch acc = 0.0982\n","epoch 7\tavg epoch loss = 2.096e+07\tavg epoch acc = 0.1009\n","epoch 8\tavg epoch loss = 1.118e+07\tavg epoch acc = 0.09932\n","epoch 9\tavg epoch loss = 5.797e+06\tavg epoch acc = 0.09935\n","training took 54.35 s\n","Avg test loss = 4.04e+06\tAvg test acc = 0.0961\n","{'lr': 0.0055000000000000005, 'beta1': 0.9, 'beta2': 0.5, 'batch_size': 32, 'weight_decay': 0.1, 'epsilon': 1e-08}\n","epoch 0\tavg epoch loss = 5.348e+18\tavg epoch acc = 0.09953\n","epoch 1\tavg epoch loss = 1.168e+15\tavg epoch acc = 0.0988\n","epoch 2\tavg epoch loss = 2.952e+14\tavg epoch acc = 0.0988\n","epoch 3\tavg epoch loss = 7.461e+13\tavg epoch acc = 0.0988\n","epoch 4\tavg epoch loss = 1.885e+13\tavg epoch acc = 0.0988\n","epoch 5\tavg epoch loss = 4.764e+12\tavg epoch acc = 0.0988\n","epoch 6\tavg epoch loss = 1.203e+12\tavg epoch acc = 0.0988\n","epoch 7\tavg epoch loss = 3.038e+11\tavg epoch acc = 0.0988\n","epoch 8\tavg epoch loss = 7.664e+10\tavg epoch acc = 0.0988\n","epoch 9\tavg epoch loss = 1.929e+10\tavg epoch acc = 0.0988\n","training took 55.36 s\n","Avg test loss = 8.98e+09\tAvg test acc = 0.0983\n","epoch 0\tavg epoch loss = 1.932e+11\tavg epoch acc = 0.09065\n","epoch 1\tavg epoch loss = 3.803e+10\tavg epoch acc = 0.09052\n","epoch 2\tavg epoch loss = 8.916e+09\tavg epoch acc = 0.09052\n","epoch 3\tavg epoch loss = 1.904e+09\tavg epoch acc = 0.09052\n","epoch 4\tavg epoch loss = 3.372e+08\tavg epoch acc = 0.09502\n","epoch 5\tavg epoch loss = 9.747e+07\tavg epoch acc = 0.09847\n","epoch 6\tavg epoch loss = 4.379e+07\tavg epoch acc = 0.1003\n","epoch 7\tavg epoch loss = 2.378e+07\tavg epoch acc = 0.1034\n","epoch 8\tavg epoch loss = 1.271e+07\tavg epoch acc = 0.1026\n","epoch 9\tavg epoch loss = 6.581e+06\tavg epoch acc = 0.101\n","training took 54.29 s\n","Avg test loss = 4.6e+06\tAvg test acc = 0.114\n","epoch 0\tavg epoch loss = inf\tavg epoch acc = 0.0965\n","epoch 1\tavg epoch loss = 8.209e+22\tavg epoch acc = 0.09915\n","epoch 2\tavg epoch loss = 2.075e+22\tavg epoch acc = 0.09915\n","epoch 3\tavg epoch loss = 5.244e+21\tavg epoch acc = 0.09915\n","epoch 4\tavg epoch loss = 1.325e+21\tavg epoch acc = 0.09915\n","epoch 5\tavg epoch loss = 3.35e+20\tavg epoch acc = 0.09915\n","epoch 6\tavg epoch loss = 8.467e+19\tavg epoch acc = 0.09915\n","epoch 7\tavg epoch loss = 2.14e+19\tavg epoch acc = 0.09915\n","epoch 8\tavg epoch loss = 5.408e+18\tavg epoch acc = 0.09915\n","epoch 9\tavg epoch loss = 1.367e+18\tavg epoch acc = 0.09915\n","training took 54.33 s\n","Avg test loss = 6.44e+17\tAvg test acc = 0.0992\n","{'lr': 0.0055000000000000005, 'beta1': 0.9, 'beta2': 0.5, 'batch_size': 64, 'weight_decay': 0.001, 'epsilon': 1e-10}\n","epoch 0\tavg epoch loss = nan\tavg epoch acc = 0.09685\n","epoch 1\tavg epoch loss = nan\tavg epoch acc = 0.0977\n","epoch 2\tavg epoch loss = nan\tavg epoch acc = 0.0977\n","epoch 3\tavg epoch loss = nan\tavg epoch acc = 0.0977\n","epoch 4\tavg epoch loss = nan\tavg epoch acc = 0.0977\n","epoch 5\tavg epoch loss = nan\tavg epoch acc = 0.0977\n","epoch 6\tavg epoch loss = nan\tavg epoch acc = 0.0977\n","epoch 7\tavg epoch loss = nan\tavg epoch acc = 0.0977\n","epoch 8\tavg epoch loss = nan\tavg epoch acc = 0.0977\n","epoch 9\tavg epoch loss = nan\tavg epoch acc = 0.0977\n","training took 28.04 s\n","Avg test loss = nan\tAvg test acc = 0.101\n","epoch 0\tavg epoch loss = 1.913e+09\tavg epoch acc = 0.09677\n","epoch 1\tavg epoch loss = 3.415e+08\tavg epoch acc = 0.09942\n","epoch 2\tavg epoch loss = 2.441e+08\tavg epoch acc = 0.09942\n","epoch 3\tavg epoch loss = 1.743e+08\tavg epoch acc = 0.09888\n","epoch 4\tavg epoch loss = 1.414e+08\tavg epoch acc = 0.1008\n","epoch 5\tavg epoch loss = 1.262e+08\tavg epoch acc = 0.1002\n","epoch 6\tavg epoch loss = 1.157e+08\tavg epoch acc = 0.09855\n","epoch 7\tavg epoch loss = 1.067e+08\tavg epoch acc = 0.09823\n","epoch 8\tavg epoch loss = 9.788e+07\tavg epoch acc = 0.0996\n","epoch 9\tavg epoch loss = 9.055e+07\tavg epoch acc = 0.09888\n","training took 28.04 s\n","Avg test loss = 8.8e+07\tAvg test acc = 0.1\n","epoch 0\tavg epoch loss = 1.849e+17\tavg epoch acc = 0.09932\n","epoch 1\tavg epoch loss = 2.327e+14\tavg epoch acc = 0.1022\n","epoch 2\tavg epoch loss = 2.311e+14\tavg epoch acc = 0.1022\n","epoch 3\tavg epoch loss = 2.295e+14\tavg epoch acc = 0.1022\n","epoch 4\tavg epoch loss = 2.279e+14\tavg epoch acc = 0.1022\n","epoch 5\tavg epoch loss = 2.263e+14\tavg epoch acc = 0.1022\n","epoch 6\tavg epoch loss = 2.248e+14\tavg epoch acc = 0.1022\n","epoch 7\tavg epoch loss = 2.232e+14\tavg epoch acc = 0.1022\n","epoch 8\tavg epoch loss = 2.217e+14\tavg epoch acc = 0.1022\n","epoch 9\tavg epoch loss = 2.202e+14\tavg epoch acc = 0.1022\n","training took 28.21 s\n","Avg test loss = 2.19e+14\tAvg test acc = 0.102\n","{'lr': 0.0055000000000000005, 'beta1': 0.9, 'beta2': 0.5, 'batch_size': 64, 'weight_decay': 0.001, 'epsilon': 1e-08}\n","epoch 0\tavg epoch loss = nan\tavg epoch acc = 0.09262\n","epoch 1\tavg epoch loss = nan\tavg epoch acc = 0.09735\n","epoch 2\tavg epoch loss = nan\tavg epoch acc = 0.09735\n","epoch 3\tavg epoch loss = nan\tavg epoch acc = 0.09735\n","epoch 4\tavg epoch loss = nan\tavg epoch acc = 0.09735\n","epoch 5\tavg epoch loss = nan\tavg epoch acc = 0.09735\n","epoch 6\tavg epoch loss = nan\tavg epoch acc = 0.09735\n","epoch 7\tavg epoch loss = nan\tavg epoch acc = 0.09735\n","epoch 8\tavg epoch loss = nan\tavg epoch acc = 0.09735\n","epoch 9\tavg epoch loss = nan\tavg epoch acc = 0.09735\n","training took 28.19 s\n","Avg test loss = nan\tAvg test acc = 0.101\n","epoch 0\tavg epoch loss = 3.269e+34\tavg epoch acc = 0.09638\n","epoch 1\tavg epoch loss = nan\tavg epoch acc = 0.09997\n","epoch 2\tavg epoch loss = nan\tavg epoch acc = 0.09965\n","epoch 3\tavg epoch loss = nan\tavg epoch acc = 0.09965\n","epoch 4\tavg epoch loss = nan\tavg epoch acc = 0.09965\n","epoch 5\tavg epoch loss = nan\tavg epoch acc = 0.09965\n","epoch 6\tavg epoch loss = nan\tavg epoch acc = 0.09965\n","epoch 7\tavg epoch loss = nan\tavg epoch acc = 0.09965\n","epoch 8\tavg epoch loss = nan\tavg epoch acc = 0.09965\n","epoch 9\tavg epoch loss = nan\tavg epoch acc = 0.09965\n","training took 28.04 s\n","Avg test loss = nan\tAvg test acc = 0.0969\n","epoch 0\tavg epoch loss = nan\tavg epoch acc = 0.09545\n","epoch 1\tavg epoch loss = nan\tavg epoch acc = 0.09915\n","epoch 2\tavg epoch loss = nan\tavg epoch acc = 0.09915\n","epoch 3\tavg epoch loss = nan\tavg epoch acc = 0.09915\n","epoch 4\tavg epoch loss = nan\tavg epoch acc = 0.09915\n","epoch 5\tavg epoch loss = nan\tavg epoch acc = 0.09915\n","epoch 6\tavg epoch loss = nan\tavg epoch acc = 0.09915\n","epoch 7\tavg epoch loss = nan\tavg epoch acc = 0.09915\n","epoch 8\tavg epoch loss = nan\tavg epoch acc = 0.09915\n","epoch 9\tavg epoch loss = nan\tavg epoch acc = 0.09915\n","training took 28.29 s\n","Avg test loss = nan\tAvg test acc = 0.0979\n","{'lr': 0.0055000000000000005, 'beta1': 0.9, 'beta2': 0.5, 'batch_size': 64, 'weight_decay': 0.1, 'epsilon': 1e-10}\n","epoch 0\tavg epoch loss = nan\tavg epoch acc = 0.09565\n","epoch 1\tavg epoch loss = nan\tavg epoch acc = 0.09957\n","epoch 2\tavg epoch loss = nan\tavg epoch acc = 0.09957\n","epoch 3\tavg epoch loss = nan\tavg epoch acc = 0.09957\n","epoch 4\tavg epoch loss = nan\tavg epoch acc = 0.09957\n","epoch 5\tavg epoch loss = nan\tavg epoch acc = 0.09957\n","epoch 6\tavg epoch loss = nan\tavg epoch acc = 0.09957\n","epoch 7\tavg epoch loss = nan\tavg epoch acc = 0.09957\n","epoch 8\tavg epoch loss = nan\tavg epoch acc = 0.09957\n","epoch 9\tavg epoch loss = nan\tavg epoch acc = 0.09957\n","training took 28.09 s\n","Avg test loss = nan\tAvg test acc = 0.097\n","epoch 0\tavg epoch loss = 2.588e+11\tavg epoch acc = 0.09773\n","epoch 1\tavg epoch loss = nan\tavg epoch acc = 0.0967\n","epoch 2\tavg epoch loss = nan\tavg epoch acc = 0.09845\n","epoch 3\tavg epoch loss = nan\tavg epoch acc = 0.09845\n","epoch 4\tavg epoch loss = nan\tavg epoch acc = 0.09845\n","epoch 5\tavg epoch loss = nan\tavg epoch acc = 0.09845\n","epoch 6\tavg epoch loss = nan\tavg epoch acc = 0.09845\n","epoch 7\tavg epoch loss = nan\tavg epoch acc = 0.09845\n","epoch 8\tavg epoch loss = nan\tavg epoch acc = 0.09845\n","epoch 9\tavg epoch loss = nan\tavg epoch acc = 0.09845\n","training took 28.06 s\n","Avg test loss = nan\tAvg test acc = 0.0993\n","epoch 0\tavg epoch loss = 2.171e+11\tavg epoch acc = 0.09773\n","epoch 1\tavg epoch loss = 7.067e+10\tavg epoch acc = 0.09748\n","epoch 2\tavg epoch loss = 3.449e+10\tavg epoch acc = 0.09748\n","epoch 3\tavg epoch loss = 1.66e+10\tavg epoch acc = 0.09748\n","epoch 4\tavg epoch loss = 7.826e+09\tavg epoch acc = 0.09748\n","epoch 5\tavg epoch loss = 3.569e+09\tavg epoch acc = 0.09748\n","epoch 6\tavg epoch loss = 1.542e+09\tavg epoch acc = 0.09748\n","epoch 7\tavg epoch loss = 6.141e+08\tavg epoch acc = 0.1014\n","epoch 8\tavg epoch loss = 3.002e+08\tavg epoch acc = 0.1132\n","epoch 9\tavg epoch loss = 1.739e+08\tavg epoch acc = 0.1073\n","training took 28.33 s\n","Avg test loss = 1.36e+08\tAvg test acc = 0.111\n","{'lr': 0.0055000000000000005, 'beta1': 0.9, 'beta2': 0.5, 'batch_size': 64, 'weight_decay': 0.1, 'epsilon': 1e-08}\n","epoch 0\tavg epoch loss = nan\tavg epoch acc = 0.0978\n","epoch 1\tavg epoch loss = nan\tavg epoch acc = 0.09913\n","epoch 2\tavg epoch loss = nan\tavg epoch acc = 0.09913\n","epoch 3\tavg epoch loss = nan\tavg epoch acc = 0.09913\n","epoch 4\tavg epoch loss = nan\tavg epoch acc = 0.09913\n","epoch 5\tavg epoch loss = nan\tavg epoch acc = 0.09913\n","epoch 6\tavg epoch loss = nan\tavg epoch acc = 0.09913\n","epoch 7\tavg epoch loss = nan\tavg epoch acc = 0.09913\n","epoch 8\tavg epoch loss = nan\tavg epoch acc = 0.09913\n","epoch 9\tavg epoch loss = nan\tavg epoch acc = 0.09913\n","training took 28.21 s\n","Avg test loss = nan\tAvg test acc = 0.0979\n","epoch 0\tavg epoch loss = 5.654e+11\tavg epoch acc = 0.0909\n","epoch 1\tavg epoch loss = 5.401e+29\tavg epoch acc = 0.09358\n","epoch 2\tavg epoch loss = nan\tavg epoch acc = 0.1017\n","epoch 3\tavg epoch loss = nan\tavg epoch acc = 0.09903\n","epoch 4\tavg epoch loss = nan\tavg epoch acc = 0.09903\n","epoch 5\tavg epoch loss = nan\tavg epoch acc = 0.09903\n","epoch 6\tavg epoch loss = nan\tavg epoch acc = 0.09903\n","epoch 7\tavg epoch loss = nan\tavg epoch acc = 0.09903\n","epoch 8\tavg epoch loss = nan\tavg epoch acc = 0.09903\n","epoch 9\tavg epoch loss = nan\tavg epoch acc = 0.09903\n","training took 27.98 s\n","Avg test loss = nan\tAvg test acc = 0.0981\n","epoch 0\tavg epoch loss = nan\tavg epoch acc = 0.09775\n","epoch 1\tavg epoch loss = nan\tavg epoch acc = 0.098\n","epoch 2\tavg epoch loss = nan\tavg epoch acc = 0.098\n","epoch 3\tavg epoch loss = nan\tavg epoch acc = 0.098\n","epoch 4\tavg epoch loss = nan\tavg epoch acc = 0.098\n","epoch 5\tavg epoch loss = nan\tavg epoch acc = 0.098\n","epoch 6\tavg epoch loss = nan\tavg epoch acc = 0.098\n","epoch 7\tavg epoch loss = nan\tavg epoch acc = 0.098\n","epoch 8\tavg epoch loss = nan\tavg epoch acc = 0.098\n","epoch 9\tavg epoch loss = nan\tavg epoch acc = 0.098\n","training took 28.03 s\n","Avg test loss = nan\tAvg test acc = 0.1\n","{'lr': 0.0055000000000000005, 'beta1': 0.9, 'beta2': 0.5, 'batch_size': 128, 'weight_decay': 0.001, 'epsilon': 1e-10}\n","epoch 0\tavg epoch loss = 1.737e+16\tavg epoch acc = 0.1002\n","epoch 1\tavg epoch loss = 4.709e+25\tavg epoch acc = 0.09912\n","epoch 2\tavg epoch loss = 5.819e+32\tavg epoch acc = 0.09749\n","epoch 3\tavg epoch loss = nan\tavg epoch acc = 0.1\n","epoch 4\tavg epoch loss = nan\tavg epoch acc = 0.1004\n","epoch 5\tavg epoch loss = nan\tavg epoch acc = 0.1004\n","epoch 6\tavg epoch loss = nan\tavg epoch acc = 0.1004\n","epoch 7\tavg epoch loss = nan\tavg epoch acc = 0.1004\n","epoch 8\tavg epoch loss = nan\tavg epoch acc = 0.1004\n","epoch 9\tavg epoch loss = nan\tavg epoch acc = 0.1004\n","training took 17.3 s\n","Avg test loss = nan\tAvg test acc = 0.0952\n","epoch 0\tavg epoch loss = 7.582e+07\tavg epoch acc = 0.0938\n","epoch 1\tavg epoch loss = 3.159e+06\tavg epoch acc = 0.0931\n","epoch 2\tavg epoch loss = 2.79e+06\tavg epoch acc = 0.09744\n","epoch 3\tavg epoch loss = 2.455e+06\tavg epoch acc = 0.09547\n","epoch 4\tavg epoch loss = 2.123e+06\tavg epoch acc = 0.09719\n","epoch 5\tavg epoch loss = 1.794e+06\tavg epoch acc = 0.0966\n","epoch 6\tavg epoch loss = 1.468e+06\tavg epoch acc = 0.09737\n","epoch 7\tavg epoch loss = 1.145e+06\tavg epoch acc = 0.09849\n","epoch 8\tavg epoch loss = 8.372e+05\tavg epoch acc = 0.09889\n","epoch 9\tavg epoch loss = 6.279e+05\tavg epoch acc = 0.09892\n","training took 17.27 s\n","Avg test loss = 5.46e+05\tAvg test acc = 0.101\n","epoch 0\tavg epoch loss = 4.812e+13\tavg epoch acc = 0.09655\n","epoch 1\tavg epoch loss = 2.598e+12\tavg epoch acc = 0.09734\n","epoch 2\tavg epoch loss = 2.038e+12\tavg epoch acc = 0.09734\n","epoch 3\tavg epoch loss = 1.594e+12\tavg epoch acc = 0.09734\n","epoch 4\tavg epoch loss = 1.275e+12\tavg epoch acc = 0.09734\n","epoch 5\tavg epoch loss = 1.063e+12\tavg epoch acc = 0.09734\n","epoch 6\tavg epoch loss = 9.057e+11\tavg epoch acc = 0.09734\n","epoch 7\tavg epoch loss = 7.752e+11\tavg epoch acc = 0.09734\n","epoch 8\tavg epoch loss = 6.875e+11\tavg epoch acc = 0.09734\n","epoch 9\tavg epoch loss = 6.428e+11\tavg epoch acc = 0.09734\n","training took 17.3 s\n","Avg test loss = 6.18e+11\tAvg test acc = 0.101\n","{'lr': 0.0055000000000000005, 'beta1': 0.9, 'beta2': 0.5, 'batch_size': 128, 'weight_decay': 0.001, 'epsilon': 1e-08}\n","epoch 0\tavg epoch loss = 1.093e+08\tavg epoch acc = 0.09739\n","epoch 1\tavg epoch loss = 2.192e+06\tavg epoch acc = 0.09724\n","epoch 2\tavg epoch loss = 1.701e+06\tavg epoch acc = 0.09879\n","epoch 3\tavg epoch loss = 1.425e+06\tavg epoch acc = 0.09819\n","epoch 4\tavg epoch loss = 1.196e+06\tavg epoch acc = 0.09822\n","epoch 5\tavg epoch loss = 1.062e+06\tavg epoch acc = 0.1002\n","epoch 6\tavg epoch loss = 9.509e+05\tavg epoch acc = 0.09992\n","epoch 7\tavg epoch loss = 8.422e+05\tavg epoch acc = 0.09844\n","epoch 8\tavg epoch loss = 7.526e+05\tavg epoch acc = 0.1011\n","epoch 9\tavg epoch loss = 6.73e+05\tavg epoch acc = 0.1017\n","training took 17.24 s\n","Avg test loss = 6.29e+05\tAvg test acc = 0.102\n","epoch 0\tavg epoch loss = 4.834e+07\tavg epoch acc = 0.08986\n","epoch 1\tavg epoch loss = 2.943e+06\tavg epoch acc = 0.08993\n","epoch 2\tavg epoch loss = 2.3e+06\tavg epoch acc = 0.0919\n","epoch 3\tavg epoch loss = 1.806e+06\tavg epoch acc = 0.09665\n","epoch 4\tavg epoch loss = 1.399e+06\tavg epoch acc = 0.09402\n","epoch 5\tavg epoch loss = 1.077e+06\tavg epoch acc = 0.0954\n","epoch 6\tavg epoch loss = 8.31e+05\tavg epoch acc = 0.09627\n","epoch 7\tavg epoch loss = 5.96e+05\tavg epoch acc = 0.09697\n","epoch 8\tavg epoch loss = 4.181e+05\tavg epoch acc = 0.09689\n","epoch 9\tavg epoch loss = 2.793e+05\tavg epoch acc = 0.09537\n","training took 17.37 s\n","Avg test loss = 2.24e+05\tAvg test acc = 0.0964\n","epoch 0\tavg epoch loss = 8.086e+23\tavg epoch acc = 0.0943\n","epoch 1\tavg epoch loss = 3.491e+31\tavg epoch acc = 0.09742\n","epoch 2\tavg epoch loss = nan\tavg epoch acc = 0.09922\n","epoch 3\tavg epoch loss = nan\tavg epoch acc = 0.09917\n","epoch 4\tavg epoch loss = nan\tavg epoch acc = 0.09917\n","epoch 5\tavg epoch loss = nan\tavg epoch acc = 0.09917\n","epoch 6\tavg epoch loss = nan\tavg epoch acc = 0.09917\n","epoch 7\tavg epoch loss = nan\tavg epoch acc = 0.09917\n","epoch 8\tavg epoch loss = nan\tavg epoch acc = 0.09917\n","epoch 9\tavg epoch loss = nan\tavg epoch acc = 0.09917\n","training took 17.22 s\n","Avg test loss = nan\tAvg test acc = 0.0978\n","{'lr': 0.0055000000000000005, 'beta1': 0.9, 'beta2': 0.5, 'batch_size': 128, 'weight_decay': 0.1, 'epsilon': 1e-10}\n","epoch 0\tavg epoch loss = 1.559e+29\tavg epoch acc = 0.09118\n","epoch 1\tavg epoch loss = 1.377e+34\tavg epoch acc = 0.09617\n","epoch 2\tavg epoch loss = nan\tavg epoch acc = 0.09737\n","epoch 3\tavg epoch loss = nan\tavg epoch acc = 0.09832\n","epoch 4\tavg epoch loss = nan\tavg epoch acc = 0.09832\n","epoch 5\tavg epoch loss = nan\tavg epoch acc = 0.09832\n","epoch 6\tavg epoch loss = nan\tavg epoch acc = 0.09832\n","epoch 7\tavg epoch loss = nan\tavg epoch acc = 0.09832\n","epoch 8\tavg epoch loss = nan\tavg epoch acc = 0.09832\n","epoch 9\tavg epoch loss = nan\tavg epoch acc = 0.09832\n","training took 17.2 s\n","Avg test loss = nan\tAvg test acc = 0.0997\n","epoch 0\tavg epoch loss = 1.14e+15\tavg epoch acc = 0.09617\n","epoch 1\tavg epoch loss = 9.922e+33\tavg epoch acc = 0.08007\n","epoch 2\tavg epoch loss = 1.131e+34\tavg epoch acc = 0.07144\n","epoch 3\tavg epoch loss = 3.081e+34\tavg epoch acc = 0.06774\n","epoch 4\tavg epoch loss = 1.732e+34\tavg epoch acc = 0.06772\n","epoch 5\tavg epoch loss = 8.733e+33\tavg epoch acc = 0.06779\n","epoch 6\tavg epoch loss = 4.487e+33\tavg epoch acc = 0.06777\n","epoch 7\tavg epoch loss = 2.386e+33\tavg epoch acc = 0.06782\n","epoch 8\tavg epoch loss = 1.378e+33\tavg epoch acc = 0.06779\n","epoch 9\tavg epoch loss = 7.058e+32\tavg epoch acc = 0.06792\n","training took 17.5 s\n","Avg test loss = 1.58e+32\tAvg test acc = 0.0641\n","epoch 0\tavg epoch loss = 5.045e+26\tavg epoch acc = 0.09105\n","epoch 1\tavg epoch loss = nan\tavg epoch acc = 0.09642\n","epoch 2\tavg epoch loss = nan\tavg epoch acc = 0.09772\n","epoch 3\tavg epoch loss = nan\tavg epoch acc = 0.09772\n","epoch 4\tavg epoch loss = nan\tavg epoch acc = 0.09772\n","epoch 5\tavg epoch loss = nan\tavg epoch acc = 0.09772\n","epoch 6\tavg epoch loss = nan\tavg epoch acc = 0.09772\n","epoch 7\tavg epoch loss = nan\tavg epoch acc = 0.09772\n","epoch 8\tavg epoch loss = nan\tavg epoch acc = 0.09772\n","epoch 9\tavg epoch loss = nan\tavg epoch acc = 0.09772\n","training took 17.3 s\n","Avg test loss = nan\tAvg test acc = 0.1\n","{'lr': 0.0055000000000000005, 'beta1': 0.9, 'beta2': 0.5, 'batch_size': 128, 'weight_decay': 0.1, 'epsilon': 1e-08}\n","epoch 0\tavg epoch loss = 2.007e+28\tavg epoch acc = 0.09457\n","epoch 1\tavg epoch loss = nan\tavg epoch acc = 0.1006\n","epoch 2\tavg epoch loss = nan\tavg epoch acc = 0.09762\n","epoch 3\tavg epoch loss = nan\tavg epoch acc = 0.09762\n","epoch 4\tavg epoch loss = nan\tavg epoch acc = 0.09762\n","epoch 5\tavg epoch loss = nan\tavg epoch acc = 0.09762\n","epoch 6\tavg epoch loss = nan\tavg epoch acc = 0.09762\n","epoch 7\tavg epoch loss = nan\tavg epoch acc = 0.09762\n","epoch 8\tavg epoch loss = nan\tavg epoch acc = 0.09762\n","epoch 9\tavg epoch loss = nan\tavg epoch acc = 0.09762\n","training took 17.35 s\n","Avg test loss = nan\tAvg test acc = 0.101\n","epoch 0\tavg epoch loss = 3.154e+22\tavg epoch acc = 0.094\n","epoch 1\tavg epoch loss = nan\tavg epoch acc = 0.1014\n","epoch 2\tavg epoch loss = nan\tavg epoch acc = 0.09947\n","epoch 3\tavg epoch loss = nan\tavg epoch acc = 0.09947\n","epoch 4\tavg epoch loss = nan\tavg epoch acc = 0.09947\n","epoch 5\tavg epoch loss = nan\tavg epoch acc = 0.09947\n","epoch 6\tavg epoch loss = nan\tavg epoch acc = 0.09947\n","epoch 7\tavg epoch loss = nan\tavg epoch acc = 0.09947\n","epoch 8\tavg epoch loss = nan\tavg epoch acc = 0.09947\n","epoch 9\tavg epoch loss = nan\tavg epoch acc = 0.09947\n","training took 17.23 s\n","Avg test loss = nan\tAvg test acc = 0.0972\n","epoch 0\tavg epoch loss = 2.848e+14\tavg epoch acc = 0.09343\n","epoch 1\tavg epoch loss = 5.527e+13\tavg epoch acc = 0.1003\n","epoch 2\tavg epoch loss = 4.108e+13\tavg epoch acc = 0.1003\n","epoch 3\tavg epoch loss = 2.91e+13\tavg epoch acc = 0.1003\n","epoch 4\tavg epoch loss = 2.061e+13\tavg epoch acc = 0.1003\n","epoch 5\tavg epoch loss = 1.46e+13\tavg epoch acc = 0.1003\n","epoch 6\tavg epoch loss = 1.034e+13\tavg epoch acc = 0.1003\n","epoch 7\tavg epoch loss = 7.325e+12\tavg epoch acc = 0.1003\n","epoch 8\tavg epoch loss = 5.187e+12\tavg epoch acc = 0.1003\n","epoch 9\tavg epoch loss = 3.673e+12\tavg epoch acc = 0.1003\n","training took 17.32 s\n","Avg test loss = 3.11e+12\tAvg test acc = 0.0969\n","{'lr': 0.0055000000000000005, 'beta1': 0.9, 'beta2': 0.999, 'batch_size': 32, 'weight_decay': 0.001, 'epsilon': 1e-10}\n","epoch 0\tavg epoch loss = 0.5866\tavg epoch acc = 0.9206\n","epoch 1\tavg epoch loss = 0.3016\tavg epoch acc = 0.976\n","epoch 2\tavg epoch loss = 0.3033\tavg epoch acc = 0.9783\n","epoch 3\tavg epoch loss = 0.2873\tavg epoch acc = 0.981\n","epoch 4\tavg epoch loss = 0.289\tavg epoch acc = 0.9833\n","epoch 5\tavg epoch loss = 0.2867\tavg epoch acc = 0.9846\n","epoch 6\tavg epoch loss = 0.2955\tavg epoch acc = 0.9861\n","epoch 7\tavg epoch loss = 0.2618\tavg epoch acc = 0.9865\n","epoch 8\tavg epoch loss = 0.2573\tavg epoch acc = 0.9882\n","epoch 9\tavg epoch loss = 0.2811\tavg epoch acc = 0.9875\n","training took 54.12 s\n","Avg test loss = 0.0792\tAvg test acc = 0.981\n","epoch 0\tavg epoch loss = 0.5877\tavg epoch acc = 0.917\n","epoch 1\tavg epoch loss = 0.3132\tavg epoch acc = 0.9752\n","epoch 2\tavg epoch loss = 0.2945\tavg epoch acc = 0.979\n","epoch 3\tavg epoch loss = 0.3108\tavg epoch acc = 0.9798\n","epoch 4\tavg epoch loss = 0.2678\tavg epoch acc = 0.9835\n","epoch 5\tavg epoch loss = 0.286\tavg epoch acc = 0.9838\n","epoch 6\tavg epoch loss = 0.2948\tavg epoch acc = 0.9847\n","epoch 7\tavg epoch loss = 0.2457\tavg epoch acc = 0.9869\n","epoch 8\tavg epoch loss = 0.2598\tavg epoch acc = 0.9876\n","epoch 9\tavg epoch loss = 0.2613\tavg epoch acc = 0.9876\n","training took 53.87 s\n","Avg test loss = 0.0917\tAvg test acc = 0.977\n","epoch 0\tavg epoch loss = 0.5846\tavg epoch acc = 0.92\n","epoch 1\tavg epoch loss = 0.3112\tavg epoch acc = 0.9732\n","epoch 2\tavg epoch loss = 0.3058\tavg epoch acc = 0.9778\n","epoch 3\tavg epoch loss = 0.2929\tavg epoch acc = 0.9803\n","epoch 4\tavg epoch loss = 0.2932\tavg epoch acc = 0.983\n","epoch 5\tavg epoch loss = 0.2639\tavg epoch acc = 0.9843\n","epoch 6\tavg epoch loss = 0.2463\tavg epoch acc = 0.986\n","epoch 7\tavg epoch loss = 0.2438\tavg epoch acc = 0.9867\n","epoch 8\tavg epoch loss = 0.2332\tavg epoch acc = 0.9873\n","epoch 9\tavg epoch loss = 0.2835\tavg epoch acc = 0.9864\n","training took 54.61 s\n","Avg test loss = 0.0766\tAvg test acc = 0.98\n","{'lr': 0.0055000000000000005, 'beta1': 0.9, 'beta2': 0.999, 'batch_size': 32, 'weight_decay': 0.001, 'epsilon': 1e-08}\n","epoch 0\tavg epoch loss = 0.5815\tavg epoch acc = 0.9205\n","epoch 1\tavg epoch loss = 0.3008\tavg epoch acc = 0.9754\n","epoch 2\tavg epoch loss = 0.3009\tavg epoch acc = 0.9779\n","epoch 3\tavg epoch loss = 0.2891\tavg epoch acc = 0.982\n","epoch 4\tavg epoch loss = 0.2949\tavg epoch acc = 0.982\n","epoch 5\tavg epoch loss = 0.2763\tavg epoch acc = 0.9849\n","epoch 6\tavg epoch loss = 0.258\tavg epoch acc = 0.9867\n","epoch 7\tavg epoch loss = 0.2792\tavg epoch acc = 0.9868\n","epoch 8\tavg epoch loss = 0.2685\tavg epoch acc = 0.9873\n","epoch 9\tavg epoch loss = 0.2485\tavg epoch acc = 0.9888\n","training took 53.99 s\n","Avg test loss = 0.11\tAvg test acc = 0.971\n","epoch 0\tavg epoch loss = 0.5941\tavg epoch acc = 0.9187\n","epoch 1\tavg epoch loss = 0.3132\tavg epoch acc = 0.9744\n","epoch 2\tavg epoch loss = 0.3131\tavg epoch acc = 0.9771\n","epoch 3\tavg epoch loss = 0.3005\tavg epoch acc = 0.9802\n","epoch 4\tavg epoch loss = 0.295\tavg epoch acc = 0.9828\n","epoch 5\tavg epoch loss = 0.2905\tavg epoch acc = 0.9829\n","epoch 6\tavg epoch loss = 0.2914\tavg epoch acc = 0.9834\n","epoch 7\tavg epoch loss = 0.2742\tavg epoch acc = 0.9851\n","epoch 8\tavg epoch loss = 0.2401\tavg epoch acc = 0.9872\n","epoch 9\tavg epoch loss = 0.2594\tavg epoch acc = 0.987\n","training took 54.0 s\n","Avg test loss = 0.101\tAvg test acc = 0.976\n","epoch 0\tavg epoch loss = 0.5852\tavg epoch acc = 0.9221\n","epoch 1\tavg epoch loss = 0.3105\tavg epoch acc = 0.976\n","epoch 2\tavg epoch loss = 0.3198\tavg epoch acc = 0.977\n","epoch 3\tavg epoch loss = 0.3009\tavg epoch acc = 0.9804\n","epoch 4\tavg epoch loss = 0.2992\tavg epoch acc = 0.9819\n","epoch 5\tavg epoch loss = 0.2746\tavg epoch acc = 0.9848\n","epoch 6\tavg epoch loss = 0.2984\tavg epoch acc = 0.9852\n","epoch 7\tavg epoch loss = 0.2785\tavg epoch acc = 0.986\n","epoch 8\tavg epoch loss = 0.2824\tavg epoch acc = 0.9863\n","epoch 9\tavg epoch loss = 0.2507\tavg epoch acc = 0.9888\n","training took 54.08 s\n","Avg test loss = 0.0692\tAvg test acc = 0.981\n","{'lr': 0.0055000000000000005, 'beta1': 0.9, 'beta2': 0.999, 'batch_size': 32, 'weight_decay': 0.1, 'epsilon': 1e-10}\n","epoch 0\tavg epoch loss = 0.5881\tavg epoch acc = 0.9184\n","epoch 1\tavg epoch loss = 0.317\tavg epoch acc = 0.9714\n","epoch 2\tavg epoch loss = 0.3063\tavg epoch acc = 0.9741\n","epoch 3\tavg epoch loss = 0.3036\tavg epoch acc = 0.9754\n","epoch 4\tavg epoch loss = 0.3068\tavg epoch acc = 0.9746\n","epoch 5\tavg epoch loss = 0.2961\tavg epoch acc = 0.9762\n","epoch 6\tavg epoch loss = 0.2849\tavg epoch acc = 0.9774\n","epoch 7\tavg epoch loss = 0.2825\tavg epoch acc = 0.978\n","epoch 8\tavg epoch loss = 0.2757\tavg epoch acc = 0.9791\n","epoch 9\tavg epoch loss = 0.2792\tavg epoch acc = 0.978\n","training took 54.24 s\n","Avg test loss = 0.0832\tAvg test acc = 0.975\n","epoch 0\tavg epoch loss = 0.581\tavg epoch acc = 0.9194\n","epoch 1\tavg epoch loss = 0.3195\tavg epoch acc = 0.9725\n","epoch 2\tavg epoch loss = 0.3019\tavg epoch acc = 0.975\n","epoch 3\tavg epoch loss = 0.3032\tavg epoch acc = 0.9756\n","epoch 4\tavg epoch loss = 0.2922\tavg epoch acc = 0.9775\n","epoch 5\tavg epoch loss = 0.2855\tavg epoch acc = 0.9774\n","epoch 6\tavg epoch loss = 0.2822\tavg epoch acc = 0.9784\n","epoch 7\tavg epoch loss = 0.2814\tavg epoch acc = 0.9789\n","epoch 8\tavg epoch loss = 0.2809\tavg epoch acc = 0.9787\n","epoch 9\tavg epoch loss = 0.2693\tavg epoch acc = 0.9796\n","training took 53.93 s\n","Avg test loss = 0.132\tAvg test acc = 0.958\n","epoch 0\tavg epoch loss = 0.5918\tavg epoch acc = 0.9182\n","epoch 1\tavg epoch loss = 0.3195\tavg epoch acc = 0.9735\n","epoch 2\tavg epoch loss = 0.3151\tavg epoch acc = 0.9748\n","epoch 3\tavg epoch loss = 0.3018\tavg epoch acc = 0.9759\n","epoch 4\tavg epoch loss = 0.2927\tavg epoch acc = 0.9774\n","epoch 5\tavg epoch loss = 0.287\tavg epoch acc = 0.9772\n","epoch 6\tavg epoch loss = 0.2755\tavg epoch acc = 0.9784\n","epoch 7\tavg epoch loss = 0.2766\tavg epoch acc = 0.9777\n","epoch 8\tavg epoch loss = 0.2755\tavg epoch acc = 0.9781\n","epoch 9\tavg epoch loss = 0.2739\tavg epoch acc = 0.9789\n","training took 54.22 s\n","Avg test loss = 0.146\tAvg test acc = 0.96\n","{'lr': 0.0055000000000000005, 'beta1': 0.9, 'beta2': 0.999, 'batch_size': 32, 'weight_decay': 0.1, 'epsilon': 1e-08}\n","epoch 0\tavg epoch loss = 0.5873\tavg epoch acc = 0.9188\n","epoch 1\tavg epoch loss = 0.3158\tavg epoch acc = 0.9749\n","epoch 2\tavg epoch loss = 0.3091\tavg epoch acc = 0.9755\n","epoch 3\tavg epoch loss = 0.2896\tavg epoch acc = 0.9761\n","epoch 4\tavg epoch loss = 0.2846\tavg epoch acc = 0.9777\n","epoch 5\tavg epoch loss = 0.2822\tavg epoch acc = 0.9782\n","epoch 6\tavg epoch loss = 0.2697\tavg epoch acc = 0.9784\n","epoch 7\tavg epoch loss = 0.276\tavg epoch acc = 0.9781\n","epoch 8\tavg epoch loss = 0.2761\tavg epoch acc = 0.9786\n","epoch 9\tavg epoch loss = 0.2653\tavg epoch acc = 0.9787\n","training took 54.56 s\n","Avg test loss = 0.0948\tAvg test acc = 0.972\n","epoch 0\tavg epoch loss = 0.5895\tavg epoch acc = 0.9194\n","epoch 1\tavg epoch loss = 0.3069\tavg epoch acc = 0.9744\n","epoch 2\tavg epoch loss = 0.3106\tavg epoch acc = 0.9749\n","epoch 3\tavg epoch loss = 0.3084\tavg epoch acc = 0.975\n","epoch 4\tavg epoch loss = 0.2974\tavg epoch acc = 0.9778\n","epoch 5\tavg epoch loss = 0.2837\tavg epoch acc = 0.9771\n","epoch 6\tavg epoch loss = 0.2797\tavg epoch acc = 0.9788\n","epoch 7\tavg epoch loss = 0.2763\tavg epoch acc = 0.9791\n","epoch 8\tavg epoch loss = 0.2763\tavg epoch acc = 0.9791\n","epoch 9\tavg epoch loss = 0.2666\tavg epoch acc = 0.9804\n","training took 54.35 s\n","Avg test loss = 0.0945\tAvg test acc = 0.972\n","epoch 0\tavg epoch loss = 0.5913\tavg epoch acc = 0.9185\n","epoch 1\tavg epoch loss = 0.3092\tavg epoch acc = 0.9733\n","epoch 2\tavg epoch loss = 0.3109\tavg epoch acc = 0.9741\n","epoch 3\tavg epoch loss = 0.3137\tavg epoch acc = 0.9739\n","epoch 4\tavg epoch loss = 0.3033\tavg epoch acc = 0.9761\n","epoch 5\tavg epoch loss = 0.2941\tavg epoch acc = 0.977\n","epoch 6\tavg epoch loss = 0.2827\tavg epoch acc = 0.9781\n","epoch 7\tavg epoch loss = 0.2826\tavg epoch acc = 0.978\n","epoch 8\tavg epoch loss = 0.2768\tavg epoch acc = 0.9778\n","epoch 9\tavg epoch loss = 0.2805\tavg epoch acc = 0.9776\n","training took 54.43 s\n","Avg test loss = 0.132\tAvg test acc = 0.963\n","{'lr': 0.0055000000000000005, 'beta1': 0.9, 'beta2': 0.999, 'batch_size': 64, 'weight_decay': 0.001, 'epsilon': 1e-10}\n","epoch 0\tavg epoch loss = 0.7447\tavg epoch acc = 0.8845\n","epoch 1\tavg epoch loss = 0.2762\tavg epoch acc = 0.9782\n","epoch 2\tavg epoch loss = 0.2372\tavg epoch acc = 0.9825\n","epoch 3\tavg epoch loss = 0.2152\tavg epoch acc = 0.9849\n","epoch 4\tavg epoch loss = 0.1939\tavg epoch acc = 0.987\n","epoch 5\tavg epoch loss = 0.1918\tavg epoch acc = 0.9893\n","epoch 6\tavg epoch loss = 0.2265\tavg epoch acc = 0.9877\n","epoch 7\tavg epoch loss = 0.1999\tavg epoch acc = 0.9897\n","epoch 8\tavg epoch loss = 0.1936\tavg epoch acc = 0.9914\n","epoch 9\tavg epoch loss = 0.2026\tavg epoch acc = 0.9915\n","training took 28.22 s\n","Avg test loss = 0.0616\tAvg test acc = 0.985\n","epoch 0\tavg epoch loss = 0.7414\tavg epoch acc = 0.8856\n","epoch 1\tavg epoch loss = 0.2711\tavg epoch acc = 0.9782\n","epoch 2\tavg epoch loss = 0.2202\tavg epoch acc = 0.983\n","epoch 3\tavg epoch loss = 0.2192\tavg epoch acc = 0.9841\n","epoch 4\tavg epoch loss = 0.2076\tavg epoch acc = 0.9869\n","epoch 5\tavg epoch loss = 0.2286\tavg epoch acc = 0.9875\n","epoch 6\tavg epoch loss = 0.2131\tavg epoch acc = 0.9887\n","epoch 7\tavg epoch loss = 0.2069\tavg epoch acc = 0.9905\n","epoch 8\tavg epoch loss = 0.2106\tavg epoch acc = 0.9912\n","epoch 9\tavg epoch loss = 0.2044\tavg epoch acc = 0.9911\n","training took 27.96 s\n","Avg test loss = 0.0624\tAvg test acc = 0.983\n","epoch 0\tavg epoch loss = 0.7374\tavg epoch acc = 0.8873\n","epoch 1\tavg epoch loss = 0.2753\tavg epoch acc = 0.9788\n","epoch 2\tavg epoch loss = 0.2325\tavg epoch acc = 0.9832\n","epoch 3\tavg epoch loss = 0.2184\tavg epoch acc = 0.9852\n","epoch 4\tavg epoch loss = 0.2173\tavg epoch acc = 0.9864\n","epoch 5\tavg epoch loss = 0.2139\tavg epoch acc = 0.9878\n","epoch 6\tavg epoch loss = 0.2153\tavg epoch acc = 0.9891\n","epoch 7\tavg epoch loss = 0.1998\tavg epoch acc = 0.9908\n","epoch 8\tavg epoch loss = 0.2006\tavg epoch acc = 0.9919\n","epoch 9\tavg epoch loss = 0.1853\tavg epoch acc = 0.9929\n","training took 27.82 s\n","Avg test loss = 0.0682\tAvg test acc = 0.984\n","{'lr': 0.0055000000000000005, 'beta1': 0.9, 'beta2': 0.999, 'batch_size': 64, 'weight_decay': 0.001, 'epsilon': 1e-08}\n","epoch 0\tavg epoch loss = 0.7494\tavg epoch acc = 0.8847\n","epoch 1\tavg epoch loss = 0.2767\tavg epoch acc = 0.9791\n","epoch 2\tavg epoch loss = 0.2275\tavg epoch acc = 0.9832\n","epoch 3\tavg epoch loss = 0.2203\tavg epoch acc = 0.9851\n","epoch 4\tavg epoch loss = 0.2072\tavg epoch acc = 0.9866\n","epoch 5\tavg epoch loss = 0.2035\tavg epoch acc = 0.9886\n","epoch 6\tavg epoch loss = 0.2129\tavg epoch acc = 0.989\n","epoch 7\tavg epoch loss = 0.2036\tavg epoch acc = 0.9905\n","epoch 8\tavg epoch loss = 0.2268\tavg epoch acc = 0.9892\n","epoch 9\tavg epoch loss = 0.1914\tavg epoch acc = 0.9917\n","training took 28.03 s\n","Avg test loss = 0.0601\tAvg test acc = 0.984\n","epoch 0\tavg epoch loss = 0.735\tavg epoch acc = 0.8868\n","epoch 1\tavg epoch loss = 0.2795\tavg epoch acc = 0.9779\n","epoch 2\tavg epoch loss = 0.2314\tavg epoch acc = 0.9825\n","epoch 3\tavg epoch loss = 0.2216\tavg epoch acc = 0.9852\n","epoch 4\tavg epoch loss = 0.2178\tavg epoch acc = 0.9866\n","epoch 5\tavg epoch loss = 0.2163\tavg epoch acc = 0.9877\n","epoch 6\tavg epoch loss = 0.2355\tavg epoch acc = 0.9866\n","epoch 7\tavg epoch loss = 0.1943\tavg epoch acc = 0.9903\n","epoch 8\tavg epoch loss = 0.2001\tavg epoch acc = 0.9909\n","epoch 9\tavg epoch loss = 0.2091\tavg epoch acc = 0.9911\n","training took 28.0 s\n","Avg test loss = 0.0559\tAvg test acc = 0.985\n","epoch 0\tavg epoch loss = 0.7414\tavg epoch acc = 0.8832\n","epoch 1\tavg epoch loss = 0.2763\tavg epoch acc = 0.9786\n","epoch 2\tavg epoch loss = 0.2322\tavg epoch acc = 0.9827\n","epoch 3\tavg epoch loss = 0.2155\tavg epoch acc = 0.9846\n","epoch 4\tavg epoch loss = 0.2055\tavg epoch acc = 0.9868\n","epoch 5\tavg epoch loss = 0.2041\tavg epoch acc = 0.9883\n","epoch 6\tavg epoch loss = 0.2115\tavg epoch acc = 0.9885\n","epoch 7\tavg epoch loss = 0.1941\tavg epoch acc = 0.9902\n","epoch 8\tavg epoch loss = 0.2187\tavg epoch acc = 0.9886\n","epoch 9\tavg epoch loss = 0.1961\tavg epoch acc = 0.9909\n","training took 27.92 s\n","Avg test loss = 0.0625\tAvg test acc = 0.983\n","{'lr': 0.0055000000000000005, 'beta1': 0.9, 'beta2': 0.999, 'batch_size': 64, 'weight_decay': 0.1, 'epsilon': 1e-10}\n","epoch 0\tavg epoch loss = 0.739\tavg epoch acc = 0.8899\n","epoch 1\tavg epoch loss = 0.2721\tavg epoch acc = 0.9785\n","epoch 2\tavg epoch loss = 0.2256\tavg epoch acc = 0.9823\n","epoch 3\tavg epoch loss = 0.2243\tavg epoch acc = 0.9833\n","epoch 4\tavg epoch loss = 0.215\tavg epoch acc = 0.9839\n","epoch 5\tavg epoch loss = 0.2095\tavg epoch acc = 0.9845\n","epoch 6\tavg epoch loss = 0.2175\tavg epoch acc = 0.9845\n","epoch 7\tavg epoch loss = 0.2047\tavg epoch acc = 0.986\n","epoch 8\tavg epoch loss = 0.2169\tavg epoch acc = 0.9853\n","epoch 9\tavg epoch loss = 0.2092\tavg epoch acc = 0.9856\n","training took 28.11 s\n","Avg test loss = 0.077\tAvg test acc = 0.977\n","epoch 0\tavg epoch loss = 0.7402\tavg epoch acc = 0.8872\n","epoch 1\tavg epoch loss = 0.2788\tavg epoch acc = 0.9779\n","epoch 2\tavg epoch loss = 0.2391\tavg epoch acc = 0.9818\n","epoch 3\tavg epoch loss = 0.2187\tavg epoch acc = 0.9831\n","epoch 4\tavg epoch loss = 0.236\tavg epoch acc = 0.982\n","epoch 5\tavg epoch loss = 0.2158\tavg epoch acc = 0.9844\n","epoch 6\tavg epoch loss = 0.2177\tavg epoch acc = 0.9853\n","epoch 7\tavg epoch loss = 0.2212\tavg epoch acc = 0.9848\n","epoch 8\tavg epoch loss = 0.2137\tavg epoch acc = 0.9858\n","epoch 9\tavg epoch loss = 0.2177\tavg epoch acc = 0.9856\n","training took 27.88 s\n","Avg test loss = 0.0728\tAvg test acc = 0.978\n","epoch 0\tavg epoch loss = 0.7351\tavg epoch acc = 0.8831\n","epoch 1\tavg epoch loss = 0.2698\tavg epoch acc = 0.9795\n","epoch 2\tavg epoch loss = 0.2296\tavg epoch acc = 0.9823\n","epoch 3\tavg epoch loss = 0.2167\tavg epoch acc = 0.9838\n","epoch 4\tavg epoch loss = 0.2141\tavg epoch acc = 0.9843\n","epoch 5\tavg epoch loss = 0.2162\tavg epoch acc = 0.9845\n","epoch 6\tavg epoch loss = 0.2192\tavg epoch acc = 0.9849\n","epoch 7\tavg epoch loss = 0.2104\tavg epoch acc = 0.9857\n","epoch 8\tavg epoch loss = 0.2063\tavg epoch acc = 0.9866\n","epoch 9\tavg epoch loss = 0.2115\tavg epoch acc = 0.9867\n","training took 28.01 s\n","Avg test loss = 0.0688\tAvg test acc = 0.98\n","{'lr': 0.0055000000000000005, 'beta1': 0.9, 'beta2': 0.999, 'batch_size': 64, 'weight_decay': 0.1, 'epsilon': 1e-08}\n","epoch 0\tavg epoch loss = 0.7523\tavg epoch acc = 0.8845\n","epoch 1\tavg epoch loss = 0.2773\tavg epoch acc = 0.9785\n","epoch 2\tavg epoch loss = 0.2359\tavg epoch acc = 0.982\n","epoch 3\tavg epoch loss = 0.2271\tavg epoch acc = 0.9833\n","epoch 4\tavg epoch loss = 0.2225\tavg epoch acc = 0.9836\n","epoch 5\tavg epoch loss = 0.2146\tavg epoch acc = 0.9843\n","epoch 6\tavg epoch loss = 0.2228\tavg epoch acc = 0.984\n","epoch 7\tavg epoch loss = 0.2172\tavg epoch acc = 0.984\n","epoch 8\tavg epoch loss = 0.2234\tavg epoch acc = 0.9853\n","epoch 9\tavg epoch loss = 0.2072\tavg epoch acc = 0.9859\n","training took 27.99 s\n","Avg test loss = 0.0637\tAvg test acc = 0.98\n","epoch 0\tavg epoch loss = 0.7381\tavg epoch acc = 0.8855\n","epoch 1\tavg epoch loss = 0.2761\tavg epoch acc = 0.9788\n","epoch 2\tavg epoch loss = 0.2237\tavg epoch acc = 0.9829\n","epoch 3\tavg epoch loss = 0.2175\tavg epoch acc = 0.9826\n","epoch 4\tavg epoch loss = 0.2191\tavg epoch acc = 0.9835\n","epoch 5\tavg epoch loss = 0.22\tavg epoch acc = 0.9839\n","epoch 6\tavg epoch loss = 0.2186\tavg epoch acc = 0.9849\n","epoch 7\tavg epoch loss = 0.2114\tavg epoch acc = 0.9862\n","epoch 8\tavg epoch loss = 0.2159\tavg epoch acc = 0.986\n","epoch 9\tavg epoch loss = 0.2159\tavg epoch acc = 0.9858\n","training took 28.04 s\n","Avg test loss = 0.0762\tAvg test acc = 0.978\n","epoch 0\tavg epoch loss = 0.7303\tavg epoch acc = 0.8849\n","epoch 1\tavg epoch loss = 0.2675\tavg epoch acc = 0.9794\n","epoch 2\tavg epoch loss = 0.2286\tavg epoch acc = 0.9821\n","epoch 3\tavg epoch loss = 0.2252\tavg epoch acc = 0.9829\n","epoch 4\tavg epoch loss = 0.2218\tavg epoch acc = 0.984\n","epoch 5\tavg epoch loss = 0.2206\tavg epoch acc = 0.9836\n","epoch 6\tavg epoch loss = 0.2267\tavg epoch acc = 0.9844\n","epoch 7\tavg epoch loss = 0.2026\tavg epoch acc = 0.9864\n","epoch 8\tavg epoch loss = 0.2131\tavg epoch acc = 0.9857\n","epoch 9\tavg epoch loss = 0.2049\tavg epoch acc = 0.9872\n","training took 28.0 s\n","Avg test loss = 0.0769\tAvg test acc = 0.978\n","{'lr': 0.0055000000000000005, 'beta1': 0.9, 'beta2': 0.999, 'batch_size': 128, 'weight_decay': 0.001, 'epsilon': 1e-10}\n","epoch 0\tavg epoch loss = 1.022\tavg epoch acc = 0.8268\n","epoch 1\tavg epoch loss = 0.3138\tavg epoch acc = 0.9758\n","epoch 2\tavg epoch loss = 0.2201\tavg epoch acc = 0.9835\n","epoch 3\tavg epoch loss = 0.1786\tavg epoch acc = 0.987\n","epoch 4\tavg epoch loss = 0.1707\tavg epoch acc = 0.9883\n","epoch 5\tavg epoch loss = 0.1445\tavg epoch acc = 0.9895\n","epoch 6\tavg epoch loss = 0.1367\tavg epoch acc = 0.9913\n","epoch 7\tavg epoch loss = 0.1396\tavg epoch acc = 0.9918\n","epoch 8\tavg epoch loss = 0.1394\tavg epoch acc = 0.9913\n","epoch 9\tavg epoch loss = 0.139\tavg epoch acc = 0.9926\n","training took 17.37 s\n","Avg test loss = 0.0626\tAvg test acc = 0.985\n","epoch 0\tavg epoch loss = 1.04\tavg epoch acc = 0.8216\n","epoch 1\tavg epoch loss = 0.3255\tavg epoch acc = 0.9756\n","epoch 2\tavg epoch loss = 0.2359\tavg epoch acc = 0.9833\n","epoch 3\tavg epoch loss = 0.1992\tavg epoch acc = 0.9866\n","epoch 4\tavg epoch loss = 0.187\tavg epoch acc = 0.9883\n","epoch 5\tavg epoch loss = 0.1583\tavg epoch acc = 0.9901\n","epoch 6\tavg epoch loss = 0.1463\tavg epoch acc = 0.992\n","epoch 7\tavg epoch loss = 0.1425\tavg epoch acc = 0.9933\n","epoch 8\tavg epoch loss = 0.1521\tavg epoch acc = 0.9928\n","epoch 9\tavg epoch loss = 0.1639\tavg epoch acc = 0.9925\n","training took 17.46 s\n","Avg test loss = 0.0552\tAvg test acc = 0.985\n","epoch 0\tavg epoch loss = 1.015\tavg epoch acc = 0.8222\n","epoch 1\tavg epoch loss = 0.3162\tavg epoch acc = 0.977\n","epoch 2\tavg epoch loss = 0.2343\tavg epoch acc = 0.9835\n","epoch 3\tavg epoch loss = 0.1962\tavg epoch acc = 0.9867\n","epoch 4\tavg epoch loss = 0.171\tavg epoch acc = 0.9886\n","epoch 5\tavg epoch loss = 0.1503\tavg epoch acc = 0.9909\n","epoch 6\tavg epoch loss = 0.1433\tavg epoch acc = 0.9921\n","epoch 7\tavg epoch loss = 0.16\tavg epoch acc = 0.9909\n","epoch 8\tavg epoch loss = 0.1403\tavg epoch acc = 0.9932\n","epoch 9\tavg epoch loss = 0.1243\tavg epoch acc = 0.9942\n","training took 17.45 s\n","Avg test loss = 0.0627\tAvg test acc = 0.984\n","{'lr': 0.0055000000000000005, 'beta1': 0.9, 'beta2': 0.999, 'batch_size': 128, 'weight_decay': 0.001, 'epsilon': 1e-08}\n","epoch 0\tavg epoch loss = 1.026\tavg epoch acc = 0.8267\n","epoch 1\tavg epoch loss = 0.327\tavg epoch acc = 0.9755\n","epoch 2\tavg epoch loss = 0.237\tavg epoch acc = 0.9833\n","epoch 3\tavg epoch loss = 0.1929\tavg epoch acc = 0.9873\n","epoch 4\tavg epoch loss = 0.169\tavg epoch acc = 0.989\n","epoch 5\tavg epoch loss = 0.1586\tavg epoch acc = 0.9901\n","epoch 6\tavg epoch loss = 0.1525\tavg epoch acc = 0.9914\n","epoch 7\tavg epoch loss = 0.1428\tavg epoch acc = 0.9923\n","epoch 8\tavg epoch loss = 0.1481\tavg epoch acc = 0.9927\n","epoch 9\tavg epoch loss = 0.1439\tavg epoch acc = 0.9928\n","training took 17.41 s\n","Avg test loss = 0.0595\tAvg test acc = 0.985\n","epoch 0\tavg epoch loss = 1.021\tavg epoch acc = 0.8276\n","epoch 1\tavg epoch loss = 0.3167\tavg epoch acc = 0.9763\n","epoch 2\tavg epoch loss = 0.2321\tavg epoch acc = 0.9836\n","epoch 3\tavg epoch loss = 0.1896\tavg epoch acc = 0.9872\n","epoch 4\tavg epoch loss = 0.1723\tavg epoch acc = 0.9894\n","epoch 5\tavg epoch loss = 0.1689\tavg epoch acc = 0.99\n","epoch 6\tavg epoch loss = 0.1558\tavg epoch acc = 0.9918\n","epoch 7\tavg epoch loss = 0.1415\tavg epoch acc = 0.9925\n","epoch 8\tavg epoch loss = 0.1286\tavg epoch acc = 0.9943\n","epoch 9\tavg epoch loss = 0.1282\tavg epoch acc = 0.9946\n","training took 17.41 s\n","Avg test loss = 0.0637\tAvg test acc = 0.984\n","epoch 0\tavg epoch loss = 1.012\tavg epoch acc = 0.826\n","epoch 1\tavg epoch loss = 0.3162\tavg epoch acc = 0.9754\n","epoch 2\tavg epoch loss = 0.2348\tavg epoch acc = 0.9837\n","epoch 3\tavg epoch loss = 0.1941\tavg epoch acc = 0.987\n","epoch 4\tavg epoch loss = 0.1651\tavg epoch acc = 0.9895\n","epoch 5\tavg epoch loss = 0.1655\tavg epoch acc = 0.9902\n","epoch 6\tavg epoch loss = 0.1599\tavg epoch acc = 0.9917\n","epoch 7\tavg epoch loss = 0.1492\tavg epoch acc = 0.9925\n","epoch 8\tavg epoch loss = 0.1323\tavg epoch acc = 0.994\n","epoch 9\tavg epoch loss = 0.1266\tavg epoch acc = 0.9943\n","training took 17.49 s\n","Avg test loss = 0.0484\tAvg test acc = 0.985\n","{'lr': 0.0055000000000000005, 'beta1': 0.9, 'beta2': 0.999, 'batch_size': 128, 'weight_decay': 0.1, 'epsilon': 1e-10}\n","epoch 0\tavg epoch loss = 1.023\tavg epoch acc = 0.8278\n","epoch 1\tavg epoch loss = 0.3147\tavg epoch acc = 0.9762\n","epoch 2\tavg epoch loss = 0.2279\tavg epoch acc = 0.9837\n","epoch 3\tavg epoch loss = 0.1891\tavg epoch acc = 0.9876\n","epoch 4\tavg epoch loss = 0.1625\tavg epoch acc = 0.9892\n","epoch 5\tavg epoch loss = 0.15\tavg epoch acc = 0.9911\n","epoch 6\tavg epoch loss = 0.1521\tavg epoch acc = 0.9908\n","epoch 7\tavg epoch loss = 0.1462\tavg epoch acc = 0.9913\n","epoch 8\tavg epoch loss = 0.1475\tavg epoch acc = 0.9919\n","epoch 9\tavg epoch loss = 0.1327\tavg epoch acc = 0.9927\n","training took 17.56 s\n","Avg test loss = 0.0534\tAvg test acc = 0.985\n","epoch 0\tavg epoch loss = 1.016\tavg epoch acc = 0.8204\n","epoch 1\tavg epoch loss = 0.3226\tavg epoch acc = 0.9757\n","epoch 2\tavg epoch loss = 0.2318\tavg epoch acc = 0.9834\n","epoch 3\tavg epoch loss = 0.191\tavg epoch acc = 0.987\n","epoch 4\tavg epoch loss = 0.1745\tavg epoch acc = 0.9883\n","epoch 5\tavg epoch loss = 0.1599\tavg epoch acc = 0.9897\n","epoch 6\tavg epoch loss = 0.1482\tavg epoch acc = 0.991\n","epoch 7\tavg epoch loss = 0.1428\tavg epoch acc = 0.9916\n","epoch 8\tavg epoch loss = 0.1396\tavg epoch acc = 0.9922\n","epoch 9\tavg epoch loss = 0.1429\tavg epoch acc = 0.992\n","training took 17.46 s\n","Avg test loss = 0.0513\tAvg test acc = 0.985\n","epoch 0\tavg epoch loss = 1.022\tavg epoch acc = 0.8247\n","epoch 1\tavg epoch loss = 0.3171\tavg epoch acc = 0.9754\n","epoch 2\tavg epoch loss = 0.2381\tavg epoch acc = 0.9827\n","epoch 3\tavg epoch loss = 0.1919\tavg epoch acc = 0.9866\n","epoch 4\tavg epoch loss = 0.1779\tavg epoch acc = 0.9881\n","epoch 5\tavg epoch loss = 0.1663\tavg epoch acc = 0.9897\n","epoch 6\tavg epoch loss = 0.1567\tavg epoch acc = 0.9902\n","epoch 7\tavg epoch loss = 0.1444\tavg epoch acc = 0.9909\n","epoch 8\tavg epoch loss = 0.1543\tavg epoch acc = 0.9909\n","epoch 9\tavg epoch loss = 0.143\tavg epoch acc = 0.9919\n","training took 17.59 s\n","Avg test loss = 0.0448\tAvg test acc = 0.985\n","{'lr': 0.0055000000000000005, 'beta1': 0.9, 'beta2': 0.999, 'batch_size': 128, 'weight_decay': 0.1, 'epsilon': 1e-08}\n","epoch 0\tavg epoch loss = 1.027\tavg epoch acc = 0.8231\n","epoch 1\tavg epoch loss = 0.3233\tavg epoch acc = 0.9757\n","epoch 2\tavg epoch loss = 0.2299\tavg epoch acc = 0.9835\n","epoch 3\tavg epoch loss = 0.2006\tavg epoch acc = 0.986\n","epoch 4\tavg epoch loss = 0.1693\tavg epoch acc = 0.9889\n","epoch 5\tavg epoch loss = 0.1591\tavg epoch acc = 0.9891\n","epoch 6\tavg epoch loss = 0.1544\tavg epoch acc = 0.9903\n","epoch 7\tavg epoch loss = 0.1511\tavg epoch acc = 0.9905\n","epoch 8\tavg epoch loss = 0.1554\tavg epoch acc = 0.9909\n","epoch 9\tavg epoch loss = 0.1569\tavg epoch acc = 0.9912\n","training took 17.67 s\n","Avg test loss = 0.054\tAvg test acc = 0.984\n","epoch 0\tavg epoch loss = 1.026\tavg epoch acc = 0.8236\n","epoch 1\tavg epoch loss = 0.3174\tavg epoch acc = 0.9762\n","epoch 2\tavg epoch loss = 0.236\tavg epoch acc = 0.9835\n","epoch 3\tavg epoch loss = 0.2028\tavg epoch acc = 0.9867\n","epoch 4\tavg epoch loss = 0.1872\tavg epoch acc = 0.9888\n","epoch 5\tavg epoch loss = 0.1728\tavg epoch acc = 0.9895\n","epoch 6\tavg epoch loss = 0.1528\tavg epoch acc = 0.9917\n","epoch 7\tavg epoch loss = 0.1567\tavg epoch acc = 0.991\n","epoch 8\tavg epoch loss = 0.1496\tavg epoch acc = 0.9913\n","epoch 9\tavg epoch loss = 0.1338\tavg epoch acc = 0.9927\n","training took 17.51 s\n","Avg test loss = 0.0529\tAvg test acc = 0.984\n","epoch 0\tavg epoch loss = 1.013\tavg epoch acc = 0.8274\n","epoch 1\tavg epoch loss = 0.3104\tavg epoch acc = 0.9766\n","epoch 2\tavg epoch loss = 0.2288\tavg epoch acc = 0.9833\n","epoch 3\tavg epoch loss = 0.1887\tavg epoch acc = 0.987\n","epoch 4\tavg epoch loss = 0.1683\tavg epoch acc = 0.9884\n","epoch 5\tavg epoch loss = 0.163\tavg epoch acc = 0.9893\n","epoch 6\tavg epoch loss = 0.15\tavg epoch acc = 0.9901\n","epoch 7\tavg epoch loss = 0.1399\tavg epoch acc = 0.9911\n","epoch 8\tavg epoch loss = 0.1373\tavg epoch acc = 0.992\n","epoch 9\tavg epoch loss = 0.1446\tavg epoch acc = 0.9916\n","training took 17.35 s\n","Avg test loss = 0.062\tAvg test acc = 0.984\n","{'lr': 0.01, 'beta1': 0.1, 'beta2': 0.5, 'batch_size': 32, 'weight_decay': 0.001, 'epsilon': 1e-10}\n","epoch 0\tavg epoch loss = 0.9075\tavg epoch acc = 0.9153\n","epoch 1\tavg epoch loss = 0.8764\tavg epoch acc = 0.9308\n","epoch 2\tavg epoch loss = 0.9539\tavg epoch acc = 0.9252\n","epoch 3\tavg epoch loss = 1.01\tavg epoch acc = 0.9225\n","epoch 4\tavg epoch loss = 1.246\tavg epoch acc = 0.9127\n","epoch 5\tavg epoch loss = 1.239\tavg epoch acc = 0.8986\n","epoch 6\tavg epoch loss = 1.347\tavg epoch acc = 0.8981\n","epoch 7\tavg epoch loss = 1.598\tavg epoch acc = 0.8447\n","epoch 8\tavg epoch loss = 1.343\tavg epoch acc = 0.8835\n","epoch 9\tavg epoch loss = 1.265\tavg epoch acc = 0.8774\n","training took 54.39 s\n","Avg test loss = 0.572\tAvg test acc = 0.908\n","epoch 0\tavg epoch loss = 0.9194\tavg epoch acc = 0.9185\n","epoch 1\tavg epoch loss = 0.936\tavg epoch acc = 0.932\n","epoch 2\tavg epoch loss = 0.9519\tavg epoch acc = 0.9204\n","epoch 3\tavg epoch loss = 1.064\tavg epoch acc = 0.9111\n","epoch 4\tavg epoch loss = 1.158\tavg epoch acc = 0.8978\n","epoch 5\tavg epoch loss = 1.222\tavg epoch acc = 0.8963\n","epoch 6\tavg epoch loss = 1.234\tavg epoch acc = 0.8884\n","epoch 7\tavg epoch loss = 1.235\tavg epoch acc = 0.8725\n","epoch 8\tavg epoch loss = 1.227\tavg epoch acc = 0.883\n","epoch 9\tavg epoch loss = 1.235\tavg epoch acc = 0.8275\n","training took 54.14 s\n","Avg test loss = 0.423\tAvg test acc = 0.898\n","epoch 0\tavg epoch loss = 0.8843\tavg epoch acc = 0.9155\n","epoch 1\tavg epoch loss = 0.885\tavg epoch acc = 0.9267\n","epoch 2\tavg epoch loss = 0.9597\tavg epoch acc = 0.9166\n","epoch 3\tavg epoch loss = 1.096\tavg epoch acc = 0.9053\n","epoch 4\tavg epoch loss = 1.191\tavg epoch acc = 0.8968\n","epoch 5\tavg epoch loss = 1.235\tavg epoch acc = 0.8963\n","epoch 6\tavg epoch loss = 1.41\tavg epoch acc = 0.8495\n","epoch 7\tavg epoch loss = 1.268\tavg epoch acc = 0.8609\n","epoch 8\tavg epoch loss = 1.102\tavg epoch acc = 0.8998\n","epoch 9\tavg epoch loss = 1.147\tavg epoch acc = 0.8893\n","training took 54.13 s\n","Avg test loss = 0.716\tAvg test acc = 0.906\n","{'lr': 0.01, 'beta1': 0.1, 'beta2': 0.5, 'batch_size': 32, 'weight_decay': 0.001, 'epsilon': 1e-08}\n","epoch 0\tavg epoch loss = 0.8506\tavg epoch acc = 0.9203\n","epoch 1\tavg epoch loss = 0.811\tavg epoch acc = 0.936\n","epoch 2\tavg epoch loss = 0.9434\tavg epoch acc = 0.9244\n","epoch 3\tavg epoch loss = 1.051\tavg epoch acc = 0.9182\n","epoch 4\tavg epoch loss = 1.166\tavg epoch acc = 0.8983\n","epoch 5\tavg epoch loss = 1.144\tavg epoch acc = 0.8852\n","epoch 6\tavg epoch loss = 1.315\tavg epoch acc = 0.839\n","epoch 7\tavg epoch loss = 1.288\tavg epoch acc = 0.8677\n","epoch 8\tavg epoch loss = 1.358\tavg epoch acc = 0.7909\n","epoch 9\tavg epoch loss = 1.688\tavg epoch acc = 0.6734\n","training took 54.73 s\n","Avg test loss = 0.517\tAvg test acc = 0.851\n","epoch 0\tavg epoch loss = 0.9408\tavg epoch acc = 0.9111\n","epoch 1\tavg epoch loss = 0.9527\tavg epoch acc = 0.9286\n","epoch 2\tavg epoch loss = 0.9238\tavg epoch acc = 0.9286\n","epoch 3\tavg epoch loss = 0.9651\tavg epoch acc = 0.9222\n","epoch 4\tavg epoch loss = 1.097\tavg epoch acc = 0.9103\n","epoch 5\tavg epoch loss = 1.222\tavg epoch acc = 0.8802\n","epoch 6\tavg epoch loss = 1.248\tavg epoch acc = 0.8795\n","epoch 7\tavg epoch loss = 1.152\tavg epoch acc = 0.8926\n","epoch 8\tavg epoch loss = 1.511\tavg epoch acc = 0.6971\n","epoch 9\tavg epoch loss = 2.398\tavg epoch acc = 0.1024\n","training took 54.51 s\n","Avg test loss = 2.31\tAvg test acc = 0.105\n","epoch 0\tavg epoch loss = 0.9212\tavg epoch acc = 0.9132\n","epoch 1\tavg epoch loss = 0.9162\tavg epoch acc = 0.9333\n","epoch 2\tavg epoch loss = 1.002\tavg epoch acc = 0.9171\n","epoch 3\tavg epoch loss = 1.037\tavg epoch acc = 0.915\n","epoch 4\tavg epoch loss = 1.105\tavg epoch acc = 0.9027\n","epoch 5\tavg epoch loss = 1.06\tavg epoch acc = 0.9062\n","epoch 6\tavg epoch loss = 1.147\tavg epoch acc = 0.8827\n","epoch 7\tavg epoch loss = 1.271\tavg epoch acc = 0.8766\n","epoch 8\tavg epoch loss = 1.073\tavg epoch acc = 0.8904\n","epoch 9\tavg epoch loss = 1.092\tavg epoch acc = 0.8889\n","training took 54.35 s\n","Avg test loss = 0.937\tAvg test acc = 0.908\n","{'lr': 0.01, 'beta1': 0.1, 'beta2': 0.5, 'batch_size': 32, 'weight_decay': 0.1, 'epsilon': 1e-10}\n","epoch 0\tavg epoch loss = 0.8477\tavg epoch acc = 0.9171\n","epoch 1\tavg epoch loss = 0.7276\tavg epoch acc = 0.9417\n","epoch 2\tavg epoch loss = 0.6952\tavg epoch acc = 0.9428\n","epoch 3\tavg epoch loss = 0.7004\tavg epoch acc = 0.9423\n","epoch 4\tavg epoch loss = 0.7002\tavg epoch acc = 0.9431\n","epoch 5\tavg epoch loss = 0.6883\tavg epoch acc = 0.9441\n","epoch 6\tavg epoch loss = 0.6759\tavg epoch acc = 0.9432\n","epoch 7\tavg epoch loss = 0.6715\tavg epoch acc = 0.9446\n","epoch 8\tavg epoch loss = 0.6838\tavg epoch acc = 0.9417\n","epoch 9\tavg epoch loss = 0.676\tavg epoch acc = 0.9445\n","training took 54.47 s\n","Avg test loss = 0.297\tAvg test acc = 0.936\n","epoch 0\tavg epoch loss = 0.8761\tavg epoch acc = 0.9102\n","epoch 1\tavg epoch loss = 0.7496\tavg epoch acc = 0.9356\n","epoch 2\tavg epoch loss = 0.6963\tavg epoch acc = 0.9377\n","epoch 3\tavg epoch loss = 0.699\tavg epoch acc = 0.9384\n","epoch 4\tavg epoch loss = 0.7219\tavg epoch acc = 0.937\n","epoch 5\tavg epoch loss = 0.7013\tavg epoch acc = 0.9377\n","epoch 6\tavg epoch loss = 0.7022\tavg epoch acc = 0.9388\n","epoch 7\tavg epoch loss = 0.7124\tavg epoch acc = 0.9376\n","epoch 8\tavg epoch loss = 0.7119\tavg epoch acc = 0.9377\n","epoch 9\tavg epoch loss = 0.7095\tavg epoch acc = 0.9384\n","training took 54.06 s\n","Avg test loss = 0.307\tAvg test acc = 0.906\n","epoch 0\tavg epoch loss = 0.8558\tavg epoch acc = 0.9135\n","epoch 1\tavg epoch loss = 0.7206\tavg epoch acc = 0.9405\n","epoch 2\tavg epoch loss = 0.6853\tavg epoch acc = 0.9424\n","epoch 3\tavg epoch loss = 0.6776\tavg epoch acc = 0.9421\n","epoch 4\tavg epoch loss = 0.661\tavg epoch acc = 0.9428\n","epoch 5\tavg epoch loss = 0.6686\tavg epoch acc = 0.9438\n","epoch 6\tavg epoch loss = 0.6675\tavg epoch acc = 0.9434\n","epoch 7\tavg epoch loss = 0.6794\tavg epoch acc = 0.9417\n","epoch 8\tavg epoch loss = 0.6742\tavg epoch acc = 0.9442\n","epoch 9\tavg epoch loss = 0.6649\tavg epoch acc = 0.9431\n","training took 54.14 s\n","Avg test loss = 0.239\tAvg test acc = 0.933\n","{'lr': 0.01, 'beta1': 0.1, 'beta2': 0.5, 'batch_size': 32, 'weight_decay': 0.1, 'epsilon': 1e-08}\n","epoch 0\tavg epoch loss = 0.8213\tavg epoch acc = 0.9107\n","epoch 1\tavg epoch loss = 0.7105\tavg epoch acc = 0.938\n","epoch 2\tavg epoch loss = 0.7126\tavg epoch acc = 0.9397\n","epoch 3\tavg epoch loss = 0.6969\tavg epoch acc = 0.9413\n","epoch 4\tavg epoch loss = 0.6659\tavg epoch acc = 0.9418\n","epoch 5\tavg epoch loss = 0.6712\tavg epoch acc = 0.9421\n","epoch 6\tavg epoch loss = 0.6718\tavg epoch acc = 0.9421\n","epoch 7\tavg epoch loss = 0.6731\tavg epoch acc = 0.9416\n","epoch 8\tavg epoch loss = 0.6665\tavg epoch acc = 0.942\n","epoch 9\tavg epoch loss = 0.6666\tavg epoch acc = 0.9418\n","training took 54.56 s\n","Avg test loss = 0.372\tAvg test acc = 0.887\n","epoch 0\tavg epoch loss = 0.8585\tavg epoch acc = 0.9144\n","epoch 1\tavg epoch loss = 0.7211\tavg epoch acc = 0.9402\n","epoch 2\tavg epoch loss = 0.7246\tavg epoch acc = 0.9391\n","epoch 3\tavg epoch loss = 0.6943\tavg epoch acc = 0.9406\n","epoch 4\tavg epoch loss = 0.7038\tavg epoch acc = 0.9384\n","epoch 5\tavg epoch loss = 0.695\tavg epoch acc = 0.9368\n","epoch 6\tavg epoch loss = 0.707\tavg epoch acc = 0.9389\n","epoch 7\tavg epoch loss = 0.671\tavg epoch acc = 0.9393\n","epoch 8\tavg epoch loss = 0.7017\tavg epoch acc = 0.9367\n","epoch 9\tavg epoch loss = 0.6798\tavg epoch acc = 0.9384\n","training took 54.47 s\n","Avg test loss = 0.399\tAvg test acc = 0.859\n","epoch 0\tavg epoch loss = 0.8399\tavg epoch acc = 0.9217\n","epoch 1\tavg epoch loss = 0.739\tavg epoch acc = 0.9412\n","epoch 2\tavg epoch loss = 0.7306\tavg epoch acc = 0.9408\n","epoch 3\tavg epoch loss = 0.7175\tavg epoch acc = 0.9419\n","epoch 4\tavg epoch loss = 0.7042\tavg epoch acc = 0.9425\n","epoch 5\tavg epoch loss = 0.7244\tavg epoch acc = 0.9426\n","epoch 6\tavg epoch loss = 0.7039\tavg epoch acc = 0.9445\n","epoch 7\tavg epoch loss = 0.6609\tavg epoch acc = 0.9439\n","epoch 8\tavg epoch loss = 0.6557\tavg epoch acc = 0.9458\n","epoch 9\tavg epoch loss = 0.6669\tavg epoch acc = 0.9434\n","training took 54.14 s\n","Avg test loss = 0.222\tAvg test acc = 0.933\n","{'lr': 0.01, 'beta1': 0.1, 'beta2': 0.5, 'batch_size': 64, 'weight_decay': 0.001, 'epsilon': 1e-10}\n","epoch 0\tavg epoch loss = 0.7807\tavg epoch acc = 0.9203\n","epoch 1\tavg epoch loss = 0.6714\tavg epoch acc = 0.9545\n","epoch 2\tavg epoch loss = 0.6996\tavg epoch acc = 0.9538\n","epoch 3\tavg epoch loss = 0.691\tavg epoch acc = 0.9524\n","epoch 4\tavg epoch loss = 0.7419\tavg epoch acc = 0.9534\n","epoch 5\tavg epoch loss = 0.774\tavg epoch acc = 0.9492\n","epoch 6\tavg epoch loss = 0.7256\tavg epoch acc = 0.9465\n","epoch 7\tavg epoch loss = 0.7446\tavg epoch acc = 0.9458\n","epoch 8\tavg epoch loss = 0.8593\tavg epoch acc = 0.9467\n","epoch 9\tavg epoch loss = 0.8079\tavg epoch acc = 0.9468\n","training took 28.07 s\n","Avg test loss = 0.313\tAvg test acc = 0.941\n","epoch 0\tavg epoch loss = 0.7497\tavg epoch acc = 0.9223\n","epoch 1\tavg epoch loss = 0.6475\tavg epoch acc = 0.9577\n","epoch 2\tavg epoch loss = 0.6955\tavg epoch acc = 0.9575\n","epoch 3\tavg epoch loss = 0.7145\tavg epoch acc = 0.9569\n","epoch 4\tavg epoch loss = 0.7293\tavg epoch acc = 0.9551\n","epoch 5\tavg epoch loss = 0.776\tavg epoch acc = 0.9556\n","epoch 6\tavg epoch loss = 0.7999\tavg epoch acc = 0.954\n","epoch 7\tavg epoch loss = 0.818\tavg epoch acc = 0.9481\n","epoch 8\tavg epoch loss = 0.8571\tavg epoch acc = 0.9474\n","epoch 9\tavg epoch loss = 0.8128\tavg epoch acc = 0.9455\n","training took 28.12 s\n","Avg test loss = 0.527\tAvg test acc = 0.953\n","epoch 0\tavg epoch loss = 0.7551\tavg epoch acc = 0.9205\n","epoch 1\tavg epoch loss = 0.6827\tavg epoch acc = 0.9566\n","epoch 2\tavg epoch loss = 0.7259\tavg epoch acc = 0.9508\n","epoch 3\tavg epoch loss = 0.7778\tavg epoch acc = 0.948\n","epoch 4\tavg epoch loss = 0.7675\tavg epoch acc = 0.9456\n","epoch 5\tavg epoch loss = 0.7606\tavg epoch acc = 0.948\n","epoch 6\tavg epoch loss = 0.8427\tavg epoch acc = 0.9476\n","epoch 7\tavg epoch loss = 0.9823\tavg epoch acc = 0.939\n","epoch 8\tavg epoch loss = 0.8383\tavg epoch acc = 0.9404\n","epoch 9\tavg epoch loss = 0.8062\tavg epoch acc = 0.9395\n","training took 28.01 s\n","Avg test loss = 0.402\tAvg test acc = 0.933\n","{'lr': 0.01, 'beta1': 0.1, 'beta2': 0.5, 'batch_size': 64, 'weight_decay': 0.001, 'epsilon': 1e-08}\n","epoch 0\tavg epoch loss = 0.7581\tavg epoch acc = 0.9172\n","epoch 1\tavg epoch loss = 0.706\tavg epoch acc = 0.952\n","epoch 2\tavg epoch loss = 0.7551\tavg epoch acc = 0.9475\n","epoch 3\tavg epoch loss = 0.8081\tavg epoch acc = 0.9411\n","epoch 4\tavg epoch loss = 0.7979\tavg epoch acc = 0.9395\n","epoch 5\tavg epoch loss = 0.806\tavg epoch acc = 0.9357\n","epoch 6\tavg epoch loss = 0.7644\tavg epoch acc = 0.9345\n","epoch 7\tavg epoch loss = 0.9335\tavg epoch acc = 0.934\n","epoch 8\tavg epoch loss = 0.7898\tavg epoch acc = 0.9342\n","epoch 9\tavg epoch loss = 0.8651\tavg epoch acc = 0.9342\n","training took 28.01 s\n","Avg test loss = 0.631\tAvg test acc = 0.921\n","epoch 0\tavg epoch loss = 0.7742\tavg epoch acc = 0.9195\n","epoch 1\tavg epoch loss = 0.6805\tavg epoch acc = 0.9565\n","epoch 2\tavg epoch loss = 0.6567\tavg epoch acc = 0.9568\n","epoch 3\tavg epoch loss = 0.6914\tavg epoch acc = 0.9539\n","epoch 4\tavg epoch loss = 0.6763\tavg epoch acc = 0.9522\n","epoch 5\tavg epoch loss = 0.7111\tavg epoch acc = 0.9508\n","epoch 6\tavg epoch loss = 0.6628\tavg epoch acc = 0.9494\n","epoch 7\tavg epoch loss = 0.7039\tavg epoch acc = 0.9462\n","epoch 8\tavg epoch loss = 0.7555\tavg epoch acc = 0.942\n","epoch 9\tavg epoch loss = 0.7335\tavg epoch acc = 0.9411\n","training took 27.91 s\n","Avg test loss = 0.557\tAvg test acc = 0.868\n","epoch 0\tavg epoch loss = 0.7374\tavg epoch acc = 0.9257\n","epoch 1\tavg epoch loss = 0.6747\tavg epoch acc = 0.9583\n","epoch 2\tavg epoch loss = 0.7304\tavg epoch acc = 0.9554\n","epoch 3\tavg epoch loss = 0.7346\tavg epoch acc = 0.9504\n","epoch 4\tavg epoch loss = 0.7426\tavg epoch acc = 0.9479\n","epoch 5\tavg epoch loss = 0.6828\tavg epoch acc = 0.9497\n","epoch 6\tavg epoch loss = 0.7757\tavg epoch acc = 0.9446\n","epoch 7\tavg epoch loss = 0.798\tavg epoch acc = 0.9436\n","epoch 8\tavg epoch loss = 0.855\tavg epoch acc = 0.9343\n","epoch 9\tavg epoch loss = 0.7485\tavg epoch acc = 0.9315\n","training took 28.05 s\n","Avg test loss = 0.473\tAvg test acc = 0.932\n","{'lr': 0.01, 'beta1': 0.1, 'beta2': 0.5, 'batch_size': 64, 'weight_decay': 0.1, 'epsilon': 1e-10}\n","epoch 0\tavg epoch loss = 0.7319\tavg epoch acc = 0.9197\n","epoch 1\tavg epoch loss = 0.6098\tavg epoch acc = 0.9565\n","epoch 2\tavg epoch loss = 0.6\tavg epoch acc = 0.957\n","epoch 3\tavg epoch loss = 0.5599\tavg epoch acc = 0.9575\n","epoch 4\tavg epoch loss = 0.5341\tavg epoch acc = 0.9579\n","epoch 5\tavg epoch loss = 0.5324\tavg epoch acc = 0.9586\n","epoch 6\tavg epoch loss = 0.5453\tavg epoch acc = 0.9597\n","epoch 7\tavg epoch loss = 0.5408\tavg epoch acc = 0.9607\n","epoch 8\tavg epoch loss = 0.5294\tavg epoch acc = 0.9595\n","epoch 9\tavg epoch loss = 0.5383\tavg epoch acc = 0.959\n","training took 28.04 s\n","Avg test loss = 0.353\tAvg test acc = 0.895\n","epoch 0\tavg epoch loss = 0.7559\tavg epoch acc = 0.9173\n","epoch 1\tavg epoch loss = 0.5841\tavg epoch acc = 0.9538\n","epoch 2\tavg epoch loss = 0.5389\tavg epoch acc = 0.954\n","epoch 3\tavg epoch loss = 0.5285\tavg epoch acc = 0.9568\n","epoch 4\tavg epoch loss = 0.5073\tavg epoch acc = 0.9584\n","epoch 5\tavg epoch loss = 0.5113\tavg epoch acc = 0.9595\n","epoch 6\tavg epoch loss = 0.503\tavg epoch acc = 0.9589\n","epoch 7\tavg epoch loss = 0.5176\tavg epoch acc = 0.9583\n","epoch 8\tavg epoch loss = 0.513\tavg epoch acc = 0.958\n","epoch 9\tavg epoch loss = 0.4944\tavg epoch acc = 0.9582\n","training took 28.36 s\n","Avg test loss = 0.256\tAvg test acc = 0.929\n","epoch 0\tavg epoch loss = 0.7656\tavg epoch acc = 0.9171\n","epoch 1\tavg epoch loss = 0.5853\tavg epoch acc = 0.9542\n","epoch 2\tavg epoch loss = 0.5546\tavg epoch acc = 0.9558\n","epoch 3\tavg epoch loss = 0.5363\tavg epoch acc = 0.9564\n","epoch 4\tavg epoch loss = 0.5375\tavg epoch acc = 0.9579\n","epoch 5\tavg epoch loss = 0.5313\tavg epoch acc = 0.9581\n","epoch 6\tavg epoch loss = 0.5361\tavg epoch acc = 0.9587\n","epoch 7\tavg epoch loss = 0.5387\tavg epoch acc = 0.959\n","epoch 8\tavg epoch loss = 0.529\tavg epoch acc = 0.9595\n","epoch 9\tavg epoch loss = 0.5186\tavg epoch acc = 0.9581\n","training took 28.15 s\n","Avg test loss = 0.21\tAvg test acc = 0.936\n","{'lr': 0.01, 'beta1': 0.1, 'beta2': 0.5, 'batch_size': 64, 'weight_decay': 0.1, 'epsilon': 1e-08}\n","epoch 0\tavg epoch loss = 0.7491\tavg epoch acc = 0.9183\n","epoch 1\tavg epoch loss = 0.625\tavg epoch acc = 0.9561\n","epoch 2\tavg epoch loss = 0.6074\tavg epoch acc = 0.9568\n","epoch 3\tavg epoch loss = 0.5832\tavg epoch acc = 0.9576\n","epoch 4\tavg epoch loss = 0.5629\tavg epoch acc = 0.9571\n","epoch 5\tavg epoch loss = 0.55\tavg epoch acc = 0.958\n","epoch 6\tavg epoch loss = 0.5542\tavg epoch acc = 0.9579\n","epoch 7\tavg epoch loss = 0.5464\tavg epoch acc = 0.9576\n","epoch 8\tavg epoch loss = 0.5516\tavg epoch acc = 0.9574\n","epoch 9\tavg epoch loss = 0.5558\tavg epoch acc = 0.9578\n","training took 28.13 s\n","Avg test loss = 0.23\tAvg test acc = 0.934\n","epoch 0\tavg epoch loss = 0.7653\tavg epoch acc = 0.9163\n","epoch 1\tavg epoch loss = 0.6355\tavg epoch acc = 0.9545\n","epoch 2\tavg epoch loss = 0.6091\tavg epoch acc = 0.9551\n","epoch 3\tavg epoch loss = 0.5514\tavg epoch acc = 0.9554\n","epoch 4\tavg epoch loss = 0.5627\tavg epoch acc = 0.9564\n","epoch 5\tavg epoch loss = 0.552\tavg epoch acc = 0.9568\n","epoch 6\tavg epoch loss = 0.5474\tavg epoch acc = 0.9584\n","epoch 7\tavg epoch loss = 0.5523\tavg epoch acc = 0.9571\n","epoch 8\tavg epoch loss = 0.5506\tavg epoch acc = 0.9575\n","epoch 9\tavg epoch loss = 0.5465\tavg epoch acc = 0.9578\n","training took 28.1 s\n","Avg test loss = 0.257\tAvg test acc = 0.92\n","epoch 0\tavg epoch loss = 0.7557\tavg epoch acc = 0.9157\n","epoch 1\tavg epoch loss = 0.6347\tavg epoch acc = 0.9572\n","epoch 2\tavg epoch loss = 0.625\tavg epoch acc = 0.9537\n","epoch 3\tavg epoch loss = 0.6071\tavg epoch acc = 0.9529\n","epoch 4\tavg epoch loss = 0.5626\tavg epoch acc = 0.9553\n","epoch 5\tavg epoch loss = 0.5636\tavg epoch acc = 0.954\n","epoch 6\tavg epoch loss = 0.5496\tavg epoch acc = 0.9553\n","epoch 7\tavg epoch loss = 0.547\tavg epoch acc = 0.9548\n","epoch 8\tavg epoch loss = 0.5191\tavg epoch acc = 0.9559\n","epoch 9\tavg epoch loss = 0.5337\tavg epoch acc = 0.9545\n","training took 28.14 s\n","Avg test loss = 0.255\tAvg test acc = 0.928\n","{'lr': 0.01, 'beta1': 0.1, 'beta2': 0.5, 'batch_size': 128, 'weight_decay': 0.001, 'epsilon': 1e-10}\n","epoch 0\tavg epoch loss = 0.7314\tavg epoch acc = 0.9011\n","epoch 1\tavg epoch loss = 0.4911\tavg epoch acc = 0.9688\n","epoch 2\tavg epoch loss = 0.4988\tavg epoch acc = 0.9723\n","epoch 3\tavg epoch loss = 0.5371\tavg epoch acc = 0.9711\n","epoch 4\tavg epoch loss = 0.5253\tavg epoch acc = 0.9689\n","epoch 5\tavg epoch loss = 0.5637\tavg epoch acc = 0.965\n","epoch 6\tavg epoch loss = 0.5506\tavg epoch acc = 0.9639\n","epoch 7\tavg epoch loss = 0.5153\tavg epoch acc = 0.9651\n","epoch 8\tavg epoch loss = 0.5265\tavg epoch acc = 0.9654\n","epoch 9\tavg epoch loss = 0.5338\tavg epoch acc = 0.965\n","training took 17.41 s\n","Avg test loss = 0.238\tAvg test acc = 0.94\n","epoch 0\tavg epoch loss = 0.7552\tavg epoch acc = 0.9008\n","epoch 1\tavg epoch loss = 0.5133\tavg epoch acc = 0.9674\n","epoch 2\tavg epoch loss = 0.514\tavg epoch acc = 0.9691\n","epoch 3\tavg epoch loss = 0.5336\tavg epoch acc = 0.9684\n","epoch 4\tavg epoch loss = 0.4776\tavg epoch acc = 0.9688\n","epoch 5\tavg epoch loss = 0.4745\tavg epoch acc = 0.9689\n","epoch 6\tavg epoch loss = 0.5319\tavg epoch acc = 0.9684\n","epoch 7\tavg epoch loss = 0.5532\tavg epoch acc = 0.9694\n","epoch 8\tavg epoch loss = 0.5886\tavg epoch acc = 0.9679\n","epoch 9\tavg epoch loss = 0.597\tavg epoch acc = 0.9686\n","training took 17.34 s\n","Avg test loss = 0.455\tAvg test acc = 0.924\n","epoch 0\tavg epoch loss = 0.7266\tavg epoch acc = 0.9054\n","epoch 1\tavg epoch loss = 0.4936\tavg epoch acc = 0.9666\n","epoch 2\tavg epoch loss = 0.5292\tavg epoch acc = 0.9683\n","epoch 3\tavg epoch loss = 0.5387\tavg epoch acc = 0.9694\n","epoch 4\tavg epoch loss = 0.5407\tavg epoch acc = 0.9692\n","epoch 5\tavg epoch loss = 0.5596\tavg epoch acc = 0.9682\n","epoch 6\tavg epoch loss = 0.519\tavg epoch acc = 0.9691\n","epoch 7\tavg epoch loss = 0.5483\tavg epoch acc = 0.9681\n","epoch 8\tavg epoch loss = 0.5516\tavg epoch acc = 0.9669\n","epoch 9\tavg epoch loss = 0.5444\tavg epoch acc = 0.966\n","training took 17.33 s\n","Avg test loss = 0.391\tAvg test acc = 0.904\n","{'lr': 0.01, 'beta1': 0.1, 'beta2': 0.5, 'batch_size': 128, 'weight_decay': 0.001, 'epsilon': 1e-08}\n","epoch 0\tavg epoch loss = 0.7483\tavg epoch acc = 0.9014\n","epoch 1\tavg epoch loss = 0.4973\tavg epoch acc = 0.9685\n","epoch 2\tavg epoch loss = 0.5234\tavg epoch acc = 0.97\n","epoch 3\tavg epoch loss = 0.5492\tavg epoch acc = 0.9679\n","epoch 4\tavg epoch loss = 0.5554\tavg epoch acc = 0.9667\n","epoch 5\tavg epoch loss = 0.5531\tavg epoch acc = 0.9666\n","epoch 6\tavg epoch loss = 0.5511\tavg epoch acc = 0.9672\n","epoch 7\tavg epoch loss = 0.5643\tavg epoch acc = 0.9674\n","epoch 8\tavg epoch loss = 0.5339\tavg epoch acc = 0.9667\n","epoch 9\tavg epoch loss = 0.565\tavg epoch acc = 0.9667\n","training took 17.33 s\n","Avg test loss = 0.423\tAvg test acc = 0.929\n","epoch 0\tavg epoch loss = 0.7407\tavg epoch acc = 0.9025\n","epoch 1\tavg epoch loss = 0.5002\tavg epoch acc = 0.9684\n","epoch 2\tavg epoch loss = 0.5054\tavg epoch acc = 0.9704\n","epoch 3\tavg epoch loss = 0.5214\tavg epoch acc = 0.9713\n","epoch 4\tavg epoch loss = 0.5456\tavg epoch acc = 0.9693\n","epoch 5\tavg epoch loss = 0.5527\tavg epoch acc = 0.9705\n","epoch 6\tavg epoch loss = 0.587\tavg epoch acc = 0.9697\n","epoch 7\tavg epoch loss = 0.5538\tavg epoch acc = 0.9708\n","epoch 8\tavg epoch loss = 0.5626\tavg epoch acc = 0.9697\n","epoch 9\tavg epoch loss = 0.5737\tavg epoch acc = 0.9692\n","training took 17.33 s\n","Avg test loss = 0.205\tAvg test acc = 0.955\n","epoch 0\tavg epoch loss = 0.7566\tavg epoch acc = 0.8966\n","epoch 1\tavg epoch loss = 0.4946\tavg epoch acc = 0.9675\n","epoch 2\tavg epoch loss = 0.4908\tavg epoch acc = 0.9693\n","epoch 3\tavg epoch loss = 0.5012\tavg epoch acc = 0.9688\n","epoch 4\tavg epoch loss = 0.5409\tavg epoch acc = 0.9703\n","epoch 5\tavg epoch loss = 0.5216\tavg epoch acc = 0.9698\n","epoch 6\tavg epoch loss = 0.5164\tavg epoch acc = 0.9687\n","epoch 7\tavg epoch loss = 0.5471\tavg epoch acc = 0.97\n","epoch 8\tavg epoch loss = 0.5363\tavg epoch acc = 0.9678\n","epoch 9\tavg epoch loss = 0.5435\tavg epoch acc = 0.9673\n","training took 17.33 s\n","Avg test loss = 0.232\tAvg test acc = 0.94\n","{'lr': 0.01, 'beta1': 0.1, 'beta2': 0.5, 'batch_size': 128, 'weight_decay': 0.1, 'epsilon': 1e-10}\n","epoch 0\tavg epoch loss = 0.729\tavg epoch acc = 0.9047\n","epoch 1\tavg epoch loss = 0.4816\tavg epoch acc = 0.9653\n","epoch 2\tavg epoch loss = 0.4837\tavg epoch acc = 0.9699\n","epoch 3\tavg epoch loss = 0.4815\tavg epoch acc = 0.9699\n","epoch 4\tavg epoch loss = 0.4771\tavg epoch acc = 0.9688\n","epoch 5\tavg epoch loss = 0.4668\tavg epoch acc = 0.9698\n","epoch 6\tavg epoch loss = 0.4516\tavg epoch acc = 0.9709\n","epoch 7\tavg epoch loss = 0.4521\tavg epoch acc = 0.9697\n","epoch 8\tavg epoch loss = 0.4535\tavg epoch acc = 0.9691\n","epoch 9\tavg epoch loss = 0.45\tavg epoch acc = 0.9691\n","training took 17.29 s\n","Avg test loss = 0.138\tAvg test acc = 0.958\n","epoch 0\tavg epoch loss = 0.7296\tavg epoch acc = 0.9024\n","epoch 1\tavg epoch loss = 0.4824\tavg epoch acc = 0.9658\n","epoch 2\tavg epoch loss = 0.489\tavg epoch acc = 0.9675\n","epoch 3\tavg epoch loss = 0.4713\tavg epoch acc = 0.9686\n","epoch 4\tavg epoch loss = 0.4708\tavg epoch acc = 0.966\n","epoch 5\tavg epoch loss = 0.4707\tavg epoch acc = 0.9672\n","epoch 6\tavg epoch loss = 0.465\tavg epoch acc = 0.9675\n","epoch 7\tavg epoch loss = 0.4586\tavg epoch acc = 0.9683\n","epoch 8\tavg epoch loss = 0.4603\tavg epoch acc = 0.9675\n","epoch 9\tavg epoch loss = 0.4415\tavg epoch acc = 0.9669\n","training took 17.28 s\n","Avg test loss = 0.225\tAvg test acc = 0.961\n","epoch 0\tavg epoch loss = 0.7327\tavg epoch acc = 0.9017\n","epoch 1\tavg epoch loss = 0.4873\tavg epoch acc = 0.9634\n","epoch 2\tavg epoch loss = 0.4856\tavg epoch acc = 0.9673\n","epoch 3\tavg epoch loss = 0.4748\tavg epoch acc = 0.9667\n","epoch 4\tavg epoch loss = 0.48\tavg epoch acc = 0.968\n","epoch 5\tavg epoch loss = 0.4693\tavg epoch acc = 0.9691\n","epoch 6\tavg epoch loss = 0.4612\tavg epoch acc = 0.9697\n","epoch 7\tavg epoch loss = 0.4652\tavg epoch acc = 0.97\n","epoch 8\tavg epoch loss = 0.4725\tavg epoch acc = 0.9685\n","epoch 9\tavg epoch loss = 0.4717\tavg epoch acc = 0.9692\n","training took 17.27 s\n","Avg test loss = 0.263\tAvg test acc = 0.912\n","{'lr': 0.01, 'beta1': 0.1, 'beta2': 0.5, 'batch_size': 128, 'weight_decay': 0.1, 'epsilon': 1e-08}\n","epoch 0\tavg epoch loss = 0.7194\tavg epoch acc = 0.901\n","epoch 1\tavg epoch loss = 0.4802\tavg epoch acc = 0.9662\n","epoch 2\tavg epoch loss = 0.448\tavg epoch acc = 0.9695\n","epoch 3\tavg epoch loss = 0.4469\tavg epoch acc = 0.9695\n","epoch 4\tavg epoch loss = 0.4307\tavg epoch acc = 0.9697\n","epoch 5\tavg epoch loss = 0.4231\tavg epoch acc = 0.9687\n","epoch 6\tavg epoch loss = 0.4042\tavg epoch acc = 0.9707\n","epoch 7\tavg epoch loss = 0.422\tavg epoch acc = 0.9716\n","epoch 8\tavg epoch loss = 0.4091\tavg epoch acc = 0.9718\n","epoch 9\tavg epoch loss = 0.4148\tavg epoch acc = 0.9717\n","training took 17.37 s\n","Avg test loss = 0.163\tAvg test acc = 0.959\n","epoch 0\tavg epoch loss = 0.7372\tavg epoch acc = 0.9019\n","epoch 1\tavg epoch loss = 0.4842\tavg epoch acc = 0.9647\n","epoch 2\tavg epoch loss = 0.4796\tavg epoch acc = 0.9684\n","epoch 3\tavg epoch loss = 0.4489\tavg epoch acc = 0.9691\n","epoch 4\tavg epoch loss = 0.46\tavg epoch acc = 0.9692\n","epoch 5\tavg epoch loss = 0.4454\tavg epoch acc = 0.97\n","epoch 6\tavg epoch loss = 0.4354\tavg epoch acc = 0.9698\n","epoch 7\tavg epoch loss = 0.4236\tavg epoch acc = 0.9698\n","epoch 8\tavg epoch loss = 0.4248\tavg epoch acc = 0.9692\n","epoch 9\tavg epoch loss = 0.4193\tavg epoch acc = 0.9696\n","training took 17.38 s\n","Avg test loss = 0.38\tAvg test acc = 0.89\n","epoch 0\tavg epoch loss = 0.7234\tavg epoch acc = 0.9065\n","epoch 1\tavg epoch loss = 0.4778\tavg epoch acc = 0.966\n","epoch 2\tavg epoch loss = 0.4616\tavg epoch acc = 0.9688\n","epoch 3\tavg epoch loss = 0.47\tavg epoch acc = 0.9678\n","epoch 4\tavg epoch loss = 0.4466\tavg epoch acc = 0.9698\n","epoch 5\tavg epoch loss = 0.4532\tavg epoch acc = 0.9693\n","epoch 6\tavg epoch loss = 0.4512\tavg epoch acc = 0.968\n","epoch 7\tavg epoch loss = 0.4337\tavg epoch acc = 0.9706\n","epoch 8\tavg epoch loss = 0.4386\tavg epoch acc = 0.9694\n","epoch 9\tavg epoch loss = 0.4423\tavg epoch acc = 0.9693\n","training took 17.4 s\n","Avg test loss = 0.212\tAvg test acc = 0.948\n","{'lr': 0.01, 'beta1': 0.1, 'beta2': 0.999, 'batch_size': 32, 'weight_decay': 0.001, 'epsilon': 1e-10}\n","epoch 0\tavg epoch loss = 0.5708\tavg epoch acc = 0.9234\n","epoch 1\tavg epoch loss = 1.365\tavg epoch acc = 0.5633\n","epoch 2\tavg epoch loss = 2.315\tavg epoch acc = 0.112\n","epoch 3\tavg epoch loss = 2.312\tavg epoch acc = 0.111\n","epoch 4\tavg epoch loss = 2.303\tavg epoch acc = 0.1118\n","epoch 5\tavg epoch loss = 2.303\tavg epoch acc = 0.1116\n","epoch 6\tavg epoch loss = 2.303\tavg epoch acc = 0.1116\n","epoch 7\tavg epoch loss = 2.303\tavg epoch acc = 0.1118\n","epoch 8\tavg epoch loss = 2.303\tavg epoch acc = 0.1118\n","epoch 9\tavg epoch loss = 2.303\tavg epoch acc = 0.1118\n","training took 54.99 s\n","Avg test loss = 2.3\tAvg test acc = 0.105\n","epoch 0\tavg epoch loss = 0.5861\tavg epoch acc = 0.9223\n","epoch 1\tavg epoch loss = 1.978\tavg epoch acc = 0.2797\n","epoch 2\tavg epoch loss = 2.304\tavg epoch acc = 0.1093\n","epoch 3\tavg epoch loss = 2.303\tavg epoch acc = 0.1085\n","epoch 4\tavg epoch loss = 2.303\tavg epoch acc = 0.1087\n","epoch 5\tavg epoch loss = 2.303\tavg epoch acc = 0.1088\n","epoch 6\tavg epoch loss = 2.303\tavg epoch acc = 0.1088\n","epoch 7\tavg epoch loss = 2.303\tavg epoch acc = 0.1088\n","epoch 8\tavg epoch loss = 2.303\tavg epoch acc = 0.1088\n","epoch 9\tavg epoch loss = 2.303\tavg epoch acc = 0.1088\n","training took 55.43 s\n","Avg test loss = 2.3\tAvg test acc = 0.103\n","epoch 0\tavg epoch loss = 0.574\tavg epoch acc = 0.9252\n","epoch 1\tavg epoch loss = 1.591\tavg epoch acc = 0.5546\n","epoch 2\tavg epoch loss = 1.951\tavg epoch acc = 0.3038\n","epoch 3\tavg epoch loss = 2.304\tavg epoch acc = 0.1076\n","epoch 4\tavg epoch loss = 2.303\tavg epoch acc = 0.11\n","epoch 5\tavg epoch loss = 2.303\tavg epoch acc = 0.11\n","epoch 6\tavg epoch loss = 2.303\tavg epoch acc = 0.11\n","epoch 7\tavg epoch loss = 2.303\tavg epoch acc = 0.11\n","epoch 8\tavg epoch loss = 2.303\tavg epoch acc = 0.11\n","epoch 9\tavg epoch loss = 2.303\tavg epoch acc = 0.11\n","training took 54.26 s\n","Avg test loss = 2.3\tAvg test acc = 0.104\n","{'lr': 0.01, 'beta1': 0.1, 'beta2': 0.999, 'batch_size': 32, 'weight_decay': 0.001, 'epsilon': 1e-08}\n","epoch 0\tavg epoch loss = 0.5773\tavg epoch acc = 0.9245\n","epoch 1\tavg epoch loss = 0.5895\tavg epoch acc = 0.9541\n","epoch 2\tavg epoch loss = 2.335\tavg epoch acc = 0.1257\n","epoch 3\tavg epoch loss = 2.303\tavg epoch acc = 0.1109\n","epoch 4\tavg epoch loss = 2.303\tavg epoch acc = 0.1108\n","epoch 5\tavg epoch loss = 2.303\tavg epoch acc = 0.1107\n","epoch 6\tavg epoch loss = 2.303\tavg epoch acc = 0.1107\n","epoch 7\tavg epoch loss = 2.303\tavg epoch acc = 0.1107\n","epoch 8\tavg epoch loss = 2.303\tavg epoch acc = 0.1107\n","epoch 9\tavg epoch loss = 2.303\tavg epoch acc = 0.1107\n","training took 54.18 s\n","Avg test loss = 2.3\tAvg test acc = 0.111\n","epoch 0\tavg epoch loss = 0.5694\tavg epoch acc = 0.9253\n","epoch 1\tavg epoch loss = 0.4832\tavg epoch acc = 0.9596\n","epoch 2\tavg epoch loss = 1.986\tavg epoch acc = 0.3185\n","epoch 3\tavg epoch loss = 2.306\tavg epoch acc = 0.1079\n","epoch 4\tavg epoch loss = 2.305\tavg epoch acc = 0.1092\n","epoch 5\tavg epoch loss = 2.303\tavg epoch acc = 0.1089\n","epoch 6\tavg epoch loss = 2.303\tavg epoch acc = 0.1089\n","epoch 7\tavg epoch loss = 2.303\tavg epoch acc = 0.1088\n","epoch 8\tavg epoch loss = 2.303\tavg epoch acc = 0.1089\n","epoch 9\tavg epoch loss = 2.303\tavg epoch acc = 0.1089\n","training took 54.16 s\n","Avg test loss = 2.3\tAvg test acc = 0.101\n","epoch 0\tavg epoch loss = 0.5736\tavg epoch acc = 0.9228\n","epoch 1\tavg epoch loss = 0.5327\tavg epoch acc = 0.9498\n","epoch 2\tavg epoch loss = 0.7388\tavg epoch acc = 0.8824\n","epoch 3\tavg epoch loss = 2.341\tavg epoch acc = 0.1078\n","epoch 4\tavg epoch loss = 2.303\tavg epoch acc = 0.1098\n","epoch 5\tavg epoch loss = 2.302\tavg epoch acc = 0.1114\n","epoch 6\tavg epoch loss = 2.302\tavg epoch acc = 0.1116\n","epoch 7\tavg epoch loss = 2.302\tavg epoch acc = 0.1116\n","epoch 8\tavg epoch loss = 2.302\tavg epoch acc = 0.1116\n","epoch 9\tavg epoch loss = 2.302\tavg epoch acc = 0.1116\n","training took 54.32 s\n","Avg test loss = 2.3\tAvg test acc = 0.104\n","{'lr': 0.01, 'beta1': 0.1, 'beta2': 0.999, 'batch_size': 32, 'weight_decay': 0.1, 'epsilon': 1e-10}\n","epoch 0\tavg epoch loss = 0.5963\tavg epoch acc = 0.9201\n","epoch 1\tavg epoch loss = 0.935\tavg epoch acc = 0.8992\n","epoch 2\tavg epoch loss = 2.808\tavg epoch acc = 0.3175\n","epoch 3\tavg epoch loss = 2.302\tavg epoch acc = 0.1091\n","epoch 4\tavg epoch loss = 2.302\tavg epoch acc = 0.1087\n","epoch 5\tavg epoch loss = 2.302\tavg epoch acc = 0.1087\n","epoch 6\tavg epoch loss = 2.302\tavg epoch acc = 0.1087\n","epoch 7\tavg epoch loss = 2.302\tavg epoch acc = 0.1087\n","epoch 8\tavg epoch loss = 2.302\tavg epoch acc = 0.1087\n","epoch 9\tavg epoch loss = 2.302\tavg epoch acc = 0.1087\n","training took 54.15 s\n","Avg test loss = 2.3\tAvg test acc = 0.105\n","epoch 0\tavg epoch loss = 0.5765\tavg epoch acc = 0.923\n","epoch 1\tavg epoch loss = 1.936\tavg epoch acc = 0.2891\n","epoch 2\tavg epoch loss = 2.302\tavg epoch acc = 0.1106\n","epoch 3\tavg epoch loss = 2.303\tavg epoch acc = 0.1101\n","epoch 4\tavg epoch loss = 2.303\tavg epoch acc = 0.1103\n","epoch 5\tavg epoch loss = 2.303\tavg epoch acc = 0.1104\n","epoch 6\tavg epoch loss = 2.303\tavg epoch acc = 0.1104\n","epoch 7\tavg epoch loss = 2.303\tavg epoch acc = 0.1104\n","epoch 8\tavg epoch loss = 2.303\tavg epoch acc = 0.1104\n","epoch 9\tavg epoch loss = 2.303\tavg epoch acc = 0.1104\n","training took 53.96 s\n","Avg test loss = 2.3\tAvg test acc = 0.105\n","epoch 0\tavg epoch loss = 0.5702\tavg epoch acc = 0.9256\n","epoch 1\tavg epoch loss = 1.245\tavg epoch acc = 0.6126\n","epoch 2\tavg epoch loss = 2.303\tavg epoch acc = 0.1101\n","epoch 3\tavg epoch loss = 2.303\tavg epoch acc = 0.1093\n","epoch 4\tavg epoch loss = 2.303\tavg epoch acc = 0.1094\n","epoch 5\tavg epoch loss = 2.303\tavg epoch acc = 0.1094\n","epoch 6\tavg epoch loss = 2.303\tavg epoch acc = 0.1095\n","epoch 7\tavg epoch loss = 2.303\tavg epoch acc = 0.1095\n","epoch 8\tavg epoch loss = 2.303\tavg epoch acc = 0.1095\n","epoch 9\tavg epoch loss = 2.303\tavg epoch acc = 0.1095\n","training took 54.15 s\n","Avg test loss = 2.3\tAvg test acc = 0.104\n","{'lr': 0.01, 'beta1': 0.1, 'beta2': 0.999, 'batch_size': 32, 'weight_decay': 0.1, 'epsilon': 1e-08}\n","epoch 0\tavg epoch loss = 0.6186\tavg epoch acc = 0.9089\n","epoch 1\tavg epoch loss = 2.308\tavg epoch acc = 0.1132\n","epoch 2\tavg epoch loss = 2.303\tavg epoch acc = 0.1116\n","epoch 3\tavg epoch loss = 2.303\tavg epoch acc = 0.1111\n","epoch 4\tavg epoch loss = 2.303\tavg epoch acc = 0.1112\n","epoch 5\tavg epoch loss = 2.303\tavg epoch acc = 0.1112\n","epoch 6\tavg epoch loss = 2.303\tavg epoch acc = 0.1112\n","epoch 7\tavg epoch loss = 2.303\tavg epoch acc = 0.1112\n","epoch 8\tavg epoch loss = 2.303\tavg epoch acc = 0.1112\n","epoch 9\tavg epoch loss = 2.303\tavg epoch acc = 0.1112\n","training took 54.45 s\n","Avg test loss = 2.3\tAvg test acc = 0.103\n","epoch 0\tavg epoch loss = 0.5907\tavg epoch acc = 0.9219\n","epoch 1\tavg epoch loss = 0.5326\tavg epoch acc = 0.9449\n","epoch 2\tavg epoch loss = 1.741\tavg epoch acc = 0.8135\n","epoch 3\tavg epoch loss = 2.303\tavg epoch acc = 0.1093\n","epoch 4\tavg epoch loss = 2.303\tavg epoch acc = 0.1098\n","epoch 5\tavg epoch loss = 2.303\tavg epoch acc = 0.1096\n","epoch 6\tavg epoch loss = 2.303\tavg epoch acc = 0.1096\n","epoch 7\tavg epoch loss = 2.303\tavg epoch acc = 0.1096\n","epoch 8\tavg epoch loss = 2.303\tavg epoch acc = 0.1096\n","epoch 9\tavg epoch loss = 2.303\tavg epoch acc = 0.1096\n","training took 54.68 s\n","Avg test loss = 2.3\tAvg test acc = 0.107\n","epoch 0\tavg epoch loss = 0.732\tavg epoch acc = 0.877\n","epoch 1\tavg epoch loss = 0.8899\tavg epoch acc = 0.8064\n","epoch 2\tavg epoch loss = 1.897\tavg epoch acc = 0.736\n","epoch 3\tavg epoch loss = 2.303\tavg epoch acc = 0.1081\n","epoch 4\tavg epoch loss = 2.303\tavg epoch acc = 0.1082\n","epoch 5\tavg epoch loss = 2.303\tavg epoch acc = 0.1082\n","epoch 6\tavg epoch loss = 2.303\tavg epoch acc = 0.1082\n","epoch 7\tavg epoch loss = 2.303\tavg epoch acc = 0.1082\n","epoch 8\tavg epoch loss = 2.303\tavg epoch acc = 0.1082\n","epoch 9\tavg epoch loss = 2.303\tavg epoch acc = 0.1082\n","training took 54.35 s\n","Avg test loss = 2.3\tAvg test acc = 0.103\n","{'lr': 0.01, 'beta1': 0.1, 'beta2': 0.999, 'batch_size': 64, 'weight_decay': 0.001, 'epsilon': 1e-10}\n","epoch 0\tavg epoch loss = 0.675\tavg epoch acc = 0.9012\n","epoch 1\tavg epoch loss = 0.3191\tavg epoch acc = 0.9732\n","epoch 2\tavg epoch loss = 1.448\tavg epoch acc = 0.6039\n","epoch 3\tavg epoch loss = 0.4113\tavg epoch acc = 0.9631\n","epoch 4\tavg epoch loss = 0.3355\tavg epoch acc = 0.9732\n","epoch 5\tavg epoch loss = 0.3218\tavg epoch acc = 0.9777\n","epoch 6\tavg epoch loss = 0.3579\tavg epoch acc = 0.9754\n","epoch 7\tavg epoch loss = 0.3438\tavg epoch acc = 0.9763\n","epoch 8\tavg epoch loss = 0.2601\tavg epoch acc = 0.983\n","epoch 9\tavg epoch loss = 2.031\tavg epoch acc = 0.3006\n","training took 28.58 s\n","Avg test loss = 2.3\tAvg test acc = 0.105\n","epoch 0\tavg epoch loss = 0.6562\tavg epoch acc = 0.9009\n","epoch 1\tavg epoch loss = 0.5896\tavg epoch acc = 0.8833\n","epoch 2\tavg epoch loss = 0.5434\tavg epoch acc = 0.9214\n","epoch 3\tavg epoch loss = 1.93\tavg epoch acc = 0.2888\n","epoch 4\tavg epoch loss = 2.302\tavg epoch acc = 0.1094\n","epoch 5\tavg epoch loss = 2.302\tavg epoch acc = 0.1105\n","epoch 6\tavg epoch loss = 2.302\tavg epoch acc = 0.1104\n","epoch 7\tavg epoch loss = 2.302\tavg epoch acc = 0.1102\n","epoch 8\tavg epoch loss = 2.302\tavg epoch acc = 0.1102\n","epoch 9\tavg epoch loss = 2.302\tavg epoch acc = 0.1103\n","training took 28.57 s\n","Avg test loss = 2.3\tAvg test acc = 0.113\n","epoch 0\tavg epoch loss = 0.6805\tavg epoch acc = 0.8984\n","epoch 1\tavg epoch loss = 0.3051\tavg epoch acc = 0.9751\n","epoch 2\tavg epoch loss = 0.682\tavg epoch acc = 0.9392\n","epoch 3\tavg epoch loss = 1.214\tavg epoch acc = 0.651\n","epoch 4\tavg epoch loss = 0.6811\tavg epoch acc = 0.9015\n","epoch 5\tavg epoch loss = 0.4244\tavg epoch acc = 0.9618\n","epoch 6\tavg epoch loss = 0.3324\tavg epoch acc = 0.9738\n","epoch 7\tavg epoch loss = 1.372\tavg epoch acc = 0.7478\n","epoch 8\tavg epoch loss = 2.307\tavg epoch acc = 0.105\n","epoch 9\tavg epoch loss = 2.303\tavg epoch acc = 0.107\n","training took 28.43 s\n","Avg test loss = 2.31\tAvg test acc = 0.104\n","{'lr': 0.01, 'beta1': 0.1, 'beta2': 0.999, 'batch_size': 64, 'weight_decay': 0.001, 'epsilon': 1e-08}\n","epoch 0\tavg epoch loss = 0.6771\tavg epoch acc = 0.8974\n","epoch 1\tavg epoch loss = 0.3197\tavg epoch acc = 0.9726\n","epoch 2\tavg epoch loss = 2.287\tavg epoch acc = 0.4492\n","epoch 3\tavg epoch loss = 2.305\tavg epoch acc = 0.1333\n","epoch 4\tavg epoch loss = 2.08\tavg epoch acc = 0.3103\n","epoch 5\tavg epoch loss = 0.7139\tavg epoch acc = 0.9003\n","epoch 6\tavg epoch loss = 0.4594\tavg epoch acc = 0.9542\n","epoch 7\tavg epoch loss = 0.4038\tavg epoch acc = 0.9616\n","epoch 8\tavg epoch loss = 0.4283\tavg epoch acc = 0.9587\n","epoch 9\tavg epoch loss = 0.3535\tavg epoch acc = 0.9657\n","training took 28.66 s\n","Avg test loss = 0.185\tAvg test acc = 0.945\n","epoch 0\tavg epoch loss = 0.7049\tavg epoch acc = 0.8962\n","epoch 1\tavg epoch loss = 0.298\tavg epoch acc = 0.9757\n","epoch 2\tavg epoch loss = 1.155\tavg epoch acc = 0.9314\n","epoch 3\tavg epoch loss = 0.3457\tavg epoch acc = 0.9688\n","epoch 4\tavg epoch loss = 0.3152\tavg epoch acc = 0.9768\n","epoch 5\tavg epoch loss = 0.2982\tavg epoch acc = 0.9788\n","epoch 6\tavg epoch loss = 0.3357\tavg epoch acc = 0.9778\n","epoch 7\tavg epoch loss = 3.684\tavg epoch acc = 0.6551\n","epoch 8\tavg epoch loss = 0.6351\tavg epoch acc = 0.9401\n","epoch 9\tavg epoch loss = 0.4126\tavg epoch acc = 0.9656\n","training took 28.54 s\n","Avg test loss = 0.211\tAvg test acc = 0.933\n","epoch 0\tavg epoch loss = 0.6621\tavg epoch acc = 0.9024\n","epoch 1\tavg epoch loss = 0.3062\tavg epoch acc = 0.9737\n","epoch 2\tavg epoch loss = 2.177\tavg epoch acc = 0.297\n","epoch 3\tavg epoch loss = 2.305\tavg epoch acc = 0.1168\n","epoch 4\tavg epoch loss = 2.303\tavg epoch acc = 0.1129\n","epoch 5\tavg epoch loss = 2.302\tavg epoch acc = 0.1092\n","epoch 6\tavg epoch loss = 2.302\tavg epoch acc = 0.1092\n","epoch 7\tavg epoch loss = 2.302\tavg epoch acc = 0.1093\n","epoch 8\tavg epoch loss = 2.302\tavg epoch acc = 0.1094\n","epoch 9\tavg epoch loss = 2.302\tavg epoch acc = 0.1095\n","training took 28.7 s\n","Avg test loss = 2.3\tAvg test acc = 0.113\n","{'lr': 0.01, 'beta1': 0.1, 'beta2': 0.999, 'batch_size': 64, 'weight_decay': 0.1, 'epsilon': 1e-10}\n","epoch 0\tavg epoch loss = 0.6837\tavg epoch acc = 0.8986\n","epoch 1\tavg epoch loss = 0.3147\tavg epoch acc = 0.973\n","epoch 2\tavg epoch loss = 0.3395\tavg epoch acc = 0.971\n","epoch 3\tavg epoch loss = 1.953\tavg epoch acc = 0.4139\n","epoch 4\tavg epoch loss = 2.302\tavg epoch acc = 0.1097\n","epoch 5\tavg epoch loss = 2.302\tavg epoch acc = 0.11\n","epoch 6\tavg epoch loss = 2.302\tavg epoch acc = 0.1101\n","epoch 7\tavg epoch loss = 2.302\tavg epoch acc = 0.1101\n","epoch 8\tavg epoch loss = 2.302\tavg epoch acc = 0.11\n","epoch 9\tavg epoch loss = 2.302\tavg epoch acc = 0.11\n","training took 28.51 s\n","Avg test loss = 2.3\tAvg test acc = 0.107\n","epoch 0\tavg epoch loss = 0.6677\tavg epoch acc = 0.8996\n","epoch 1\tavg epoch loss = 0.3049\tavg epoch acc = 0.9715\n","epoch 2\tavg epoch loss = 1.291\tavg epoch acc = 0.5849\n","epoch 3\tavg epoch loss = 2.306\tavg epoch acc = 0.112\n","epoch 4\tavg epoch loss = 2.303\tavg epoch acc = 0.1126\n","epoch 5\tavg epoch loss = 2.302\tavg epoch acc = 0.1099\n","epoch 6\tavg epoch loss = 2.302\tavg epoch acc = 0.1098\n","epoch 7\tavg epoch loss = 2.302\tavg epoch acc = 0.1096\n","epoch 8\tavg epoch loss = 2.302\tavg epoch acc = 0.1097\n","epoch 9\tavg epoch loss = 2.302\tavg epoch acc = 0.1097\n","training took 28.45 s\n","Avg test loss = 2.3\tAvg test acc = 0.113\n","epoch 0\tavg epoch loss = 0.6572\tavg epoch acc = 0.9034\n","epoch 1\tavg epoch loss = 0.3309\tavg epoch acc = 0.9715\n","epoch 2\tavg epoch loss = 0.8855\tavg epoch acc = 0.8223\n","epoch 3\tavg epoch loss = 1.904\tavg epoch acc = 0.3173\n","epoch 4\tavg epoch loss = 2.302\tavg epoch acc = 0.1134\n","epoch 5\tavg epoch loss = 2.303\tavg epoch acc = 0.1158\n","epoch 6\tavg epoch loss = 2.302\tavg epoch acc = 0.1124\n","epoch 7\tavg epoch loss = 2.302\tavg epoch acc = 0.1122\n","epoch 8\tavg epoch loss = 2.302\tavg epoch acc = 0.1121\n","epoch 9\tavg epoch loss = 2.302\tavg epoch acc = 0.1121\n","training took 28.6 s\n","Avg test loss = 2.3\tAvg test acc = 0.103\n","{'lr': 0.01, 'beta1': 0.1, 'beta2': 0.999, 'batch_size': 64, 'weight_decay': 0.1, 'epsilon': 1e-08}\n","epoch 0\tavg epoch loss = 0.6535\tavg epoch acc = 0.9038\n","epoch 1\tavg epoch loss = 0.3199\tavg epoch acc = 0.9724\n","epoch 2\tavg epoch loss = 2.028\tavg epoch acc = 0.3164\n","epoch 3\tavg epoch loss = 2.303\tavg epoch acc = 0.1114\n","epoch 4\tavg epoch loss = 2.304\tavg epoch acc = 0.1123\n","epoch 5\tavg epoch loss = 2.302\tavg epoch acc = 0.1108\n","epoch 6\tavg epoch loss = 2.302\tavg epoch acc = 0.1104\n","epoch 7\tavg epoch loss = 2.302\tavg epoch acc = 0.1103\n","epoch 8\tavg epoch loss = 2.302\tavg epoch acc = 0.1101\n","epoch 9\tavg epoch loss = 2.302\tavg epoch acc = 0.1103\n","training took 28.5 s\n","Avg test loss = 2.3\tAvg test acc = 0.104\n","epoch 0\tavg epoch loss = 0.663\tavg epoch acc = 0.9001\n","epoch 1\tavg epoch loss = 0.3722\tavg epoch acc = 0.9666\n","epoch 2\tavg epoch loss = 2.304\tavg epoch acc = 0.1159\n","epoch 3\tavg epoch loss = 2.305\tavg epoch acc = 0.1133\n","epoch 4\tavg epoch loss = 2.304\tavg epoch acc = 0.1126\n","epoch 5\tavg epoch loss = 2.302\tavg epoch acc = 0.1114\n","epoch 6\tavg epoch loss = 2.302\tavg epoch acc = 0.1112\n","epoch 7\tavg epoch loss = 2.302\tavg epoch acc = 0.1112\n","epoch 8\tavg epoch loss = 2.302\tavg epoch acc = 0.1108\n","epoch 9\tavg epoch loss = 2.302\tavg epoch acc = 0.1106\n","training took 28.22 s\n","Avg test loss = 2.3\tAvg test acc = 0.104\n","epoch 0\tavg epoch loss = 0.6771\tavg epoch acc = 0.8987\n","epoch 1\tavg epoch loss = 0.3385\tavg epoch acc = 0.9699\n","epoch 2\tavg epoch loss = 0.7287\tavg epoch acc = 0.821\n","epoch 3\tavg epoch loss = 2.302\tavg epoch acc = 0.1118\n","epoch 4\tavg epoch loss = 2.302\tavg epoch acc = 0.1128\n","epoch 5\tavg epoch loss = 2.302\tavg epoch acc = 0.1126\n","epoch 6\tavg epoch loss = 2.302\tavg epoch acc = 0.1124\n","epoch 7\tavg epoch loss = 2.302\tavg epoch acc = 0.1124\n","epoch 8\tavg epoch loss = 2.302\tavg epoch acc = 0.1124\n","epoch 9\tavg epoch loss = 2.302\tavg epoch acc = 0.1124\n","training took 28.21 s\n","Avg test loss = 2.3\tAvg test acc = 0.11\n","{'lr': 0.01, 'beta1': 0.1, 'beta2': 0.999, 'batch_size': 128, 'weight_decay': 0.001, 'epsilon': 1e-10}\n","epoch 0\tavg epoch loss = 0.8892\tavg epoch acc = 0.8512\n","epoch 1\tavg epoch loss = 0.321\tavg epoch acc = 0.9747\n","epoch 2\tavg epoch loss = 0.2506\tavg epoch acc = 0.9816\n","epoch 3\tavg epoch loss = 0.2817\tavg epoch acc = 0.9769\n","epoch 4\tavg epoch loss = 1.95\tavg epoch acc = 0.2982\n","epoch 5\tavg epoch loss = 2.302\tavg epoch acc = 0.1132\n","epoch 6\tavg epoch loss = 2.305\tavg epoch acc = 0.1141\n","epoch 7\tavg epoch loss = 2.302\tavg epoch acc = 0.1121\n","epoch 8\tavg epoch loss = 2.302\tavg epoch acc = 0.1124\n","epoch 9\tavg epoch loss = 2.302\tavg epoch acc = 0.1112\n","training took 17.62 s\n","Avg test loss = 2.3\tAvg test acc = 0.107\n","epoch 0\tavg epoch loss = 0.8835\tavg epoch acc = 0.8521\n","epoch 1\tavg epoch loss = 0.3168\tavg epoch acc = 0.974\n","epoch 2\tavg epoch loss = 0.2405\tavg epoch acc = 0.9825\n","epoch 3\tavg epoch loss = 0.262\tavg epoch acc = 0.9788\n","epoch 4\tavg epoch loss = 2.547\tavg epoch acc = 0.1186\n","epoch 5\tavg epoch loss = 2.305\tavg epoch acc = 0.1133\n","epoch 6\tavg epoch loss = 2.302\tavg epoch acc = 0.1125\n","epoch 7\tavg epoch loss = 2.302\tavg epoch acc = 0.1125\n","epoch 8\tavg epoch loss = 2.302\tavg epoch acc = 0.1124\n","epoch 9\tavg epoch loss = 2.303\tavg epoch acc = 0.1128\n","training took 17.51 s\n","Avg test loss = 2.3\tAvg test acc = 0.103\n","epoch 0\tavg epoch loss = 0.8784\tavg epoch acc = 0.852\n","epoch 1\tavg epoch loss = 0.3426\tavg epoch acc = 0.9706\n","epoch 2\tavg epoch loss = 0.2505\tavg epoch acc = 0.9816\n","epoch 3\tavg epoch loss = 0.6192\tavg epoch acc = 0.9145\n","epoch 4\tavg epoch loss = 0.246\tavg epoch acc = 0.9823\n","epoch 5\tavg epoch loss = 0.2284\tavg epoch acc = 0.9844\n","epoch 6\tavg epoch loss = 2.396\tavg epoch acc = 0.1349\n","epoch 7\tavg epoch loss = 2.302\tavg epoch acc = 0.1116\n","epoch 8\tavg epoch loss = 2.302\tavg epoch acc = 0.1116\n","epoch 9\tavg epoch loss = 2.302\tavg epoch acc = 0.1119\n","training took 17.98 s\n","Avg test loss = 2.3\tAvg test acc = 0.104\n","{'lr': 0.01, 'beta1': 0.1, 'beta2': 0.999, 'batch_size': 128, 'weight_decay': 0.001, 'epsilon': 1e-08}\n","epoch 0\tavg epoch loss = 0.8882\tavg epoch acc = 0.8548\n","epoch 1\tavg epoch loss = 0.3284\tavg epoch acc = 0.9732\n","epoch 2\tavg epoch loss = 0.2348\tavg epoch acc = 0.9831\n","epoch 3\tavg epoch loss = 0.8825\tavg epoch acc = 0.7538\n","epoch 4\tavg epoch loss = 2.318\tavg epoch acc = 0.1289\n","epoch 5\tavg epoch loss = 2.296\tavg epoch acc = 0.1411\n","epoch 6\tavg epoch loss = 2.083\tavg epoch acc = 0.3273\n","epoch 7\tavg epoch loss = 2.096\tavg epoch acc = 0.2547\n","epoch 8\tavg epoch loss = 2.303\tavg epoch acc = 0.1088\n","epoch 9\tavg epoch loss = 2.302\tavg epoch acc = 0.1101\n","training took 17.8 s\n","Avg test loss = 2.3\tAvg test acc = 0.105\n","epoch 0\tavg epoch loss = 0.8893\tavg epoch acc = 0.8526\n","epoch 1\tavg epoch loss = 0.3133\tavg epoch acc = 0.9751\n","epoch 2\tavg epoch loss = 0.2545\tavg epoch acc = 0.9807\n","epoch 3\tavg epoch loss = 0.2462\tavg epoch acc = 0.9813\n","epoch 4\tavg epoch loss = 0.2288\tavg epoch acc = 0.9846\n","epoch 5\tavg epoch loss = 2.98\tavg epoch acc = 0.1163\n","epoch 6\tavg epoch loss = 2.302\tavg epoch acc = 0.1093\n","epoch 7\tavg epoch loss = 2.302\tavg epoch acc = 0.1098\n","epoch 8\tavg epoch loss = 2.302\tavg epoch acc = 0.11\n","epoch 9\tavg epoch loss = 2.302\tavg epoch acc = 0.1099\n","training took 17.66 s\n","Avg test loss = 2.3\tAvg test acc = 0.102\n","epoch 0\tavg epoch loss = 0.8882\tavg epoch acc = 0.8508\n","epoch 1\tavg epoch loss = 0.3247\tavg epoch acc = 0.9738\n","epoch 2\tavg epoch loss = 0.2415\tavg epoch acc = 0.9807\n","epoch 3\tavg epoch loss = 0.2648\tavg epoch acc = 0.9795\n","epoch 4\tavg epoch loss = 0.3233\tavg epoch acc = 0.9741\n","epoch 5\tavg epoch loss = 2.336\tavg epoch acc = 0.1486\n","epoch 6\tavg epoch loss = 2.315\tavg epoch acc = 0.2063\n","epoch 7\tavg epoch loss = 2.302\tavg epoch acc = 0.1112\n","epoch 8\tavg epoch loss = 2.31\tavg epoch acc = 0.1203\n","epoch 9\tavg epoch loss = 2.303\tavg epoch acc = 0.1199\n","training took 17.46 s\n","Avg test loss = 2.3\tAvg test acc = 0.111\n","{'lr': 0.01, 'beta1': 0.1, 'beta2': 0.999, 'batch_size': 128, 'weight_decay': 0.1, 'epsilon': 1e-10}\n","epoch 0\tavg epoch loss = 0.8812\tavg epoch acc = 0.854\n","epoch 1\tavg epoch loss = 0.3157\tavg epoch acc = 0.9751\n","epoch 2\tavg epoch loss = 0.2557\tavg epoch acc = 0.9797\n","epoch 3\tavg epoch loss = 0.2289\tavg epoch acc = 0.9822\n","epoch 4\tavg epoch loss = 1.249\tavg epoch acc = 0.8154\n","epoch 5\tavg epoch loss = 0.2928\tavg epoch acc = 0.9751\n","epoch 6\tavg epoch loss = 0.7525\tavg epoch acc = 0.8119\n","epoch 7\tavg epoch loss = 2.303\tavg epoch acc = 0.1088\n","epoch 8\tavg epoch loss = 2.302\tavg epoch acc = 0.1106\n","epoch 9\tavg epoch loss = 2.302\tavg epoch acc = 0.1113\n","training took 17.36 s\n","Avg test loss = 2.3\tAvg test acc = 0.104\n","epoch 0\tavg epoch loss = 0.88\tavg epoch acc = 0.8489\n","epoch 1\tavg epoch loss = 0.306\tavg epoch acc = 0.975\n","epoch 2\tavg epoch loss = 0.6287\tavg epoch acc = 0.8983\n","epoch 3\tavg epoch loss = 0.3816\tavg epoch acc = 0.9622\n","epoch 4\tavg epoch loss = 0.3481\tavg epoch acc = 0.9632\n","epoch 5\tavg epoch loss = 1.273\tavg epoch acc = 0.8191\n","epoch 6\tavg epoch loss = 0.4475\tavg epoch acc = 0.954\n","epoch 7\tavg epoch loss = 0.6784\tavg epoch acc = 0.8458\n","epoch 8\tavg epoch loss = 2.307\tavg epoch acc = 0.1094\n","epoch 9\tavg epoch loss = 2.305\tavg epoch acc = 0.1155\n","training took 17.36 s\n","Avg test loss = 2.3\tAvg test acc = 0.113\n","epoch 0\tavg epoch loss = 0.8809\tavg epoch acc = 0.8535\n","epoch 1\tavg epoch loss = 0.3465\tavg epoch acc = 0.9706\n","epoch 2\tavg epoch loss = 0.276\tavg epoch acc = 0.9763\n","epoch 3\tavg epoch loss = 0.392\tavg epoch acc = 0.956\n","epoch 4\tavg epoch loss = 0.2534\tavg epoch acc = 0.9792\n","epoch 5\tavg epoch loss = 0.8356\tavg epoch acc = 0.8467\n","epoch 6\tavg epoch loss = 1.583\tavg epoch acc = 0.5403\n","epoch 7\tavg epoch loss = 2.302\tavg epoch acc = 0.1127\n","epoch 8\tavg epoch loss = 2.301\tavg epoch acc = 0.1125\n","epoch 9\tavg epoch loss = 2.301\tavg epoch acc = 0.1131\n","training took 17.48 s\n","Avg test loss = 2.3\tAvg test acc = 0.107\n","{'lr': 0.01, 'beta1': 0.1, 'beta2': 0.999, 'batch_size': 128, 'weight_decay': 0.1, 'epsilon': 1e-08}\n","epoch 0\tavg epoch loss = 0.8903\tavg epoch acc = 0.8497\n","epoch 1\tavg epoch loss = 0.3293\tavg epoch acc = 0.9723\n","epoch 2\tavg epoch loss = 0.3118\tavg epoch acc = 0.9708\n","epoch 3\tavg epoch loss = 0.7302\tavg epoch acc = 0.8782\n","epoch 4\tavg epoch loss = 0.9232\tavg epoch acc = 0.7811\n","epoch 5\tavg epoch loss = 0.4984\tavg epoch acc = 0.9373\n","epoch 6\tavg epoch loss = 2.771\tavg epoch acc = 0.7388\n","epoch 7\tavg epoch loss = 2.31\tavg epoch acc = 0.1078\n","epoch 8\tavg epoch loss = 2.302\tavg epoch acc = 0.109\n","epoch 9\tavg epoch loss = 2.302\tavg epoch acc = 0.1095\n","training took 17.47 s\n","Avg test loss = 2.3\tAvg test acc = 0.104\n","epoch 0\tavg epoch loss = 0.8799\tavg epoch acc = 0.8512\n","epoch 1\tavg epoch loss = 0.3088\tavg epoch acc = 0.9756\n","epoch 2\tavg epoch loss = 0.2407\tavg epoch acc = 0.9822\n","epoch 3\tavg epoch loss = 0.3401\tavg epoch acc = 0.9677\n","epoch 4\tavg epoch loss = 0.7212\tavg epoch acc = 0.9297\n","epoch 5\tavg epoch loss = 0.7553\tavg epoch acc = 0.8376\n","epoch 6\tavg epoch loss = 0.3866\tavg epoch acc = 0.9588\n","epoch 7\tavg epoch loss = 0.2637\tavg epoch acc = 0.9782\n","epoch 8\tavg epoch loss = 0.8772\tavg epoch acc = 0.7372\n","epoch 9\tavg epoch loss = 2.303\tavg epoch acc = 0.1112\n","training took 17.36 s\n","Avg test loss = 2.3\tAvg test acc = 0.104\n","epoch 0\tavg epoch loss = 0.8929\tavg epoch acc = 0.8513\n","epoch 1\tavg epoch loss = 0.3206\tavg epoch acc = 0.9731\n","epoch 2\tavg epoch loss = 0.2473\tavg epoch acc = 0.9815\n","epoch 3\tavg epoch loss = 0.6444\tavg epoch acc = 0.9009\n","epoch 4\tavg epoch loss = 2.411\tavg epoch acc = 0.1206\n","epoch 5\tavg epoch loss = 2.302\tavg epoch acc = 0.1125\n","epoch 6\tavg epoch loss = 2.302\tavg epoch acc = 0.1126\n","epoch 7\tavg epoch loss = 2.302\tavg epoch acc = 0.1146\n","epoch 8\tavg epoch loss = 2.302\tavg epoch acc = 0.1145\n","epoch 9\tavg epoch loss = 2.302\tavg epoch acc = 0.1126\n","training took 17.44 s\n","Avg test loss = 2.3\tAvg test acc = 0.105\n","{'lr': 0.01, 'beta1': 0.9, 'beta2': 0.5, 'batch_size': 32, 'weight_decay': 0.001, 'epsilon': 1e-10}\n","epoch 0\tavg epoch loss = 3.268e+14\tavg epoch acc = 0.0952\n","epoch 1\tavg epoch loss = 3.299e+09\tavg epoch acc = 0.104\n","epoch 2\tavg epoch loss = 1.815e+09\tavg epoch acc = 0.1008\n","epoch 3\tavg epoch loss = 1.516e+09\tavg epoch acc = 0.1023\n","epoch 4\tavg epoch loss = 1.394e+09\tavg epoch acc = 0.1011\n","epoch 5\tavg epoch loss = 1.282e+09\tavg epoch acc = 0.1034\n","epoch 6\tavg epoch loss = 1.182e+09\tavg epoch acc = 0.1037\n","epoch 7\tavg epoch loss = 1.1e+09\tavg epoch acc = 0.1017\n","epoch 8\tavg epoch loss = 1.027e+09\tavg epoch acc = 0.1\n","epoch 9\tavg epoch loss = 9.572e+08\tavg epoch acc = 0.1008\n","training took 54.6 s\n","Avg test loss = 9.18e+08\tAvg test acc = 0.0999\n","epoch 0\tavg epoch loss = 4.63e+08\tavg epoch acc = 0.09875\n","epoch 1\tavg epoch loss = 1.083e+06\tavg epoch acc = 0.09853\n","epoch 2\tavg epoch loss = 5.058e+05\tavg epoch acc = 0.09895\n","epoch 3\tavg epoch loss = 2.833e+05\tavg epoch acc = 0.09867\n","epoch 4\tavg epoch loss = 8.679e+04\tavg epoch acc = 0.098\n","epoch 5\tavg epoch loss = 4.781e+03\tavg epoch acc = 0.1012\n","epoch 6\tavg epoch loss = 4.544e+03\tavg epoch acc = 0.09945\n","epoch 7\tavg epoch loss = 4.926e+03\tavg epoch acc = 0.09915\n","epoch 8\tavg epoch loss = 4.981e+03\tavg epoch acc = 0.0988\n","epoch 9\tavg epoch loss = 4.762e+03\tavg epoch acc = 0.1011\n","training took 54.52 s\n","Avg test loss = 4.08e+03\tAvg test acc = 0.0977\n","epoch 0\tavg epoch loss = 2.253e+09\tavg epoch acc = 0.08872\n","epoch 1\tavg epoch loss = 1.115e+06\tavg epoch acc = 0.09652\n","epoch 2\tavg epoch loss = 7.732e+04\tavg epoch acc = 0.1022\n","epoch 3\tavg epoch loss = 9.233e+03\tavg epoch acc = 0.09897\n","epoch 4\tavg epoch loss = 957.4\tavg epoch acc = 0.1004\n","epoch 5\tavg epoch loss = 843.3\tavg epoch acc = 0.09942\n","epoch 6\tavg epoch loss = 827.7\tavg epoch acc = 0.1007\n","epoch 7\tavg epoch loss = 876.8\tavg epoch acc = 0.0978\n","epoch 8\tavg epoch loss = 829.0\tavg epoch acc = 0.09928\n","epoch 9\tavg epoch loss = 839.8\tavg epoch acc = 0.0973\n","training took 54.67 s\n","Avg test loss = 5.99e+02\tAvg test acc = 0.0988\n","{'lr': 0.01, 'beta1': 0.9, 'beta2': 0.5, 'batch_size': 32, 'weight_decay': 0.001, 'epsilon': 1e-08}\n","epoch 0\tavg epoch loss = nan\tavg epoch acc = 0.1008\n","epoch 1\tavg epoch loss = nan\tavg epoch acc = 0.1005\n","epoch 2\tavg epoch loss = nan\tavg epoch acc = 0.1005\n","epoch 3\tavg epoch loss = nan\tavg epoch acc = 0.1005\n","epoch 4\tavg epoch loss = nan\tavg epoch acc = 0.1005\n","epoch 5\tavg epoch loss = nan\tavg epoch acc = 0.1005\n","epoch 6\tavg epoch loss = nan\tavg epoch acc = 0.1005\n","epoch 7\tavg epoch loss = nan\tavg epoch acc = 0.1005\n","epoch 8\tavg epoch loss = nan\tavg epoch acc = 0.1005\n","epoch 9\tavg epoch loss = nan\tavg epoch acc = 0.1005\n","training took 54.68 s\n","Avg test loss = nan\tAvg test acc = 0.0951\n","epoch 0\tavg epoch loss = nan\tavg epoch acc = 0.09813\n","epoch 1\tavg epoch loss = nan\tavg epoch acc = 0.0978\n","epoch 2\tavg epoch loss = nan\tavg epoch acc = 0.0978\n","epoch 3\tavg epoch loss = nan\tavg epoch acc = 0.0978\n","epoch 4\tavg epoch loss = nan\tavg epoch acc = 0.0978\n","epoch 5\tavg epoch loss = nan\tavg epoch acc = 0.0978\n","epoch 6\tavg epoch loss = nan\tavg epoch acc = 0.0978\n","epoch 7\tavg epoch loss = nan\tavg epoch acc = 0.0978\n","epoch 8\tavg epoch loss = nan\tavg epoch acc = 0.0978\n","epoch 9\tavg epoch loss = nan\tavg epoch acc = 0.0978\n","training took 54.51 s\n","Avg test loss = nan\tAvg test acc = 0.101\n","epoch 0\tavg epoch loss = 1.767e+08\tavg epoch acc = 0.09765\n","epoch 1\tavg epoch loss = 7.177e+05\tavg epoch acc = 0.1013\n","epoch 2\tavg epoch loss = 7.315e+04\tavg epoch acc = 0.09925\n","epoch 3\tavg epoch loss = 2.354e+03\tavg epoch acc = 0.101\n","epoch 4\tavg epoch loss = 2.155e+03\tavg epoch acc = 0.09745\n","epoch 5\tavg epoch loss = 2.15e+03\tavg epoch acc = 0.09585\n","epoch 6\tavg epoch loss = 2.201e+03\tavg epoch acc = 0.1003\n","epoch 7\tavg epoch loss = 1.963e+03\tavg epoch acc = 0.0992\n","epoch 8\tavg epoch loss = 2.081e+03\tavg epoch acc = 0.1015\n","epoch 9\tavg epoch loss = 2.042e+03\tavg epoch acc = 0.1016\n","training took 55.18 s\n","Avg test loss = 7.11e+18\tAvg test acc = 0.0985\n","{'lr': 0.01, 'beta1': 0.9, 'beta2': 0.5, 'batch_size': 32, 'weight_decay': 0.1, 'epsilon': 1e-10}\n","epoch 0\tavg epoch loss = 4.302e+13\tavg epoch acc = 0.1031\n","epoch 1\tavg epoch loss = 3.26e+12\tavg epoch acc = 0.1033\n","epoch 2\tavg epoch loss = 2.639e+11\tavg epoch acc = 0.1033\n","epoch 3\tavg epoch loss = 2.069e+10\tavg epoch acc = 0.1033\n","epoch 4\tavg epoch loss = 1.424e+09\tavg epoch acc = 0.1028\n","epoch 5\tavg epoch loss = 6.416e+07\tavg epoch acc = 0.1037\n","epoch 6\tavg epoch loss = 2.961e+06\tavg epoch acc = 0.1005\n","epoch 7\tavg epoch loss = 8.399e+05\tavg epoch acc = 0.1002\n","epoch 8\tavg epoch loss = 2.931e+05\tavg epoch acc = 0.1015\n","epoch 9\tavg epoch loss = 8.464e+04\tavg epoch acc = 0.0989\n","training took 54.94 s\n","Avg test loss = 3.9e+04\tAvg test acc = 0.102\n","epoch 0\tavg epoch loss = 1.677e+24\tavg epoch acc = 0.1286\n","epoch 1\tavg epoch loss = 7.665e+23\tavg epoch acc = 0.1519\n","epoch 2\tavg epoch loss = 1.466e+21\tavg epoch acc = 0.1433\n","epoch 3\tavg epoch loss = 5.49e+09\tavg epoch acc = 0.1322\n","epoch 4\tavg epoch loss = 4.665e+08\tavg epoch acc = 0.0956\n","epoch 5\tavg epoch loss = 3.883e+07\tavg epoch acc = 0.0666\n","epoch 6\tavg epoch loss = 4.787e+30\tavg epoch acc = 0.09287\n","epoch 7\tavg epoch loss = 2.633e+21\tavg epoch acc = 0.09897\n","epoch 8\tavg epoch loss = 2.159e+20\tavg epoch acc = 0.09897\n","epoch 9\tavg epoch loss = 1.77e+19\tavg epoch acc = 0.09897\n","training took 54.93 s\n","Avg test loss = 3.95e+18\tAvg test acc = 0.0995\n","epoch 0\tavg epoch loss = 2.307e+13\tavg epoch acc = 0.1051\n","epoch 1\tavg epoch loss = 2.239e+30\tavg epoch acc = 0.1109\n","epoch 2\tavg epoch loss = 1.94e+33\tavg epoch acc = 0.1076\n","epoch 3\tavg epoch loss = 1.643e+33\tavg epoch acc = 0.09728\n","epoch 4\tavg epoch loss = 9.016e+32\tavg epoch acc = 0.09427\n","epoch 5\tavg epoch loss = 7.028e+30\tavg epoch acc = 0.09315\n","epoch 6\tavg epoch loss = 5.88e+28\tavg epoch acc = 0.09508\n","epoch 7\tavg epoch loss = 4.957e+26\tavg epoch acc = 0.09703\n","epoch 8\tavg epoch loss = 2.727e+24\tavg epoch acc = 0.09592\n","epoch 9\tavg epoch loss = 2.412e+22\tavg epoch acc = 0.09483\n","training took 54.68 s\n","Avg test loss = 1.35e+20\tAvg test acc = 0.106\n","{'lr': 0.01, 'beta1': 0.9, 'beta2': 0.5, 'batch_size': 32, 'weight_decay': 0.1, 'epsilon': 1e-08}\n","epoch 0\tavg epoch loss = 3.477e+25\tavg epoch acc = 0.09043\n","epoch 1\tavg epoch loss = 1.303e+25\tavg epoch acc = 0.1488\n","epoch 2\tavg epoch loss = 3.362e+19\tavg epoch acc = 0.1613\n","epoch 3\tavg epoch loss = 3.538e+17\tavg epoch acc = 0.1453\n","epoch 4\tavg epoch loss = 2.188e+15\tavg epoch acc = 0.09878\n","epoch 5\tavg epoch loss = 6.293e+12\tavg epoch acc = 0.07635\n","epoch 6\tavg epoch loss = 7.713e+11\tavg epoch acc = 0.09033\n","epoch 7\tavg epoch loss = 9.103e+22\tavg epoch acc = 0.09352\n","epoch 8\tavg epoch loss = 4.13e+26\tavg epoch acc = 0.0937\n","epoch 9\tavg epoch loss = 8.536e+30\tavg epoch acc = 0.0867\n","training took 54.67 s\n","Avg test loss = 8.41e+25\tAvg test acc = 0.108\n","epoch 0\tavg epoch loss = nan\tavg epoch acc = 0.1111\n","epoch 1\tavg epoch loss = nan\tavg epoch acc = 0.09857\n","epoch 2\tavg epoch loss = nan\tavg epoch acc = 0.09857\n","epoch 3\tavg epoch loss = nan\tavg epoch acc = 0.09857\n","epoch 4\tavg epoch loss = nan\tavg epoch acc = 0.09857\n","epoch 5\tavg epoch loss = nan\tavg epoch acc = 0.09857\n","epoch 6\tavg epoch loss = nan\tavg epoch acc = 0.09857\n","epoch 7\tavg epoch loss = nan\tavg epoch acc = 0.09857\n","epoch 8\tavg epoch loss = nan\tavg epoch acc = 0.09857\n","epoch 9\tavg epoch loss = nan\tavg epoch acc = 0.09857\n","training took 54.74 s\n","Avg test loss = nan\tAvg test acc = 0.099\n","epoch 0\tavg epoch loss = 1.844e+16\tavg epoch acc = 0.1563\n","epoch 1\tavg epoch loss = 1.859e+17\tavg epoch acc = 0.1097\n","epoch 2\tavg epoch loss = 7.881e+10\tavg epoch acc = 0.0989\n","epoch 3\tavg epoch loss = 5.941e+09\tavg epoch acc = 0.101\n","epoch 4\tavg epoch loss = 3.538e+08\tavg epoch acc = 0.1003\n","epoch 5\tavg epoch loss = 1.519e+07\tavg epoch acc = 0.1022\n","epoch 6\tavg epoch loss = 4.058e+06\tavg epoch acc = 0.1031\n","epoch 7\tavg epoch loss = 1.404e+06\tavg epoch acc = 0.1016\n","epoch 8\tavg epoch loss = 4.452e+05\tavg epoch acc = 0.1042\n","epoch 9\tavg epoch loss = 1.277e+05\tavg epoch acc = 0.1024\n","training took 54.55 s\n","Avg test loss = 8.99e+08\tAvg test acc = 0.0969\n","{'lr': 0.01, 'beta1': 0.9, 'beta2': 0.5, 'batch_size': 64, 'weight_decay': 0.001, 'epsilon': 1e-10}\n","epoch 0\tavg epoch loss = 9.059e+18\tavg epoch acc = 0.09945\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"wanted-grocery"},"source":["### Nesterov"],"id":"wanted-grocery"},{"cell_type":"code","metadata":{"id":"conditional-mirror","colab":{"base_uri":"https://localhost:8080/"},"outputId":"a83bcd07-87e2-447a-e62e-5994ede0b954"},"source":["search_grid_nesterov = {\n","    'lr': np.logspace(0, 1, num=15),\n","    'batch_size': [32, 64, 128]\n","}\n","\n","if prot_hyperparameter_tune:\n","    results_nesterov_prot = tune_optimizer(\n","        model=Net().to(device),\n","        optim_fun=NesterovOptimizer,\n","        xtrain=train_dataset.data,\n","        ytrain=train_dataset.targets,\n","        search_grid=search_grid_nesterov,\n","        nfolds=3,\n","        func=protected_training,\n","        **training_config\n","    )\n","\n","else:\n","    results_nesterov_prot = optimizers[NesterovOptimizer]"],"id":"conditional-mirror","execution_count":null,"outputs":[{"output_type":"stream","text":["Launching hyperparameter tuning:\n","\tlr = [ 1.          1.04811313  1.09854114  1.1513954   1.20679264  1.26485522\n","  1.32571137  1.38949549  1.45634848  1.52641797  1.59985872  1.67683294\n","  1.75751062  1.84206997  1.93069773  2.02358965  2.12095089  2.22299648\n","  2.32995181  2.44205309  2.55954792  2.6826958   2.8117687   2.9470517\n","  3.0888436   3.23745754  3.39322177  3.55648031  3.72759372  3.90693994\n","  4.09491506  4.29193426  4.49843267  4.71486636  4.94171336  5.17947468\n","  5.42867544  5.68986603  5.96362332  6.25055193  6.55128557  6.86648845\n","  7.19685673  7.54312006  7.90604321  8.28642773  8.68511374  9.10298178\n","  9.54095476 10.        ]\n","\tbatch_size = [32, 64, 128]\n","{'lr': 1.0, 'batch_size': 32}\n","epoch 0\tavg epoch loss = nan\tavg epoch acc = 0.09767\n","epoch 1\tavg epoch loss = nan\tavg epoch acc = 0.09835\n","epoch 2\tavg epoch loss = nan\tavg epoch acc = 0.09835\n","epoch 3\tavg epoch loss = nan\tavg epoch acc = 0.09835\n","epoch 4\tavg epoch loss = nan\tavg epoch acc = 0.09835\n","epoch 5\tavg epoch loss = nan\tavg epoch acc = 0.09835\n","epoch 6\tavg epoch loss = nan\tavg epoch acc = 0.09835\n","epoch 7\tavg epoch loss = nan\tavg epoch acc = 0.09835\n","epoch 8\tavg epoch loss = nan\tavg epoch acc = 0.09835\n","epoch 9\tavg epoch loss = nan\tavg epoch acc = 0.09835\n","training took 44.4 s\n","Avg test loss = nan\tAvg test acc = 0.0994\n","epoch 0\tavg epoch loss = nan\tavg epoch acc = 0.09988\n","epoch 1\tavg epoch loss = nan\tavg epoch acc = 0.09853\n","epoch 2\tavg epoch loss = nan\tavg epoch acc = 0.09853\n","epoch 3\tavg epoch loss = nan\tavg epoch acc = 0.09853\n","epoch 4\tavg epoch loss = nan\tavg epoch acc = 0.09853\n","epoch 5\tavg epoch loss = nan\tavg epoch acc = 0.09853\n","epoch 6\tavg epoch loss = nan\tavg epoch acc = 0.09853\n","epoch 7\tavg epoch loss = nan\tavg epoch acc = 0.09853\n","epoch 8\tavg epoch loss = nan\tavg epoch acc = 0.09853\n","epoch 9\tavg epoch loss = nan\tavg epoch acc = 0.09853\n","training took 44.57 s\n","Avg test loss = nan\tAvg test acc = 0.0991\n","epoch 0\tavg epoch loss = 1.346e+24\tavg epoch acc = 0.1011\n","epoch 1\tavg epoch loss = nan\tavg epoch acc = 0.09935\n","epoch 2\tavg epoch loss = nan\tavg epoch acc = 0.09928\n","epoch 3\tavg epoch loss = nan\tavg epoch acc = 0.09928\n","epoch 4\tavg epoch loss = nan\tavg epoch acc = 0.09928\n","epoch 5\tavg epoch loss = nan\tavg epoch acc = 0.09928\n","epoch 6\tavg epoch loss = nan\tavg epoch acc = 0.09928\n","epoch 7\tavg epoch loss = nan\tavg epoch acc = 0.09928\n","epoch 8\tavg epoch loss = nan\tavg epoch acc = 0.09928\n","epoch 9\tavg epoch loss = nan\tavg epoch acc = 0.09928\n","training took 44.35 s\n","Avg test loss = nan\tAvg test acc = 0.0976\n","{'lr': 1.0, 'batch_size': 64}\n","epoch 0\tavg epoch loss = 2.773\tavg epoch acc = 0.09832\n","epoch 1\tavg epoch loss = 41.87\tavg epoch acc = 0.09855\n","epoch 2\tavg epoch loss = 56.88\tavg epoch acc = 0.0995\n","epoch 3\tavg epoch loss = 2.734\tavg epoch acc = 0.09895\n","epoch 4\tavg epoch loss = 2.336\tavg epoch acc = 0.09897\n","epoch 5\tavg epoch loss = 2.336\tavg epoch acc = 0.09888\n","epoch 6\tavg epoch loss = 2.336\tavg epoch acc = 0.09888\n","epoch 7\tavg epoch loss = 2.336\tavg epoch acc = 0.09888\n","epoch 8\tavg epoch loss = 2.336\tavg epoch acc = 0.09888\n","epoch 9\tavg epoch loss = 2.336\tavg epoch acc = 0.09888\n","training took 23.3 s\n","Avg test loss = 2.31\tAvg test acc = 0.102\n","epoch 0\tavg epoch loss = nan\tavg epoch acc = 0.1007\n","epoch 1\tavg epoch loss = nan\tavg epoch acc = 0.09872\n","epoch 2\tavg epoch loss = nan\tavg epoch acc = 0.09872\n","epoch 3\tavg epoch loss = nan\tavg epoch acc = 0.09872\n","epoch 4\tavg epoch loss = nan\tavg epoch acc = 0.09872\n","epoch 5\tavg epoch loss = nan\tavg epoch acc = 0.09872\n","epoch 6\tavg epoch loss = nan\tavg epoch acc = 0.09872\n","epoch 7\tavg epoch loss = nan\tavg epoch acc = 0.09872\n","epoch 8\tavg epoch loss = nan\tavg epoch acc = 0.09872\n","epoch 9\tavg epoch loss = nan\tavg epoch acc = 0.09872\n","training took 23.16 s\n","Avg test loss = nan\tAvg test acc = 0.0988\n","epoch 0\tavg epoch loss = nan\tavg epoch acc = 0.1024\n","epoch 1\tavg epoch loss = nan\tavg epoch acc = 0.09978\n","epoch 2\tavg epoch loss = nan\tavg epoch acc = 0.09978\n","epoch 3\tavg epoch loss = nan\tavg epoch acc = 0.09978\n","epoch 4\tavg epoch loss = nan\tavg epoch acc = 0.09978\n","epoch 5\tavg epoch loss = nan\tavg epoch acc = 0.09978\n","epoch 6\tavg epoch loss = nan\tavg epoch acc = 0.09978\n","epoch 7\tavg epoch loss = nan\tavg epoch acc = 0.09978\n","epoch 8\tavg epoch loss = nan\tavg epoch acc = 0.09978\n","epoch 9\tavg epoch loss = nan\tavg epoch acc = 0.09978\n","training took 23.2 s\n","Avg test loss = nan\tAvg test acc = 0.0965\n","{'lr': 1.0, 'batch_size': 128}\n","epoch 0\tavg epoch loss = nan\tavg epoch acc = 0.1002\n","epoch 1\tavg epoch loss = nan\tavg epoch acc = 0.09852\n","epoch 2\tavg epoch loss = nan\tavg epoch acc = 0.09852\n","epoch 3\tavg epoch loss = nan\tavg epoch acc = 0.09852\n","epoch 4\tavg epoch loss = nan\tavg epoch acc = 0.09852\n","epoch 5\tavg epoch loss = nan\tavg epoch acc = 0.09852\n","epoch 6\tavg epoch loss = nan\tavg epoch acc = 0.09852\n","epoch 7\tavg epoch loss = nan\tavg epoch acc = 0.09852\n","epoch 8\tavg epoch loss = nan\tavg epoch acc = 0.09852\n","epoch 9\tavg epoch loss = nan\tavg epoch acc = 0.09852\n","training took 15.61 s\n","Avg test loss = nan\tAvg test acc = 0.0992\n","epoch 0\tavg epoch loss = nan\tavg epoch acc = 0.09997\n","epoch 1\tavg epoch loss = nan\tavg epoch acc = 0.09889\n","epoch 2\tavg epoch loss = nan\tavg epoch acc = 0.09889\n","epoch 3\tavg epoch loss = nan\tavg epoch acc = 0.09889\n","epoch 4\tavg epoch loss = nan\tavg epoch acc = 0.09889\n","epoch 5\tavg epoch loss = nan\tavg epoch acc = 0.09889\n","epoch 6\tavg epoch loss = nan\tavg epoch acc = 0.09889\n","epoch 7\tavg epoch loss = nan\tavg epoch acc = 0.09889\n","epoch 8\tavg epoch loss = nan\tavg epoch acc = 0.09889\n","epoch 9\tavg epoch loss = nan\tavg epoch acc = 0.09889\n","training took 15.88 s\n","Avg test loss = nan\tAvg test acc = 0.0983\n","epoch 0\tavg epoch loss = 2.32\tavg epoch acc = 0.1036\n","epoch 1\tavg epoch loss = 2.318\tavg epoch acc = 0.1011\n","epoch 2\tavg epoch loss = 2.361\tavg epoch acc = 0.102\n","epoch 3\tavg epoch loss = 2.844\tavg epoch acc = 0.101\n","epoch 4\tavg epoch loss = 3.779\tavg epoch acc = 0.09999\n","epoch 5\tavg epoch loss = 3.74\tavg epoch acc = 0.1009\n","epoch 6\tavg epoch loss = 2.318\tavg epoch acc = 0.1005\n","epoch 7\tavg epoch loss = 2.317\tavg epoch acc = 0.1009\n","epoch 8\tavg epoch loss = 2.317\tavg epoch acc = 0.1009\n","epoch 9\tavg epoch loss = 2.374\tavg epoch acc = 0.1017\n","training took 15.79 s\n","Avg test loss = 2.31\tAvg test acc = 0.0877\n","{'lr': 1.0481131341546857, 'batch_size': 32}\n","epoch 0\tavg epoch loss = nan\tavg epoch acc = 0.09907\n","epoch 1\tavg epoch loss = nan\tavg epoch acc = 0.09917\n","epoch 2\tavg epoch loss = nan\tavg epoch acc = 0.09917\n","epoch 3\tavg epoch loss = nan\tavg epoch acc = 0.09917\n","epoch 4\tavg epoch loss = nan\tavg epoch acc = 0.09917\n","epoch 5\tavg epoch loss = nan\tavg epoch acc = 0.09917\n","epoch 6\tavg epoch loss = nan\tavg epoch acc = 0.09917\n","epoch 7\tavg epoch loss = nan\tavg epoch acc = 0.09917\n","epoch 8\tavg epoch loss = nan\tavg epoch acc = 0.09917\n","epoch 9\tavg epoch loss = nan\tavg epoch acc = 0.09917\n","training took 44.67 s\n","Avg test loss = nan\tAvg test acc = 0.0978\n","epoch 0\tavg epoch loss = 2.373\tavg epoch acc = 0.0942\n","epoch 1\tavg epoch loss = 2.384\tavg epoch acc = 0.09517\n","epoch 2\tavg epoch loss = 2.377\tavg epoch acc = 0.09473\n","epoch 3\tavg epoch loss = 2.376\tavg epoch acc = 0.0944\n","epoch 4\tavg epoch loss = 2.377\tavg epoch acc = 0.0944\n","epoch 5\tavg epoch loss = 2.377\tavg epoch acc = 0.09445\n","epoch 6\tavg epoch loss = 2.377\tavg epoch acc = 0.09448\n","epoch 7\tavg epoch loss = 2.377\tavg epoch acc = 0.09448\n","epoch 8\tavg epoch loss = 2.377\tavg epoch acc = 0.09442\n","epoch 9\tavg epoch loss = 2.377\tavg epoch acc = 0.09442\n","training took 44.34 s\n","Avg test loss = 2.33\tAvg test acc = 0.113\n","epoch 0\tavg epoch loss = 2.804e+10\tavg epoch acc = 0.0984\n","epoch 1\tavg epoch loss = 4.779e+12\tavg epoch acc = 0.09788\n","epoch 2\tavg epoch loss = 4.957e+13\tavg epoch acc = 0.09895\n","epoch 3\tavg epoch loss = 1.045e+17\tavg epoch acc = 0.09675\n","epoch 4\tavg epoch loss = 2.49e+14\tavg epoch acc = 0.09978\n","epoch 5\tavg epoch loss = 2.755e+12\tavg epoch acc = 0.0981\n","epoch 6\tavg epoch loss = 2.309e+12\tavg epoch acc = 0.098\n","epoch 7\tavg epoch loss = 9.965e+08\tavg epoch acc = 0.09865\n","epoch 8\tavg epoch loss = 2.37\tavg epoch acc = 0.09813\n","epoch 9\tavg epoch loss = 3.012e+10\tavg epoch acc = 0.0986\n","training took 44.6 s\n","Avg test loss = 2.35\tAvg test acc = 0.115\n","{'lr': 1.0481131341546857, 'batch_size': 64}\n","epoch 0\tavg epoch loss = nan\tavg epoch acc = 0.1\n","epoch 1\tavg epoch loss = nan\tavg epoch acc = 0.09863\n","epoch 2\tavg epoch loss = nan\tavg epoch acc = 0.09863\n","epoch 3\tavg epoch loss = nan\tavg epoch acc = 0.09863\n","epoch 4\tavg epoch loss = nan\tavg epoch acc = 0.09863\n","epoch 5\tavg epoch loss = nan\tavg epoch acc = 0.09863\n","epoch 6\tavg epoch loss = nan\tavg epoch acc = 0.09863\n","epoch 7\tavg epoch loss = nan\tavg epoch acc = 0.09863\n","epoch 8\tavg epoch loss = nan\tavg epoch acc = 0.09863\n","epoch 9\tavg epoch loss = nan\tavg epoch acc = 0.09863\n","training took 24.15 s\n","Avg test loss = nan\tAvg test acc = 0.0989\n","epoch 0\tavg epoch loss = 21.9\tavg epoch acc = 0.1013\n","epoch 1\tavg epoch loss = 2.335\tavg epoch acc = 0.1008\n","epoch 2\tavg epoch loss = 2.336\tavg epoch acc = 0.1005\n","epoch 3\tavg epoch loss = 2.336\tavg epoch acc = 0.1007\n","epoch 4\tavg epoch loss = 2.336\tavg epoch acc = 0.1008\n","epoch 5\tavg epoch loss = 2.336\tavg epoch acc = 0.1008\n","epoch 6\tavg epoch loss = 2.336\tavg epoch acc = 0.1008\n","epoch 7\tavg epoch loss = 2.336\tavg epoch acc = 0.1008\n","epoch 8\tavg epoch loss = 2.336\tavg epoch acc = 0.1008\n","epoch 9\tavg epoch loss = 2.336\tavg epoch acc = 0.1008\n","training took 24.05 s\n","Avg test loss = 2.31\tAvg test acc = 0.0991\n","epoch 0\tavg epoch loss = 3.096e+03\tavg epoch acc = 0.1008\n","epoch 1\tavg epoch loss = 12.71\tavg epoch acc = 0.1008\n","epoch 2\tavg epoch loss = 2.338\tavg epoch acc = 0.1008\n","epoch 3\tavg epoch loss = 2.337\tavg epoch acc = 0.1008\n","epoch 4\tavg epoch loss = 2.337\tavg epoch acc = 0.1008\n","epoch 5\tavg epoch loss = 2.337\tavg epoch acc = 0.1008\n","epoch 6\tavg epoch loss = 2.337\tavg epoch acc = 0.1006\n","epoch 7\tavg epoch loss = 2.337\tavg epoch acc = 0.1005\n","epoch 8\tavg epoch loss = 2.337\tavg epoch acc = 0.1005\n","epoch 9\tavg epoch loss = 2.337\tavg epoch acc = 0.1005\n","training took 23.51 s\n","Avg test loss = 2.33\tAvg test acc = 0.103\n","{'lr': 1.0481131341546857, 'batch_size': 128}\n","epoch 0\tavg epoch loss = 2.322\tavg epoch acc = 0.1041\n","epoch 1\tavg epoch loss = 2.316\tavg epoch acc = 0.1028\n","epoch 2\tavg epoch loss = 46.7\tavg epoch acc = 0.1017\n","epoch 3\tavg epoch loss = 4.113\tavg epoch acc = 0.1015\n","epoch 4\tavg epoch loss = 2.577\tavg epoch acc = 0.1024\n","epoch 5\tavg epoch loss = 2.317\tavg epoch acc = 0.1017\n","epoch 6\tavg epoch loss = 2.317\tavg epoch acc = 0.1017\n","epoch 7\tavg epoch loss = 3.407e+03\tavg epoch acc = 0.1024\n","epoch 8\tavg epoch loss = 1.696e+05\tavg epoch acc = 0.1011\n","epoch 9\tavg epoch loss = 1.91e+06\tavg epoch acc = 0.1005\n","training took 15.63 s\n","Avg test loss = 1.15e+02\tAvg test acc = 0.104\n","epoch 0\tavg epoch loss = nan\tavg epoch acc = 0.1012\n","epoch 1\tavg epoch loss = nan\tavg epoch acc = 0.09952\n","epoch 2\tavg epoch loss = nan\tavg epoch acc = 0.09952\n","epoch 3\tavg epoch loss = nan\tavg epoch acc = 0.09952\n","epoch 4\tavg epoch loss = nan\tavg epoch acc = 0.09952\n","epoch 5\tavg epoch loss = nan\tavg epoch acc = 0.09952\n","epoch 6\tavg epoch loss = nan\tavg epoch acc = 0.09952\n","epoch 7\tavg epoch loss = nan\tavg epoch acc = 0.09952\n","epoch 8\tavg epoch loss = nan\tavg epoch acc = 0.09952\n","epoch 9\tavg epoch loss = nan\tavg epoch acc = 0.09952\n","training took 15.86 s\n","Avg test loss = nan\tAvg test acc = 0.0972\n","epoch 0\tavg epoch loss = nan\tavg epoch acc = 0.102\n","epoch 1\tavg epoch loss = nan\tavg epoch acc = 0.09917\n","epoch 2\tavg epoch loss = nan\tavg epoch acc = 0.09917\n","epoch 3\tavg epoch loss = nan\tavg epoch acc = 0.09917\n","epoch 4\tavg epoch loss = nan\tavg epoch acc = 0.09917\n","epoch 5\tavg epoch loss = nan\tavg epoch acc = 0.09917\n","epoch 6\tavg epoch loss = nan\tavg epoch acc = 0.09917\n","epoch 7\tavg epoch loss = nan\tavg epoch acc = 0.09917\n","epoch 8\tavg epoch loss = nan\tavg epoch acc = 0.09917\n","epoch 9\tavg epoch loss = nan\tavg epoch acc = 0.09917\n","training took 15.77 s\n","Avg test loss = nan\tAvg test acc = 0.0977\n","{'lr': 1.0985411419875581, 'batch_size': 32}\n","epoch 0\tavg epoch loss = 2.096e+06\tavg epoch acc = 0.1011\n","epoch 1\tavg epoch loss = nan\tavg epoch acc = 0.0997\n","epoch 2\tavg epoch loss = nan\tavg epoch acc = 0.1013\n","epoch 3\tavg epoch loss = nan\tavg epoch acc = 0.1013\n","epoch 4\tavg epoch loss = nan\tavg epoch acc = 0.1013\n","epoch 5\tavg epoch loss = nan\tavg epoch acc = 0.1013\n","epoch 6\tavg epoch loss = nan\tavg epoch acc = 0.1013\n","epoch 7\tavg epoch loss = nan\tavg epoch acc = 0.1013\n","epoch 8\tavg epoch loss = nan\tavg epoch acc = 0.1013\n","epoch 9\tavg epoch loss = nan\tavg epoch acc = 0.1013\n","training took 44.44 s\n","Avg test loss = nan\tAvg test acc = 0.0935\n","epoch 0\tavg epoch loss = 2.37\tavg epoch acc = 0.0995\n","epoch 1\tavg epoch loss = 2.374\tavg epoch acc = 0.1001\n","epoch 2\tavg epoch loss = 2.374\tavg epoch acc = 0.1001\n","epoch 3\tavg epoch loss = 2.374\tavg epoch acc = 0.1001\n","epoch 4\tavg epoch loss = 2.374\tavg epoch acc = 0.1001\n","epoch 5\tavg epoch loss = 2.374\tavg epoch acc = 0.1001\n","epoch 6\tavg epoch loss = 2.374\tavg epoch acc = 0.1001\n","epoch 7\tavg epoch loss = nan\tavg epoch acc = 0.09863\n","epoch 8\tavg epoch loss = nan\tavg epoch acc = 0.09742\n","epoch 9\tavg epoch loss = nan\tavg epoch acc = 0.09742\n","training took 44.49 s\n","Avg test loss = nan\tAvg test acc = 0.101\n","epoch 0\tavg epoch loss = nan\tavg epoch acc = 0.0977\n","epoch 1\tavg epoch loss = nan\tavg epoch acc = 0.09742\n","epoch 2\tavg epoch loss = nan\tavg epoch acc = 0.09742\n","epoch 3\tavg epoch loss = nan\tavg epoch acc = 0.09742\n","epoch 4\tavg epoch loss = nan\tavg epoch acc = 0.09742\n","epoch 5\tavg epoch loss = nan\tavg epoch acc = 0.09742\n","epoch 6\tavg epoch loss = nan\tavg epoch acc = 0.09742\n","epoch 7\tavg epoch loss = nan\tavg epoch acc = 0.09742\n","epoch 8\tavg epoch loss = nan\tavg epoch acc = 0.09742\n","epoch 9\tavg epoch loss = nan\tavg epoch acc = 0.09742\n","training took 44.6 s\n","Avg test loss = nan\tAvg test acc = 0.101\n","{'lr': 1.0985411419875581, 'batch_size': 64}\n","epoch 0\tavg epoch loss = 4.108e+03\tavg epoch acc = 0.1004\n","epoch 1\tavg epoch loss = 1.192e+03\tavg epoch acc = 0.09738\n","epoch 2\tavg epoch loss = 23.25\tavg epoch acc = 0.09985\n","epoch 3\tavg epoch loss = 2.749\tavg epoch acc = 0.09935\n","epoch 4\tavg epoch loss = 2.335\tavg epoch acc = 0.0993\n","epoch 5\tavg epoch loss = 2.666\tavg epoch acc = 0.0992\n","epoch 6\tavg epoch loss = 2.335\tavg epoch acc = 0.0993\n","epoch 7\tavg epoch loss = 2.335\tavg epoch acc = 0.0993\n","epoch 8\tavg epoch loss = 2.335\tavg epoch acc = 0.0993\n","epoch 9\tavg epoch loss = 2.335\tavg epoch acc = 0.09917\n","training took 23.32 s\n","Avg test loss = 2.33\tAvg test acc = 0.1\n","epoch 0\tavg epoch loss = 1.937e+09\tavg epoch acc = 0.1002\n","epoch 1\tavg epoch loss = 7.436e+11\tavg epoch acc = 0.09865\n","epoch 2\tavg epoch loss = 2.212e+12\tavg epoch acc = 0.0978\n","epoch 3\tavg epoch loss = 5.899e+11\tavg epoch acc = 0.09913\n","epoch 4\tavg epoch loss = 4.98e+09\tavg epoch acc = 0.09953\n","epoch 5\tavg epoch loss = 2.038e+09\tavg epoch acc = 0.0988\n","epoch 6\tavg epoch loss = 4.187e+12\tavg epoch acc = 0.09965\n","epoch 7\tavg epoch loss = 1.966e+09\tavg epoch acc = 0.09972\n","epoch 8\tavg epoch loss = 1.39e+09\tavg epoch acc = 0.09955\n","epoch 9\tavg epoch loss = 2.336\tavg epoch acc = 0.09935\n","training took 23.35 s\n","Avg test loss = 2.34\tAvg test acc = 0.0999\n","epoch 0\tavg epoch loss = nan\tavg epoch acc = 0.1008\n","epoch 1\tavg epoch loss = nan\tavg epoch acc = 0.0994\n","epoch 2\tavg epoch loss = nan\tavg epoch acc = 0.0994\n","epoch 3\tavg epoch loss = nan\tavg epoch acc = 0.0994\n","epoch 4\tavg epoch loss = nan\tavg epoch acc = 0.0994\n","epoch 5\tavg epoch loss = nan\tavg epoch acc = 0.0994\n","epoch 6\tavg epoch loss = nan\tavg epoch acc = 0.0994\n","epoch 7\tavg epoch loss = nan\tavg epoch acc = 0.0994\n","epoch 8\tavg epoch loss = nan\tavg epoch acc = 0.0994\n","epoch 9\tavg epoch loss = nan\tavg epoch acc = 0.0994\n","training took 23.52 s\n","Avg test loss = nan\tAvg test acc = 0.0973\n","{'lr': 1.0985411419875581, 'batch_size': 128}\n","epoch 0\tavg epoch loss = nan\tavg epoch acc = 0.1003\n","epoch 1\tavg epoch loss = nan\tavg epoch acc = 0.09809\n","epoch 2\tavg epoch loss = nan\tavg epoch acc = 0.09809\n","epoch 3\tavg epoch loss = nan\tavg epoch acc = 0.09809\n","epoch 4\tavg epoch loss = nan\tavg epoch acc = 0.09809\n","epoch 5\tavg epoch loss = nan\tavg epoch acc = 0.09809\n","epoch 6\tavg epoch loss = nan\tavg epoch acc = 0.09809\n","epoch 7\tavg epoch loss = nan\tavg epoch acc = 0.09809\n","epoch 8\tavg epoch loss = nan\tavg epoch acc = 0.09809\n","epoch 9\tavg epoch loss = nan\tavg epoch acc = 0.09809\n","training took 15.62 s\n","Avg test loss = nan\tAvg test acc = 0.1\n","epoch 0\tavg epoch loss = nan\tavg epoch acc = 0.09852\n","epoch 1\tavg epoch loss = nan\tavg epoch acc = 0.09727\n","epoch 2\tavg epoch loss = nan\tavg epoch acc = 0.09727\n","epoch 3\tavg epoch loss = nan\tavg epoch acc = 0.09727\n","epoch 4\tavg epoch loss = nan\tavg epoch acc = 0.09727\n","epoch 5\tavg epoch loss = nan\tavg epoch acc = 0.09727\n","epoch 6\tavg epoch loss = nan\tavg epoch acc = 0.09727\n","epoch 7\tavg epoch loss = nan\tavg epoch acc = 0.09727\n","epoch 8\tavg epoch loss = nan\tavg epoch acc = 0.09727\n","epoch 9\tavg epoch loss = nan\tavg epoch acc = 0.09727\n","training took 15.82 s\n","Avg test loss = nan\tAvg test acc = 0.102\n","epoch 0\tavg epoch loss = nan\tavg epoch acc = 0.1027\n","epoch 1\tavg epoch loss = nan\tavg epoch acc = 0.1008\n","epoch 2\tavg epoch loss = nan\tavg epoch acc = 0.1008\n","epoch 3\tavg epoch loss = nan\tavg epoch acc = 0.1008\n","epoch 4\tavg epoch loss = nan\tavg epoch acc = 0.1008\n","epoch 5\tavg epoch loss = nan\tavg epoch acc = 0.1008\n","epoch 6\tavg epoch loss = nan\tavg epoch acc = 0.1008\n","epoch 7\tavg epoch loss = nan\tavg epoch acc = 0.1008\n","epoch 8\tavg epoch loss = nan\tavg epoch acc = 0.1008\n","epoch 9\tavg epoch loss = nan\tavg epoch acc = 0.1008\n","training took 15.9 s\n","Avg test loss = nan\tAvg test acc = 0.0945\n","{'lr': 1.1513953993264474, 'batch_size': 32}\n","epoch 0\tavg epoch loss = 6.794e+09\tavg epoch acc = 0.09997\n","epoch 1\tavg epoch loss = 3.944e+06\tavg epoch acc = 0.0973\n","epoch 2\tavg epoch loss = 2.377\tavg epoch acc = 0.09823\n","epoch 3\tavg epoch loss = 2.377\tavg epoch acc = 0.09817\n","epoch 4\tavg epoch loss = 2.378\tavg epoch acc = 0.09815\n","epoch 5\tavg epoch loss = 4.027e+03\tavg epoch acc = 0.0984\n","epoch 6\tavg epoch loss = 2.378\tavg epoch acc = 0.09803\n","epoch 7\tavg epoch loss = 2.378\tavg epoch acc = 0.09803\n","epoch 8\tavg epoch loss = 2.378\tavg epoch acc = 0.09803\n","epoch 9\tavg epoch loss = 2.378\tavg epoch acc = 0.09803\n","training took 44.61 s\n","Avg test loss = 3.61e+11\tAvg test acc = 0.0998\n","epoch 0\tavg epoch loss = 89.09\tavg epoch acc = 0.09865\n","epoch 1\tavg epoch loss = 2.379\tavg epoch acc = 0.0972\n","epoch 2\tavg epoch loss = 2.38\tavg epoch acc = 0.0972\n","epoch 3\tavg epoch loss = 2.38\tavg epoch acc = 0.0972\n","epoch 4\tavg epoch loss = 2.38\tavg epoch acc = 0.09728\n","epoch 5\tavg epoch loss = 2.38\tavg epoch acc = 0.09728\n","epoch 6\tavg epoch loss = 2.38\tavg epoch acc = 0.09728\n","epoch 7\tavg epoch loss = 2.38\tavg epoch acc = 0.09728\n","epoch 8\tavg epoch loss = 2.38\tavg epoch acc = 0.09728\n","epoch 9\tavg epoch loss = 2.38\tavg epoch acc = 0.09728\n","training took 44.6 s\n","Avg test loss = 2.35\tAvg test acc = 0.095\n","epoch 0\tavg epoch loss = 2.368\tavg epoch acc = 0.09725\n","epoch 1\tavg epoch loss = 2.371\tavg epoch acc = 0.09673\n","epoch 2\tavg epoch loss = 2.372\tavg epoch acc = 0.09703\n","epoch 3\tavg epoch loss = 2.372\tavg epoch acc = 0.09723\n","epoch 4\tavg epoch loss = 2.372\tavg epoch acc = 0.0971\n","epoch 5\tavg epoch loss = 2.372\tavg epoch acc = 0.09723\n","epoch 6\tavg epoch loss = 2.372\tavg epoch acc = 0.09723\n","epoch 7\tavg epoch loss = 2.372\tavg epoch acc = 0.09723\n","epoch 8\tavg epoch loss = 2.372\tavg epoch acc = 0.09723\n","epoch 9\tavg epoch loss = 2.372\tavg epoch acc = 0.09723\n","training took 44.64 s\n","Avg test loss = 2.35\tAvg test acc = 0.115\n","{'lr': 1.1513953993264474, 'batch_size': 64}\n","epoch 0\tavg epoch loss = nan\tavg epoch acc = 0.09985\n","epoch 1\tavg epoch loss = nan\tavg epoch acc = 0.09875\n","epoch 2\tavg epoch loss = nan\tavg epoch acc = 0.09875\n","epoch 3\tavg epoch loss = nan\tavg epoch acc = 0.09875\n","epoch 4\tavg epoch loss = nan\tavg epoch acc = 0.09875\n","epoch 5\tavg epoch loss = nan\tavg epoch acc = 0.09875\n","epoch 6\tavg epoch loss = nan\tavg epoch acc = 0.09875\n","epoch 7\tavg epoch loss = nan\tavg epoch acc = 0.09875\n","epoch 8\tavg epoch loss = nan\tavg epoch acc = 0.09875\n","epoch 9\tavg epoch loss = nan\tavg epoch acc = 0.09875\n","training took 23.47 s\n","Avg test loss = nan\tAvg test acc = 0.0986\n","epoch 0\tavg epoch loss = nan\tavg epoch acc = 0.1006\n","epoch 1\tavg epoch loss = nan\tavg epoch acc = 0.09857\n","epoch 2\tavg epoch loss = nan\tavg epoch acc = 0.09857\n","epoch 3\tavg epoch loss = nan\tavg epoch acc = 0.09857\n","epoch 4\tavg epoch loss = nan\tavg epoch acc = 0.09857\n","epoch 5\tavg epoch loss = nan\tavg epoch acc = 0.09857\n","epoch 6\tavg epoch loss = nan\tavg epoch acc = 0.09857\n","epoch 7\tavg epoch loss = nan\tavg epoch acc = 0.09857\n","epoch 8\tavg epoch loss = nan\tavg epoch acc = 0.09857\n","epoch 9\tavg epoch loss = nan\tavg epoch acc = 0.09857\n","training took 23.84 s\n","Avg test loss = nan\tAvg test acc = 0.099\n","epoch 0\tavg epoch loss = nan\tavg epoch acc = 0.1013\n","epoch 1\tavg epoch loss = nan\tavg epoch acc = 0.09882\n","epoch 2\tavg epoch loss = nan\tavg epoch acc = 0.09882\n","epoch 3\tavg epoch loss = nan\tavg epoch acc = 0.09882\n","epoch 4\tavg epoch loss = nan\tavg epoch acc = 0.09882\n","epoch 5\tavg epoch loss = nan\tavg epoch acc = 0.09882\n","epoch 6\tavg epoch loss = nan\tavg epoch acc = 0.09882\n","epoch 7\tavg epoch loss = nan\tavg epoch acc = 0.09882\n","epoch 8\tavg epoch loss = nan\tavg epoch acc = 0.09882\n","epoch 9\tavg epoch loss = nan\tavg epoch acc = 0.09882\n","training took 24.33 s\n","Avg test loss = nan\tAvg test acc = 0.0985\n","{'lr': 1.1513953993264474, 'batch_size': 128}\n","epoch 0\tavg epoch loss = nan\tavg epoch acc = 0.1001\n","epoch 1\tavg epoch loss = nan\tavg epoch acc = 0.09804\n","epoch 2\tavg epoch loss = nan\tavg epoch acc = 0.09804\n","epoch 3\tavg epoch loss = nan\tavg epoch acc = 0.09804\n","epoch 4\tavg epoch loss = nan\tavg epoch acc = 0.09804\n","epoch 5\tavg epoch loss = nan\tavg epoch acc = 0.09804\n","epoch 6\tavg epoch loss = nan\tavg epoch acc = 0.09804\n","epoch 7\tavg epoch loss = nan\tavg epoch acc = 0.09804\n","epoch 8\tavg epoch loss = nan\tavg epoch acc = 0.09804\n","epoch 9\tavg epoch loss = nan\tavg epoch acc = 0.09804\n","training took 15.84 s\n","Avg test loss = nan\tAvg test acc = 0.0999\n","epoch 0\tavg epoch loss = 2.701\tavg epoch acc = 0.1017\n","epoch 1\tavg epoch loss = 2.317\tavg epoch acc = 0.09959\n","epoch 2\tavg epoch loss = 2.318\tavg epoch acc = 0.09947\n","epoch 3\tavg epoch loss = 2.318\tavg epoch acc = 0.09929\n","epoch 4\tavg epoch loss = 2.318\tavg epoch acc = 0.09929\n","epoch 5\tavg epoch loss = 2.318\tavg epoch acc = 0.09929\n","epoch 6\tavg epoch loss = 2.318\tavg epoch acc = 0.09929\n","epoch 7\tavg epoch loss = 2.318\tavg epoch acc = 0.09929\n","epoch 8\tavg epoch loss = 2.318\tavg epoch acc = 0.09929\n","epoch 9\tavg epoch loss = 2.318\tavg epoch acc = 0.09929\n","training took 15.89 s\n","Avg test loss = 2.31\tAvg test acc = 0.0987\n","epoch 0\tavg epoch loss = nan\tavg epoch acc = 0.101\n","epoch 1\tavg epoch loss = nan\tavg epoch acc = 0.09937\n","epoch 2\tavg epoch loss = nan\tavg epoch acc = 0.09937\n","epoch 3\tavg epoch loss = nan\tavg epoch acc = 0.09937\n","epoch 4\tavg epoch loss = nan\tavg epoch acc = 0.09937\n","epoch 5\tavg epoch loss = nan\tavg epoch acc = 0.09937\n","epoch 6\tavg epoch loss = nan\tavg epoch acc = 0.09937\n","epoch 7\tavg epoch loss = nan\tavg epoch acc = 0.09937\n","epoch 8\tavg epoch loss = nan\tavg epoch acc = 0.09937\n","epoch 9\tavg epoch loss = nan\tavg epoch acc = 0.09937\n","training took 16.03 s\n","Avg test loss = nan\tAvg test acc = 0.0974\n","{'lr': 1.2067926406393286, 'batch_size': 32}\n","epoch 0\tavg epoch loss = nan\tavg epoch acc = 0.09798\n","epoch 1\tavg epoch loss = nan\tavg epoch acc = 0.0986\n","epoch 2\tavg epoch loss = nan\tavg epoch acc = 0.0986\n","epoch 3\tavg epoch loss = nan\tavg epoch acc = 0.0986\n","epoch 4\tavg epoch loss = nan\tavg epoch acc = 0.0986\n","epoch 5\tavg epoch loss = nan\tavg epoch acc = 0.0986\n","epoch 6\tavg epoch loss = nan\tavg epoch acc = 0.0986\n","epoch 7\tavg epoch loss = nan\tavg epoch acc = 0.0986\n","epoch 8\tavg epoch loss = nan\tavg epoch acc = 0.0986\n","epoch 9\tavg epoch loss = nan\tavg epoch acc = 0.0986\n","training took 45.16 s\n","Avg test loss = nan\tAvg test acc = 0.0989\n","epoch 0\tavg epoch loss = 170.5\tavg epoch acc = 0.09895\n","epoch 1\tavg epoch loss = 2.378\tavg epoch acc = 0.09915\n","epoch 2\tavg epoch loss = 2.378\tavg epoch acc = 0.09905\n","epoch 3\tavg epoch loss = 2.378\tavg epoch acc = 0.09905\n","epoch 4\tavg epoch loss = 2.379\tavg epoch acc = 0.099\n","epoch 5\tavg epoch loss = 2.379\tavg epoch acc = 0.099\n","epoch 6\tavg epoch loss = 2.379\tavg epoch acc = 0.099\n","epoch 7\tavg epoch loss = 2.379\tavg epoch acc = 0.099\n","epoch 8\tavg epoch loss = 2.379\tavg epoch acc = 0.099\n","epoch 9\tavg epoch loss = 2.379\tavg epoch acc = 0.099\n","training took 45.23 s\n","Avg test loss = 2.36\tAvg test acc = 0.113\n","epoch 0\tavg epoch loss = 13.77\tavg epoch acc = 0.1006\n","epoch 1\tavg epoch loss = 2.154e+05\tavg epoch acc = 0.1012\n","epoch 2\tavg epoch loss = 6.728e+03\tavg epoch acc = 0.09855\n","epoch 3\tavg epoch loss = 124.5\tavg epoch acc = 0.0994\n","epoch 4\tavg epoch loss = 2.378\tavg epoch acc = 0.0988\n","epoch 5\tavg epoch loss = 2.378\tavg epoch acc = 0.09882\n","epoch 6\tavg epoch loss = 2.378\tavg epoch acc = 0.09882\n","epoch 7\tavg epoch loss = 2.378\tavg epoch acc = 0.09905\n","epoch 8\tavg epoch loss = 2.538\tavg epoch acc = 0.0986\n","epoch 9\tavg epoch loss = 2.378\tavg epoch acc = 0.09882\n","training took 45.04 s\n","Avg test loss = 2.37\tAvg test acc = 0.111\n","{'lr': 1.2067926406393286, 'batch_size': 64}\n","epoch 0\tavg epoch loss = 7.077e+10\tavg epoch acc = 0.1001\n","epoch 1\tavg epoch loss = 7.862e+13\tavg epoch acc = 0.1008\n","epoch 2\tavg epoch loss = 3.653e+08\tavg epoch acc = 0.09945\n","epoch 3\tavg epoch loss = 2.339\tavg epoch acc = 0.09945\n","epoch 4\tavg epoch loss = 2.339\tavg epoch acc = 0.09945\n","epoch 5\tavg epoch loss = 2.339\tavg epoch acc = 0.09945\n","epoch 6\tavg epoch loss = 2.339\tavg epoch acc = 0.09945\n","epoch 7\tavg epoch loss = 2.339\tavg epoch acc = 0.09957\n","epoch 8\tavg epoch loss = 2.339\tavg epoch acc = 0.09957\n","epoch 9\tavg epoch loss = 2.339\tavg epoch acc = 0.09957\n","training took 23.79 s\n","Avg test loss = 3.2e+15\tAvg test acc = 0.0982\n","epoch 0\tavg epoch loss = nan\tavg epoch acc = 0.09903\n","epoch 1\tavg epoch loss = nan\tavg epoch acc = 0.09823\n","epoch 2\tavg epoch loss = nan\tavg epoch acc = 0.09823\n","epoch 3\tavg epoch loss = nan\tavg epoch acc = 0.09823\n","epoch 4\tavg epoch loss = nan\tavg epoch acc = 0.09823\n","epoch 5\tavg epoch loss = nan\tavg epoch acc = 0.09823\n","epoch 6\tavg epoch loss = nan\tavg epoch acc = 0.09823\n","epoch 7\tavg epoch loss = nan\tavg epoch acc = 0.09823\n","epoch 8\tavg epoch loss = nan\tavg epoch acc = 0.09823\n","epoch 9\tavg epoch loss = nan\tavg epoch acc = 0.09823\n","training took 23.66 s\n","Avg test loss = nan\tAvg test acc = 0.0996\n","epoch 0\tavg epoch loss = nan\tavg epoch acc = 0.1001\n","epoch 1\tavg epoch loss = nan\tavg epoch acc = 0.09892\n","epoch 2\tavg epoch loss = nan\tavg epoch acc = 0.09892\n","epoch 3\tavg epoch loss = nan\tavg epoch acc = 0.09892\n","epoch 4\tavg epoch loss = nan\tavg epoch acc = 0.09892\n","epoch 5\tavg epoch loss = nan\tavg epoch acc = 0.09892\n","epoch 6\tavg epoch loss = nan\tavg epoch acc = 0.09892\n","epoch 7\tavg epoch loss = nan\tavg epoch acc = 0.09892\n","epoch 8\tavg epoch loss = nan\tavg epoch acc = 0.09892\n","epoch 9\tavg epoch loss = nan\tavg epoch acc = 0.09892\n","training took 23.39 s\n","Avg test loss = nan\tAvg test acc = 0.0983\n","{'lr': 1.2067926406393286, 'batch_size': 128}\n","epoch 0\tavg epoch loss = nan\tavg epoch acc = 0.1016\n","epoch 1\tavg epoch loss = nan\tavg epoch acc = 0.09859\n","epoch 2\tavg epoch loss = nan\tavg epoch acc = 0.09859\n","epoch 3\tavg epoch loss = nan\tavg epoch acc = 0.09859\n","epoch 4\tavg epoch loss = nan\tavg epoch acc = 0.09859\n","epoch 5\tavg epoch loss = nan\tavg epoch acc = 0.09859\n","epoch 6\tavg epoch loss = nan\tavg epoch acc = 0.09859\n","epoch 7\tavg epoch loss = nan\tavg epoch acc = 0.09859\n","epoch 8\tavg epoch loss = nan\tavg epoch acc = 0.09859\n","epoch 9\tavg epoch loss = nan\tavg epoch acc = 0.09859\n","training took 15.68 s\n","Avg test loss = nan\tAvg test acc = 0.0988\n","epoch 0\tavg epoch loss = 4.778e+23\tavg epoch acc = 0.1056\n","epoch 1\tavg epoch loss = 2.318\tavg epoch acc = 0.1047\n","epoch 2\tavg epoch loss = 2.318\tavg epoch acc = 0.1046\n","epoch 3\tavg epoch loss = 2.318\tavg epoch acc = 0.1046\n","epoch 4\tavg epoch loss = 2.319\tavg epoch acc = 0.1045\n","epoch 5\tavg epoch loss = 2.319\tavg epoch acc = 0.1043\n","epoch 6\tavg epoch loss = 2.319\tavg epoch acc = 0.1043\n","epoch 7\tavg epoch loss = 2.319\tavg epoch acc = 0.1043\n","epoch 8\tavg epoch loss = 2.319\tavg epoch acc = 0.1043\n","epoch 9\tavg epoch loss = 2.319\tavg epoch acc = 0.1043\n","training took 15.95 s\n","Avg test loss = 2.31\tAvg test acc = 0.0986\n","epoch 0\tavg epoch loss = 2.32\tavg epoch acc = 0.1035\n","epoch 1\tavg epoch loss = 2.32\tavg epoch acc = 0.1018\n","epoch 2\tavg epoch loss = 3.097\tavg epoch acc = 0.1004\n","epoch 3\tavg epoch loss = 4.002e+12\tavg epoch acc = 0.1\n","epoch 4\tavg epoch loss = 7.262e+14\tavg epoch acc = 0.1018\n","epoch 5\tavg epoch loss = 6.666e+17\tavg epoch acc = 0.1014\n","epoch 6\tavg epoch loss = 8.774e+19\tavg epoch acc = 0.1036\n","epoch 7\tavg epoch loss = 2.495e+16\tavg epoch acc = 0.1018\n","epoch 8\tavg epoch loss = 5.399e+15\tavg epoch acc = 0.1023\n","epoch 9\tavg epoch loss = 1.087e+15\tavg epoch acc = 0.1018\n","training took 15.93 s\n","Avg test loss = 18.6\tAvg test acc = 0.0956\n","{'lr': 1.264855216855296, 'batch_size': 32}\n","epoch 0\tavg epoch loss = 3.074\tavg epoch acc = 0.09753\n","epoch 1\tavg epoch loss = 2.377\tavg epoch acc = 0.0966\n","epoch 2\tavg epoch loss = 2.378\tavg epoch acc = 0.09663\n","epoch 3\tavg epoch loss = 2.378\tavg epoch acc = 0.0966\n","epoch 4\tavg epoch loss = 2.378\tavg epoch acc = 0.0966\n","epoch 5\tavg epoch loss = 2.378\tavg epoch acc = 0.09657\n","epoch 6\tavg epoch loss = 2.378\tavg epoch acc = 0.0966\n","epoch 7\tavg epoch loss = 2.378\tavg epoch acc = 0.0966\n","epoch 8\tavg epoch loss = 2.378\tavg epoch acc = 0.0966\n","epoch 9\tavg epoch loss = 2.378\tavg epoch acc = 0.0966\n","training took 45.07 s\n","Avg test loss = 2.35\tAvg test acc = 0.0982\n","epoch 0\tavg epoch loss = nan\tavg epoch acc = 0.0986\n","epoch 1\tavg epoch loss = nan\tavg epoch acc = 0.09725\n","epoch 2\tavg epoch loss = nan\tavg epoch acc = 0.09725\n","epoch 3\tavg epoch loss = nan\tavg epoch acc = 0.09725\n","epoch 4\tavg epoch loss = nan\tavg epoch acc = 0.09725\n","epoch 5\tavg epoch loss = nan\tavg epoch acc = 0.09725\n","epoch 6\tavg epoch loss = nan\tavg epoch acc = 0.09725\n","epoch 7\tavg epoch loss = nan\tavg epoch acc = 0.09725\n","epoch 8\tavg epoch loss = nan\tavg epoch acc = 0.09725\n","epoch 9\tavg epoch loss = nan\tavg epoch acc = 0.09725\n","training took 45.1 s\n","Avg test loss = nan\tAvg test acc = 0.102\n","epoch 0\tavg epoch loss = 2.903\tavg epoch acc = 0.09703\n","epoch 1\tavg epoch loss = 2.404\tavg epoch acc = 0.09585\n","epoch 2\tavg epoch loss = 2.378\tavg epoch acc = 0.0959\n","epoch 3\tavg epoch loss = 2.378\tavg epoch acc = 0.09588\n","epoch 4\tavg epoch loss = 2.378\tavg epoch acc = 0.09595\n","epoch 5\tavg epoch loss = 2.378\tavg epoch acc = 0.09595\n","epoch 6\tavg epoch loss = 2.378\tavg epoch acc = 0.09602\n","epoch 7\tavg epoch loss = 2.378\tavg epoch acc = 0.09602\n","epoch 8\tavg epoch loss = 2.378\tavg epoch acc = 0.09602\n","epoch 9\tavg epoch loss = 2.378\tavg epoch acc = 0.09602\n","training took 45.14 s\n","Avg test loss = 2.38\tAvg test acc = 0.1\n","{'lr': 1.264855216855296, 'batch_size': 64}\n","epoch 0\tavg epoch loss = nan\tavg epoch acc = 0.09945\n","epoch 1\tavg epoch loss = nan\tavg epoch acc = 0.09942\n","epoch 2\tavg epoch loss = nan\tavg epoch acc = 0.09942\n","epoch 3\tavg epoch loss = nan\tavg epoch acc = 0.09942\n","epoch 4\tavg epoch loss = nan\tavg epoch acc = 0.09942\n","epoch 5\tavg epoch loss = nan\tavg epoch acc = 0.09942\n","epoch 6\tavg epoch loss = nan\tavg epoch acc = 0.09942\n","epoch 7\tavg epoch loss = nan\tavg epoch acc = 0.09942\n","epoch 8\tavg epoch loss = nan\tavg epoch acc = 0.09942\n","epoch 9\tavg epoch loss = nan\tavg epoch acc = 0.09942\n","training took 23.78 s\n","Avg test loss = nan\tAvg test acc = 0.0972\n","epoch 0\tavg epoch loss = 5.171e+04\tavg epoch acc = 0.1009\n","epoch 1\tavg epoch loss = 2.337\tavg epoch acc = 0.1021\n","epoch 2\tavg epoch loss = 2.337\tavg epoch acc = 0.1021\n","epoch 3\tavg epoch loss = 2.338\tavg epoch acc = 0.1021\n","epoch 4\tavg epoch loss = 2.338\tavg epoch acc = 0.1021\n","epoch 5\tavg epoch loss = 2.338\tavg epoch acc = 0.1021\n","epoch 6\tavg epoch loss = 2.338\tavg epoch acc = 0.1022\n","epoch 7\tavg epoch loss = 2.338\tavg epoch acc = 0.1022\n","epoch 8\tavg epoch loss = 2.338\tavg epoch acc = 0.1022\n","epoch 9\tavg epoch loss = 2.338\tavg epoch acc = 0.1022\n","training took 24.01 s\n","Avg test loss = 2.3\tAvg test acc = 0.101\n","epoch 0\tavg epoch loss = 6.53e+20\tavg epoch acc = 0.1004\n","epoch 1\tavg epoch loss = 2.337\tavg epoch acc = 0.1005\n","epoch 2\tavg epoch loss = 2.337\tavg epoch acc = 0.1006\n","epoch 3\tavg epoch loss = 2.337\tavg epoch acc = 0.1005\n","epoch 4\tavg epoch loss = 2.338\tavg epoch acc = 0.1005\n","epoch 5\tavg epoch loss = 2.338\tavg epoch acc = 0.1005\n","epoch 6\tavg epoch loss = 2.338\tavg epoch acc = 0.1005\n","epoch 7\tavg epoch loss = 2.338\tavg epoch acc = 0.1005\n","epoch 8\tavg epoch loss = 2.338\tavg epoch acc = 0.1005\n","epoch 9\tavg epoch loss = 2.338\tavg epoch acc = 0.1005\n","training took 23.65 s\n","Avg test loss = 2.35\tAvg test acc = 0.0958\n","{'lr': 1.264855216855296, 'batch_size': 128}\n","epoch 0\tavg epoch loss = nan\tavg epoch acc = 0.1001\n","epoch 1\tavg epoch loss = nan\tavg epoch acc = 0.09862\n","epoch 2\tavg epoch loss = nan\tavg epoch acc = 0.09862\n","epoch 3\tavg epoch loss = nan\tavg epoch acc = 0.09862\n","epoch 4\tavg epoch loss = nan\tavg epoch acc = 0.09862\n","epoch 5\tavg epoch loss = nan\tavg epoch acc = 0.09862\n","epoch 6\tavg epoch loss = nan\tavg epoch acc = 0.09862\n","epoch 7\tavg epoch loss = nan\tavg epoch acc = 0.09862\n","epoch 8\tavg epoch loss = nan\tavg epoch acc = 0.09862\n","epoch 9\tavg epoch loss = nan\tavg epoch acc = 0.09862\n","training took 15.72 s\n","Avg test loss = nan\tAvg test acc = 0.0988\n","epoch 0\tavg epoch loss = 3.406\tavg epoch acc = 0.1032\n","epoch 1\tavg epoch loss = 1.612e+08\tavg epoch acc = 0.1017\n","epoch 2\tavg epoch loss = 1.942e+04\tavg epoch acc = 0.09887\n","epoch 3\tavg epoch loss = 2.777\tavg epoch acc = 0.09959\n","epoch 4\tavg epoch loss = 2.319\tavg epoch acc = 0.1012\n","epoch 5\tavg epoch loss = 9.032\tavg epoch acc = 0.1009\n","epoch 6\tavg epoch loss = 2.319\tavg epoch acc = 0.1012\n","epoch 7\tavg epoch loss = 65.06\tavg epoch acc = 0.1015\n","epoch 8\tavg epoch loss = 2.319\tavg epoch acc = 0.1011\n","epoch 9\tavg epoch loss = 2.319\tavg epoch acc = 0.101\n","training took 16.06 s\n","Avg test loss = 2.32\tAvg test acc = 0.0985\n","epoch 0\tavg epoch loss = 438.8\tavg epoch acc = 0.1047\n","epoch 1\tavg epoch loss = 64.48\tavg epoch acc = 0.1012\n","epoch 2\tavg epoch loss = 4.032\tavg epoch acc = 0.1035\n","epoch 3\tavg epoch loss = 19.55\tavg epoch acc = 0.1011\n","epoch 4\tavg epoch loss = 2.317\tavg epoch acc = 0.1015\n","epoch 5\tavg epoch loss = 2.317\tavg epoch acc = 0.1014\n","epoch 6\tavg epoch loss = 10.32\tavg epoch acc = 0.1018\n","epoch 7\tavg epoch loss = 4.342\tavg epoch acc = 0.1027\n","epoch 8\tavg epoch loss = 2.361\tavg epoch acc = 0.1016\n","epoch 9\tavg epoch loss = 2.317\tavg epoch acc = 0.1015\n","training took 16.07 s\n","Avg test loss = 2.31\tAvg test acc = 0.0966\n","{'lr': 1.3257113655901092, 'batch_size': 32}\n","epoch 0\tavg epoch loss = 2.378\tavg epoch acc = 0.09785\n","epoch 1\tavg epoch loss = 2.381\tavg epoch acc = 0.09763\n","epoch 2\tavg epoch loss = 2.361e+03\tavg epoch acc = 0.09782\n","epoch 3\tavg epoch loss = 5.118e+04\tavg epoch acc = 0.09935\n","epoch 4\tavg epoch loss = 6.053e+04\tavg epoch acc = 0.09817\n","epoch 5\tavg epoch loss = 536.6\tavg epoch acc = 0.09765\n","epoch 6\tavg epoch loss = 2.382\tavg epoch acc = 0.09753\n","epoch 7\tavg epoch loss = 2.382\tavg epoch acc = 0.09753\n","epoch 8\tavg epoch loss = 2.382\tavg epoch acc = 0.09753\n","epoch 9\tavg epoch loss = 2.382\tavg epoch acc = 0.09753\n","training took 45.8 s\n","Avg test loss = 2.23e+06\tAvg test acc = 0.0994\n","epoch 0\tavg epoch loss = nan\tavg epoch acc = 0.09932\n","epoch 1\tavg epoch loss = nan\tavg epoch acc = 0.09935\n","epoch 2\tavg epoch loss = nan\tavg epoch acc = 0.09935\n","epoch 3\tavg epoch loss = nan\tavg epoch acc = 0.09935\n","epoch 4\tavg epoch loss = nan\tavg epoch acc = 0.09935\n","epoch 5\tavg epoch loss = nan\tavg epoch acc = 0.09935\n","epoch 6\tavg epoch loss = nan\tavg epoch acc = 0.09935\n","epoch 7\tavg epoch loss = nan\tavg epoch acc = 0.09935\n","epoch 8\tavg epoch loss = nan\tavg epoch acc = 0.09935\n","epoch 9\tavg epoch loss = nan\tavg epoch acc = 0.09935\n","training took 45.68 s\n","Avg test loss = nan\tAvg test acc = 0.0974\n","epoch 0\tavg epoch loss = nan\tavg epoch acc = 0.09922\n","epoch 1\tavg epoch loss = nan\tavg epoch acc = 0.09953\n","epoch 2\tavg epoch loss = nan\tavg epoch acc = 0.09953\n","epoch 3\tavg epoch loss = nan\tavg epoch acc = 0.09953\n","epoch 4\tavg epoch loss = nan\tavg epoch acc = 0.09953\n","epoch 5\tavg epoch loss = nan\tavg epoch acc = 0.09953\n","epoch 6\tavg epoch loss = nan\tavg epoch acc = 0.09953\n","epoch 7\tavg epoch loss = nan\tavg epoch acc = 0.09953\n","epoch 8\tavg epoch loss = nan\tavg epoch acc = 0.09953\n","epoch 9\tavg epoch loss = nan\tavg epoch acc = 0.09953\n","training took 45.63 s\n","Avg test loss = nan\tAvg test acc = 0.0971\n","{'lr': 1.3257113655901092, 'batch_size': 64}\n","epoch 0\tavg epoch loss = 116.7\tavg epoch acc = 0.1032\n","epoch 1\tavg epoch loss = 3.746e+03\tavg epoch acc = 0.0998\n","epoch 2\tavg epoch loss = 1.17e+04\tavg epoch acc = 0.1028\n","epoch 3\tavg epoch loss = 90.09\tavg epoch acc = 0.1002\n","epoch 4\tavg epoch loss = 2.339\tavg epoch acc = 0.1005\n","epoch 5\tavg epoch loss = 2.339\tavg epoch acc = 0.1003\n","epoch 6\tavg epoch loss = 2.339\tavg epoch acc = 0.1003\n","epoch 7\tavg epoch loss = 2.339\tavg epoch acc = 0.1003\n","epoch 8\tavg epoch loss = 2.339\tavg epoch acc = 0.1003\n","epoch 9\tavg epoch loss = 2.339\tavg epoch acc = 0.1003\n","training took 24.0 s\n","Avg test loss = 2.31\tAvg test acc = 0.098\n","epoch 0\tavg epoch loss = 2.339\tavg epoch acc = 0.1004\n","epoch 1\tavg epoch loss = 6.574\tavg epoch acc = 0.09895\n","epoch 2\tavg epoch loss = 30.51\tavg epoch acc = 0.09828\n","epoch 3\tavg epoch loss = 28.53\tavg epoch acc = 0.1\n","epoch 4\tavg epoch loss = 66.18\tavg epoch acc = 0.09963\n","epoch 5\tavg epoch loss = 2.433\tavg epoch acc = 0.09967\n","epoch 6\tavg epoch loss = 2.399\tavg epoch acc = 0.1002\n","epoch 7\tavg epoch loss = 2.34\tavg epoch acc = 0.09988\n","epoch 8\tavg epoch loss = 2.34\tavg epoch acc = 0.09988\n","epoch 9\tavg epoch loss = 2.34\tavg epoch acc = 0.09988\n","training took 23.98 s\n","Avg test loss = 2.33\tAvg test acc = 0.0998\n","epoch 0\tavg epoch loss = 294.9\tavg epoch acc = 0.1002\n","epoch 1\tavg epoch loss = 9.128e+03\tavg epoch acc = 0.1013\n","epoch 2\tavg epoch loss = 2.363e+04\tavg epoch acc = 0.09915\n","epoch 3\tavg epoch loss = 4.444e+05\tavg epoch acc = 0.09905\n","epoch 4\tavg epoch loss = 5.993e+07\tavg epoch acc = 0.1016\n","epoch 5\tavg epoch loss = 1.331e+05\tavg epoch acc = 0.1002\n","epoch 6\tavg epoch loss = 5.397e+04\tavg epoch acc = 0.1002\n","epoch 7\tavg epoch loss = 53.44\tavg epoch acc = 0.09997\n","epoch 8\tavg epoch loss = 7.887e+03\tavg epoch acc = 0.09985\n","epoch 9\tavg epoch loss = 7.179e+03\tavg epoch acc = 0.1006\n","training took 23.81 s\n","Avg test loss = 2.62e+09\tAvg test acc = 0.103\n","{'lr': 1.3257113655901092, 'batch_size': 128}\n","epoch 0\tavg epoch loss = nan\tavg epoch acc = 0.1021\n","epoch 1\tavg epoch loss = nan\tavg epoch acc = 0.09944\n","epoch 2\tavg epoch loss = nan\tavg epoch acc = 0.09944\n","epoch 3\tavg epoch loss = nan\tavg epoch acc = 0.09944\n","epoch 4\tavg epoch loss = nan\tavg epoch acc = 0.09944\n","epoch 5\tavg epoch loss = nan\tavg epoch acc = 0.09944\n","epoch 6\tavg epoch loss = nan\tavg epoch acc = 0.09944\n","epoch 7\tavg epoch loss = nan\tavg epoch acc = 0.09944\n","epoch 8\tavg epoch loss = nan\tavg epoch acc = 0.09944\n","epoch 9\tavg epoch loss = nan\tavg epoch acc = 0.09944\n","training took 15.76 s\n","Avg test loss = nan\tAvg test acc = 0.0974\n","epoch 0\tavg epoch loss = 1.143e+06\tavg epoch acc = 0.1028\n","epoch 1\tavg epoch loss = 2.318\tavg epoch acc = 0.1021\n","epoch 2\tavg epoch loss = 2.319\tavg epoch acc = 0.1021\n","epoch 3\tavg epoch loss = 2.319\tavg epoch acc = 0.1021\n","epoch 4\tavg epoch loss = 2.319\tavg epoch acc = 0.1021\n","epoch 5\tavg epoch loss = 2.319\tavg epoch acc = 0.1021\n","epoch 6\tavg epoch loss = 2.319\tavg epoch acc = 0.1021\n","epoch 7\tavg epoch loss = 2.319\tavg epoch acc = 0.1019\n","epoch 8\tavg epoch loss = 2.319\tavg epoch acc = 0.1019\n","epoch 9\tavg epoch loss = 2.319\tavg epoch acc = 0.1019\n","training took 16.08 s\n","Avg test loss = 2.34\tAvg test acc = 0.099\n","epoch 0\tavg epoch loss = nan\tavg epoch acc = 0.1011\n","epoch 1\tavg epoch loss = nan\tavg epoch acc = 0.09877\n","epoch 2\tavg epoch loss = nan\tavg epoch acc = 0.09877\n","epoch 3\tavg epoch loss = nan\tavg epoch acc = 0.09877\n","epoch 4\tavg epoch loss = nan\tavg epoch acc = 0.09877\n","epoch 5\tavg epoch loss = nan\tavg epoch acc = 0.09877\n","epoch 6\tavg epoch loss = nan\tavg epoch acc = 0.09877\n","epoch 7\tavg epoch loss = nan\tavg epoch acc = 0.09877\n","epoch 8\tavg epoch loss = nan\tavg epoch acc = 0.09877\n","epoch 9\tavg epoch loss = nan\tavg epoch acc = 0.09877\n","training took 16.08 s\n","Avg test loss = nan\tAvg test acc = 0.0985\n","{'lr': 1.3894954943731377, 'batch_size': 32}\n","epoch 0\tavg epoch loss = nan\tavg epoch acc = 0.09978\n","epoch 1\tavg epoch loss = nan\tavg epoch acc = 0.09957\n","epoch 2\tavg epoch loss = nan\tavg epoch acc = 0.09957\n","epoch 3\tavg epoch loss = nan\tavg epoch acc = 0.09957\n","epoch 4\tavg epoch loss = nan\tavg epoch acc = 0.09957\n","epoch 5\tavg epoch loss = nan\tavg epoch acc = 0.09957\n","epoch 6\tavg epoch loss = nan\tavg epoch acc = 0.09957\n","epoch 7\tavg epoch loss = nan\tavg epoch acc = 0.09957\n","epoch 8\tavg epoch loss = nan\tavg epoch acc = 0.09957\n","epoch 9\tavg epoch loss = nan\tavg epoch acc = 0.09957\n","training took 45.29 s\n","Avg test loss = nan\tAvg test acc = 0.097\n","epoch 0\tavg epoch loss = 5.796\tavg epoch acc = 0.09685\n","epoch 1\tavg epoch loss = 6.606e+05\tavg epoch acc = 0.1\n","epoch 2\tavg epoch loss = 11.5\tavg epoch acc = 0.0979\n","epoch 3\tavg epoch loss = 2.384\tavg epoch acc = 0.09665\n","epoch 4\tavg epoch loss = 2.384\tavg epoch acc = 0.09665\n","epoch 5\tavg epoch loss = 2.384\tavg epoch acc = 0.09665\n","epoch 6\tavg epoch loss = 2.384\tavg epoch acc = 0.09665\n","epoch 7\tavg epoch loss = 2.384\tavg epoch acc = 0.09665\n","epoch 8\tavg epoch loss = 2.384\tavg epoch acc = 0.09665\n","epoch 9\tavg epoch loss = 2.384\tavg epoch acc = 0.09665\n","training took 44.93 s\n","Avg test loss = 2.75e+06\tAvg test acc = 0.103\n","epoch 0\tavg epoch loss = 2.38\tavg epoch acc = 0.09667\n","epoch 1\tavg epoch loss = 10.96\tavg epoch acc = 0.09745\n","epoch 2\tavg epoch loss = 4.193\tavg epoch acc = 0.09707\n","epoch 3\tavg epoch loss = 2.38\tavg epoch acc = 0.09667\n","epoch 4\tavg epoch loss = 4.348\tavg epoch acc = 0.09648\n","epoch 5\tavg epoch loss = 2.38\tavg epoch acc = 0.09667\n","epoch 6\tavg epoch loss = 2.381\tavg epoch acc = 0.09667\n","epoch 7\tavg epoch loss = 2.381\tavg epoch acc = 0.09667\n","epoch 8\tavg epoch loss = 2.381\tavg epoch acc = 0.09667\n","epoch 9\tavg epoch loss = 2.381\tavg epoch acc = 0.09667\n","training took 45.12 s\n","Avg test loss = 2.38\tAvg test acc = 0.0984\n","{'lr': 1.3894954943731377, 'batch_size': 64}\n","epoch 0\tavg epoch loss = 2.336\tavg epoch acc = 0.1013\n","epoch 1\tavg epoch loss = 2.561\tavg epoch acc = 0.1011\n","epoch 2\tavg epoch loss = 2.337\tavg epoch acc = 0.1006\n","epoch 3\tavg epoch loss = 2.337\tavg epoch acc = 0.1005\n","epoch 4\tavg epoch loss = 2.337\tavg epoch acc = 0.1005\n","epoch 5\tavg epoch loss = 2.337\tavg epoch acc = 0.1005\n","epoch 6\tavg epoch loss = 2.337\tavg epoch acc = 0.1005\n","epoch 7\tavg epoch loss = 2.337\tavg epoch acc = 0.1006\n","epoch 8\tavg epoch loss = 2.337\tavg epoch acc = 0.1006\n","epoch 9\tavg epoch loss = 2.402\tavg epoch acc = 0.1007\n","training took 23.84 s\n","Avg test loss = 2.32\tAvg test acc = 0.1\n","epoch 0\tavg epoch loss = 2.34\tavg epoch acc = 0.1003\n","epoch 1\tavg epoch loss = 2.34\tavg epoch acc = 0.09988\n","epoch 2\tavg epoch loss = 2.341\tavg epoch acc = 0.09988\n","epoch 3\tavg epoch loss = 2.341\tavg epoch acc = 0.09992\n","epoch 4\tavg epoch loss = 2.341\tavg epoch acc = 0.09992\n","epoch 5\tavg epoch loss = 2.341\tavg epoch acc = 0.09992\n","epoch 6\tavg epoch loss = 2.341\tavg epoch acc = 0.09992\n","epoch 7\tavg epoch loss = 2.341\tavg epoch acc = 0.09992\n","epoch 8\tavg epoch loss = 2.341\tavg epoch acc = 0.09992\n","epoch 9\tavg epoch loss = 2.341\tavg epoch acc = 0.09992\n","training took 23.52 s\n","Avg test loss = 2.35\tAvg test acc = 0.098\n","epoch 0\tavg epoch loss = 3.963\tavg epoch acc = 0.1023\n","epoch 1\tavg epoch loss = 2.55\tavg epoch acc = 0.1006\n","epoch 2\tavg epoch loss = 2.338\tavg epoch acc = 0.1008\n","epoch 3\tavg epoch loss = 2.338\tavg epoch acc = 0.1008\n","epoch 4\tavg epoch loss = 2.338\tavg epoch acc = 0.1008\n","epoch 5\tavg epoch loss = 2.338\tavg epoch acc = 0.1008\n","epoch 6\tavg epoch loss = 2.338\tavg epoch acc = 0.1008\n","epoch 7\tavg epoch loss = 2.338\tavg epoch acc = 0.1008\n","epoch 8\tavg epoch loss = 2.338\tavg epoch acc = 0.1008\n","epoch 9\tavg epoch loss = 2.338\tavg epoch acc = 0.1008\n","training took 23.63 s\n","Avg test loss = 2.34\tAvg test acc = 0.1\n","{'lr': 1.3894954943731377, 'batch_size': 128}\n","epoch 0\tavg epoch loss = 2.48\tavg epoch acc = 0.1034\n","epoch 1\tavg epoch loss = 2.701\tavg epoch acc = 0.1042\n","epoch 2\tavg epoch loss = 3.264\tavg epoch acc = 0.1021\n","epoch 3\tavg epoch loss = 2.462\tavg epoch acc = 0.1009\n","epoch 4\tavg epoch loss = 4.34\tavg epoch acc = 0.1009\n","epoch 5\tavg epoch loss = 2.373\tavg epoch acc = 0.1025\n","epoch 6\tavg epoch loss = 2.332\tavg epoch acc = 0.1019\n","epoch 7\tavg epoch loss = 2.831\tavg epoch acc = 0.1019\n","epoch 8\tavg epoch loss = 2.32\tavg epoch acc = 0.1022\n","epoch 9\tavg epoch loss = 2.32\tavg epoch acc = 0.1022\n","training took 15.68 s\n","Avg test loss = 2.32\tAvg test acc = 0.1\n","epoch 0\tavg epoch loss = nan\tavg epoch acc = 0.1007\n","epoch 1\tavg epoch loss = nan\tavg epoch acc = 0.09829\n","epoch 2\tavg epoch loss = nan\tavg epoch acc = 0.09829\n","epoch 3\tavg epoch loss = nan\tavg epoch acc = 0.09829\n","epoch 4\tavg epoch loss = nan\tavg epoch acc = 0.09829\n","epoch 5\tavg epoch loss = nan\tavg epoch acc = 0.09829\n","epoch 6\tavg epoch loss = nan\tavg epoch acc = 0.09829\n","epoch 7\tavg epoch loss = nan\tavg epoch acc = 0.09829\n","epoch 8\tavg epoch loss = nan\tavg epoch acc = 0.09829\n","epoch 9\tavg epoch loss = nan\tavg epoch acc = 0.09829\n","training took 15.93 s\n","Avg test loss = nan\tAvg test acc = 0.0995\n","epoch 0\tavg epoch loss = 2.357\tavg epoch acc = 0.1032\n","epoch 1\tavg epoch loss = 84.78\tavg epoch acc = 0.1006\n","epoch 2\tavg epoch loss = 2.441\tavg epoch acc = 0.1012\n","epoch 3\tavg epoch loss = 2.318\tavg epoch acc = 0.1007\n","epoch 4\tavg epoch loss = 2.328\tavg epoch acc = 0.1003\n","epoch 5\tavg epoch loss = 2.319\tavg epoch acc = 0.1006\n","epoch 6\tavg epoch loss = 2.319\tavg epoch acc = 0.1006\n","epoch 7\tavg epoch loss = 2.319\tavg epoch acc = 0.1006\n","epoch 8\tavg epoch loss = 2.319\tavg epoch acc = 0.1006\n","epoch 9\tavg epoch loss = 2.319\tavg epoch acc = 0.1006\n","training took 15.9 s\n","Avg test loss = 2.37\tAvg test acc = 0.0972\n","{'lr': 1.4563484775012439, 'batch_size': 32}\n","epoch 0\tavg epoch loss = 22.26\tavg epoch acc = 0.09523\n","epoch 1\tavg epoch loss = 2.385\tavg epoch acc = 0.09483\n","epoch 2\tavg epoch loss = 2.386\tavg epoch acc = 0.09483\n","epoch 3\tavg epoch loss = 2.386\tavg epoch acc = 0.09488\n","epoch 4\tavg epoch loss = 2.386\tavg epoch acc = 0.09488\n","epoch 5\tavg epoch loss = 2.386\tavg epoch acc = 0.09483\n","epoch 6\tavg epoch loss = 2.386\tavg epoch acc = 0.09483\n","epoch 7\tavg epoch loss = 2.386\tavg epoch acc = 0.09483\n","epoch 8\tavg epoch loss = 2.386\tavg epoch acc = 0.09483\n","epoch 9\tavg epoch loss = 2.386\tavg epoch acc = 0.09483\n","training took 45.09 s\n","Avg test loss = 2.36\tAvg test acc = 0.0972\n","epoch 0\tavg epoch loss = nan\tavg epoch acc = 0.1003\n","epoch 1\tavg epoch loss = nan\tavg epoch acc = 0.09945\n","epoch 2\tavg epoch loss = nan\tavg epoch acc = 0.09945\n","epoch 3\tavg epoch loss = nan\tavg epoch acc = 0.09945\n","epoch 4\tavg epoch loss = nan\tavg epoch acc = 0.09945\n","epoch 5\tavg epoch loss = nan\tavg epoch acc = 0.09945\n","epoch 6\tavg epoch loss = nan\tavg epoch acc = 0.09945\n","epoch 7\tavg epoch loss = nan\tavg epoch acc = 0.09945\n","epoch 8\tavg epoch loss = nan\tavg epoch acc = 0.09945\n","epoch 9\tavg epoch loss = nan\tavg epoch acc = 0.09945\n","training took 44.83 s\n","Avg test loss = nan\tAvg test acc = 0.0973\n","epoch 0\tavg epoch loss = 4.918e+31\tavg epoch acc = 0.09698\n","epoch 1\tavg epoch loss = nan\tavg epoch acc = 0.09922\n","epoch 2\tavg epoch loss = nan\tavg epoch acc = 0.09863\n","epoch 3\tavg epoch loss = nan\tavg epoch acc = 0.09863\n","epoch 4\tavg epoch loss = nan\tavg epoch acc = 0.09863\n","epoch 5\tavg epoch loss = nan\tavg epoch acc = 0.09863\n","epoch 6\tavg epoch loss = nan\tavg epoch acc = 0.09863\n","epoch 7\tavg epoch loss = nan\tavg epoch acc = 0.09863\n","epoch 8\tavg epoch loss = nan\tavg epoch acc = 0.09863\n","epoch 9\tavg epoch loss = nan\tavg epoch acc = 0.09863\n","training took 44.83 s\n","Avg test loss = nan\tAvg test acc = 0.0989\n","{'lr': 1.4563484775012439, 'batch_size': 64}\n","epoch 0\tavg epoch loss = 2.898\tavg epoch acc = 0.09947\n","epoch 1\tavg epoch loss = 2.336\tavg epoch acc = 0.09842\n","epoch 2\tavg epoch loss = 2.336\tavg epoch acc = 0.09847\n","epoch 3\tavg epoch loss = 2.336\tavg epoch acc = 0.09863\n","epoch 4\tavg epoch loss = 2.336\tavg epoch acc = 0.09863\n","epoch 5\tavg epoch loss = 2.336\tavg epoch acc = 0.09863\n","epoch 6\tavg epoch loss = 2.337\tavg epoch acc = 0.09863\n","epoch 7\tavg epoch loss = 2.337\tavg epoch acc = 0.09863\n","epoch 8\tavg epoch loss = 2.337\tavg epoch acc = 0.09863\n","epoch 9\tavg epoch loss = 2.337\tavg epoch acc = 0.09863\n","training took 23.55 s\n","Avg test loss = 2.33\tAvg test acc = 0.0967\n","epoch 0\tavg epoch loss = 2.338\tavg epoch acc = 0.09853\n","epoch 1\tavg epoch loss = 2.34\tavg epoch acc = 0.0994\n","epoch 2\tavg epoch loss = nan\tavg epoch acc = 0.09905\n","epoch 3\tavg epoch loss = nan\tavg epoch acc = 0.09773\n","epoch 4\tavg epoch loss = nan\tavg epoch acc = 0.09773\n","epoch 5\tavg epoch loss = nan\tavg epoch acc = 0.09773\n","epoch 6\tavg epoch loss = nan\tavg epoch acc = 0.09773\n","epoch 7\tavg epoch loss = nan\tavg epoch acc = 0.09773\n","epoch 8\tavg epoch loss = nan\tavg epoch acc = 0.09773\n","epoch 9\tavg epoch loss = nan\tavg epoch acc = 0.09773\n","training took 23.62 s\n","Avg test loss = nan\tAvg test acc = 0.101\n","epoch 0\tavg epoch loss = nan\tavg epoch acc = 0.0993\n","epoch 1\tavg epoch loss = nan\tavg epoch acc = 0.0982\n","epoch 2\tavg epoch loss = nan\tavg epoch acc = 0.0982\n","epoch 3\tavg epoch loss = nan\tavg epoch acc = 0.0982\n","epoch 4\tavg epoch loss = nan\tavg epoch acc = 0.0982\n","epoch 5\tavg epoch loss = nan\tavg epoch acc = 0.0982\n","epoch 6\tavg epoch loss = nan\tavg epoch acc = 0.0982\n","epoch 7\tavg epoch loss = nan\tavg epoch acc = 0.0982\n","epoch 8\tavg epoch loss = nan\tavg epoch acc = 0.0982\n","epoch 9\tavg epoch loss = nan\tavg epoch acc = 0.0982\n","training took 23.69 s\n","Avg test loss = nan\tAvg test acc = 0.0998\n","{'lr': 1.4563484775012439, 'batch_size': 128}\n","epoch 0\tavg epoch loss = nan\tavg epoch acc = 0.1016\n","epoch 1\tavg epoch loss = nan\tavg epoch acc = 0.09952\n","epoch 2\tavg epoch loss = nan\tavg epoch acc = 0.09952\n","epoch 3\tavg epoch loss = nan\tavg epoch acc = 0.09952\n","epoch 4\tavg epoch loss = nan\tavg epoch acc = 0.09952\n","epoch 5\tavg epoch loss = nan\tavg epoch acc = 0.09952\n","epoch 6\tavg epoch loss = nan\tavg epoch acc = 0.09952\n","epoch 7\tavg epoch loss = nan\tavg epoch acc = 0.09952\n","epoch 8\tavg epoch loss = nan\tavg epoch acc = 0.09952\n","epoch 9\tavg epoch loss = nan\tavg epoch acc = 0.09952\n","training took 15.6 s\n","Avg test loss = nan\tAvg test acc = 0.0971\n","epoch 0\tavg epoch loss = nan\tavg epoch acc = 0.1004\n","epoch 1\tavg epoch loss = nan\tavg epoch acc = 0.09909\n","epoch 2\tavg epoch loss = nan\tavg epoch acc = 0.09909\n","epoch 3\tavg epoch loss = nan\tavg epoch acc = 0.09909\n","epoch 4\tavg epoch loss = nan\tavg epoch acc = 0.09909\n","epoch 5\tavg epoch loss = nan\tavg epoch acc = 0.09909\n","epoch 6\tavg epoch loss = nan\tavg epoch acc = 0.09909\n","epoch 7\tavg epoch loss = nan\tavg epoch acc = 0.09909\n","epoch 8\tavg epoch loss = nan\tavg epoch acc = 0.09909\n","epoch 9\tavg epoch loss = nan\tavg epoch acc = 0.09909\n","training took 15.86 s\n","Avg test loss = nan\tAvg test acc = 0.0979\n","epoch 0\tavg epoch loss = 2.326\tavg epoch acc = 0.1033\n","epoch 1\tavg epoch loss = 2.319\tavg epoch acc = 0.1018\n","epoch 2\tavg epoch loss = 2.32\tavg epoch acc = 0.1018\n","epoch 3\tavg epoch loss = 2.32\tavg epoch acc = 0.1017\n","epoch 4\tavg epoch loss = 2.32\tavg epoch acc = 0.1019\n","epoch 5\tavg epoch loss = 2.32\tavg epoch acc = 0.1019\n","epoch 6\tavg epoch loss = 2.32\tavg epoch acc = 0.1019\n","epoch 7\tavg epoch loss = 2.32\tavg epoch acc = 0.1019\n","epoch 8\tavg epoch loss = 2.32\tavg epoch acc = 0.1019\n","epoch 9\tavg epoch loss = 2.32\tavg epoch acc = 0.1019\n","training took 15.86 s\n","Avg test loss = 2.32\tAvg test acc = 0.0972\n","{'lr': 1.5264179671752334, 'batch_size': 32}\n","epoch 0\tavg epoch loss = 5.352\tavg epoch acc = 0.09732\n","epoch 1\tavg epoch loss = 2.388\tavg epoch acc = 0.09738\n","epoch 2\tavg epoch loss = 2.388\tavg epoch acc = 0.09742\n","epoch 3\tavg epoch loss = 2.388\tavg epoch acc = 0.09742\n","epoch 4\tavg epoch loss = 2.388\tavg epoch acc = 0.09742\n","epoch 5\tavg epoch loss = 2.388\tavg epoch acc = 0.09748\n","epoch 6\tavg epoch loss = 2.388\tavg epoch acc = 0.09748\n","epoch 7\tavg epoch loss = 2.388\tavg epoch acc = 0.09748\n","epoch 8\tavg epoch loss = 2.388\tavg epoch acc = 0.09735\n","epoch 9\tavg epoch loss = 2.388\tavg epoch acc = 0.09735\n","training took 44.89 s\n","Avg test loss = 2.35\tAvg test acc = 0.102\n","epoch 0\tavg epoch loss = nan\tavg epoch acc = 0.09842\n","epoch 1\tavg epoch loss = nan\tavg epoch acc = 0.09857\n","epoch 2\tavg epoch loss = nan\tavg epoch acc = 0.09857\n","epoch 3\tavg epoch loss = nan\tavg epoch acc = 0.09857\n","epoch 4\tavg epoch loss = nan\tavg epoch acc = 0.09857\n","epoch 5\tavg epoch loss = nan\tavg epoch acc = 0.09857\n","epoch 6\tavg epoch loss = nan\tavg epoch acc = 0.09857\n","epoch 7\tavg epoch loss = nan\tavg epoch acc = 0.09857\n","epoch 8\tavg epoch loss = nan\tavg epoch acc = 0.09857\n","epoch 9\tavg epoch loss = nan\tavg epoch acc = 0.09857\n","training took 44.91 s\n","Avg test loss = nan\tAvg test acc = 0.099\n","epoch 0\tavg epoch loss = 758.6\tavg epoch acc = 0.09748\n","epoch 1\tavg epoch loss = 6.052\tavg epoch acc = 0.09655\n","epoch 2\tavg epoch loss = nan\tavg epoch acc = 0.0981\n","epoch 3\tavg epoch loss = nan\tavg epoch acc = 0.09735\n","epoch 4\tavg epoch loss = nan\tavg epoch acc = 0.09735\n","epoch 5\tavg epoch loss = nan\tavg epoch acc = 0.09735\n","epoch 6\tavg epoch loss = nan\tavg epoch acc = 0.09735\n","epoch 7\tavg epoch loss = nan\tavg epoch acc = 0.09735\n","epoch 8\tavg epoch loss = nan\tavg epoch acc = 0.09735\n","epoch 9\tavg epoch loss = nan\tavg epoch acc = 0.09735\n","training took 44.78 s\n","Avg test loss = nan\tAvg test acc = 0.101\n","{'lr': 1.5264179671752334, 'batch_size': 64}\n","epoch 0\tavg epoch loss = nan\tavg epoch acc = 0.09832\n","epoch 1\tavg epoch loss = nan\tavg epoch acc = 0.09813\n","epoch 2\tavg epoch loss = nan\tavg epoch acc = 0.09813\n","epoch 3\tavg epoch loss = nan\tavg epoch acc = 0.09813\n","epoch 4\tavg epoch loss = nan\tavg epoch acc = 0.09813\n","epoch 5\tavg epoch loss = nan\tavg epoch acc = 0.09813\n","epoch 6\tavg epoch loss = nan\tavg epoch acc = 0.09813\n","epoch 7\tavg epoch loss = nan\tavg epoch acc = 0.09813\n","epoch 8\tavg epoch loss = nan\tavg epoch acc = 0.09813\n","epoch 9\tavg epoch loss = nan\tavg epoch acc = 0.09813\n","training took 23.45 s\n","Avg test loss = nan\tAvg test acc = 0.0998\n","epoch 0\tavg epoch loss = 2.346\tavg epoch acc = 0.1009\n","epoch 1\tavg epoch loss = 2.337\tavg epoch acc = 0.1009\n","epoch 2\tavg epoch loss = 2.338\tavg epoch acc = 0.101\n","epoch 3\tavg epoch loss = 2.338\tavg epoch acc = 0.101\n","epoch 4\tavg epoch loss = 2.338\tavg epoch acc = 0.1009\n","epoch 5\tavg epoch loss = 2.338\tavg epoch acc = 0.101\n","epoch 6\tavg epoch loss = 2.338\tavg epoch acc = 0.101\n","epoch 7\tavg epoch loss = 2.338\tavg epoch acc = 0.101\n","epoch 8\tavg epoch loss = 2.338\tavg epoch acc = 0.101\n","epoch 9\tavg epoch loss = 2.338\tavg epoch acc = 0.1009\n","training took 23.36 s\n","Avg test loss = 2.32\tAvg test acc = 0.112\n","epoch 0\tavg epoch loss = 2.342\tavg epoch acc = 0.1009\n","epoch 1\tavg epoch loss = 2.34\tavg epoch acc = 0.1009\n","epoch 2\tavg epoch loss = 2.343\tavg epoch acc = 0.1004\n","epoch 3\tavg epoch loss = 2.34\tavg epoch acc = 0.1005\n","epoch 4\tavg epoch loss = 2.34\tavg epoch acc = 0.1007\n","epoch 5\tavg epoch loss = 2.34\tavg epoch acc = 0.1007\n","epoch 6\tavg epoch loss = 2.34\tavg epoch acc = 0.1007\n","epoch 7\tavg epoch loss = 2.341\tavg epoch acc = 0.1008\n","epoch 8\tavg epoch loss = 2.341\tavg epoch acc = 0.1007\n","epoch 9\tavg epoch loss = 2.341\tavg epoch acc = 0.1009\n","training took 23.49 s\n","Avg test loss = 2.33\tAvg test acc = 0.1\n","{'lr': 1.5264179671752334, 'batch_size': 128}\n","epoch 0\tavg epoch loss = nan\tavg epoch acc = 0.1011\n","epoch 1\tavg epoch loss = nan\tavg epoch acc = 0.09949\n","epoch 2\tavg epoch loss = nan\tavg epoch acc = 0.09949\n","epoch 3\tavg epoch loss = nan\tavg epoch acc = 0.09949\n","epoch 4\tavg epoch loss = nan\tavg epoch acc = 0.09949\n","epoch 5\tavg epoch loss = nan\tavg epoch acc = 0.09949\n","epoch 6\tavg epoch loss = nan\tavg epoch acc = 0.09949\n","epoch 7\tavg epoch loss = nan\tavg epoch acc = 0.09949\n","epoch 8\tavg epoch loss = nan\tavg epoch acc = 0.09949\n","epoch 9\tavg epoch loss = nan\tavg epoch acc = 0.09949\n","training took 15.6 s\n","Avg test loss = nan\tAvg test acc = 0.097\n","epoch 0\tavg epoch loss = 3.312\tavg epoch acc = 0.1023\n","epoch 1\tavg epoch loss = 2.782\tavg epoch acc = 0.1014\n","epoch 2\tavg epoch loss = 2.355\tavg epoch acc = 0.101\n","epoch 3\tavg epoch loss = 2.319\tavg epoch acc = 0.1021\n","epoch 4\tavg epoch loss = 2.319\tavg epoch acc = 0.1021\n","epoch 5\tavg epoch loss = 2.319\tavg epoch acc = 0.1021\n","epoch 6\tavg epoch loss = 2.319\tavg epoch acc = 0.1021\n","epoch 7\tavg epoch loss = 2.319\tavg epoch acc = 0.1021\n","epoch 8\tavg epoch loss = 2.319\tavg epoch acc = 0.1021\n","epoch 9\tavg epoch loss = 2.329\tavg epoch acc = 0.1023\n","training took 15.8 s\n","Avg test loss = 2.31\tAvg test acc = 0.0959\n","epoch 0\tavg epoch loss = nan\tavg epoch acc = 0.1019\n","epoch 1\tavg epoch loss = nan\tavg epoch acc = 0.09927\n","epoch 2\tavg epoch loss = nan\tavg epoch acc = 0.09927\n","epoch 3\tavg epoch loss = nan\tavg epoch acc = 0.09927\n","epoch 4\tavg epoch loss = nan\tavg epoch acc = 0.09927\n","epoch 5\tavg epoch loss = nan\tavg epoch acc = 0.09927\n","epoch 6\tavg epoch loss = nan\tavg epoch acc = 0.09927\n","epoch 7\tavg epoch loss = nan\tavg epoch acc = 0.09927\n","epoch 8\tavg epoch loss = nan\tavg epoch acc = 0.09927\n","epoch 9\tavg epoch loss = nan\tavg epoch acc = 0.09927\n","training took 15.97 s\n","Avg test loss = nan\tAvg test acc = 0.0975\n","{'lr': 1.599858719606058, 'batch_size': 32}\n","epoch 0\tavg epoch loss = 3.429e+06\tavg epoch acc = 0.09882\n","epoch 1\tavg epoch loss = 7.952e+09\tavg epoch acc = 0.09803\n","epoch 2\tavg epoch loss = 1.94e+08\tavg epoch acc = 0.0995\n","epoch 3\tavg epoch loss = 8.211e+06\tavg epoch acc = 0.09945\n","epoch 4\tavg epoch loss = 3.108e+06\tavg epoch acc = 0.09853\n","epoch 5\tavg epoch loss = 2.387\tavg epoch acc = 0.09867\n","epoch 6\tavg epoch loss = 2.387\tavg epoch acc = 0.09867\n","epoch 7\tavg epoch loss = 2.387\tavg epoch acc = 0.09867\n","epoch 8\tavg epoch loss = 2.387\tavg epoch acc = 0.0987\n","epoch 9\tavg epoch loss = 2.387\tavg epoch acc = 0.0987\n","training took 44.71 s\n","Avg test loss = 2.36\tAvg test acc = 0.101\n","epoch 0\tavg epoch loss = nan\tavg epoch acc = 0.1002\n","epoch 1\tavg epoch loss = nan\tavg epoch acc = 0.09992\n","epoch 2\tavg epoch loss = nan\tavg epoch acc = 0.09992\n","epoch 3\tavg epoch loss = nan\tavg epoch acc = 0.09992\n","epoch 4\tavg epoch loss = nan\tavg epoch acc = 0.09992\n","epoch 5\tavg epoch loss = nan\tavg epoch acc = 0.09992\n","epoch 6\tavg epoch loss = nan\tavg epoch acc = 0.09992\n","epoch 7\tavg epoch loss = nan\tavg epoch acc = 0.09992\n","epoch 8\tavg epoch loss = nan\tavg epoch acc = 0.09992\n","epoch 9\tavg epoch loss = nan\tavg epoch acc = 0.09992\n","training took 44.75 s\n","Avg test loss = nan\tAvg test acc = 0.0963\n","epoch 0\tavg epoch loss = 12.36\tavg epoch acc = 0.09703\n","epoch 1\tavg epoch loss = 2.388\tavg epoch acc = 0.0961\n","epoch 2\tavg epoch loss = 2.389\tavg epoch acc = 0.09598\n","epoch 3\tavg epoch loss = 2.389\tavg epoch acc = 0.09598\n","epoch 4\tavg epoch loss = 2.389\tavg epoch acc = 0.09585\n","epoch 5\tavg epoch loss = 2.389\tavg epoch acc = 0.09582\n","epoch 6\tavg epoch loss = 2.389\tavg epoch acc = 0.0959\n","epoch 7\tavg epoch loss = 2.389\tavg epoch acc = 0.0959\n","epoch 8\tavg epoch loss = 2.389\tavg epoch acc = 0.0959\n","epoch 9\tavg epoch loss = 2.389\tavg epoch acc = 0.0959\n","training took 45.07 s\n","Avg test loss = 2.34\tAvg test acc = 0.101\n","{'lr': 1.599858719606058, 'batch_size': 64}\n","epoch 0\tavg epoch loss = 2.358\tavg epoch acc = 0.09688\n","epoch 1\tavg epoch loss = 2.342\tavg epoch acc = 0.09817\n","epoch 2\tavg epoch loss = 2.341\tavg epoch acc = 0.09803\n","epoch 3\tavg epoch loss = 2.341\tavg epoch acc = 0.09785\n","epoch 4\tavg epoch loss = 2.341\tavg epoch acc = 0.09795\n","epoch 5\tavg epoch loss = 2.341\tavg epoch acc = 0.09795\n","epoch 6\tavg epoch loss = 2.341\tavg epoch acc = 0.09795\n","epoch 7\tavg epoch loss = 2.341\tavg epoch acc = 0.09795\n","epoch 8\tavg epoch loss = 2.341\tavg epoch acc = 0.09795\n","epoch 9\tavg epoch loss = 2.341\tavg epoch acc = 0.09795\n","training took 23.36 s\n","Avg test loss = 2.32\tAvg test acc = 0.0965\n","epoch 0\tavg epoch loss = nan\tavg epoch acc = 0.1001\n","epoch 1\tavg epoch loss = nan\tavg epoch acc = 0.09842\n","epoch 2\tavg epoch loss = nan\tavg epoch acc = 0.09842\n","epoch 3\tavg epoch loss = nan\tavg epoch acc = 0.09842\n","epoch 4\tavg epoch loss = nan\tavg epoch acc = 0.09842\n","epoch 5\tavg epoch loss = nan\tavg epoch acc = 0.09842\n","epoch 6\tavg epoch loss = nan\tavg epoch acc = 0.09842\n","epoch 7\tavg epoch loss = nan\tavg epoch acc = 0.09842\n","epoch 8\tavg epoch loss = nan\tavg epoch acc = 0.09842\n","epoch 9\tavg epoch loss = nan\tavg epoch acc = 0.09842\n","training took 23.28 s\n","Avg test loss = nan\tAvg test acc = 0.0991\n","epoch 0\tavg epoch loss = 2.355\tavg epoch acc = 0.102\n","epoch 1\tavg epoch loss = 2.338\tavg epoch acc = 0.1009\n","epoch 2\tavg epoch loss = 2.338\tavg epoch acc = 0.1008\n","epoch 3\tavg epoch loss = 2.339\tavg epoch acc = 0.101\n","epoch 4\tavg epoch loss = 2.339\tavg epoch acc = 0.101\n","epoch 5\tavg epoch loss = 2.339\tavg epoch acc = 0.101\n","epoch 6\tavg epoch loss = 2.339\tavg epoch acc = 0.1011\n","epoch 7\tavg epoch loss = 2.339\tavg epoch acc = 0.1011\n","epoch 8\tavg epoch loss = 2.339\tavg epoch acc = 0.1011\n","epoch 9\tavg epoch loss = 2.339\tavg epoch acc = 0.1011\n","training took 23.37 s\n","Avg test loss = 2.34\tAvg test acc = 0.099\n","{'lr': 1.599858719606058, 'batch_size': 128}\n","epoch 0\tavg epoch loss = 6.249e+07\tavg epoch acc = 0.09964\n","epoch 1\tavg epoch loss = 2.321\tavg epoch acc = 0.09872\n","epoch 2\tavg epoch loss = 2.321\tavg epoch acc = 0.09879\n","epoch 3\tavg epoch loss = 2.321\tavg epoch acc = 0.09879\n","epoch 4\tavg epoch loss = 2.321\tavg epoch acc = 0.09877\n","epoch 5\tavg epoch loss = 2.321\tavg epoch acc = 0.09877\n","epoch 6\tavg epoch loss = 2.321\tavg epoch acc = 0.09874\n","epoch 7\tavg epoch loss = 2.321\tavg epoch acc = 0.09874\n","epoch 8\tavg epoch loss = 2.321\tavg epoch acc = 0.09874\n","epoch 9\tavg epoch loss = 2.321\tavg epoch acc = 0.09874\n","training took 15.62 s\n","Avg test loss = 2.32\tAvg test acc = 0.0968\n","epoch 0\tavg epoch loss = nan\tavg epoch acc = 0.1002\n","epoch 1\tavg epoch loss = nan\tavg epoch acc = 0.09874\n","epoch 2\tavg epoch loss = nan\tavg epoch acc = 0.09874\n","epoch 3\tavg epoch loss = nan\tavg epoch acc = 0.09874\n","epoch 4\tavg epoch loss = nan\tavg epoch acc = 0.09874\n","epoch 5\tavg epoch loss = nan\tavg epoch acc = 0.09874\n","epoch 6\tavg epoch loss = nan\tavg epoch acc = 0.09874\n","epoch 7\tavg epoch loss = nan\tavg epoch acc = 0.09874\n","epoch 8\tavg epoch loss = nan\tavg epoch acc = 0.09874\n","epoch 9\tavg epoch loss = nan\tavg epoch acc = 0.09874\n","training took 15.95 s\n","Avg test loss = nan\tAvg test acc = 0.0984\n","epoch 0\tavg epoch loss = nan\tavg epoch acc = 0.1006\n","epoch 1\tavg epoch loss = nan\tavg epoch acc = 0.09864\n","epoch 2\tavg epoch loss = nan\tavg epoch acc = 0.09864\n","epoch 3\tavg epoch loss = nan\tavg epoch acc = 0.09864\n","epoch 4\tavg epoch loss = nan\tavg epoch acc = 0.09864\n","epoch 5\tavg epoch loss = nan\tavg epoch acc = 0.09864\n","epoch 6\tavg epoch loss = nan\tavg epoch acc = 0.09864\n","epoch 7\tavg epoch loss = nan\tavg epoch acc = 0.09864\n","epoch 8\tavg epoch loss = nan\tavg epoch acc = 0.09864\n","epoch 9\tavg epoch loss = nan\tavg epoch acc = 0.09864\n","training took 15.84 s\n","Avg test loss = nan\tAvg test acc = 0.099\n","{'lr': 1.676832936811008, 'batch_size': 32}\n","epoch 0\tavg epoch loss = 2.399\tavg epoch acc = 0.0975\n","epoch 1\tavg epoch loss = 2.385\tavg epoch acc = 0.09753\n","epoch 2\tavg epoch loss = 2.385\tavg epoch acc = 0.09753\n","epoch 3\tavg epoch loss = 2.385\tavg epoch acc = 0.09753\n","epoch 4\tavg epoch loss = 2.385\tavg epoch acc = 0.09753\n","epoch 5\tavg epoch loss = 2.385\tavg epoch acc = 0.09753\n","epoch 6\tavg epoch loss = 2.385\tavg epoch acc = 0.09753\n","epoch 7\tavg epoch loss = 2.385\tavg epoch acc = 0.09753\n","epoch 8\tavg epoch loss = 2.385\tavg epoch acc = 0.09753\n","epoch 9\tavg epoch loss = 2.385\tavg epoch acc = 0.0975\n","training took 44.48 s\n","Avg test loss = 2.34\tAvg test acc = 0.101\n","epoch 0\tavg epoch loss = 392.1\tavg epoch acc = 0.09703\n","epoch 1\tavg epoch loss = 83.48\tavg epoch acc = 0.0978\n","epoch 2\tavg epoch loss = 2.39\tavg epoch acc = 0.09728\n","epoch 3\tavg epoch loss = 2.39\tavg epoch acc = 0.09732\n","epoch 4\tavg epoch loss = 2.39\tavg epoch acc = 0.09732\n","epoch 5\tavg epoch loss = 2.39\tavg epoch acc = 0.09732\n","epoch 6\tavg epoch loss = 2.39\tavg epoch acc = 0.09732\n","epoch 7\tavg epoch loss = 2.39\tavg epoch acc = 0.09738\n","epoch 8\tavg epoch loss = 2.391\tavg epoch acc = 0.09745\n","epoch 9\tavg epoch loss = 2.391\tavg epoch acc = 0.09745\n","training took 44.86 s\n","Avg test loss = 2.38\tAvg test acc = 0.0993\n","epoch 0\tavg epoch loss = 2.385\tavg epoch acc = 0.09798\n","epoch 1\tavg epoch loss = 2.388\tavg epoch acc = 0.09825\n","epoch 2\tavg epoch loss = 2.389\tavg epoch acc = 0.0983\n","epoch 3\tavg epoch loss = 2.389\tavg epoch acc = 0.0983\n","epoch 4\tavg epoch loss = 2.389\tavg epoch acc = 0.09828\n","epoch 5\tavg epoch loss = 2.389\tavg epoch acc = 0.09828\n","epoch 6\tavg epoch loss = 2.389\tavg epoch acc = 0.09828\n","epoch 7\tavg epoch loss = 2.389\tavg epoch acc = 0.09828\n","epoch 8\tavg epoch loss = 2.389\tavg epoch acc = 0.09828\n","epoch 9\tavg epoch loss = 2.389\tavg epoch acc = 0.09828\n","training took 44.47 s\n","Avg test loss = 2.34\tAvg test acc = 0.0969\n","{'lr': 1.676832936811008, 'batch_size': 64}\n","epoch 0\tavg epoch loss = 2.339\tavg epoch acc = 0.1012\n","epoch 1\tavg epoch loss = 2.339\tavg epoch acc = 0.1009\n","epoch 2\tavg epoch loss = 2.34\tavg epoch acc = 0.1011\n","epoch 3\tavg epoch loss = 2.34\tavg epoch acc = 0.1012\n","epoch 4\tavg epoch loss = 2.34\tavg epoch acc = 0.1011\n","epoch 5\tavg epoch loss = 2.34\tavg epoch acc = 0.1011\n","epoch 6\tavg epoch loss = 2.34\tavg epoch acc = 0.1011\n","epoch 7\tavg epoch loss = 2.34\tavg epoch acc = 0.1011\n","epoch 8\tavg epoch loss = 2.34\tavg epoch acc = 0.1011\n","epoch 9\tavg epoch loss = 2.34\tavg epoch acc = 0.1011\n","training took 23.36 s\n","Avg test loss = 2.32\tAvg test acc = 0.0994\n","epoch 0\tavg epoch loss = 2.869e+03\tavg epoch acc = 0.098\n","epoch 1\tavg epoch loss = 2.34\tavg epoch acc = 0.09817\n","epoch 2\tavg epoch loss = 2.341\tavg epoch acc = 0.0978\n","epoch 3\tavg epoch loss = 2.341\tavg epoch acc = 0.0978\n","epoch 4\tavg epoch loss = 2.341\tavg epoch acc = 0.0978\n","epoch 5\tavg epoch loss = 2.341\tavg epoch acc = 0.0978\n","epoch 6\tavg epoch loss = 2.341\tavg epoch acc = 0.0978\n","epoch 7\tavg epoch loss = 2.341\tavg epoch acc = 0.0978\n","epoch 8\tavg epoch loss = 2.341\tavg epoch acc = 0.0978\n","epoch 9\tavg epoch loss = 2.341\tavg epoch acc = 0.0978\n","training took 23.29 s\n","Avg test loss = 2.32\tAvg test acc = 0.0998\n","epoch 0\tavg epoch loss = 2.714\tavg epoch acc = 0.0989\n","epoch 1\tavg epoch loss = 2.317e+07\tavg epoch acc = 0.1009\n","epoch 2\tavg epoch loss = 7.018\tavg epoch acc = 0.09972\n","epoch 3\tavg epoch loss = 2.341\tavg epoch acc = 0.1001\n","epoch 4\tavg epoch loss = 2.341\tavg epoch acc = 0.1001\n","epoch 5\tavg epoch loss = 3.168\tavg epoch acc = 0.0997\n","epoch 6\tavg epoch loss = 2.342\tavg epoch acc = 0.1001\n","epoch 7\tavg epoch loss = 2.342\tavg epoch acc = 0.1001\n","epoch 8\tavg epoch loss = 2.342\tavg epoch acc = 0.1001\n","epoch 9\tavg epoch loss = 2.342\tavg epoch acc = 0.1001\n","training took 23.31 s\n","Avg test loss = 2.32\tAvg test acc = 0.1\n","{'lr': 1.676832936811008, 'batch_size': 128}\n","epoch 0\tavg epoch loss = nan\tavg epoch acc = 0.1008\n","epoch 1\tavg epoch loss = nan\tavg epoch acc = 0.09902\n","epoch 2\tavg epoch loss = nan\tavg epoch acc = 0.09902\n","epoch 3\tavg epoch loss = nan\tavg epoch acc = 0.09902\n","epoch 4\tavg epoch loss = nan\tavg epoch acc = 0.09902\n","epoch 5\tavg epoch loss = nan\tavg epoch acc = 0.09902\n","epoch 6\tavg epoch loss = nan\tavg epoch acc = 0.09902\n","epoch 7\tavg epoch loss = nan\tavg epoch acc = 0.09902\n","epoch 8\tavg epoch loss = nan\tavg epoch acc = 0.09902\n","epoch 9\tavg epoch loss = nan\tavg epoch acc = 0.09902\n","training took 15.67 s\n","Avg test loss = nan\tAvg test acc = 0.0979\n","epoch 0\tavg epoch loss = 2.379\tavg epoch acc = 0.1057\n","epoch 1\tavg epoch loss = 2.319\tavg epoch acc = 0.1026\n","epoch 2\tavg epoch loss = 2.32\tavg epoch acc = 0.1022\n","epoch 3\tavg epoch loss = 2.319\tavg epoch acc = 0.1022\n","epoch 4\tavg epoch loss = 2.319\tavg epoch acc = 0.1022\n","epoch 5\tavg epoch loss = 2.319\tavg epoch acc = 0.1022\n","epoch 6\tavg epoch loss = 2.319\tavg epoch acc = 0.1022\n","epoch 7\tavg epoch loss = 2.319\tavg epoch acc = 0.1022\n","epoch 8\tavg epoch loss = 2.319\tavg epoch acc = 0.1022\n","epoch 9\tavg epoch loss = 2.319\tavg epoch acc = 0.1022\n","training took 15.87 s\n","Avg test loss = 2.32\tAvg test acc = 0.0998\n","epoch 0\tavg epoch loss = 7.127\tavg epoch acc = 0.1002\n","epoch 1\tavg epoch loss = 2.321\tavg epoch acc = 0.09912\n","epoch 2\tavg epoch loss = 2.321\tavg epoch acc = 0.09912\n","epoch 3\tavg epoch loss = 2.321\tavg epoch acc = 0.09922\n","epoch 4\tavg epoch loss = 2.321\tavg epoch acc = 0.09922\n","epoch 5\tavg epoch loss = 2.321\tavg epoch acc = 0.09922\n","epoch 6\tavg epoch loss = 2.321\tavg epoch acc = 0.09922\n","epoch 7\tavg epoch loss = 2.321\tavg epoch acc = 0.09922\n","epoch 8\tavg epoch loss = 2.321\tavg epoch acc = 0.09922\n","epoch 9\tavg epoch loss = 2.321\tavg epoch acc = 0.09922\n","training took 15.86 s\n","Avg test loss = 2.32\tAvg test acc = 0.0985\n","{'lr': 1.7575106248547918, 'batch_size': 32}\n","epoch 0\tavg epoch loss = 2.398\tavg epoch acc = 0.0975\n","epoch 1\tavg epoch loss = 2.393\tavg epoch acc = 0.09785\n","epoch 2\tavg epoch loss = 2.393\tavg epoch acc = 0.09792\n","epoch 3\tavg epoch loss = 2.393\tavg epoch acc = 0.09792\n","epoch 4\tavg epoch loss = 2.393\tavg epoch acc = 0.09792\n","epoch 5\tavg epoch loss = 2.393\tavg epoch acc = 0.09795\n","epoch 6\tavg epoch loss = 2.393\tavg epoch acc = 0.09795\n","epoch 7\tavg epoch loss = 2.393\tavg epoch acc = 0.09795\n","epoch 8\tavg epoch loss = 2.393\tavg epoch acc = 0.09773\n","epoch 9\tavg epoch loss = 2.769\tavg epoch acc = 0.0969\n","training took 44.59 s\n","Avg test loss = 2.41\tAvg test acc = 0.0996\n","epoch 0\tavg epoch loss = 1.074e+06\tavg epoch acc = 0.1\n","epoch 1\tavg epoch loss = 2.393\tavg epoch acc = 0.09817\n","epoch 2\tavg epoch loss = 2.393\tavg epoch acc = 0.09823\n","epoch 3\tavg epoch loss = 2.393\tavg epoch acc = 0.0983\n","epoch 4\tavg epoch loss = 2.393\tavg epoch acc = 0.0983\n","epoch 5\tavg epoch loss = 2.393\tavg epoch acc = 0.0983\n","epoch 6\tavg epoch loss = 2.393\tavg epoch acc = 0.0983\n","epoch 7\tavg epoch loss = 2.393\tavg epoch acc = 0.0983\n","epoch 8\tavg epoch loss = 2.393\tavg epoch acc = 0.0983\n","epoch 9\tavg epoch loss = 2.393\tavg epoch acc = 0.0983\n","training took 44.51 s\n","Avg test loss = 2.34\tAvg test acc = 0.0996\n","epoch 0\tavg epoch loss = 245.3\tavg epoch acc = 0.09717\n","epoch 1\tavg epoch loss = 9.54e+03\tavg epoch acc = 0.09867\n","epoch 2\tavg epoch loss = 5.081\tavg epoch acc = 0.09703\n","epoch 3\tavg epoch loss = 2.412\tavg epoch acc = 0.09735\n","epoch 4\tavg epoch loss = 2.404\tavg epoch acc = 0.09753\n","epoch 5\tavg epoch loss = 2.391\tavg epoch acc = 0.09735\n","epoch 6\tavg epoch loss = 2.391\tavg epoch acc = 0.09735\n","epoch 7\tavg epoch loss = 2.391\tavg epoch acc = 0.09735\n","epoch 8\tavg epoch loss = 2.391\tavg epoch acc = 0.0973\n","epoch 9\tavg epoch loss = 2.391\tavg epoch acc = 0.0973\n","training took 44.79 s\n","Avg test loss = 2.37\tAvg test acc = 0.102\n","{'lr': 1.7575106248547918, 'batch_size': 64}\n","epoch 0\tavg epoch loss = nan\tavg epoch acc = 0.0991\n","epoch 1\tavg epoch loss = nan\tavg epoch acc = 0.09917\n","epoch 2\tavg epoch loss = nan\tavg epoch acc = 0.09917\n","epoch 3\tavg epoch loss = nan\tavg epoch acc = 0.09917\n","epoch 4\tavg epoch loss = nan\tavg epoch acc = 0.09917\n","epoch 5\tavg epoch loss = nan\tavg epoch acc = 0.09917\n","epoch 6\tavg epoch loss = nan\tavg epoch acc = 0.09917\n","epoch 7\tavg epoch loss = nan\tavg epoch acc = 0.09917\n","epoch 8\tavg epoch loss = nan\tavg epoch acc = 0.09917\n","epoch 9\tavg epoch loss = nan\tavg epoch acc = 0.09917\n","training took 23.38 s\n","Avg test loss = nan\tAvg test acc = 0.0977\n","epoch 0\tavg epoch loss = nan\tavg epoch acc = 0.09778\n","epoch 1\tavg epoch loss = nan\tavg epoch acc = 0.09773\n","epoch 2\tavg epoch loss = nan\tavg epoch acc = 0.09773\n","epoch 3\tavg epoch loss = nan\tavg epoch acc = 0.09773\n","epoch 4\tavg epoch loss = nan\tavg epoch acc = 0.09773\n","epoch 5\tavg epoch loss = nan\tavg epoch acc = 0.09773\n","epoch 6\tavg epoch loss = nan\tavg epoch acc = 0.09773\n","epoch 7\tavg epoch loss = nan\tavg epoch acc = 0.09773\n","epoch 8\tavg epoch loss = nan\tavg epoch acc = 0.09773\n","epoch 9\tavg epoch loss = nan\tavg epoch acc = 0.09773\n","training took 23.28 s\n","Avg test loss = nan\tAvg test acc = 0.101\n","epoch 0\tavg epoch loss = 2.349\tavg epoch acc = 0.09938\n","epoch 1\tavg epoch loss = 2.34\tavg epoch acc = 0.1003\n","epoch 2\tavg epoch loss = 2.34\tavg epoch acc = 0.1003\n","epoch 3\tavg epoch loss = 2.34\tavg epoch acc = 0.1003\n","epoch 4\tavg epoch loss = 2.34\tavg epoch acc = 0.1004\n","epoch 5\tavg epoch loss = 2.34\tavg epoch acc = 0.1003\n","epoch 6\tavg epoch loss = 2.34\tavg epoch acc = 0.1003\n","epoch 7\tavg epoch loss = 2.34\tavg epoch acc = 0.1003\n","epoch 8\tavg epoch loss = 2.34\tavg epoch acc = 0.1003\n","epoch 9\tavg epoch loss = 2.34\tavg epoch acc = 0.1003\n","training took 23.3 s\n","Avg test loss = 2.32\tAvg test acc = 0.0994\n","{'lr': 1.7575106248547918, 'batch_size': 128}\n","epoch 0\tavg epoch loss = 2.324\tavg epoch acc = 0.1025\n","epoch 1\tavg epoch loss = 2.321\tavg epoch acc = 0.1018\n","epoch 2\tavg epoch loss = 2.321\tavg epoch acc = 0.1011\n","epoch 3\tavg epoch loss = 2.321\tavg epoch acc = 0.1012\n","epoch 4\tavg epoch loss = 2.321\tavg epoch acc = 0.1012\n","epoch 5\tavg epoch loss = 2.321\tavg epoch acc = 0.1012\n","epoch 6\tavg epoch loss = 2.321\tavg epoch acc = 0.1012\n","epoch 7\tavg epoch loss = 2.321\tavg epoch acc = 0.1011\n","epoch 8\tavg epoch loss = 2.321\tavg epoch acc = 0.1011\n","epoch 9\tavg epoch loss = 2.321\tavg epoch acc = 0.1011\n","training took 15.64 s\n","Avg test loss = 2.32\tAvg test acc = 0.104\n","epoch 0\tavg epoch loss = nan\tavg epoch acc = 0.1013\n","epoch 1\tavg epoch loss = nan\tavg epoch acc = 0.09892\n","epoch 2\tavg epoch loss = nan\tavg epoch acc = 0.09892\n","epoch 3\tavg epoch loss = nan\tavg epoch acc = 0.09892\n","epoch 4\tavg epoch loss = nan\tavg epoch acc = 0.09892\n","epoch 5\tavg epoch loss = nan\tavg epoch acc = 0.09892\n","epoch 6\tavg epoch loss = nan\tavg epoch acc = 0.09892\n","epoch 7\tavg epoch loss = nan\tavg epoch acc = 0.09892\n","epoch 8\tavg epoch loss = nan\tavg epoch acc = 0.09892\n","epoch 9\tavg epoch loss = nan\tavg epoch acc = 0.09892\n","training took 15.63 s\n","Avg test loss = nan\tAvg test acc = 0.0983\n","epoch 0\tavg epoch loss = nan\tavg epoch acc = 0.1004\n","epoch 1\tavg epoch loss = nan\tavg epoch acc = 0.09847\n","epoch 2\tavg epoch loss = nan\tavg epoch acc = 0.09847\n","epoch 3\tavg epoch loss = nan\tavg epoch acc = 0.09847\n","epoch 4\tavg epoch loss = nan\tavg epoch acc = 0.09847\n","epoch 5\tavg epoch loss = nan\tavg epoch acc = 0.09847\n","epoch 6\tavg epoch loss = nan\tavg epoch acc = 0.09847\n","epoch 7\tavg epoch loss = nan\tavg epoch acc = 0.09847\n","epoch 8\tavg epoch loss = nan\tavg epoch acc = 0.09847\n","epoch 9\tavg epoch loss = nan\tavg epoch acc = 0.09847\n","training took 15.61 s\n","Avg test loss = nan\tAvg test acc = 0.0991\n","{'lr': 1.842069969326716, 'batch_size': 32}\n","epoch 0\tavg epoch loss = 2.404\tavg epoch acc = 0.0982\n","epoch 1\tavg epoch loss = 2.394\tavg epoch acc = 0.0985\n","epoch 2\tavg epoch loss = 2.395\tavg epoch acc = 0.09845\n","epoch 3\tavg epoch loss = 2.395\tavg epoch acc = 0.09845\n","epoch 4\tavg epoch loss = 2.395\tavg epoch acc = 0.09845\n","epoch 5\tavg epoch loss = 2.395\tavg epoch acc = 0.0985\n","epoch 6\tavg epoch loss = 2.395\tavg epoch acc = 0.0985\n","epoch 7\tavg epoch loss = 2.395\tavg epoch acc = 0.0985\n","epoch 8\tavg epoch loss = 2.395\tavg epoch acc = 0.0985\n","epoch 9\tavg epoch loss = 2.395\tavg epoch acc = 0.0985\n","training took 44.54 s\n","Avg test loss = 2.36\tAvg test acc = 0.0974\n","epoch 0\tavg epoch loss = 27.07\tavg epoch acc = 0.09525\n","epoch 1\tavg epoch loss = 3.446\tavg epoch acc = 0.09557\n","epoch 2\tavg epoch loss = 2.394\tavg epoch acc = 0.09648\n","epoch 3\tavg epoch loss = 2.394\tavg epoch acc = 0.09648\n","epoch 4\tavg epoch loss = 2.394\tavg epoch acc = 0.09648\n","epoch 5\tavg epoch loss = 2.394\tavg epoch acc = 0.09652\n","epoch 6\tavg epoch loss = 2.394\tavg epoch acc = 0.09652\n","epoch 7\tavg epoch loss = 2.394\tavg epoch acc = 0.09652\n","epoch 8\tavg epoch loss = 2.394\tavg epoch acc = 0.09657\n","epoch 9\tavg epoch loss = 2.394\tavg epoch acc = 0.09648\n","training took 44.44 s\n","Avg test loss = 2.35\tAvg test acc = 0.1\n","epoch 0\tavg epoch loss = 10.33\tavg epoch acc = 0.09548\n","epoch 1\tavg epoch loss = 2.393\tavg epoch acc = 0.09433\n","epoch 2\tavg epoch loss = 2.394\tavg epoch acc = 0.09433\n","epoch 3\tavg epoch loss = 2.394\tavg epoch acc = 0.09433\n","epoch 4\tavg epoch loss = 2.394\tavg epoch acc = 0.09435\n","epoch 5\tavg epoch loss = 2.394\tavg epoch acc = 0.0943\n","epoch 6\tavg epoch loss = 2.394\tavg epoch acc = 0.0943\n","epoch 7\tavg epoch loss = 2.394\tavg epoch acc = 0.0943\n","epoch 8\tavg epoch loss = 2.394\tavg epoch acc = 0.09425\n","epoch 9\tavg epoch loss = 2.394\tavg epoch acc = 0.09425\n","training took 44.45 s\n","Avg test loss = 2.33\tAvg test acc = 0.0976\n","{'lr': 1.842069969326716, 'batch_size': 64}\n","epoch 0\tavg epoch loss = 2.386e+23\tavg epoch acc = 0.1006\n","epoch 1\tavg epoch loss = 2.342\tavg epoch acc = 0.09953\n","epoch 2\tavg epoch loss = 2.343\tavg epoch acc = 0.0995\n","epoch 3\tavg epoch loss = 2.343\tavg epoch acc = 0.0994\n","epoch 4\tavg epoch loss = 2.343\tavg epoch acc = 0.0994\n","epoch 5\tavg epoch loss = 2.343\tavg epoch acc = 0.09942\n","epoch 6\tavg epoch loss = 2.343\tavg epoch acc = 0.09942\n","epoch 7\tavg epoch loss = 2.343\tavg epoch acc = 0.0994\n","epoch 8\tavg epoch loss = 2.343\tavg epoch acc = 0.0994\n","epoch 9\tavg epoch loss = 2.343\tavg epoch acc = 0.0994\n","training took 23.38 s\n","Avg test loss = 2.31\tAvg test acc = 0.0987\n","epoch 0\tavg epoch loss = 2.389\tavg epoch acc = 0.09995\n","epoch 1\tavg epoch loss = 2.342\tavg epoch acc = 0.0993\n","epoch 2\tavg epoch loss = 2.342\tavg epoch acc = 0.0993\n","epoch 3\tavg epoch loss = 2.342\tavg epoch acc = 0.0993\n","epoch 4\tavg epoch loss = 2.342\tavg epoch acc = 0.0993\n","epoch 5\tavg epoch loss = 2.342\tavg epoch acc = 0.0993\n","epoch 6\tavg epoch loss = 2.342\tavg epoch acc = 0.0993\n","epoch 7\tavg epoch loss = 2.343\tavg epoch acc = 0.0993\n","epoch 8\tavg epoch loss = 2.343\tavg epoch acc = 0.0993\n","epoch 9\tavg epoch loss = 2.343\tavg epoch acc = 0.09922\n","training took 23.51 s\n","Avg test loss = 2.34\tAvg test acc = 0.0936\n","epoch 0\tavg epoch loss = nan\tavg epoch acc = 0.09978\n","epoch 1\tavg epoch loss = nan\tavg epoch acc = 0.09982\n","epoch 2\tavg epoch loss = nan\tavg epoch acc = 0.09982\n","epoch 3\tavg epoch loss = nan\tavg epoch acc = 0.09982\n","epoch 4\tavg epoch loss = nan\tavg epoch acc = 0.09982\n","epoch 5\tavg epoch loss = nan\tavg epoch acc = 0.09982\n","epoch 6\tavg epoch loss = nan\tavg epoch acc = 0.09982\n","epoch 7\tavg epoch loss = nan\tavg epoch acc = 0.09982\n","epoch 8\tavg epoch loss = nan\tavg epoch acc = 0.09982\n","epoch 9\tavg epoch loss = nan\tavg epoch acc = 0.09982\n","training took 23.42 s\n","Avg test loss = nan\tAvg test acc = 0.0965\n","{'lr': 1.842069969326716, 'batch_size': 128}\n","epoch 0\tavg epoch loss = 4.607\tavg epoch acc = 0.1003\n","epoch 1\tavg epoch loss = nan\tavg epoch acc = 0.1002\n","epoch 2\tavg epoch loss = nan\tavg epoch acc = 0.09867\n","epoch 3\tavg epoch loss = nan\tavg epoch acc = 0.09867\n","epoch 4\tavg epoch loss = nan\tavg epoch acc = 0.09867\n","epoch 5\tavg epoch loss = nan\tavg epoch acc = 0.09867\n","epoch 6\tavg epoch loss = nan\tavg epoch acc = 0.09867\n","epoch 7\tavg epoch loss = nan\tavg epoch acc = 0.09867\n","epoch 8\tavg epoch loss = nan\tavg epoch acc = 0.09867\n","epoch 9\tavg epoch loss = nan\tavg epoch acc = 0.09867\n","training took 15.59 s\n","Avg test loss = nan\tAvg test acc = 0.0988\n","epoch 0\tavg epoch loss = 201.0\tavg epoch acc = 0.1031\n","epoch 1\tavg epoch loss = 5.001e+17\tavg epoch acc = 0.1003\n","epoch 2\tavg epoch loss = 1.126e+07\tavg epoch acc = 0.1005\n","epoch 3\tavg epoch loss = 2.322\tavg epoch acc = 0.1007\n","epoch 4\tavg epoch loss = 4.837e+04\tavg epoch acc = 0.1008\n","epoch 5\tavg epoch loss = 2.325\tavg epoch acc = 0.101\n","epoch 6\tavg epoch loss = 2.322\tavg epoch acc = 0.1007\n","epoch 7\tavg epoch loss = 2.322\tavg epoch acc = 0.1005\n","epoch 8\tavg epoch loss = 2.322\tavg epoch acc = 0.1005\n","epoch 9\tavg epoch loss = 2.322\tavg epoch acc = 0.1005\n","training took 15.64 s\n","Avg test loss = 2.3\tAvg test acc = 0.106\n","epoch 0\tavg epoch loss = 2.573e+04\tavg epoch acc = 0.1028\n","epoch 1\tavg epoch loss = 2.321\tavg epoch acc = 0.1026\n","epoch 2\tavg epoch loss = 2.322\tavg epoch acc = 0.1025\n","epoch 3\tavg epoch loss = 2.322\tavg epoch acc = 0.1025\n","epoch 4\tavg epoch loss = 2.322\tavg epoch acc = 0.1025\n","epoch 5\tavg epoch loss = 2.322\tavg epoch acc = 0.1025\n","epoch 6\tavg epoch loss = 2.322\tavg epoch acc = 0.1025\n","epoch 7\tavg epoch loss = 2.322\tavg epoch acc = 0.1025\n","epoch 8\tavg epoch loss = 2.322\tavg epoch acc = 0.1025\n","epoch 9\tavg epoch loss = 2.322\tavg epoch acc = 0.1025\n","training took 15.63 s\n","Avg test loss = 2.31\tAvg test acc = 0.098\n","{'lr': 1.93069772888325, 'batch_size': 32}\n","epoch 0\tavg epoch loss = nan\tavg epoch acc = 0.0986\n","epoch 1\tavg epoch loss = nan\tavg epoch acc = 0.09863\n","epoch 2\tavg epoch loss = nan\tavg epoch acc = 0.09863\n","epoch 3\tavg epoch loss = nan\tavg epoch acc = 0.09863\n","epoch 4\tavg epoch loss = nan\tavg epoch acc = 0.09863\n","epoch 5\tavg epoch loss = nan\tavg epoch acc = 0.09863\n","epoch 6\tavg epoch loss = nan\tavg epoch acc = 0.09863\n","epoch 7\tavg epoch loss = nan\tavg epoch acc = 0.09863\n","epoch 8\tavg epoch loss = nan\tavg epoch acc = 0.09863\n","epoch 9\tavg epoch loss = nan\tavg epoch acc = 0.09863\n","training took 44.54 s\n","Avg test loss = nan\tAvg test acc = 0.0989\n","epoch 0\tavg epoch loss = nan\tavg epoch acc = 0.09885\n","epoch 1\tavg epoch loss = nan\tavg epoch acc = 0.09835\n","epoch 2\tavg epoch loss = nan\tavg epoch acc = 0.09835\n","epoch 3\tavg epoch loss = nan\tavg epoch acc = 0.09835\n","epoch 4\tavg epoch loss = nan\tavg epoch acc = 0.09835\n","epoch 5\tavg epoch loss = nan\tavg epoch acc = 0.09835\n","epoch 6\tavg epoch loss = nan\tavg epoch acc = 0.09835\n","epoch 7\tavg epoch loss = nan\tavg epoch acc = 0.09835\n","epoch 8\tavg epoch loss = nan\tavg epoch acc = 0.09835\n","epoch 9\tavg epoch loss = nan\tavg epoch acc = 0.09835\n","training took 44.43 s\n","Avg test loss = nan\tAvg test acc = 0.0994\n","epoch 0\tavg epoch loss = 1.378e+10\tavg epoch acc = 0.09602\n","epoch 1\tavg epoch loss = 2.396\tavg epoch acc = 0.0957\n","epoch 2\tavg epoch loss = 2.396\tavg epoch acc = 0.09585\n","epoch 3\tavg epoch loss = 2.396\tavg epoch acc = 0.09585\n","epoch 4\tavg epoch loss = 2.396\tavg epoch acc = 0.09585\n","epoch 5\tavg epoch loss = 2.396\tavg epoch acc = 0.09585\n","epoch 6\tavg epoch loss = 2.396\tavg epoch acc = 0.09585\n","epoch 7\tavg epoch loss = 2.396\tavg epoch acc = 0.09582\n","epoch 8\tavg epoch loss = 2.396\tavg epoch acc = 0.09582\n","epoch 9\tavg epoch loss = 2.396\tavg epoch acc = 0.09582\n","training took 44.47 s\n","Avg test loss = 2.35\tAvg test acc = 0.0986\n","{'lr': 1.93069772888325, 'batch_size': 64}\n","epoch 0\tavg epoch loss = 2.347\tavg epoch acc = 0.09965\n","epoch 1\tavg epoch loss = 2.345\tavg epoch acc = 0.1012\n","epoch 2\tavg epoch loss = 2.345\tavg epoch acc = 0.1012\n","epoch 3\tavg epoch loss = 2.345\tavg epoch acc = 0.1012\n","epoch 4\tavg epoch loss = 2.345\tavg epoch acc = 0.1013\n","epoch 5\tavg epoch loss = 2.345\tavg epoch acc = 0.1013\n","epoch 6\tavg epoch loss = 2.345\tavg epoch acc = 0.1013\n","epoch 7\tavg epoch loss = 2.345\tavg epoch acc = 0.1013\n","epoch 8\tavg epoch loss = 2.345\tavg epoch acc = 0.1013\n","epoch 9\tavg epoch loss = 2.345\tavg epoch acc = 0.1013\n","training took 23.15 s\n","Avg test loss = 2.32\tAvg test acc = 0.0997\n","epoch 0\tavg epoch loss = 115.3\tavg epoch acc = 0.09825\n","epoch 1\tavg epoch loss = 2.444\tavg epoch acc = 0.09897\n","epoch 2\tavg epoch loss = 2.36\tavg epoch acc = 0.09865\n","epoch 3\tavg epoch loss = 2.343\tavg epoch acc = 0.09875\n","epoch 4\tavg epoch loss = 2.343\tavg epoch acc = 0.09875\n","epoch 5\tavg epoch loss = 2.343\tavg epoch acc = 0.09875\n","epoch 6\tavg epoch loss = 2.343\tavg epoch acc = 0.09875\n","epoch 7\tavg epoch loss = 2.343\tavg epoch acc = 0.09875\n","epoch 8\tavg epoch loss = 2.343\tavg epoch acc = 0.09875\n","epoch 9\tavg epoch loss = 2.343\tavg epoch acc = 0.09875\n","training took 23.34 s\n","Avg test loss = 2.32\tAvg test acc = 0.101\n","epoch 0\tavg epoch loss = 2.345\tavg epoch acc = 0.1015\n","epoch 1\tavg epoch loss = 2.345\tavg epoch acc = 0.1011\n","epoch 2\tavg epoch loss = 2.345\tavg epoch acc = 0.1009\n","epoch 3\tavg epoch loss = 2.345\tavg epoch acc = 0.1009\n","epoch 4\tavg epoch loss = 2.345\tavg epoch acc = 0.1009\n","epoch 5\tavg epoch loss = 2.345\tavg epoch acc = 0.1009\n","epoch 6\tavg epoch loss = 2.345\tavg epoch acc = 0.1009\n","epoch 7\tavg epoch loss = 2.345\tavg epoch acc = 0.1009\n","epoch 8\tavg epoch loss = 2.345\tavg epoch acc = 0.1009\n","epoch 9\tavg epoch loss = 2.345\tavg epoch acc = 0.1009\n","training took 23.33 s\n","Avg test loss = 2.32\tAvg test acc = 0.0986\n","{'lr': 1.93069772888325, 'batch_size': 128}\n","epoch 0\tavg epoch loss = 3.61\tavg epoch acc = 0.1015\n","epoch 1\tavg epoch loss = 137.1\tavg epoch acc = 0.1007\n","epoch 2\tavg epoch loss = 104.3\tavg epoch acc = 0.09974\n","epoch 3\tavg epoch loss = 3.633\tavg epoch acc = 0.1005\n","epoch 4\tavg epoch loss = 106.0\tavg epoch acc = 0.101\n","epoch 5\tavg epoch loss = 1.493e+03\tavg epoch acc = 0.1028\n","epoch 6\tavg epoch loss = nan\tavg epoch acc = 0.09852\n","epoch 7\tavg epoch loss = nan\tavg epoch acc = 0.0966\n","epoch 8\tavg epoch loss = nan\tavg epoch acc = 0.0966\n","epoch 9\tavg epoch loss = nan\tavg epoch acc = 0.0966\n","training took 15.69 s\n","Avg test loss = nan\tAvg test acc = 0.103\n","epoch 0\tavg epoch loss = nan\tavg epoch acc = 0.101\n","epoch 1\tavg epoch loss = nan\tavg epoch acc = 0.1001\n","epoch 2\tavg epoch loss = nan\tavg epoch acc = 0.1001\n","epoch 3\tavg epoch loss = nan\tavg epoch acc = 0.1001\n","epoch 4\tavg epoch loss = nan\tavg epoch acc = 0.1001\n","epoch 5\tavg epoch loss = nan\tavg epoch acc = 0.1001\n","epoch 6\tavg epoch loss = nan\tavg epoch acc = 0.1001\n","epoch 7\tavg epoch loss = nan\tavg epoch acc = 0.1001\n","epoch 8\tavg epoch loss = nan\tavg epoch acc = 0.1001\n","epoch 9\tavg epoch loss = nan\tavg epoch acc = 0.1001\n","training took 15.77 s\n","Avg test loss = nan\tAvg test acc = 0.0958\n","epoch 0\tavg epoch loss = 2.85e+05\tavg epoch acc = 0.1019\n","epoch 1\tavg epoch loss = 913.5\tavg epoch acc = 0.103\n","epoch 2\tavg epoch loss = 25.37\tavg epoch acc = 0.102\n","epoch 3\tavg epoch loss = 2.432\tavg epoch acc = 0.1024\n","epoch 4\tavg epoch loss = 2.323\tavg epoch acc = 0.1024\n","epoch 5\tavg epoch loss = 2.322\tavg epoch acc = 0.103\n","epoch 6\tavg epoch loss = 2.322\tavg epoch acc = 0.103\n","epoch 7\tavg epoch loss = 2.322\tavg epoch acc = 0.103\n","epoch 8\tavg epoch loss = 2.322\tavg epoch acc = 0.103\n","epoch 9\tavg epoch loss = 2.322\tavg epoch acc = 0.103\n","training took 15.68 s\n","Avg test loss = 2.31\tAvg test acc = 0.102\n","{'lr': 2.023589647725157, 'batch_size': 32}\n","epoch 0\tavg epoch loss = nan\tavg epoch acc = 0.09982\n","epoch 1\tavg epoch loss = nan\tavg epoch acc = 0.09928\n","epoch 2\tavg epoch loss = nan\tavg epoch acc = 0.09928\n","epoch 3\tavg epoch loss = nan\tavg epoch acc = 0.09928\n","epoch 4\tavg epoch loss = nan\tavg epoch acc = 0.09928\n","epoch 5\tavg epoch loss = nan\tavg epoch acc = 0.09928\n","epoch 6\tavg epoch loss = nan\tavg epoch acc = 0.09928\n","epoch 7\tavg epoch loss = nan\tavg epoch acc = 0.09928\n","epoch 8\tavg epoch loss = nan\tavg epoch acc = 0.09928\n","epoch 9\tavg epoch loss = nan\tavg epoch acc = 0.09928\n","training took 46.35 s\n","Avg test loss = nan\tAvg test acc = 0.0976\n","epoch 0\tavg epoch loss = 2.474e+11\tavg epoch acc = 0.09613\n","epoch 1\tavg epoch loss = 1.515e+07\tavg epoch acc = 0.09532\n","epoch 2\tavg epoch loss = 2.399\tavg epoch acc = 0.09535\n","epoch 3\tavg epoch loss = 2.399\tavg epoch acc = 0.09535\n","epoch 4\tavg epoch loss = 2.399\tavg epoch acc = 0.09535\n","epoch 5\tavg epoch loss = nan\tavg epoch acc = 0.09617\n","epoch 6\tavg epoch loss = nan\tavg epoch acc = 0.09978\n","epoch 7\tavg epoch loss = nan\tavg epoch acc = 0.09978\n","epoch 8\tavg epoch loss = nan\tavg epoch acc = 0.09978\n","epoch 9\tavg epoch loss = nan\tavg epoch acc = 0.09978\n","training took 44.77 s\n","Avg test loss = nan\tAvg test acc = 0.0966\n","epoch 0\tavg epoch loss = 4.182e+08\tavg epoch acc = 0.09492\n","epoch 1\tavg epoch loss = 2.398\tavg epoch acc = 0.09552\n","epoch 2\tavg epoch loss = 2.398\tavg epoch acc = 0.09542\n","epoch 3\tavg epoch loss = 2.398\tavg epoch acc = 0.09555\n","epoch 4\tavg epoch loss = 2.398\tavg epoch acc = 0.09548\n","epoch 5\tavg epoch loss = 2.398\tavg epoch acc = 0.0955\n","epoch 6\tavg epoch loss = 2.398\tavg epoch acc = 0.0955\n","epoch 7\tavg epoch loss = 2.398\tavg epoch acc = 0.0955\n","epoch 8\tavg epoch loss = 2.398\tavg epoch acc = 0.0955\n","epoch 9\tavg epoch loss = 2.398\tavg epoch acc = 0.0955\n","training took 44.6 s\n","Avg test loss = 1.75e+07\tAvg test acc = 0.102\n","{'lr': 2.023589647725157, 'batch_size': 64}\n","epoch 0\tavg epoch loss = 1.453e+13\tavg epoch acc = 0.09955\n","epoch 1\tavg epoch loss = 2.345\tavg epoch acc = 0.09965\n","epoch 2\tavg epoch loss = 2.345\tavg epoch acc = 0.09965\n","epoch 3\tavg epoch loss = 2.345\tavg epoch acc = 0.09965\n","epoch 4\tavg epoch loss = 2.345\tavg epoch acc = 0.09965\n","epoch 5\tavg epoch loss = 2.345\tavg epoch acc = 0.09965\n","epoch 6\tavg epoch loss = 2.345\tavg epoch acc = 0.09963\n","epoch 7\tavg epoch loss = 2.345\tavg epoch acc = 0.09963\n","epoch 8\tavg epoch loss = 2.345\tavg epoch acc = 0.09963\n","epoch 9\tavg epoch loss = 2.345\tavg epoch acc = 0.09972\n","training took 23.42 s\n","Avg test loss = 1.84e+22\tAvg test acc = 0.101\n","epoch 0\tavg epoch loss = 3.096e+10\tavg epoch acc = 0.09688\n","epoch 1\tavg epoch loss = 3.103e+07\tavg epoch acc = 0.09915\n","epoch 2\tavg epoch loss = 2.345\tavg epoch acc = 0.09867\n","epoch 3\tavg epoch loss = 2.345\tavg epoch acc = 0.09867\n","epoch 4\tavg epoch loss = 2.345\tavg epoch acc = 0.09867\n","epoch 5\tavg epoch loss = 2.345\tavg epoch acc = 0.09872\n","epoch 6\tavg epoch loss = 2.345\tavg epoch acc = 0.0988\n","epoch 7\tavg epoch loss = 2.345\tavg epoch acc = 0.0988\n","epoch 8\tavg epoch loss = 2.345\tavg epoch acc = 0.0988\n","epoch 9\tavg epoch loss = 2.345\tavg epoch acc = 0.0988\n","training took 23.54 s\n","Avg test loss = 2.33\tAvg test acc = 0.0954\n","epoch 0\tavg epoch loss = 2.138e+12\tavg epoch acc = 0.1009\n","epoch 1\tavg epoch loss = 356.8\tavg epoch acc = 0.09938\n","epoch 2\tavg epoch loss = 2.343\tavg epoch acc = 0.09925\n","epoch 3\tavg epoch loss = 2.343\tavg epoch acc = 0.0993\n","epoch 4\tavg epoch loss = 2.344\tavg epoch acc = 0.0993\n","epoch 5\tavg epoch loss = 2.344\tavg epoch acc = 0.0993\n","epoch 6\tavg epoch loss = 2.344\tavg epoch acc = 0.0993\n","epoch 7\tavg epoch loss = 2.344\tavg epoch acc = 0.0993\n","epoch 8\tavg epoch loss = 2.344\tavg epoch acc = 0.0993\n","epoch 9\tavg epoch loss = 2.344\tavg epoch acc = 0.0993\n","training took 23.36 s\n","Avg test loss = 2.34\tAvg test acc = 0.0989\n","{'lr': 2.023589647725157, 'batch_size': 128}\n","epoch 0\tavg epoch loss = 3.623\tavg epoch acc = 0.1038\n","epoch 1\tavg epoch loss = 2.327\tavg epoch acc = 0.1018\n","epoch 2\tavg epoch loss = 2.372\tavg epoch acc = 0.1017\n","epoch 3\tavg epoch loss = 2.323\tavg epoch acc = 0.1017\n","epoch 4\tavg epoch loss = 2.323\tavg epoch acc = 0.1016\n","epoch 5\tavg epoch loss = 2.323\tavg epoch acc = 0.1017\n","epoch 6\tavg epoch loss = 2.323\tavg epoch acc = 0.1017\n","epoch 7\tavg epoch loss = 2.323\tavg epoch acc = 0.1017\n","epoch 8\tavg epoch loss = 2.323\tavg epoch acc = 0.1017\n","epoch 9\tavg epoch loss = 2.323\tavg epoch acc = 0.1017\n","training took 15.81 s\n","Avg test loss = 2.31\tAvg test acc = 0.0988\n","epoch 0\tavg epoch loss = 2.775\tavg epoch acc = 0.1045\n","epoch 1\tavg epoch loss = 2.321\tavg epoch acc = 0.1034\n","epoch 2\tavg epoch loss = 2.321\tavg epoch acc = 0.1034\n","epoch 3\tavg epoch loss = 2.321\tavg epoch acc = 0.1034\n","epoch 4\tavg epoch loss = 2.321\tavg epoch acc = 0.1033\n","epoch 5\tavg epoch loss = 2.321\tavg epoch acc = 0.1033\n","epoch 6\tavg epoch loss = 2.321\tavg epoch acc = 0.1033\n","epoch 7\tavg epoch loss = 2.321\tavg epoch acc = 0.1033\n","epoch 8\tavg epoch loss = 2.321\tavg epoch acc = 0.1033\n","epoch 9\tavg epoch loss = 2.321\tavg epoch acc = 0.1033\n","training took 15.68 s\n","Avg test loss = 2.32\tAvg test acc = 0.105\n","epoch 0\tavg epoch loss = 10.57\tavg epoch acc = 0.1023\n","epoch 1\tavg epoch loss = 9.167\tavg epoch acc = 0.1015\n","epoch 2\tavg epoch loss = 56.79\tavg epoch acc = 0.09987\n","epoch 3\tavg epoch loss = 11.76\tavg epoch acc = 0.1003\n","epoch 4\tavg epoch loss = 53.33\tavg epoch acc = 0.1014\n","epoch 5\tavg epoch loss = 2.383\tavg epoch acc = 0.1005\n","epoch 6\tavg epoch loss = 2.395\tavg epoch acc = 0.1007\n","epoch 7\tavg epoch loss = 2.372\tavg epoch acc = 0.1005\n","epoch 8\tavg epoch loss = 2.402\tavg epoch acc = 0.09997\n","epoch 9\tavg epoch loss = 2.323\tavg epoch acc = 0.1006\n","training took 15.76 s\n","Avg test loss = 2.32\tAvg test acc = 0.0957\n","{'lr': 2.120950887920191, 'batch_size': 32}\n","epoch 0\tavg epoch loss = 3.558\tavg epoch acc = 0.09545\n","epoch 1\tavg epoch loss = 2.4\tavg epoch acc = 0.0957\n","epoch 2\tavg epoch loss = 7.484\tavg epoch acc = 0.09692\n","epoch 3\tavg epoch loss = 3.587e+04\tavg epoch acc = 0.09872\n","epoch 4\tavg epoch loss = 2.582\tavg epoch acc = 0.09577\n","epoch 5\tavg epoch loss = 2.4\tavg epoch acc = 0.09582\n","epoch 6\tavg epoch loss = 2.4\tavg epoch acc = 0.09582\n","epoch 7\tavg epoch loss = 2.4\tavg epoch acc = 0.09582\n","epoch 8\tavg epoch loss = 2.4\tavg epoch acc = 0.09582\n","epoch 9\tavg epoch loss = 2.4\tavg epoch acc = 0.09582\n","training took 45.01 s\n","Avg test loss = 2.33\tAvg test acc = 0.104\n","epoch 0\tavg epoch loss = nan\tavg epoch acc = 0.1002\n","epoch 1\tavg epoch loss = nan\tavg epoch acc = 0.1003\n","epoch 2\tavg epoch loss = nan\tavg epoch acc = 0.1003\n","epoch 3\tavg epoch loss = nan\tavg epoch acc = 0.1003\n","epoch 4\tavg epoch loss = nan\tavg epoch acc = 0.1003\n","epoch 5\tavg epoch loss = nan\tavg epoch acc = 0.1003\n","epoch 6\tavg epoch loss = nan\tavg epoch acc = 0.1003\n","epoch 7\tavg epoch loss = nan\tavg epoch acc = 0.1003\n","epoch 8\tavg epoch loss = nan\tavg epoch acc = 0.1003\n","epoch 9\tavg epoch loss = nan\tavg epoch acc = 0.1003\n","training took 44.59 s\n","Avg test loss = nan\tAvg test acc = 0.0956\n","epoch 0\tavg epoch loss = nan\tavg epoch acc = 0.0978\n","epoch 1\tavg epoch loss = nan\tavg epoch acc = 0.09792\n","epoch 2\tavg epoch loss = nan\tavg epoch acc = 0.09792\n","epoch 3\tavg epoch loss = nan\tavg epoch acc = 0.09792\n","epoch 4\tavg epoch loss = nan\tavg epoch acc = 0.09792\n","epoch 5\tavg epoch loss = nan\tavg epoch acc = 0.09792\n","epoch 6\tavg epoch loss = nan\tavg epoch acc = 0.09792\n","epoch 7\tavg epoch loss = nan\tavg epoch acc = 0.09792\n","epoch 8\tavg epoch loss = nan\tavg epoch acc = 0.09792\n","epoch 9\tavg epoch loss = nan\tavg epoch acc = 0.09792\n","training took 44.52 s\n","Avg test loss = nan\tAvg test acc = 0.1\n","{'lr': 2.120950887920191, 'batch_size': 64}\n","epoch 0\tavg epoch loss = 5.96e+16\tavg epoch acc = 0.09953\n","epoch 1\tavg epoch loss = 1.674e+07\tavg epoch acc = 0.09878\n","epoch 2\tavg epoch loss = 1.995e+04\tavg epoch acc = 0.0981\n","epoch 3\tavg epoch loss = 2.346\tavg epoch acc = 0.0983\n","epoch 4\tavg epoch loss = 2.346\tavg epoch acc = 0.0983\n","epoch 5\tavg epoch loss = 2.346\tavg epoch acc = 0.0983\n","epoch 6\tavg epoch loss = 2.346\tavg epoch acc = 0.0983\n","epoch 7\tavg epoch loss = 2.346\tavg epoch acc = 0.09825\n","epoch 8\tavg epoch loss = 2.346\tavg epoch acc = 0.09825\n","epoch 9\tavg epoch loss = 2.346\tavg epoch acc = 0.09825\n","training took 23.3 s\n","Avg test loss = 2.33\tAvg test acc = 0.0982\n","epoch 0\tavg epoch loss = nan\tavg epoch acc = 0.0988\n","epoch 1\tavg epoch loss = nan\tavg epoch acc = 0.09872\n","epoch 2\tavg epoch loss = nan\tavg epoch acc = 0.09872\n","epoch 3\tavg epoch loss = nan\tavg epoch acc = 0.09872\n","epoch 4\tavg epoch loss = nan\tavg epoch acc = 0.09872\n","epoch 5\tavg epoch loss = nan\tavg epoch acc = 0.09872\n","epoch 6\tavg epoch loss = nan\tavg epoch acc = 0.09872\n","epoch 7\tavg epoch loss = nan\tavg epoch acc = 0.09872\n","epoch 8\tavg epoch loss = nan\tavg epoch acc = 0.09872\n","epoch 9\tavg epoch loss = nan\tavg epoch acc = 0.09872\n","training took 23.25 s\n","Avg test loss = nan\tAvg test acc = 0.0987\n","epoch 0\tavg epoch loss = 2.376\tavg epoch acc = 0.09845\n","epoch 1\tavg epoch loss = 3.618\tavg epoch acc = 0.1016\n","epoch 2\tavg epoch loss = 2.538\tavg epoch acc = 0.09892\n","epoch 3\tavg epoch loss = 2.467\tavg epoch acc = 0.09903\n","epoch 4\tavg epoch loss = 2.409\tavg epoch acc = 0.0991\n","epoch 5\tavg epoch loss = 2.346\tavg epoch acc = 0.09907\n","epoch 6\tavg epoch loss = 2.346\tavg epoch acc = 0.09892\n","epoch 7\tavg epoch loss = 2.346\tavg epoch acc = 0.09885\n","epoch 8\tavg epoch loss = 2.346\tavg epoch acc = 0.09885\n","epoch 9\tavg epoch loss = 2.346\tavg epoch acc = 0.09885\n","training took 23.24 s\n","Avg test loss = 2.33\tAvg test acc = 0.0974\n","{'lr': 2.120950887920191, 'batch_size': 128}\n","epoch 0\tavg epoch loss = 2.442\tavg epoch acc = 0.1006\n","epoch 1\tavg epoch loss = 2.326\tavg epoch acc = 0.09992\n","epoch 2\tavg epoch loss = 2.38\tavg epoch acc = 0.1018\n","epoch 3\tavg epoch loss = 2.323\tavg epoch acc = 0.1001\n","epoch 4\tavg epoch loss = 2.402\tavg epoch acc = 0.1003\n","epoch 5\tavg epoch loss = 2.322\tavg epoch acc = 0.1003\n","epoch 6\tavg epoch loss = 2.322\tavg epoch acc = 0.1003\n","epoch 7\tavg epoch loss = 2.323\tavg epoch acc = 0.1003\n","epoch 8\tavg epoch loss = 2.323\tavg epoch acc = 0.1003\n","epoch 9\tavg epoch loss = 2.323\tavg epoch acc = 0.1003\n","training took 15.62 s\n","Avg test loss = 2.31\tAvg test acc = 0.0994\n","epoch 0\tavg epoch loss = nan\tavg epoch acc = 0.09887\n","epoch 1\tavg epoch loss = nan\tavg epoch acc = 0.09867\n","epoch 2\tavg epoch loss = nan\tavg epoch acc = 0.09867\n","epoch 3\tavg epoch loss = nan\tavg epoch acc = 0.09867\n","epoch 4\tavg epoch loss = nan\tavg epoch acc = 0.09867\n","epoch 5\tavg epoch loss = nan\tavg epoch acc = 0.09867\n","epoch 6\tavg epoch loss = nan\tavg epoch acc = 0.09867\n","epoch 7\tavg epoch loss = nan\tavg epoch acc = 0.09867\n","epoch 8\tavg epoch loss = nan\tavg epoch acc = 0.09867\n","epoch 9\tavg epoch loss = nan\tavg epoch acc = 0.09867\n","training took 15.68 s\n","Avg test loss = nan\tAvg test acc = 0.0989\n","epoch 0\tavg epoch loss = 2.953\tavg epoch acc = 0.1026\n","epoch 1\tavg epoch loss = 3.472e+14\tavg epoch acc = 0.1014\n","epoch 2\tavg epoch loss = 1.772e+05\tavg epoch acc = 0.1022\n","epoch 3\tavg epoch loss = 1.185e+10\tavg epoch acc = 0.1019\n","epoch 4\tavg epoch loss = 2.323\tavg epoch acc = 0.1\n","epoch 5\tavg epoch loss = 2.323\tavg epoch acc = 0.1001\n","epoch 6\tavg epoch loss = 2.323\tavg epoch acc = 0.1001\n","epoch 7\tavg epoch loss = 2.323\tavg epoch acc = 0.1001\n","epoch 8\tavg epoch loss = 2.323\tavg epoch acc = 0.1001\n","epoch 9\tavg epoch loss = 2.323\tavg epoch acc = 0.1001\n","training took 15.63 s\n","Avg test loss = 2.31\tAvg test acc = 0.0984\n","{'lr': 2.2229964825261948, 'batch_size': 32}\n","epoch 0\tavg epoch loss = nan\tavg epoch acc = 0.09745\n","epoch 1\tavg epoch loss = nan\tavg epoch acc = 0.09913\n","epoch 2\tavg epoch loss = nan\tavg epoch acc = 0.09913\n","epoch 3\tavg epoch loss = nan\tavg epoch acc = 0.09913\n","epoch 4\tavg epoch loss = nan\tavg epoch acc = 0.09913\n","epoch 5\tavg epoch loss = nan\tavg epoch acc = 0.09913\n","epoch 6\tavg epoch loss = nan\tavg epoch acc = 0.09913\n","epoch 7\tavg epoch loss = nan\tavg epoch acc = 0.09913\n","epoch 8\tavg epoch loss = nan\tavg epoch acc = 0.09913\n","epoch 9\tavg epoch loss = nan\tavg epoch acc = 0.09913\n","training took 44.6 s\n","Avg test loss = nan\tAvg test acc = 0.0979\n","epoch 0\tavg epoch loss = nan\tavg epoch acc = 0.098\n","epoch 1\tavg epoch loss = nan\tavg epoch acc = 0.0982\n","epoch 2\tavg epoch loss = nan\tavg epoch acc = 0.0982\n","epoch 3\tavg epoch loss = nan\tavg epoch acc = 0.0982\n","epoch 4\tavg epoch loss = nan\tavg epoch acc = 0.0982\n","epoch 5\tavg epoch loss = nan\tavg epoch acc = 0.0982\n","epoch 6\tavg epoch loss = nan\tavg epoch acc = 0.0982\n","epoch 7\tavg epoch loss = nan\tavg epoch acc = 0.0982\n","epoch 8\tavg epoch loss = nan\tavg epoch acc = 0.0982\n","epoch 9\tavg epoch loss = nan\tavg epoch acc = 0.0982\n","training took 44.82 s\n","Avg test loss = nan\tAvg test acc = 0.0998\n","epoch 0\tavg epoch loss = 18.94\tavg epoch acc = 0.09828\n","epoch 1\tavg epoch loss = 2.404\tavg epoch acc = 0.09792\n","epoch 2\tavg epoch loss = 4.034\tavg epoch acc = 0.09863\n","epoch 3\tavg epoch loss = 2.405\tavg epoch acc = 0.0982\n","epoch 4\tavg epoch loss = 2.405\tavg epoch acc = 0.0982\n","epoch 5\tavg epoch loss = 2.405\tavg epoch acc = 0.09828\n","epoch 6\tavg epoch loss = 2.405\tavg epoch acc = 0.09828\n","epoch 7\tavg epoch loss = 2.405\tavg epoch acc = 0.09828\n","epoch 8\tavg epoch loss = 2.405\tavg epoch acc = 0.09828\n","epoch 9\tavg epoch loss = 2.405\tavg epoch acc = 0.09828\n","training took 44.77 s\n","Avg test loss = 2.34\tAvg test acc = 0.112\n","{'lr': 2.2229964825261948, 'batch_size': 64}\n","epoch 0\tavg epoch loss = nan\tavg epoch acc = 0.09738\n","epoch 1\tavg epoch loss = nan\tavg epoch acc = 0.09763\n","epoch 2\tavg epoch loss = nan\tavg epoch acc = 0.09763\n","epoch 3\tavg epoch loss = nan\tavg epoch acc = 0.09763\n","epoch 4\tavg epoch loss = nan\tavg epoch acc = 0.09763\n","epoch 5\tavg epoch loss = nan\tavg epoch acc = 0.09763\n","epoch 6\tavg epoch loss = nan\tavg epoch acc = 0.09763\n","epoch 7\tavg epoch loss = nan\tavg epoch acc = 0.09763\n","epoch 8\tavg epoch loss = nan\tavg epoch acc = 0.09763\n","epoch 9\tavg epoch loss = nan\tavg epoch acc = 0.09763\n","training took 23.39 s\n","Avg test loss = nan\tAvg test acc = 0.101\n","epoch 0\tavg epoch loss = nan\tavg epoch acc = 0.09892\n","epoch 1\tavg epoch loss = nan\tavg epoch acc = 0.09895\n","epoch 2\tavg epoch loss = nan\tavg epoch acc = 0.09895\n","epoch 3\tavg epoch loss = nan\tavg epoch acc = 0.09895\n","epoch 4\tavg epoch loss = nan\tavg epoch acc = 0.09895\n","epoch 5\tavg epoch loss = nan\tavg epoch acc = 0.09895\n","epoch 6\tavg epoch loss = nan\tavg epoch acc = 0.09895\n","epoch 7\tavg epoch loss = nan\tavg epoch acc = 0.09895\n","epoch 8\tavg epoch loss = nan\tavg epoch acc = 0.09895\n","epoch 9\tavg epoch loss = nan\tavg epoch acc = 0.09895\n","training took 23.17 s\n","Avg test loss = nan\tAvg test acc = 0.0981\n","epoch 0\tavg epoch loss = nan\tavg epoch acc = 0.09953\n","epoch 1\tavg epoch loss = nan\tavg epoch acc = 0.09957\n","epoch 2\tavg epoch loss = nan\tavg epoch acc = 0.09957\n","epoch 3\tavg epoch loss = nan\tavg epoch acc = 0.09957\n","epoch 4\tavg epoch loss = nan\tavg epoch acc = 0.09957\n","epoch 5\tavg epoch loss = nan\tavg epoch acc = 0.09957\n","epoch 6\tavg epoch loss = nan\tavg epoch acc = 0.09957\n","epoch 7\tavg epoch loss = nan\tavg epoch acc = 0.09957\n","epoch 8\tavg epoch loss = nan\tavg epoch acc = 0.09957\n","epoch 9\tavg epoch loss = nan\tavg epoch acc = 0.09957\n","training took 23.22 s\n","Avg test loss = nan\tAvg test acc = 0.097\n","{'lr': 2.2229964825261948, 'batch_size': 128}\n","epoch 0\tavg epoch loss = 7.252e+11\tavg epoch acc = 0.1017\n","epoch 1\tavg epoch loss = 471.0\tavg epoch acc = 0.1\n","epoch 2\tavg epoch loss = 2.324\tavg epoch acc = 0.09937\n","epoch 3\tavg epoch loss = 2.324\tavg epoch acc = 0.09922\n","epoch 4\tavg epoch loss = 2.324\tavg epoch acc = 0.09922\n","epoch 5\tavg epoch loss = 2.324\tavg epoch acc = 0.09927\n","epoch 6\tavg epoch loss = 2.324\tavg epoch acc = 0.09927\n","epoch 7\tavg epoch loss = 2.324\tavg epoch acc = 0.09927\n","epoch 8\tavg epoch loss = 2.324\tavg epoch acc = 0.09927\n","epoch 9\tavg epoch loss = 2.324\tavg epoch acc = 0.09927\n","training took 15.64 s\n","Avg test loss = 2.32\tAvg test acc = 0.0982\n","epoch 0\tavg epoch loss = 7.202e+06\tavg epoch acc = 0.1038\n","epoch 1\tavg epoch loss = 7.392\tavg epoch acc = 0.1029\n","epoch 2\tavg epoch loss = 4.864e+05\tavg epoch acc = 0.1013\n","epoch 3\tavg epoch loss = 1.392e+06\tavg epoch acc = 0.1007\n","epoch 4\tavg epoch loss = 2.978e+04\tavg epoch acc = 0.1031\n","epoch 5\tavg epoch loss = nan\tavg epoch acc = 0.09839\n","epoch 6\tavg epoch loss = nan\tavg epoch acc = 0.09867\n","epoch 7\tavg epoch loss = nan\tavg epoch acc = 0.09867\n","epoch 8\tavg epoch loss = nan\tavg epoch acc = 0.09867\n","epoch 9\tavg epoch loss = nan\tavg epoch acc = 0.09867\n","training took 15.68 s\n","Avg test loss = nan\tAvg test acc = 0.0986\n","epoch 0\tavg epoch loss = 2.536\tavg epoch acc = 0.1025\n","epoch 1\tavg epoch loss = 2.323\tavg epoch acc = 0.101\n","epoch 2\tavg epoch loss = 2.324\tavg epoch acc = 0.1008\n","epoch 3\tavg epoch loss = 2.342\tavg epoch acc = 0.101\n","epoch 4\tavg epoch loss = 2.324\tavg epoch acc = 0.1008\n","epoch 5\tavg epoch loss = 2.324\tavg epoch acc = 0.1009\n","epoch 6\tavg epoch loss = 2.324\tavg epoch acc = 0.1009\n","epoch 7\tavg epoch loss = 2.324\tavg epoch acc = 0.1009\n","epoch 8\tavg epoch loss = 2.324\tavg epoch acc = 0.1009\n","epoch 9\tavg epoch loss = 2.324\tavg epoch acc = 0.1009\n","training took 15.63 s\n","Avg test loss = 2.32\tAvg test acc = 0.0953\n","{'lr': 2.329951810515372, 'batch_size': 32}\n","epoch 0\tavg epoch loss = nan\tavg epoch acc = 0.09853\n","epoch 1\tavg epoch loss = nan\tavg epoch acc = 0.09863\n","epoch 2\tavg epoch loss = nan\tavg epoch acc = 0.09863\n","epoch 3\tavg epoch loss = nan\tavg epoch acc = 0.09863\n","epoch 4\tavg epoch loss = nan\tavg epoch acc = 0.09863\n","epoch 5\tavg epoch loss = nan\tavg epoch acc = 0.09863\n","epoch 6\tavg epoch loss = nan\tavg epoch acc = 0.09863\n","epoch 7\tavg epoch loss = nan\tavg epoch acc = 0.09863\n","epoch 8\tavg epoch loss = nan\tavg epoch acc = 0.09863\n","epoch 9\tavg epoch loss = nan\tavg epoch acc = 0.09863\n","training took 44.29 s\n","Avg test loss = nan\tAvg test acc = 0.0989\n","epoch 0\tavg epoch loss = 1.91e+15\tavg epoch acc = 0.09767\n","epoch 1\tavg epoch loss = 2.404\tavg epoch acc = 0.0977\n","epoch 2\tavg epoch loss = 2.404\tavg epoch acc = 0.09765\n","epoch 3\tavg epoch loss = 2.404\tavg epoch acc = 0.09765\n","epoch 4\tavg epoch loss = 2.405\tavg epoch acc = 0.09773\n","epoch 5\tavg epoch loss = 2.405\tavg epoch acc = 0.09773\n","epoch 6\tavg epoch loss = 2.405\tavg epoch acc = 0.09773\n","epoch 7\tavg epoch loss = 2.405\tavg epoch acc = 0.09773\n","epoch 8\tavg epoch loss = 2.405\tavg epoch acc = 0.09773\n","epoch 9\tavg epoch loss = 2.405\tavg epoch acc = 0.09773\n","training took 44.4 s\n","Avg test loss = 2.34\tAvg test acc = 0.0994\n","epoch 0\tavg epoch loss = nan\tavg epoch acc = 0.099\n","epoch 1\tavg epoch loss = nan\tavg epoch acc = 0.09897\n","epoch 2\tavg epoch loss = nan\tavg epoch acc = 0.09897\n","epoch 3\tavg epoch loss = nan\tavg epoch acc = 0.09897\n","epoch 4\tavg epoch loss = nan\tavg epoch acc = 0.09897\n","epoch 5\tavg epoch loss = nan\tavg epoch acc = 0.09897\n","epoch 6\tavg epoch loss = nan\tavg epoch acc = 0.09897\n","epoch 7\tavg epoch loss = nan\tavg epoch acc = 0.09897\n","epoch 8\tavg epoch loss = nan\tavg epoch acc = 0.09897\n","epoch 9\tavg epoch loss = nan\tavg epoch acc = 0.09897\n","training took 44.77 s\n","Avg test loss = nan\tAvg test acc = 0.0982\n","{'lr': 2.329951810515372, 'batch_size': 64}\n","epoch 0\tavg epoch loss = nan\tavg epoch acc = 0.1001\n","epoch 1\tavg epoch loss = nan\tavg epoch acc = 0.09997\n","epoch 2\tavg epoch loss = nan\tavg epoch acc = 0.09997\n","epoch 3\tavg epoch loss = nan\tavg epoch acc = 0.09997\n","epoch 4\tavg epoch loss = nan\tavg epoch acc = 0.09997\n","epoch 5\tavg epoch loss = nan\tavg epoch acc = 0.09997\n","epoch 6\tavg epoch loss = nan\tavg epoch acc = 0.09997\n","epoch 7\tavg epoch loss = nan\tavg epoch acc = 0.09997\n","epoch 8\tavg epoch loss = nan\tavg epoch acc = 0.09997\n","epoch 9\tavg epoch loss = nan\tavg epoch acc = 0.09997\n","training took 23.53 s\n","Avg test loss = nan\tAvg test acc = 0.0962\n","epoch 0\tavg epoch loss = nan\tavg epoch acc = 0.0984\n","epoch 1\tavg epoch loss = nan\tavg epoch acc = 0.09835\n","epoch 2\tavg epoch loss = nan\tavg epoch acc = 0.09835\n","epoch 3\tavg epoch loss = nan\tavg epoch acc = 0.09835\n","epoch 4\tavg epoch loss = nan\tavg epoch acc = 0.09835\n","epoch 5\tavg epoch loss = nan\tavg epoch acc = 0.09835\n","epoch 6\tavg epoch loss = nan\tavg epoch acc = 0.09835\n","epoch 7\tavg epoch loss = nan\tavg epoch acc = 0.09835\n","epoch 8\tavg epoch loss = nan\tavg epoch acc = 0.09835\n","epoch 9\tavg epoch loss = nan\tavg epoch acc = 0.09835\n","training took 24.14 s\n","Avg test loss = nan\tAvg test acc = 0.0994\n","epoch 0\tavg epoch loss = nan\tavg epoch acc = 0.09782\n","epoch 1\tavg epoch loss = nan\tavg epoch acc = 0.09782\n","epoch 2\tavg epoch loss = nan\tavg epoch acc = 0.09782\n","epoch 3\tavg epoch loss = nan\tavg epoch acc = 0.09782\n","epoch 4\tavg epoch loss = nan\tavg epoch acc = 0.09782\n","epoch 5\tavg epoch loss = nan\tavg epoch acc = 0.09782\n","epoch 6\tavg epoch loss = nan\tavg epoch acc = 0.09782\n","epoch 7\tavg epoch loss = nan\tavg epoch acc = 0.09782\n","epoch 8\tavg epoch loss = nan\tavg epoch acc = 0.09782\n","epoch 9\tavg epoch loss = nan\tavg epoch acc = 0.09782\n","training took 23.78 s\n","Avg test loss = nan\tAvg test acc = 0.101\n","{'lr': 2.329951810515372, 'batch_size': 128}\n","epoch 0\tavg epoch loss = 2.333\tavg epoch acc = 0.09999\n","epoch 1\tavg epoch loss = 2.323\tavg epoch acc = 0.09979\n","epoch 2\tavg epoch loss = 2.323\tavg epoch acc = 0.09949\n","epoch 3\tavg epoch loss = 2.324\tavg epoch acc = 0.09949\n","epoch 4\tavg epoch loss = 2.324\tavg epoch acc = 0.09949\n","epoch 5\tavg epoch loss = 2.324\tavg epoch acc = 0.09942\n","epoch 6\tavg epoch loss = 2.324\tavg epoch acc = 0.09942\n","epoch 7\tavg epoch loss = 2.324\tavg epoch acc = 0.09942\n","epoch 8\tavg epoch loss = 2.324\tavg epoch acc = 0.09942\n","epoch 9\tavg epoch loss = 2.324\tavg epoch acc = 0.09914\n","training took 15.7 s\n","Avg test loss = 2.31\tAvg test acc = 0.0964\n","epoch 0\tavg epoch loss = 833.1\tavg epoch acc = 0.1023\n","epoch 1\tavg epoch loss = 2.325\tavg epoch acc = 0.1023\n","epoch 2\tavg epoch loss = 2.466\tavg epoch acc = 0.1025\n","epoch 3\tavg epoch loss = 2.325\tavg epoch acc = 0.1024\n","epoch 4\tavg epoch loss = 2.325\tavg epoch acc = 0.1024\n","epoch 5\tavg epoch loss = 2.325\tavg epoch acc = 0.1024\n","epoch 6\tavg epoch loss = 2.325\tavg epoch acc = 0.1023\n","epoch 7\tavg epoch loss = 2.325\tavg epoch acc = 0.1023\n","epoch 8\tavg epoch loss = 2.325\tavg epoch acc = 0.1023\n","epoch 9\tavg epoch loss = 2.325\tavg epoch acc = 0.1023\n","training took 15.72 s\n","Avg test loss = 7.64e+02\tAvg test acc = 0.099\n","epoch 0\tavg epoch loss = 2.336\tavg epoch acc = 0.1008\n","epoch 1\tavg epoch loss = 3.644\tavg epoch acc = 0.1006\n","epoch 2\tavg epoch loss = 6.831\tavg epoch acc = 0.1002\n","epoch 3\tavg epoch loss = 2.323\tavg epoch acc = 0.09992\n","epoch 4\tavg epoch loss = 3.729\tavg epoch acc = 0.1007\n","epoch 5\tavg epoch loss = 3.978\tavg epoch acc = 0.09937\n","epoch 6\tavg epoch loss = 2.52\tavg epoch acc = 0.1014\n","epoch 7\tavg epoch loss = 2.712\tavg epoch acc = 0.09974\n","epoch 8\tavg epoch loss = 2.359\tavg epoch acc = 0.1002\n","epoch 9\tavg epoch loss = 2.323\tavg epoch acc = 0.09999\n","training took 15.68 s\n","Avg test loss = 2.31\tAvg test acc = 0.101\n","{'lr': 2.442053094548651, 'batch_size': 32}\n","epoch 0\tavg epoch loss = 1.29e+05\tavg epoch acc = 0.09623\n","epoch 1\tavg epoch loss = 2.412\tavg epoch acc = 0.09613\n","epoch 2\tavg epoch loss = 2.413\tavg epoch acc = 0.09617\n","epoch 3\tavg epoch loss = 2.413\tavg epoch acc = 0.09617\n","epoch 4\tavg epoch loss = 2.413\tavg epoch acc = 0.09623\n","epoch 5\tavg epoch loss = 2.413\tavg epoch acc = 0.09623\n","epoch 6\tavg epoch loss = 2.413\tavg epoch acc = 0.09623\n","epoch 7\tavg epoch loss = 2.413\tavg epoch acc = 0.09623\n","epoch 8\tavg epoch loss = 2.413\tavg epoch acc = 0.09623\n","epoch 9\tavg epoch loss = 2.413\tavg epoch acc = 0.09623\n","training took 44.62 s\n","Avg test loss = 2.07e+02\tAvg test acc = 0.0988\n","epoch 0\tavg epoch loss = nan\tavg epoch acc = 0.0993\n","epoch 1\tavg epoch loss = nan\tavg epoch acc = 0.09942\n","epoch 2\tavg epoch loss = nan\tavg epoch acc = 0.09942\n","epoch 3\tavg epoch loss = nan\tavg epoch acc = 0.09942\n","epoch 4\tavg epoch loss = nan\tavg epoch acc = 0.09942\n","epoch 5\tavg epoch loss = nan\tavg epoch acc = 0.09942\n","epoch 6\tavg epoch loss = nan\tavg epoch acc = 0.09942\n","epoch 7\tavg epoch loss = nan\tavg epoch acc = 0.09942\n","epoch 8\tavg epoch loss = nan\tavg epoch acc = 0.09942\n","epoch 9\tavg epoch loss = nan\tavg epoch acc = 0.09942\n","training took 44.26 s\n","Avg test loss = nan\tAvg test acc = 0.0973\n","epoch 0\tavg epoch loss = 3.178e+18\tavg epoch acc = 0.09585\n","epoch 1\tavg epoch loss = 2.411\tavg epoch acc = 0.09582\n","epoch 2\tavg epoch loss = 2.411\tavg epoch acc = 0.0958\n","epoch 3\tavg epoch loss = 2.411\tavg epoch acc = 0.0958\n","epoch 4\tavg epoch loss = 2.411\tavg epoch acc = 0.0958\n","epoch 5\tavg epoch loss = 2.411\tavg epoch acc = 0.09585\n","epoch 6\tavg epoch loss = 2.411\tavg epoch acc = 0.09588\n","epoch 7\tavg epoch loss = 2.411\tavg epoch acc = 0.09588\n","epoch 8\tavg epoch loss = 2.411\tavg epoch acc = 0.09588\n","epoch 9\tavg epoch loss = 2.412\tavg epoch acc = 0.09588\n","training took 44.31 s\n","Avg test loss = 2.39\tAvg test acc = 0.102\n","{'lr': 2.442053094548651, 'batch_size': 64}\n","epoch 0\tavg epoch loss = 334.0\tavg epoch acc = 0.09915\n","epoch 1\tavg epoch loss = 2.347\tavg epoch acc = 0.1008\n","epoch 2\tavg epoch loss = 2.347\tavg epoch acc = 0.1008\n","epoch 3\tavg epoch loss = 2.347\tavg epoch acc = 0.1008\n","epoch 4\tavg epoch loss = 2.347\tavg epoch acc = 0.1008\n","epoch 5\tavg epoch loss = 2.347\tavg epoch acc = 0.1008\n","epoch 6\tavg epoch loss = 2.347\tavg epoch acc = 0.1008\n","epoch 7\tavg epoch loss = 2.347\tavg epoch acc = 0.1008\n","epoch 8\tavg epoch loss = 2.347\tavg epoch acc = 0.1008\n","epoch 9\tavg epoch loss = 2.347\tavg epoch acc = 0.1008\n","training took 23.17 s\n","Avg test loss = 2.32\tAvg test acc = 0.0976\n","epoch 0\tavg epoch loss = 1.114e+17\tavg epoch acc = 0.1007\n","epoch 1\tavg epoch loss = 2.606e+18\tavg epoch acc = 0.09942\n","epoch 2\tavg epoch loss = 3.089\tavg epoch acc = 0.1003\n","epoch 3\tavg epoch loss = 5.214e+14\tavg epoch acc = 0.1008\n","epoch 4\tavg epoch loss = 2.349\tavg epoch acc = 0.1007\n","epoch 5\tavg epoch loss = 2.349\tavg epoch acc = 0.1007\n","epoch 6\tavg epoch loss = 2.349\tavg epoch acc = 0.1007\n","epoch 7\tavg epoch loss = 2.349\tavg epoch acc = 0.1007\n","epoch 8\tavg epoch loss = 2.349\tavg epoch acc = 0.1007\n","epoch 9\tavg epoch loss = 2.349\tavg epoch acc = 0.1007\n","training took 23.27 s\n","Avg test loss = 2.32\tAvg test acc = 0.0978\n","epoch 0\tavg epoch loss = 2.8\tavg epoch acc = 0.09932\n","epoch 1\tavg epoch loss = 2.352\tavg epoch acc = 0.09865\n","epoch 2\tavg epoch loss = 2.352\tavg epoch acc = 0.09865\n","epoch 3\tavg epoch loss = 2.352\tavg epoch acc = 0.0985\n","epoch 4\tavg epoch loss = 2.352\tavg epoch acc = 0.09845\n","epoch 5\tavg epoch loss = 2.352\tavg epoch acc = 0.09845\n","epoch 6\tavg epoch loss = 2.352\tavg epoch acc = 0.09845\n","epoch 7\tavg epoch loss = 2.352\tavg epoch acc = 0.09845\n","epoch 8\tavg epoch loss = 2.352\tavg epoch acc = 0.09845\n","epoch 9\tavg epoch loss = 2.352\tavg epoch acc = 0.09845\n","training took 23.42 s\n","Avg test loss = 2.31\tAvg test acc = 0.114\n","{'lr': 2.442053094548651, 'batch_size': 128}\n","epoch 0\tavg epoch loss = nan\tavg epoch acc = 0.09794\n","epoch 1\tavg epoch loss = nan\tavg epoch acc = 0.09779\n","epoch 2\tavg epoch loss = nan\tavg epoch acc = 0.09779\n","epoch 3\tavg epoch loss = nan\tavg epoch acc = 0.09779\n","epoch 4\tavg epoch loss = nan\tavg epoch acc = 0.09779\n","epoch 5\tavg epoch loss = nan\tavg epoch acc = 0.09779\n","epoch 6\tavg epoch loss = nan\tavg epoch acc = 0.09779\n","epoch 7\tavg epoch loss = nan\tavg epoch acc = 0.09779\n","epoch 8\tavg epoch loss = nan\tavg epoch acc = 0.09779\n","epoch 9\tavg epoch loss = nan\tavg epoch acc = 0.09779\n","training took 15.61 s\n","Avg test loss = nan\tAvg test acc = 0.101\n","epoch 0\tavg epoch loss = nan\tavg epoch acc = 0.09907\n","epoch 1\tavg epoch loss = nan\tavg epoch acc = 0.09904\n","epoch 2\tavg epoch loss = nan\tavg epoch acc = 0.09904\n","epoch 3\tavg epoch loss = nan\tavg epoch acc = 0.09904\n","epoch 4\tavg epoch loss = nan\tavg epoch acc = 0.09904\n","epoch 5\tavg epoch loss = nan\tavg epoch acc = 0.09904\n","epoch 6\tavg epoch loss = nan\tavg epoch acc = 0.09904\n","epoch 7\tavg epoch loss = nan\tavg epoch acc = 0.09904\n","epoch 8\tavg epoch loss = nan\tavg epoch acc = 0.09904\n","epoch 9\tavg epoch loss = nan\tavg epoch acc = 0.09904\n","training took 15.63 s\n","Avg test loss = nan\tAvg test acc = 0.0982\n","epoch 0\tavg epoch loss = nan\tavg epoch acc = 0.09899\n","epoch 1\tavg epoch loss = nan\tavg epoch acc = 0.09932\n","epoch 2\tavg epoch loss = nan\tavg epoch acc = 0.09932\n","epoch 3\tavg epoch loss = nan\tavg epoch acc = 0.09932\n","epoch 4\tavg epoch loss = nan\tavg epoch acc = 0.09932\n","epoch 5\tavg epoch loss = nan\tavg epoch acc = 0.09932\n","epoch 6\tavg epoch loss = nan\tavg epoch acc = 0.09932\n","epoch 7\tavg epoch loss = nan\tavg epoch acc = 0.09932\n","epoch 8\tavg epoch loss = nan\tavg epoch acc = 0.09932\n","epoch 9\tavg epoch loss = nan\tavg epoch acc = 0.09932\n","training took 15.62 s\n","Avg test loss = nan\tAvg test acc = 0.0972\n","{'lr': 2.5595479226995357, 'batch_size': 32}\n","epoch 0\tavg epoch loss = nan\tavg epoch acc = 0.09805\n","epoch 1\tavg epoch loss = nan\tavg epoch acc = 0.098\n","epoch 2\tavg epoch loss = nan\tavg epoch acc = 0.098\n","epoch 3\tavg epoch loss = nan\tavg epoch acc = 0.098\n","epoch 4\tavg epoch loss = nan\tavg epoch acc = 0.098\n","epoch 5\tavg epoch loss = nan\tavg epoch acc = 0.098\n","epoch 6\tavg epoch loss = nan\tavg epoch acc = 0.098\n","epoch 7\tavg epoch loss = nan\tavg epoch acc = 0.098\n","epoch 8\tavg epoch loss = nan\tavg epoch acc = 0.098\n","epoch 9\tavg epoch loss = nan\tavg epoch acc = 0.098\n","training took 44.28 s\n","Avg test loss = nan\tAvg test acc = 0.1\n","epoch 0\tavg epoch loss = nan\tavg epoch acc = 0.09903\n","epoch 1\tavg epoch loss = nan\tavg epoch acc = 0.099\n","epoch 2\tavg epoch loss = nan\tavg epoch acc = 0.099\n","epoch 3\tavg epoch loss = nan\tavg epoch acc = 0.099\n","epoch 4\tavg epoch loss = nan\tavg epoch acc = 0.099\n","epoch 5\tavg epoch loss = nan\tavg epoch acc = 0.099\n","epoch 6\tavg epoch loss = nan\tavg epoch acc = 0.099\n","epoch 7\tavg epoch loss = nan\tavg epoch acc = 0.099\n","epoch 8\tavg epoch loss = nan\tavg epoch acc = 0.099\n","epoch 9\tavg epoch loss = nan\tavg epoch acc = 0.099\n","training took 44.67 s\n","Avg test loss = nan\tAvg test acc = 0.0982\n","epoch 0\tavg epoch loss = nan\tavg epoch acc = 0.09897\n","epoch 1\tavg epoch loss = nan\tavg epoch acc = 0.09915\n","epoch 2\tavg epoch loss = nan\tavg epoch acc = 0.09915\n","epoch 3\tavg epoch loss = nan\tavg epoch acc = 0.09915\n","epoch 4\tavg epoch loss = nan\tavg epoch acc = 0.09915\n","epoch 5\tavg epoch loss = nan\tavg epoch acc = 0.09915\n","epoch 6\tavg epoch loss = nan\tavg epoch acc = 0.09915\n","epoch 7\tavg epoch loss = nan\tavg epoch acc = 0.09915\n","epoch 8\tavg epoch loss = nan\tavg epoch acc = 0.09915\n","epoch 9\tavg epoch loss = nan\tavg epoch acc = 0.09915\n","training took 46.04 s\n","Avg test loss = nan\tAvg test acc = 0.0979\n","{'lr': 2.5595479226995357, 'batch_size': 64}\n","epoch 0\tavg epoch loss = 2.386\tavg epoch acc = 0.09863\n","epoch 1\tavg epoch loss = 37.34\tavg epoch acc = 0.09917\n","epoch 2\tavg epoch loss = 13.29\tavg epoch acc = 0.09915\n","epoch 3\tavg epoch loss = 2.352\tavg epoch acc = 0.09935\n","epoch 4\tavg epoch loss = 3.98\tavg epoch acc = 0.0989\n","epoch 5\tavg epoch loss = 2.352\tavg epoch acc = 0.09925\n","epoch 6\tavg epoch loss = 2.352\tavg epoch acc = 0.09925\n","epoch 7\tavg epoch loss = 2.352\tavg epoch acc = 0.09925\n","epoch 8\tavg epoch loss = 2.352\tavg epoch acc = 0.09925\n","epoch 9\tavg epoch loss = 2.352\tavg epoch acc = 0.09925\n","training took 23.5 s\n","Avg test loss = 2.32\tAvg test acc = 0.113\n","epoch 0\tavg epoch loss = 3.801e+06\tavg epoch acc = 0.09935\n","epoch 1\tavg epoch loss = 7.749\tavg epoch acc = 0.09895\n","epoch 2\tavg epoch loss = 2.351\tavg epoch acc = 0.09915\n","epoch 3\tavg epoch loss = 2.351\tavg epoch acc = 0.09915\n","epoch 4\tavg epoch loss = 2.351\tavg epoch acc = 0.09915\n","epoch 5\tavg epoch loss = 2.351\tavg epoch acc = 0.09925\n","epoch 6\tavg epoch loss = 2.351\tavg epoch acc = 0.09913\n","epoch 7\tavg epoch loss = 2.351\tavg epoch acc = 0.099\n","epoch 8\tavg epoch loss = 2.351\tavg epoch acc = 0.099\n","epoch 9\tavg epoch loss = 2.351\tavg epoch acc = 0.099\n","training took 23.37 s\n","Avg test loss = 2.33\tAvg test acc = 0.0996\n","epoch 0\tavg epoch loss = 58.84\tavg epoch acc = 0.1001\n","epoch 1\tavg epoch loss = 2.352\tavg epoch acc = 0.1003\n","epoch 2\tavg epoch loss = 2.352\tavg epoch acc = 0.1003\n","epoch 3\tavg epoch loss = 2.352\tavg epoch acc = 0.1003\n","epoch 4\tavg epoch loss = 2.352\tavg epoch acc = 0.1003\n","epoch 5\tavg epoch loss = 2.352\tavg epoch acc = 0.1003\n","epoch 6\tavg epoch loss = 2.353\tavg epoch acc = 0.1003\n","epoch 7\tavg epoch loss = 2.353\tavg epoch acc = 0.1003\n","epoch 8\tavg epoch loss = 2.353\tavg epoch acc = 0.1003\n","epoch 9\tavg epoch loss = 2.353\tavg epoch acc = 0.1003\n","training took 23.43 s\n","Avg test loss = 2.32\tAvg test acc = 0.0974\n","{'lr': 2.5595479226995357, 'batch_size': 128}\n","epoch 0\tavg epoch loss = 2.331\tavg epoch acc = 0.1026\n","epoch 1\tavg epoch loss = 2.324\tavg epoch acc = 0.1027\n","epoch 2\tavg epoch loss = 2.325\tavg epoch acc = 0.1026\n","epoch 3\tavg epoch loss = 2.325\tavg epoch acc = 0.1025\n","epoch 4\tavg epoch loss = 2.325\tavg epoch acc = 0.1025\n","epoch 5\tavg epoch loss = 2.325\tavg epoch acc = 0.1025\n","epoch 6\tavg epoch loss = 2.325\tavg epoch acc = 0.1025\n","epoch 7\tavg epoch loss = 2.325\tavg epoch acc = 0.1026\n","epoch 8\tavg epoch loss = 2.325\tavg epoch acc = 0.1026\n","epoch 9\tavg epoch loss = 2.325\tavg epoch acc = 0.1026\n","training took 15.7 s\n","Avg test loss = 2.32\tAvg test acc = 0.0985\n","epoch 0\tavg epoch loss = nan\tavg epoch acc = 0.09977\n","epoch 1\tavg epoch loss = nan\tavg epoch acc = 0.09832\n","epoch 2\tavg epoch loss = nan\tavg epoch acc = 0.09832\n","epoch 3\tavg epoch loss = nan\tavg epoch acc = 0.09832\n","epoch 4\tavg epoch loss = nan\tavg epoch acc = 0.09832\n","epoch 5\tavg epoch loss = nan\tavg epoch acc = 0.09832\n","epoch 6\tavg epoch loss = nan\tavg epoch acc = 0.09832\n","epoch 7\tavg epoch loss = nan\tavg epoch acc = 0.09832\n","epoch 8\tavg epoch loss = nan\tavg epoch acc = 0.09832\n","epoch 9\tavg epoch loss = nan\tavg epoch acc = 0.09832\n","training took 15.78 s\n","Avg test loss = nan\tAvg test acc = 0.0997\n","epoch 0\tavg epoch loss = 2.327\tavg epoch acc = 0.09959\n","epoch 1\tavg epoch loss = 2.324\tavg epoch acc = 0.09967\n","epoch 2\tavg epoch loss = 2.324\tavg epoch acc = 0.09967\n","epoch 3\tavg epoch loss = 2.324\tavg epoch acc = 0.09949\n","epoch 4\tavg epoch loss = 2.324\tavg epoch acc = 0.09949\n","epoch 5\tavg epoch loss = 2.324\tavg epoch acc = 0.09967\n","epoch 6\tavg epoch loss = 2.324\tavg epoch acc = 0.09967\n","epoch 7\tavg epoch loss = 2.324\tavg epoch acc = 0.09967\n","epoch 8\tavg epoch loss = 2.324\tavg epoch acc = 0.09954\n","epoch 9\tavg epoch loss = 2.324\tavg epoch acc = 0.09954\n","training took 15.72 s\n","Avg test loss = 2.31\tAvg test acc = 0.103\n","{'lr': 2.6826957952797255, 'batch_size': 32}\n","epoch 0\tavg epoch loss = nan\tavg epoch acc = 0.0979\n","epoch 1\tavg epoch loss = nan\tavg epoch acc = 0.09807\n","epoch 2\tavg epoch loss = nan\tavg epoch acc = 0.09807\n","epoch 3\tavg epoch loss = nan\tavg epoch acc = 0.09807\n","epoch 4\tavg epoch loss = nan\tavg epoch acc = 0.09807\n","epoch 5\tavg epoch loss = nan\tavg epoch acc = 0.09807\n","epoch 6\tavg epoch loss = nan\tavg epoch acc = 0.09807\n","epoch 7\tavg epoch loss = nan\tavg epoch acc = 0.09807\n","epoch 8\tavg epoch loss = nan\tavg epoch acc = 0.09807\n","epoch 9\tavg epoch loss = nan\tavg epoch acc = 0.09807\n","training took 44.69 s\n","Avg test loss = nan\tAvg test acc = 0.1\n","epoch 0\tavg epoch loss = nan\tavg epoch acc = 0.09935\n","epoch 1\tavg epoch loss = nan\tavg epoch acc = 0.0995\n","epoch 2\tavg epoch loss = nan\tavg epoch acc = 0.0995\n","epoch 3\tavg epoch loss = nan\tavg epoch acc = 0.0995\n","epoch 4\tavg epoch loss = nan\tavg epoch acc = 0.0995\n","epoch 5\tavg epoch loss = nan\tavg epoch acc = 0.0995\n","epoch 6\tavg epoch loss = nan\tavg epoch acc = 0.0995\n","epoch 7\tavg epoch loss = nan\tavg epoch acc = 0.0995\n","epoch 8\tavg epoch loss = nan\tavg epoch acc = 0.0995\n","epoch 9\tavg epoch loss = nan\tavg epoch acc = 0.0995\n","training took 44.66 s\n","Avg test loss = nan\tAvg test acc = 0.0972\n","epoch 0\tavg epoch loss = nan\tavg epoch acc = 0.09853\n","epoch 1\tavg epoch loss = nan\tavg epoch acc = 0.09857\n","epoch 2\tavg epoch loss = nan\tavg epoch acc = 0.09857\n","epoch 3\tavg epoch loss = nan\tavg epoch acc = 0.09857\n","epoch 4\tavg epoch loss = nan\tavg epoch acc = 0.09857\n","epoch 5\tavg epoch loss = nan\tavg epoch acc = 0.09857\n","epoch 6\tavg epoch loss = nan\tavg epoch acc = 0.09857\n","epoch 7\tavg epoch loss = nan\tavg epoch acc = 0.09857\n","epoch 8\tavg epoch loss = nan\tavg epoch acc = 0.09857\n","epoch 9\tavg epoch loss = nan\tavg epoch acc = 0.09857\n","training took 44.66 s\n","Avg test loss = nan\tAvg test acc = 0.099\n","{'lr': 2.6826957952797255, 'batch_size': 64}\n","epoch 0\tavg epoch loss = nan\tavg epoch acc = 0.09917\n","epoch 1\tavg epoch loss = nan\tavg epoch acc = 0.09913\n","epoch 2\tavg epoch loss = nan\tavg epoch acc = 0.09913\n","epoch 3\tavg epoch loss = nan\tavg epoch acc = 0.09913\n","epoch 4\tavg epoch loss = nan\tavg epoch acc = 0.09913\n","epoch 5\tavg epoch loss = nan\tavg epoch acc = 0.09913\n","epoch 6\tavg epoch loss = nan\tavg epoch acc = 0.09913\n","epoch 7\tavg epoch loss = nan\tavg epoch acc = 0.09913\n","epoch 8\tavg epoch loss = nan\tavg epoch acc = 0.09913\n","epoch 9\tavg epoch loss = nan\tavg epoch acc = 0.09913\n","training took 23.5 s\n","Avg test loss = nan\tAvg test acc = 0.0979\n","epoch 0\tavg epoch loss = 2.8\tavg epoch acc = 0.09928\n","epoch 1\tavg epoch loss = 2.353\tavg epoch acc = 0.09885\n","epoch 2\tavg epoch loss = 2.353\tavg epoch acc = 0.0988\n","epoch 3\tavg epoch loss = 2.353\tavg epoch acc = 0.09888\n","epoch 4\tavg epoch loss = 2.353\tavg epoch acc = 0.09882\n","epoch 5\tavg epoch loss = 2.353\tavg epoch acc = 0.09882\n","epoch 6\tavg epoch loss = 2.353\tavg epoch acc = 0.09882\n","epoch 7\tavg epoch loss = 2.353\tavg epoch acc = 0.09882\n","epoch 8\tavg epoch loss = 2.353\tavg epoch acc = 0.09882\n","epoch 9\tavg epoch loss = 2.353\tavg epoch acc = 0.09882\n","training took 23.9 s\n","Avg test loss = 2.32\tAvg test acc = 0.0978\n","epoch 0\tavg epoch loss = 9.538e+14\tavg epoch acc = 0.09895\n","epoch 1\tavg epoch loss = 2.354\tavg epoch acc = 0.09897\n","epoch 2\tavg epoch loss = 2.355\tavg epoch acc = 0.09897\n","epoch 3\tavg epoch loss = 2.355\tavg epoch acc = 0.09907\n","epoch 4\tavg epoch loss = 2.355\tavg epoch acc = 0.09907\n","epoch 5\tavg epoch loss = 2.355\tavg epoch acc = 0.09907\n","epoch 6\tavg epoch loss = 2.355\tavg epoch acc = 0.09907\n","epoch 7\tavg epoch loss = 2.355\tavg epoch acc = 0.09907\n","epoch 8\tavg epoch loss = 2.355\tavg epoch acc = 0.09907\n","epoch 9\tavg epoch loss = 2.355\tavg epoch acc = 0.09907\n","training took 23.88 s\n","Avg test loss = 2.33\tAvg test acc = 0.105\n","{'lr': 2.6826957952797255, 'batch_size': 128}\n","epoch 0\tavg epoch loss = nan\tavg epoch acc = 0.09874\n","epoch 1\tavg epoch loss = nan\tavg epoch acc = 0.09889\n","epoch 2\tavg epoch loss = nan\tavg epoch acc = 0.09889\n","epoch 3\tavg epoch loss = nan\tavg epoch acc = 0.09889\n","epoch 4\tavg epoch loss = nan\tavg epoch acc = 0.09889\n","epoch 5\tavg epoch loss = nan\tavg epoch acc = 0.09889\n","epoch 6\tavg epoch loss = nan\tavg epoch acc = 0.09889\n","epoch 7\tavg epoch loss = nan\tavg epoch acc = 0.09889\n","epoch 8\tavg epoch loss = nan\tavg epoch acc = 0.09889\n","epoch 9\tavg epoch loss = nan\tavg epoch acc = 0.09889\n","training took 15.64 s\n","Avg test loss = nan\tAvg test acc = 0.0981\n","epoch 0\tavg epoch loss = 1.12e+04\tavg epoch acc = 0.1013\n","epoch 1\tavg epoch loss = 9.623\tavg epoch acc = 0.1029\n","epoch 2\tavg epoch loss = 2.326\tavg epoch acc = 0.1029\n","epoch 3\tavg epoch loss = 2.326\tavg epoch acc = 0.1029\n","epoch 4\tavg epoch loss = 2.326\tavg epoch acc = 0.1029\n","epoch 5\tavg epoch loss = 2.326\tavg epoch acc = 0.1027\n","epoch 6\tavg epoch loss = 2.326\tavg epoch acc = 0.1027\n","epoch 7\tavg epoch loss = 2.326\tavg epoch acc = 0.1027\n","epoch 8\tavg epoch loss = 2.326\tavg epoch acc = 0.1027\n","epoch 9\tavg epoch loss = 2.326\tavg epoch acc = 0.1026\n","training took 15.68 s\n","Avg test loss = 2.32\tAvg test acc = 0.0992\n","epoch 0\tavg epoch loss = nan\tavg epoch acc = 0.09914\n","epoch 1\tavg epoch loss = nan\tavg epoch acc = 0.09902\n","epoch 2\tavg epoch loss = nan\tavg epoch acc = 0.09902\n","epoch 3\tavg epoch loss = nan\tavg epoch acc = 0.09902\n","epoch 4\tavg epoch loss = nan\tavg epoch acc = 0.09902\n","epoch 5\tavg epoch loss = nan\tavg epoch acc = 0.09902\n","epoch 6\tavg epoch loss = nan\tavg epoch acc = 0.09902\n","epoch 7\tavg epoch loss = nan\tavg epoch acc = 0.09902\n","epoch 8\tavg epoch loss = nan\tavg epoch acc = 0.09902\n","epoch 9\tavg epoch loss = nan\tavg epoch acc = 0.09902\n","training took 15.71 s\n","Avg test loss = nan\tAvg test acc = 0.0982\n","{'lr': 2.8117686979742302, 'batch_size': 32}\n","epoch 0\tavg epoch loss = 8.724e+10\tavg epoch acc = 0.09627\n","epoch 1\tavg epoch loss = 2.603e+12\tavg epoch acc = 0.09607\n","epoch 2\tavg epoch loss = 4.146e+07\tavg epoch acc = 0.09483\n","epoch 3\tavg epoch loss = 2.42\tavg epoch acc = 0.09485\n","epoch 4\tavg epoch loss = 2.77e+07\tavg epoch acc = 0.09535\n","epoch 5\tavg epoch loss = 2.42\tavg epoch acc = 0.09485\n","epoch 6\tavg epoch loss = 2.42\tavg epoch acc = 0.09483\n","epoch 7\tavg epoch loss = 2.42\tavg epoch acc = 0.09483\n","epoch 8\tavg epoch loss = 2.42\tavg epoch acc = 0.09483\n","epoch 9\tavg epoch loss = 2.42\tavg epoch acc = 0.09483\n","training took 45.76 s\n","Avg test loss = 2.41\tAvg test acc = 0.103\n","epoch 0\tavg epoch loss = 5.144e+21\tavg epoch acc = 0.09655\n","epoch 1\tavg epoch loss = 2.421\tavg epoch acc = 0.09545\n","epoch 2\tavg epoch loss = 2.422\tavg epoch acc = 0.09545\n","epoch 3\tavg epoch loss = 2.422\tavg epoch acc = 0.09545\n","epoch 4\tavg epoch loss = 2.422\tavg epoch acc = 0.09548\n","epoch 5\tavg epoch loss = 2.422\tavg epoch acc = 0.09548\n","epoch 6\tavg epoch loss = 2.422\tavg epoch acc = 0.09548\n","epoch 7\tavg epoch loss = 2.422\tavg epoch acc = 0.09548\n","epoch 8\tavg epoch loss = 2.422\tavg epoch acc = 0.09548\n","epoch 9\tavg epoch loss = 2.422\tavg epoch acc = 0.09548\n","training took 44.87 s\n","Avg test loss = 2.37\tAvg test acc = 0.0981\n","epoch 0\tavg epoch loss = 1.368e+05\tavg epoch acc = 0.096\n","epoch 1\tavg epoch loss = 2.416\tavg epoch acc = 0.0964\n","epoch 2\tavg epoch loss = 2.473\tavg epoch acc = 0.09642\n","epoch 3\tavg epoch loss = 2.417\tavg epoch acc = 0.09627\n","epoch 4\tavg epoch loss = 2.417\tavg epoch acc = 0.09627\n","epoch 5\tavg epoch loss = 2.417\tavg epoch acc = 0.09627\n","epoch 6\tavg epoch loss = 2.417\tavg epoch acc = 0.09627\n","epoch 7\tavg epoch loss = 2.417\tavg epoch acc = 0.09627\n","epoch 8\tavg epoch loss = 2.417\tavg epoch acc = 0.09627\n","epoch 9\tavg epoch loss = 2.417\tavg epoch acc = 0.09627\n","training took 44.22 s\n","Avg test loss = 2.39\tAvg test acc = 0.101\n","{'lr': 2.8117686979742302, 'batch_size': 64}\n","epoch 0\tavg epoch loss = nan\tavg epoch acc = 0.0979\n","epoch 1\tavg epoch loss = nan\tavg epoch acc = 0.0974\n","epoch 2\tavg epoch loss = nan\tavg epoch acc = 0.0974\n","epoch 3\tavg epoch loss = nan\tavg epoch acc = 0.0974\n","epoch 4\tavg epoch loss = nan\tavg epoch acc = 0.0974\n","epoch 5\tavg epoch loss = nan\tavg epoch acc = 0.0974\n","epoch 6\tavg epoch loss = nan\tavg epoch acc = 0.0974\n","epoch 7\tavg epoch loss = nan\tavg epoch acc = 0.0974\n","epoch 8\tavg epoch loss = nan\tavg epoch acc = 0.0974\n","epoch 9\tavg epoch loss = nan\tavg epoch acc = 0.0974\n","training took 23.17 s\n","Avg test loss = nan\tAvg test acc = 0.101\n","epoch 0\tavg epoch loss = nan\tavg epoch acc = 0.1\n","epoch 1\tavg epoch loss = nan\tavg epoch acc = 0.0996\n","epoch 2\tavg epoch loss = nan\tavg epoch acc = 0.0996\n","epoch 3\tavg epoch loss = nan\tavg epoch acc = 0.0996\n","epoch 4\tavg epoch loss = nan\tavg epoch acc = 0.0996\n","epoch 5\tavg epoch loss = nan\tavg epoch acc = 0.0996\n","epoch 6\tavg epoch loss = nan\tavg epoch acc = 0.0996\n","epoch 7\tavg epoch loss = nan\tavg epoch acc = 0.0996\n","epoch 8\tavg epoch loss = nan\tavg epoch acc = 0.0996\n","epoch 9\tavg epoch loss = nan\tavg epoch acc = 0.0996\n","training took 23.27 s\n","Avg test loss = nan\tAvg test acc = 0.0969\n","epoch 0\tavg epoch loss = 9.565e+13\tavg epoch acc = 0.099\n","epoch 1\tavg epoch loss = 2.353\tavg epoch acc = 0.09905\n","epoch 2\tavg epoch loss = 2.354\tavg epoch acc = 0.0991\n","epoch 3\tavg epoch loss = 2.354\tavg epoch acc = 0.0991\n","epoch 4\tavg epoch loss = 2.354\tavg epoch acc = 0.09903\n","epoch 5\tavg epoch loss = 2.354\tavg epoch acc = 0.09903\n","epoch 6\tavg epoch loss = 2.354\tavg epoch acc = 0.09903\n","epoch 7\tavg epoch loss = 2.354\tavg epoch acc = 0.09903\n","epoch 8\tavg epoch loss = 2.354\tavg epoch acc = 0.09903\n","epoch 9\tavg epoch loss = 2.354\tavg epoch acc = 0.09903\n","training took 23.17 s\n","Avg test loss = 2.33\tAvg test acc = 0.0974\n","{'lr': 2.8117686979742302, 'batch_size': 128}\n","epoch 0\tavg epoch loss = nan\tavg epoch acc = 0.09989\n","epoch 1\tavg epoch loss = nan\tavg epoch acc = 0.09982\n","epoch 2\tavg epoch loss = nan\tavg epoch acc = 0.09982\n","epoch 3\tavg epoch loss = nan\tavg epoch acc = 0.09982\n","epoch 4\tavg epoch loss = nan\tavg epoch acc = 0.09982\n","epoch 5\tavg epoch loss = nan\tavg epoch acc = 0.09982\n","epoch 6\tavg epoch loss = nan\tavg epoch acc = 0.09982\n","epoch 7\tavg epoch loss = nan\tavg epoch acc = 0.09982\n","epoch 8\tavg epoch loss = nan\tavg epoch acc = 0.09982\n","epoch 9\tavg epoch loss = nan\tavg epoch acc = 0.09982\n","training took 15.53 s\n","Avg test loss = nan\tAvg test acc = 0.0965\n","epoch 0\tavg epoch loss = nan\tavg epoch acc = 0.09812\n","epoch 1\tavg epoch loss = nan\tavg epoch acc = 0.09787\n","epoch 2\tavg epoch loss = nan\tavg epoch acc = 0.09787\n","epoch 3\tavg epoch loss = nan\tavg epoch acc = 0.09787\n","epoch 4\tavg epoch loss = nan\tavg epoch acc = 0.09787\n","epoch 5\tavg epoch loss = nan\tavg epoch acc = 0.09787\n","epoch 6\tavg epoch loss = nan\tavg epoch acc = 0.09787\n","epoch 7\tavg epoch loss = nan\tavg epoch acc = 0.09787\n","epoch 8\tavg epoch loss = nan\tavg epoch acc = 0.09787\n","epoch 9\tavg epoch loss = nan\tavg epoch acc = 0.09787\n","training took 15.55 s\n","Avg test loss = nan\tAvg test acc = 0.1\n","epoch 0\tavg epoch loss = 7.597e+07\tavg epoch acc = 0.1005\n","epoch 1\tavg epoch loss = 2.332\tavg epoch acc = 0.09977\n","epoch 2\tavg epoch loss = 2.327\tavg epoch acc = 0.1002\n","epoch 3\tavg epoch loss = 2.327\tavg epoch acc = 0.1002\n","epoch 4\tavg epoch loss = 2.327\tavg epoch acc = 0.1003\n","epoch 5\tavg epoch loss = 2.327\tavg epoch acc = 0.1003\n","epoch 6\tavg epoch loss = 2.327\tavg epoch acc = 0.1003\n","epoch 7\tavg epoch loss = 2.327\tavg epoch acc = 0.1003\n","epoch 8\tavg epoch loss = 2.327\tavg epoch acc = 0.1003\n","epoch 9\tavg epoch loss = 2.327\tavg epoch acc = 0.1002\n","training took 15.58 s\n","Avg test loss = 2.31\tAvg test acc = 0.101\n","{'lr': 2.9470517025518106, 'batch_size': 32}\n","epoch 0\tavg epoch loss = 2.974e+13\tavg epoch acc = 0.09607\n","epoch 1\tavg epoch loss = 2.426\tavg epoch acc = 0.09648\n","epoch 2\tavg epoch loss = 2.426\tavg epoch acc = 0.09648\n","epoch 3\tavg epoch loss = 2.426\tavg epoch acc = 0.09648\n","epoch 4\tavg epoch loss = 2.426\tavg epoch acc = 0.0965\n","epoch 5\tavg epoch loss = 2.426\tavg epoch acc = 0.0965\n","epoch 6\tavg epoch loss = 2.426\tavg epoch acc = 0.09635\n","epoch 7\tavg epoch loss = 2.427\tavg epoch acc = 0.0963\n","epoch 8\tavg epoch loss = 2.427\tavg epoch acc = 0.0963\n","epoch 9\tavg epoch loss = 2.427\tavg epoch acc = 0.0963\n","training took 44.36 s\n","Avg test loss = 2.42\tAvg test acc = 0.0983\n","epoch 0\tavg epoch loss = nan\tavg epoch acc = 0.09807\n","epoch 1\tavg epoch loss = nan\tavg epoch acc = 0.09773\n","epoch 2\tavg epoch loss = nan\tavg epoch acc = 0.09773\n","epoch 3\tavg epoch loss = nan\tavg epoch acc = 0.09773\n","epoch 4\tavg epoch loss = nan\tavg epoch acc = 0.09773\n","epoch 5\tavg epoch loss = nan\tavg epoch acc = 0.09773\n","epoch 6\tavg epoch loss = nan\tavg epoch acc = 0.09773\n","epoch 7\tavg epoch loss = nan\tavg epoch acc = 0.09773\n","epoch 8\tavg epoch loss = nan\tavg epoch acc = 0.09773\n","epoch 9\tavg epoch loss = nan\tavg epoch acc = 0.09773\n","training took 44.53 s\n","Avg test loss = nan\tAvg test acc = 0.101\n","epoch 0\tavg epoch loss = 4.59\tavg epoch acc = 0.09645\n","epoch 1\tavg epoch loss = 2.425\tavg epoch acc = 0.09642\n","epoch 2\tavg epoch loss = 2.425\tavg epoch acc = 0.0964\n","epoch 3\tavg epoch loss = 8.961e+03\tavg epoch acc = 0.0965\n","epoch 4\tavg epoch loss = 1.224e+04\tavg epoch acc = 0.09825\n","epoch 5\tavg epoch loss = 2.455\tavg epoch acc = 0.09675\n","epoch 6\tavg epoch loss = 2.425\tavg epoch acc = 0.09645\n","epoch 7\tavg epoch loss = 2.425\tavg epoch acc = 0.09645\n","epoch 8\tavg epoch loss = 2.426\tavg epoch acc = 0.09645\n","epoch 9\tavg epoch loss = 2.426\tavg epoch acc = 0.09645\n","training took 44.49 s\n","Avg test loss = 2.37\tAvg test acc = 0.103\n","{'lr': 2.9470517025518106, 'batch_size': 64}\n","epoch 0\tavg epoch loss = nan\tavg epoch acc = 0.09745\n","epoch 1\tavg epoch loss = nan\tavg epoch acc = 0.09742\n","epoch 2\tavg epoch loss = nan\tavg epoch acc = 0.09742\n","epoch 3\tavg epoch loss = nan\tavg epoch acc = 0.09742\n","epoch 4\tavg epoch loss = nan\tavg epoch acc = 0.09742\n","epoch 5\tavg epoch loss = nan\tavg epoch acc = 0.09742\n","epoch 6\tavg epoch loss = nan\tavg epoch acc = 0.09742\n","epoch 7\tavg epoch loss = nan\tavg epoch acc = 0.09742\n","epoch 8\tavg epoch loss = nan\tavg epoch acc = 0.09742\n","epoch 9\tavg epoch loss = nan\tavg epoch acc = 0.09742\n","training took 23.29 s\n","Avg test loss = nan\tAvg test acc = 0.101\n","epoch 0\tavg epoch loss = 8.348e+17\tavg epoch acc = 0.1003\n","epoch 1\tavg epoch loss = 2.356\tavg epoch acc = 0.09938\n","epoch 2\tavg epoch loss = 2.356\tavg epoch acc = 0.09932\n","epoch 3\tavg epoch loss = 2.356\tavg epoch acc = 0.09932\n","epoch 4\tavg epoch loss = 2.356\tavg epoch acc = 0.09932\n","epoch 5\tavg epoch loss = 2.356\tavg epoch acc = 0.09925\n","epoch 6\tavg epoch loss = 2.356\tavg epoch acc = 0.0993\n","epoch 7\tavg epoch loss = 2.356\tavg epoch acc = 0.0993\n","epoch 8\tavg epoch loss = 2.356\tavg epoch acc = 0.0993\n","epoch 9\tavg epoch loss = 2.356\tavg epoch acc = 0.0993\n","training took 23.24 s\n","Avg test loss = 2.34\tAvg test acc = 0.0983\n","epoch 0\tavg epoch loss = 5.317e+14\tavg epoch acc = 0.09692\n","epoch 1\tavg epoch loss = 2.355\tavg epoch acc = 0.09703\n","epoch 2\tavg epoch loss = 2.355\tavg epoch acc = 0.09703\n","epoch 3\tavg epoch loss = 2.355\tavg epoch acc = 0.09703\n","epoch 4\tavg epoch loss = 2.355\tavg epoch acc = 0.09703\n","epoch 5\tavg epoch loss = 2.355\tavg epoch acc = 0.0971\n","epoch 6\tavg epoch loss = 2.355\tavg epoch acc = 0.0971\n","epoch 7\tavg epoch loss = 2.355\tavg epoch acc = 0.0971\n","epoch 8\tavg epoch loss = 2.355\tavg epoch acc = 0.09715\n","epoch 9\tavg epoch loss = 2.355\tavg epoch acc = 0.09715\n","training took 23.2 s\n","Avg test loss = 2.32\tAvg test acc = 0.113\n","{'lr': 2.9470517025518106, 'batch_size': 128}\n","epoch 0\tavg epoch loss = nan\tavg epoch acc = 0.09932\n","epoch 1\tavg epoch loss = nan\tavg epoch acc = 0.09912\n","epoch 2\tavg epoch loss = nan\tavg epoch acc = 0.09912\n","epoch 3\tavg epoch loss = nan\tavg epoch acc = 0.09912\n","epoch 4\tavg epoch loss = nan\tavg epoch acc = 0.09912\n","epoch 5\tavg epoch loss = nan\tavg epoch acc = 0.09912\n","epoch 6\tavg epoch loss = nan\tavg epoch acc = 0.09912\n","epoch 7\tavg epoch loss = nan\tavg epoch acc = 0.09912\n","epoch 8\tavg epoch loss = nan\tavg epoch acc = 0.09912\n","epoch 9\tavg epoch loss = nan\tavg epoch acc = 0.09912\n","training took 15.54 s\n","Avg test loss = nan\tAvg test acc = 0.0976\n","epoch 0\tavg epoch loss = nan\tavg epoch acc = 0.09937\n","epoch 1\tavg epoch loss = nan\tavg epoch acc = 0.09932\n","epoch 2\tavg epoch loss = nan\tavg epoch acc = 0.09932\n","epoch 3\tavg epoch loss = nan\tavg epoch acc = 0.09932\n","epoch 4\tavg epoch loss = nan\tavg epoch acc = 0.09932\n","epoch 5\tavg epoch loss = nan\tavg epoch acc = 0.09932\n","epoch 6\tavg epoch loss = nan\tavg epoch acc = 0.09932\n","epoch 7\tavg epoch loss = nan\tavg epoch acc = 0.09932\n","epoch 8\tavg epoch loss = nan\tavg epoch acc = 0.09932\n","epoch 9\tavg epoch loss = nan\tavg epoch acc = 0.09932\n","training took 15.55 s\n","Avg test loss = nan\tAvg test acc = 0.0976\n","epoch 0\tavg epoch loss = nan\tavg epoch acc = 0.09859\n","epoch 1\tavg epoch loss = nan\tavg epoch acc = 0.09769\n","epoch 2\tavg epoch loss = nan\tavg epoch acc = 0.09769\n","epoch 3\tavg epoch loss = nan\tavg epoch acc = 0.09769\n","epoch 4\tavg epoch loss = nan\tavg epoch acc = 0.09769\n","epoch 5\tavg epoch loss = nan\tavg epoch acc = 0.09769\n","epoch 6\tavg epoch loss = nan\tavg epoch acc = 0.09769\n","epoch 7\tavg epoch loss = nan\tavg epoch acc = 0.09769\n","epoch 8\tavg epoch loss = nan\tavg epoch acc = 0.09769\n","epoch 9\tavg epoch loss = nan\tavg epoch acc = 0.09769\n","training took 15.55 s\n","Avg test loss = nan\tAvg test acc = 0.101\n","{'lr': 3.088843596477481, 'batch_size': 32}\n","epoch 0\tavg epoch loss = 683.9\tavg epoch acc = 0.09748\n","epoch 1\tavg epoch loss = 3.048e+04\tavg epoch acc = 0.09673\n","epoch 2\tavg epoch loss = 13.42\tavg epoch acc = 0.09745\n","epoch 3\tavg epoch loss = 2.429\tavg epoch acc = 0.09667\n","epoch 4\tavg epoch loss = 2.514\tavg epoch acc = 0.09675\n","epoch 5\tavg epoch loss = 2.429\tavg epoch acc = 0.09667\n","epoch 6\tavg epoch loss = 2.45\tavg epoch acc = 0.09675\n","epoch 7\tavg epoch loss = 2.429\tavg epoch acc = 0.09667\n","epoch 8\tavg epoch loss = 2.429\tavg epoch acc = 0.09667\n","epoch 9\tavg epoch loss = 2.429\tavg epoch acc = 0.09667\n","training took 44.26 s\n","Avg test loss = 2.4\tAvg test acc = 0.105\n","epoch 0\tavg epoch loss = nan\tavg epoch acc = 0.09967\n","epoch 1\tavg epoch loss = nan\tavg epoch acc = 0.09967\n","epoch 2\tavg epoch loss = nan\tavg epoch acc = 0.09967\n","epoch 3\tavg epoch loss = nan\tavg epoch acc = 0.09967\n","epoch 4\tavg epoch loss = nan\tavg epoch acc = 0.09967\n","epoch 5\tavg epoch loss = nan\tavg epoch acc = 0.09967\n","epoch 6\tavg epoch loss = nan\tavg epoch acc = 0.09967\n","epoch 7\tavg epoch loss = nan\tavg epoch acc = 0.09967\n","epoch 8\tavg epoch loss = nan\tavg epoch acc = 0.09967\n","epoch 9\tavg epoch loss = nan\tavg epoch acc = 0.09967\n","training took 44.47 s\n","Avg test loss = nan\tAvg test acc = 0.0968\n","epoch 0\tavg epoch loss = 3.617e+10\tavg epoch acc = 0.09717\n","epoch 1\tavg epoch loss = 2.425\tavg epoch acc = 0.09705\n","epoch 2\tavg epoch loss = 2.44\tavg epoch acc = 0.09688\n","epoch 3\tavg epoch loss = 2.425\tavg epoch acc = 0.09705\n","epoch 4\tavg epoch loss = 2.425\tavg epoch acc = 0.09705\n","epoch 5\tavg epoch loss = 2.425\tavg epoch acc = 0.0971\n","epoch 6\tavg epoch loss = 2.425\tavg epoch acc = 0.0971\n","epoch 7\tavg epoch loss = 2.425\tavg epoch acc = 0.0971\n","epoch 8\tavg epoch loss = 2.425\tavg epoch acc = 0.09707\n","epoch 9\tavg epoch loss = 2.425\tavg epoch acc = 0.09707\n","training took 44.77 s\n","Avg test loss = 2.38\tAvg test acc = 0.0907\n","{'lr': 3.088843596477481, 'batch_size': 64}\n","epoch 0\tavg epoch loss = nan\tavg epoch acc = 0.09928\n","epoch 1\tavg epoch loss = nan\tavg epoch acc = 0.09925\n","epoch 2\tavg epoch loss = nan\tavg epoch acc = 0.09925\n","epoch 3\tavg epoch loss = nan\tavg epoch acc = 0.09925\n","epoch 4\tavg epoch loss = nan\tavg epoch acc = 0.09925\n","epoch 5\tavg epoch loss = nan\tavg epoch acc = 0.09925\n","epoch 6\tavg epoch loss = nan\tavg epoch acc = 0.09925\n","epoch 7\tavg epoch loss = nan\tavg epoch acc = 0.09925\n","epoch 8\tavg epoch loss = nan\tavg epoch acc = 0.09925\n","epoch 9\tavg epoch loss = nan\tavg epoch acc = 0.09925\n","training took 23.52 s\n","Avg test loss = nan\tAvg test acc = 0.0975\n","epoch 0\tavg epoch loss = 4.262\tavg epoch acc = 0.1\n","epoch 1\tavg epoch loss = 2.358\tavg epoch acc = 0.0993\n","epoch 2\tavg epoch loss = 2.358\tavg epoch acc = 0.09942\n","epoch 3\tavg epoch loss = 2.358\tavg epoch acc = 0.09942\n","epoch 4\tavg epoch loss = 2.358\tavg epoch acc = 0.09942\n","epoch 5\tavg epoch loss = 2.358\tavg epoch acc = 0.09942\n","epoch 6\tavg epoch loss = 2.358\tavg epoch acc = 0.09942\n","epoch 7\tavg epoch loss = 2.394\tavg epoch acc = 0.09997\n","epoch 8\tavg epoch loss = 2.358\tavg epoch acc = 0.09947\n","epoch 9\tavg epoch loss = 2.358\tavg epoch acc = 0.09947\n","training took 23.32 s\n","Avg test loss = 2.35\tAvg test acc = 0.111\n","epoch 0\tavg epoch loss = 1.785e+04\tavg epoch acc = 0.09895\n","epoch 1\tavg epoch loss = nan\tavg epoch acc = 0.09838\n","epoch 2\tavg epoch loss = nan\tavg epoch acc = 0.09813\n","epoch 3\tavg epoch loss = nan\tavg epoch acc = 0.09813\n","epoch 4\tavg epoch loss = nan\tavg epoch acc = 0.09813\n","epoch 5\tavg epoch loss = nan\tavg epoch acc = 0.09813\n","epoch 6\tavg epoch loss = nan\tavg epoch acc = 0.09813\n","epoch 7\tavg epoch loss = nan\tavg epoch acc = 0.09813\n","epoch 8\tavg epoch loss = nan\tavg epoch acc = 0.09813\n","epoch 9\tavg epoch loss = nan\tavg epoch acc = 0.09813\n","training took 23.17 s\n","Avg test loss = nan\tAvg test acc = 0.0999\n","{'lr': 3.088843596477481, 'batch_size': 128}\n","epoch 0\tavg epoch loss = nan\tavg epoch acc = 0.09847\n","epoch 1\tavg epoch loss = nan\tavg epoch acc = 0.09772\n","epoch 2\tavg epoch loss = nan\tavg epoch acc = 0.09772\n","epoch 3\tavg epoch loss = nan\tavg epoch acc = 0.09772\n","epoch 4\tavg epoch loss = nan\tavg epoch acc = 0.09772\n","epoch 5\tavg epoch loss = nan\tavg epoch acc = 0.09772\n","epoch 6\tavg epoch loss = nan\tavg epoch acc = 0.09772\n","epoch 7\tavg epoch loss = nan\tavg epoch acc = 0.09772\n","epoch 8\tavg epoch loss = nan\tavg epoch acc = 0.09772\n","epoch 9\tavg epoch loss = nan\tavg epoch acc = 0.09772\n","training took 15.56 s\n","Avg test loss = nan\tAvg test acc = 0.101\n","epoch 0\tavg epoch loss = nan\tavg epoch acc = 0.09904\n","epoch 1\tavg epoch loss = nan\tavg epoch acc = 0.09867\n","epoch 2\tavg epoch loss = nan\tavg epoch acc = 0.09867\n","epoch 3\tavg epoch loss = nan\tavg epoch acc = 0.09867\n","epoch 4\tavg epoch loss = nan\tavg epoch acc = 0.09867\n","epoch 5\tavg epoch loss = nan\tavg epoch acc = 0.09867\n","epoch 6\tavg epoch loss = nan\tavg epoch acc = 0.09867\n","epoch 7\tavg epoch loss = nan\tavg epoch acc = 0.09867\n","epoch 8\tavg epoch loss = nan\tavg epoch acc = 0.09867\n","epoch 9\tavg epoch loss = nan\tavg epoch acc = 0.09867\n","training took 15.59 s\n","Avg test loss = nan\tAvg test acc = 0.0989\n","epoch 0\tavg epoch loss = 13.13\tavg epoch acc = 0.1011\n","epoch 1\tavg epoch loss = 2.327\tavg epoch acc = 0.1006\n","epoch 2\tavg epoch loss = 2.327\tavg epoch acc = 0.1007\n","epoch 3\tavg epoch loss = 2.327\tavg epoch acc = 0.1007\n","epoch 4\tavg epoch loss = 2.327\tavg epoch acc = 0.1007\n","epoch 5\tavg epoch loss = 2.327\tavg epoch acc = 0.1007\n","epoch 6\tavg epoch loss = 2.327\tavg epoch acc = 0.1007\n","epoch 7\tavg epoch loss = 2.327\tavg epoch acc = 0.1007\n","epoch 8\tavg epoch loss = 2.327\tavg epoch acc = 0.1007\n","epoch 9\tavg epoch loss = 2.327\tavg epoch acc = 0.1007\n","training took 15.55 s\n","Avg test loss = 2.31\tAvg test acc = 0.101\n","{'lr': 3.237457542817644, 'batch_size': 32}\n","epoch 0\tavg epoch loss = 1.37e+19\tavg epoch acc = 0.09728\n","epoch 1\tavg epoch loss = nan\tavg epoch acc = 0.09738\n","epoch 2\tavg epoch loss = nan\tavg epoch acc = 0.09917\n","epoch 3\tavg epoch loss = nan\tavg epoch acc = 0.09917\n","epoch 4\tavg epoch loss = nan\tavg epoch acc = 0.09917\n","epoch 5\tavg epoch loss = nan\tavg epoch acc = 0.09917\n","epoch 6\tavg epoch loss = nan\tavg epoch acc = 0.09917\n","epoch 7\tavg epoch loss = nan\tavg epoch acc = 0.09917\n","epoch 8\tavg epoch loss = nan\tavg epoch acc = 0.09917\n","epoch 9\tavg epoch loss = nan\tavg epoch acc = 0.09917\n","training took 44.29 s\n","Avg test loss = nan\tAvg test acc = 0.0978\n","epoch 0\tavg epoch loss = nan\tavg epoch acc = 0.09855\n","epoch 1\tavg epoch loss = nan\tavg epoch acc = 0.09867\n","epoch 2\tavg epoch loss = nan\tavg epoch acc = 0.09867\n","epoch 3\tavg epoch loss = nan\tavg epoch acc = 0.09867\n","epoch 4\tavg epoch loss = nan\tavg epoch acc = 0.09867\n","epoch 5\tavg epoch loss = nan\tavg epoch acc = 0.09867\n","epoch 6\tavg epoch loss = nan\tavg epoch acc = 0.09867\n","epoch 7\tavg epoch loss = nan\tavg epoch acc = 0.09867\n","epoch 8\tavg epoch loss = nan\tavg epoch acc = 0.09867\n","epoch 9\tavg epoch loss = nan\tavg epoch acc = 0.09867\n","training took 44.22 s\n","Avg test loss = nan\tAvg test acc = 0.0988\n","epoch 0\tavg epoch loss = nan\tavg epoch acc = 0.09823\n","epoch 1\tavg epoch loss = nan\tavg epoch acc = 0.0983\n","epoch 2\tavg epoch loss = nan\tavg epoch acc = 0.0983\n","epoch 3\tavg epoch loss = nan\tavg epoch acc = 0.0983\n","epoch 4\tavg epoch loss = nan\tavg epoch acc = 0.0983\n","epoch 5\tavg epoch loss = nan\tavg epoch acc = 0.0983\n","epoch 6\tavg epoch loss = nan\tavg epoch acc = 0.0983\n","epoch 7\tavg epoch loss = nan\tavg epoch acc = 0.0983\n","epoch 8\tavg epoch loss = nan\tavg epoch acc = 0.0983\n","epoch 9\tavg epoch loss = nan\tavg epoch acc = 0.0983\n","training took 44.31 s\n","Avg test loss = nan\tAvg test acc = 0.0995\n","{'lr': 3.237457542817644, 'batch_size': 64}\n","epoch 0\tavg epoch loss = nan\tavg epoch acc = 0.09825\n","epoch 1\tavg epoch loss = nan\tavg epoch acc = 0.09825\n","epoch 2\tavg epoch loss = nan\tavg epoch acc = 0.09825\n","epoch 3\tavg epoch loss = nan\tavg epoch acc = 0.09825\n","epoch 4\tavg epoch loss = nan\tavg epoch acc = 0.09825\n","epoch 5\tavg epoch loss = nan\tavg epoch acc = 0.09825\n","epoch 6\tavg epoch loss = nan\tavg epoch acc = 0.09825\n","epoch 7\tavg epoch loss = nan\tavg epoch acc = 0.09825\n","epoch 8\tavg epoch loss = nan\tavg epoch acc = 0.09825\n","epoch 9\tavg epoch loss = nan\tavg epoch acc = 0.09825\n","training took 23.15 s\n","Avg test loss = nan\tAvg test acc = 0.0995\n","epoch 0\tavg epoch loss = nan\tavg epoch acc = 0.1003\n","epoch 1\tavg epoch loss = nan\tavg epoch acc = 0.1003\n","epoch 2\tavg epoch loss = nan\tavg epoch acc = 0.1003\n","epoch 3\tavg epoch loss = nan\tavg epoch acc = 0.1003\n","epoch 4\tavg epoch loss = nan\tavg epoch acc = 0.1003\n","epoch 5\tavg epoch loss = nan\tavg epoch acc = 0.1003\n","epoch 6\tavg epoch loss = nan\tavg epoch acc = 0.1003\n","epoch 7\tavg epoch loss = nan\tavg epoch acc = 0.1003\n","epoch 8\tavg epoch loss = nan\tavg epoch acc = 0.1003\n","epoch 9\tavg epoch loss = nan\tavg epoch acc = 0.1003\n","training took 23.22 s\n","Avg test loss = nan\tAvg test acc = 0.0957\n","epoch 0\tavg epoch loss = nan\tavg epoch acc = 0.09763\n","epoch 1\tavg epoch loss = nan\tavg epoch acc = 0.0976\n","epoch 2\tavg epoch loss = nan\tavg epoch acc = 0.0976\n","epoch 3\tavg epoch loss = nan\tavg epoch acc = 0.0976\n","epoch 4\tavg epoch loss = nan\tavg epoch acc = 0.0976\n","epoch 5\tavg epoch loss = nan\tavg epoch acc = 0.0976\n","epoch 6\tavg epoch loss = nan\tavg epoch acc = 0.0976\n","epoch 7\tavg epoch loss = nan\tavg epoch acc = 0.0976\n","epoch 8\tavg epoch loss = nan\tavg epoch acc = 0.0976\n","epoch 9\tavg epoch loss = nan\tavg epoch acc = 0.0976\n","training took 23.21 s\n","Avg test loss = nan\tAvg test acc = 0.101\n","{'lr': 3.237457542817644, 'batch_size': 128}\n","epoch 0\tavg epoch loss = 2.343\tavg epoch acc = 0.1004\n","epoch 1\tavg epoch loss = 2.328\tavg epoch acc = 0.1002\n","epoch 2\tavg epoch loss = 2.328\tavg epoch acc = 0.1001\n","epoch 3\tavg epoch loss = 2.328\tavg epoch acc = 0.1001\n","epoch 4\tavg epoch loss = 2.328\tavg epoch acc = 0.1001\n","epoch 5\tavg epoch loss = 2.328\tavg epoch acc = 0.1001\n","epoch 6\tavg epoch loss = 2.328\tavg epoch acc = 0.1001\n","epoch 7\tavg epoch loss = 2.328\tavg epoch acc = 0.1001\n","epoch 8\tavg epoch loss = 2.328\tavg epoch acc = 0.1001\n","epoch 9\tavg epoch loss = 2.328\tavg epoch acc = 0.1001\n","training took 15.63 s\n","Avg test loss = 2.31\tAvg test acc = 0.0972\n","epoch 0\tavg epoch loss = nan\tavg epoch acc = 0.09722\n","epoch 1\tavg epoch loss = nan\tavg epoch acc = 0.09714\n","epoch 2\tavg epoch loss = nan\tavg epoch acc = 0.09714\n","epoch 3\tavg epoch loss = nan\tavg epoch acc = 0.09714\n","epoch 4\tavg epoch loss = nan\tavg epoch acc = 0.09714\n","epoch 5\tavg epoch loss = nan\tavg epoch acc = 0.09714\n","epoch 6\tavg epoch loss = nan\tavg epoch acc = 0.09714\n","epoch 7\tavg epoch loss = nan\tavg epoch acc = 0.09714\n","epoch 8\tavg epoch loss = nan\tavg epoch acc = 0.09714\n","epoch 9\tavg epoch loss = nan\tavg epoch acc = 0.09714\n","training took 15.53 s\n","Avg test loss = nan\tAvg test acc = 0.102\n","epoch 0\tavg epoch loss = nan\tavg epoch acc = 0.1001\n","epoch 1\tavg epoch loss = nan\tavg epoch acc = 0.09952\n","epoch 2\tavg epoch loss = nan\tavg epoch acc = 0.09952\n","epoch 3\tavg epoch loss = nan\tavg epoch acc = 0.09952\n","epoch 4\tavg epoch loss = nan\tavg epoch acc = 0.09952\n","epoch 5\tavg epoch loss = nan\tavg epoch acc = 0.09952\n","epoch 6\tavg epoch loss = nan\tavg epoch acc = 0.09952\n","epoch 7\tavg epoch loss = nan\tavg epoch acc = 0.09952\n","epoch 8\tavg epoch loss = nan\tavg epoch acc = 0.09952\n","epoch 9\tavg epoch loss = nan\tavg epoch acc = 0.09952\n","training took 15.55 s\n","Avg test loss = nan\tAvg test acc = 0.0968\n","{'lr': 3.393221771895328, 'batch_size': 32}\n","epoch 0\tavg epoch loss = nan\tavg epoch acc = 0.09792\n","epoch 1\tavg epoch loss = nan\tavg epoch acc = 0.098\n","epoch 2\tavg epoch loss = nan\tavg epoch acc = 0.098\n","epoch 3\tavg epoch loss = nan\tavg epoch acc = 0.098\n","epoch 4\tavg epoch loss = nan\tavg epoch acc = 0.098\n","epoch 5\tavg epoch loss = nan\tavg epoch acc = 0.098\n","epoch 6\tavg epoch loss = nan\tavg epoch acc = 0.098\n","epoch 7\tavg epoch loss = nan\tavg epoch acc = 0.098\n","epoch 8\tavg epoch loss = nan\tavg epoch acc = 0.098\n","epoch 9\tavg epoch loss = nan\tavg epoch acc = 0.098\n","training took 44.35 s\n","Avg test loss = nan\tAvg test acc = 0.1\n","epoch 0\tavg epoch loss = 3.272e+03\tavg epoch acc = 0.0947\n","epoch 1\tavg epoch loss = 2.622\tavg epoch acc = 0.09492\n","epoch 2\tavg epoch loss = 2.436\tavg epoch acc = 0.09545\n","epoch 3\tavg epoch loss = 2.437\tavg epoch acc = 0.09545\n","epoch 4\tavg epoch loss = 2.437\tavg epoch acc = 0.09545\n","epoch 5\tavg epoch loss = 2.437\tavg epoch acc = 0.09545\n","epoch 6\tavg epoch loss = 2.437\tavg epoch acc = 0.09545\n","epoch 7\tavg epoch loss = 2.437\tavg epoch acc = 0.09552\n","epoch 8\tavg epoch loss = 2.437\tavg epoch acc = 0.09555\n","epoch 9\tavg epoch loss = 2.437\tavg epoch acc = 0.09555\n","training took 44.41 s\n","Avg test loss = 4.62e+04\tAvg test acc = 0.0959\n","epoch 0\tavg epoch loss = 1.594e+12\tavg epoch acc = 0.0965\n","epoch 1\tavg epoch loss = 2.436\tavg epoch acc = 0.09632\n","epoch 2\tavg epoch loss = 2.436\tavg epoch acc = 0.09655\n","epoch 3\tavg epoch loss = 2.436\tavg epoch acc = 0.09655\n","epoch 4\tavg epoch loss = 2.436\tavg epoch acc = 0.09655\n","epoch 5\tavg epoch loss = 2.436\tavg epoch acc = 0.09655\n","epoch 6\tavg epoch loss = 2.436\tavg epoch acc = 0.09655\n","epoch 7\tavg epoch loss = 2.436\tavg epoch acc = 0.09655\n","epoch 8\tavg epoch loss = 2.436\tavg epoch acc = 0.09655\n","epoch 9\tavg epoch loss = 2.436\tavg epoch acc = 0.09655\n","training took 44.31 s\n","Avg test loss = 1.38e+11\tAvg test acc = 0.0985\n","{'lr': 3.393221771895328, 'batch_size': 64}\n","epoch 0\tavg epoch loss = nan\tavg epoch acc = 0.0988\n","epoch 1\tavg epoch loss = nan\tavg epoch acc = 0.09853\n","epoch 2\tavg epoch loss = nan\tavg epoch acc = 0.09853\n","epoch 3\tavg epoch loss = nan\tavg epoch acc = 0.09853\n","epoch 4\tavg epoch loss = nan\tavg epoch acc = 0.09853\n","epoch 5\tavg epoch loss = nan\tavg epoch acc = 0.09853\n","epoch 6\tavg epoch loss = nan\tavg epoch acc = 0.09853\n","epoch 7\tavg epoch loss = nan\tavg epoch acc = 0.09853\n","epoch 8\tavg epoch loss = nan\tavg epoch acc = 0.09853\n","epoch 9\tavg epoch loss = nan\tavg epoch acc = 0.09853\n","training took 23.13 s\n","Avg test loss = nan\tAvg test acc = 0.0992\n","epoch 0\tavg epoch loss = 801.9\tavg epoch acc = 0.101\n","epoch 1\tavg epoch loss = 2.361\tavg epoch acc = 0.1011\n","epoch 2\tavg epoch loss = 2.361\tavg epoch acc = 0.101\n","epoch 3\tavg epoch loss = 2.361\tavg epoch acc = 0.101\n","epoch 4\tavg epoch loss = 2.361\tavg epoch acc = 0.1011\n","epoch 5\tavg epoch loss = 2.361\tavg epoch acc = 0.1011\n","epoch 6\tavg epoch loss = 2.361\tavg epoch acc = 0.1011\n","epoch 7\tavg epoch loss = 2.361\tavg epoch acc = 0.1011\n","epoch 8\tavg epoch loss = 2.361\tavg epoch acc = 0.1011\n","epoch 9\tavg epoch loss = 2.361\tavg epoch acc = 0.1011\n","training took 23.16 s\n","Avg test loss = 2.33\tAvg test acc = 0.111\n","epoch 0\tavg epoch loss = nan\tavg epoch acc = 0.09985\n","epoch 1\tavg epoch loss = nan\tavg epoch acc = 0.0998\n","epoch 2\tavg epoch loss = nan\tavg epoch acc = 0.0998\n","epoch 3\tavg epoch loss = nan\tavg epoch acc = 0.0998\n","epoch 4\tavg epoch loss = nan\tavg epoch acc = 0.0998\n","epoch 5\tavg epoch loss = nan\tavg epoch acc = 0.0998\n","epoch 6\tavg epoch loss = nan\tavg epoch acc = 0.0998\n","epoch 7\tavg epoch loss = nan\tavg epoch acc = 0.0998\n","epoch 8\tavg epoch loss = nan\tavg epoch acc = 0.0998\n","epoch 9\tavg epoch loss = nan\tavg epoch acc = 0.0998\n","training took 23.37 s\n","Avg test loss = nan\tAvg test acc = 0.0965\n","{'lr': 3.393221771895328, 'batch_size': 128}\n","epoch 0\tavg epoch loss = nan\tavg epoch acc = 0.09859\n","epoch 1\tavg epoch loss = nan\tavg epoch acc = 0.09839\n","epoch 2\tavg epoch loss = nan\tavg epoch acc = 0.09839\n","epoch 3\tavg epoch loss = nan\tavg epoch acc = 0.09839\n","epoch 4\tavg epoch loss = nan\tavg epoch acc = 0.09839\n","epoch 5\tavg epoch loss = nan\tavg epoch acc = 0.09839\n","epoch 6\tavg epoch loss = nan\tavg epoch acc = 0.09839\n","epoch 7\tavg epoch loss = nan\tavg epoch acc = 0.09839\n","epoch 8\tavg epoch loss = nan\tavg epoch acc = 0.09839\n","epoch 9\tavg epoch loss = nan\tavg epoch acc = 0.09839\n","training took 15.55 s\n","Avg test loss = nan\tAvg test acc = 0.0993\n","epoch 0\tavg epoch loss = nan\tavg epoch acc = 0.09854\n","epoch 1\tavg epoch loss = nan\tavg epoch acc = 0.09817\n","epoch 2\tavg epoch loss = nan\tavg epoch acc = 0.09817\n","epoch 3\tavg epoch loss = nan\tavg epoch acc = 0.09817\n","epoch 4\tavg epoch loss = nan\tavg epoch acc = 0.09817\n","epoch 5\tavg epoch loss = nan\tavg epoch acc = 0.09817\n","epoch 6\tavg epoch loss = nan\tavg epoch acc = 0.09817\n","epoch 7\tavg epoch loss = nan\tavg epoch acc = 0.09817\n","epoch 8\tavg epoch loss = nan\tavg epoch acc = 0.09817\n","epoch 9\tavg epoch loss = nan\tavg epoch acc = 0.09817\n","training took 15.57 s\n","Avg test loss = nan\tAvg test acc = 0.0998\n","epoch 0\tavg epoch loss = 358.4\tavg epoch acc = 0.09932\n","epoch 1\tavg epoch loss = 2.328\tavg epoch acc = 0.09854\n","epoch 2\tavg epoch loss = 2.328\tavg epoch acc = 0.09862\n","epoch 3\tavg epoch loss = 2.329\tavg epoch acc = 0.09862\n","epoch 4\tavg epoch loss = 2.329\tavg epoch acc = 0.09862\n","epoch 5\tavg epoch loss = 2.329\tavg epoch acc = 0.09862\n","epoch 6\tavg epoch loss = 2.329\tavg epoch acc = 0.09862\n","epoch 7\tavg epoch loss = 2.329\tavg epoch acc = 0.09862\n","epoch 8\tavg epoch loss = 2.329\tavg epoch acc = 0.09862\n","epoch 9\tavg epoch loss = 2.329\tavg epoch acc = 0.09862\n","training took 15.64 s\n","Avg test loss = 2.32\tAvg test acc = 0.1\n","{'lr': 3.5564803062231287, 'batch_size': 32}\n","epoch 0\tavg epoch loss = 6.145e+21\tavg epoch acc = 0.0993\n","epoch 1\tavg epoch loss = 2.442\tavg epoch acc = 0.09885\n","epoch 2\tavg epoch loss = 2.442\tavg epoch acc = 0.09888\n","epoch 3\tavg epoch loss = 2.442\tavg epoch acc = 0.09888\n","epoch 4\tavg epoch loss = 2.442\tavg epoch acc = 0.09892\n","epoch 5\tavg epoch loss = 2.442\tavg epoch acc = 0.09892\n","epoch 6\tavg epoch loss = 2.442\tavg epoch acc = 0.09892\n","epoch 7\tavg epoch loss = 2.442\tavg epoch acc = 0.09892\n","epoch 8\tavg epoch loss = 2.442\tavg epoch acc = 0.09892\n","epoch 9\tavg epoch loss = 2.442\tavg epoch acc = 0.09897\n","training took 45.44 s\n","Avg test loss = 2.36\tAvg test acc = 0.0925\n","epoch 0\tavg epoch loss = nan\tavg epoch acc = 0.09847\n","epoch 1\tavg epoch loss = nan\tavg epoch acc = 0.09867\n","epoch 2\tavg epoch loss = nan\tavg epoch acc = 0.09867\n","epoch 3\tavg epoch loss = nan\tavg epoch acc = 0.09867\n","epoch 4\tavg epoch loss = nan\tavg epoch acc = 0.09867\n","epoch 5\tavg epoch loss = nan\tavg epoch acc = 0.09867\n","epoch 6\tavg epoch loss = nan\tavg epoch acc = 0.09867\n","epoch 7\tavg epoch loss = nan\tavg epoch acc = 0.09867\n","epoch 8\tavg epoch loss = nan\tavg epoch acc = 0.09867\n","epoch 9\tavg epoch loss = nan\tavg epoch acc = 0.09867\n","training took 44.58 s\n","Avg test loss = nan\tAvg test acc = 0.0988\n","epoch 0\tavg epoch loss = 7.51e+17\tavg epoch acc = 0.096\n","epoch 1\tavg epoch loss = 2.443\tavg epoch acc = 0.09552\n","epoch 2\tavg epoch loss = 2.443\tavg epoch acc = 0.0955\n","epoch 3\tavg epoch loss = 2.443\tavg epoch acc = 0.09548\n","epoch 4\tavg epoch loss = 2.443\tavg epoch acc = 0.09548\n","epoch 5\tavg epoch loss = 2.443\tavg epoch acc = 0.09548\n","epoch 6\tavg epoch loss = 2.443\tavg epoch acc = 0.09548\n","epoch 7\tavg epoch loss = 2.443\tavg epoch acc = 0.09548\n","epoch 8\tavg epoch loss = 2.443\tavg epoch acc = 0.09548\n","epoch 9\tavg epoch loss = 2.443\tavg epoch acc = 0.09548\n","training took 44.65 s\n","Avg test loss = 2.4\tAvg test acc = 0.0997\n","{'lr': 3.5564803062231287, 'batch_size': 64}\n","epoch 0\tavg epoch loss = nan\tavg epoch acc = 0.09745\n","epoch 1\tavg epoch loss = nan\tavg epoch acc = 0.09703\n","epoch 2\tavg epoch loss = nan\tavg epoch acc = 0.09703\n","epoch 3\tavg epoch loss = nan\tavg epoch acc = 0.09703\n","epoch 4\tavg epoch loss = nan\tavg epoch acc = 0.09703\n","epoch 5\tavg epoch loss = nan\tavg epoch acc = 0.09703\n","epoch 6\tavg epoch loss = nan\tavg epoch acc = 0.09703\n","epoch 7\tavg epoch loss = nan\tavg epoch acc = 0.09703\n","epoch 8\tavg epoch loss = nan\tavg epoch acc = 0.09703\n","epoch 9\tavg epoch loss = nan\tavg epoch acc = 0.09703\n","training took 23.23 s\n","Avg test loss = nan\tAvg test acc = 0.102\n","epoch 0\tavg epoch loss = 2.957e+05\tavg epoch acc = 0.09953\n","epoch 1\tavg epoch loss = 3.152\tavg epoch acc = 0.0971\n","epoch 2\tavg epoch loss = 2.367\tavg epoch acc = 0.09738\n","epoch 3\tavg epoch loss = 2.367\tavg epoch acc = 0.09738\n","epoch 4\tavg epoch loss = 2.367\tavg epoch acc = 0.09738\n","epoch 5\tavg epoch loss = 2.368\tavg epoch acc = 0.09738\n","epoch 6\tavg epoch loss = 2.368\tavg epoch acc = 0.09738\n","epoch 7\tavg epoch loss = 2.368\tavg epoch acc = 0.09738\n","epoch 8\tavg epoch loss = 2.368\tavg epoch acc = 0.09738\n","epoch 9\tavg epoch loss = 2.368\tavg epoch acc = 0.09738\n","training took 23.34 s\n","Avg test loss = 2.33\tAvg test acc = 0.0993\n","epoch 0\tavg epoch loss = nan\tavg epoch acc = 0.0998\n","epoch 1\tavg epoch loss = nan\tavg epoch acc = 0.09972\n","epoch 2\tavg epoch loss = nan\tavg epoch acc = 0.09972\n","epoch 3\tavg epoch loss = nan\tavg epoch acc = 0.09972\n","epoch 4\tavg epoch loss = nan\tavg epoch acc = 0.09972\n","epoch 5\tavg epoch loss = nan\tavg epoch acc = 0.09972\n","epoch 6\tavg epoch loss = nan\tavg epoch acc = 0.09972\n","epoch 7\tavg epoch loss = nan\tavg epoch acc = 0.09972\n","epoch 8\tavg epoch loss = nan\tavg epoch acc = 0.09972\n","epoch 9\tavg epoch loss = nan\tavg epoch acc = 0.09972\n","training took 23.42 s\n","Avg test loss = nan\tAvg test acc = 0.0966\n","{'lr': 3.5564803062231287, 'batch_size': 128}\n","epoch 0\tavg epoch loss = nan\tavg epoch acc = 0.09872\n","epoch 1\tavg epoch loss = nan\tavg epoch acc = 0.09847\n","epoch 2\tavg epoch loss = nan\tavg epoch acc = 0.09847\n","epoch 3\tavg epoch loss = nan\tavg epoch acc = 0.09847\n","epoch 4\tavg epoch loss = nan\tavg epoch acc = 0.09847\n","epoch 5\tavg epoch loss = nan\tavg epoch acc = 0.09847\n","epoch 6\tavg epoch loss = nan\tavg epoch acc = 0.09847\n","epoch 7\tavg epoch loss = nan\tavg epoch acc = 0.09847\n","epoch 8\tavg epoch loss = nan\tavg epoch acc = 0.09847\n","epoch 9\tavg epoch loss = nan\tavg epoch acc = 0.09847\n","training took 15.61 s\n","Avg test loss = nan\tAvg test acc = 0.0993\n","epoch 0\tavg epoch loss = nan\tavg epoch acc = 0.09894\n","epoch 1\tavg epoch loss = nan\tavg epoch acc = 0.09857\n","epoch 2\tavg epoch loss = nan\tavg epoch acc = 0.09857\n","epoch 3\tavg epoch loss = nan\tavg epoch acc = 0.09857\n","epoch 4\tavg epoch loss = nan\tavg epoch acc = 0.09857\n","epoch 5\tavg epoch loss = nan\tavg epoch acc = 0.09857\n","epoch 6\tavg epoch loss = nan\tavg epoch acc = 0.09857\n","epoch 7\tavg epoch loss = nan\tavg epoch acc = 0.09857\n","epoch 8\tavg epoch loss = nan\tavg epoch acc = 0.09857\n","epoch 9\tavg epoch loss = nan\tavg epoch acc = 0.09857\n","training took 15.65 s\n","Avg test loss = nan\tAvg test acc = 0.099\n","epoch 0\tavg epoch loss = nan\tavg epoch acc = 0.09884\n","epoch 1\tavg epoch loss = nan\tavg epoch acc = 0.09909\n","epoch 2\tavg epoch loss = nan\tavg epoch acc = 0.09909\n","epoch 3\tavg epoch loss = nan\tavg epoch acc = 0.09909\n","epoch 4\tavg epoch loss = nan\tavg epoch acc = 0.09909\n","epoch 5\tavg epoch loss = nan\tavg epoch acc = 0.09909\n","epoch 6\tavg epoch loss = nan\tavg epoch acc = 0.09909\n","epoch 7\tavg epoch loss = nan\tavg epoch acc = 0.09909\n","epoch 8\tavg epoch loss = nan\tavg epoch acc = 0.09909\n","epoch 9\tavg epoch loss = nan\tavg epoch acc = 0.09909\n","training took 15.65 s\n","Avg test loss = nan\tAvg test acc = 0.0978\n","{'lr': 3.72759372031494, 'batch_size': 32}\n","epoch 0\tavg epoch loss = nan\tavg epoch acc = 0.09742\n","epoch 1\tavg epoch loss = nan\tavg epoch acc = 0.09748\n","epoch 2\tavg epoch loss = nan\tavg epoch acc = 0.09748\n","epoch 3\tavg epoch loss = nan\tavg epoch acc = 0.09748\n","epoch 4\tavg epoch loss = nan\tavg epoch acc = 0.09748\n","epoch 5\tavg epoch loss = nan\tavg epoch acc = 0.09748\n","epoch 6\tavg epoch loss = nan\tavg epoch acc = 0.09748\n","epoch 7\tavg epoch loss = nan\tavg epoch acc = 0.09748\n","epoch 8\tavg epoch loss = nan\tavg epoch acc = 0.09748\n","epoch 9\tavg epoch loss = nan\tavg epoch acc = 0.09748\n","training took 44.77 s\n","Avg test loss = nan\tAvg test acc = 0.101\n","epoch 0\tavg epoch loss = 1.037e+22\tavg epoch acc = 0.09575\n","epoch 1\tavg epoch loss = 1.082e+11\tavg epoch acc = 0.09677\n","epoch 2\tavg epoch loss = 1.845e+09\tavg epoch acc = 0.0961\n","epoch 3\tavg epoch loss = 2.449\tavg epoch acc = 0.096\n","epoch 4\tavg epoch loss = 2.449\tavg epoch acc = 0.096\n","epoch 5\tavg epoch loss = 2.449\tavg epoch acc = 0.096\n","epoch 6\tavg epoch loss = 2.449\tavg epoch acc = 0.096\n","epoch 7\tavg epoch loss = 2.449\tavg epoch acc = 0.096\n","epoch 8\tavg epoch loss = 2.449\tavg epoch acc = 0.096\n","epoch 9\tavg epoch loss = 2.449\tavg epoch acc = 0.096\n","training took 44.71 s\n","Avg test loss = 2.48\tAvg test acc = 0.0962\n","epoch 0\tavg epoch loss = nan\tavg epoch acc = 0.09832\n","epoch 1\tavg epoch loss = nan\tavg epoch acc = 0.0983\n","epoch 2\tavg epoch loss = nan\tavg epoch acc = 0.0983\n","epoch 3\tavg epoch loss = nan\tavg epoch acc = 0.0983\n","epoch 4\tavg epoch loss = nan\tavg epoch acc = 0.0983\n","epoch 5\tavg epoch loss = nan\tavg epoch acc = 0.0983\n","epoch 6\tavg epoch loss = nan\tavg epoch acc = 0.0983\n","epoch 7\tavg epoch loss = nan\tavg epoch acc = 0.0983\n","epoch 8\tavg epoch loss = nan\tavg epoch acc = 0.0983\n","epoch 9\tavg epoch loss = nan\tavg epoch acc = 0.0983\n","training took 44.68 s\n","Avg test loss = nan\tAvg test acc = 0.0995\n","{'lr': 3.72759372031494, 'batch_size': 64}\n","epoch 0\tavg epoch loss = 1.201e+06\tavg epoch acc = 0.09803\n","epoch 1\tavg epoch loss = 2.367\tavg epoch acc = 0.09838\n","epoch 2\tavg epoch loss = 2.367\tavg epoch acc = 0.09847\n","epoch 3\tavg epoch loss = 2.367\tavg epoch acc = 0.09847\n","epoch 4\tavg epoch loss = 2.367\tavg epoch acc = 0.09847\n","epoch 5\tavg epoch loss = 2.367\tavg epoch acc = 0.09847\n","epoch 6\tavg epoch loss = 2.367\tavg epoch acc = 0.09847\n","epoch 7\tavg epoch loss = 2.367\tavg epoch acc = 0.09847\n","epoch 8\tavg epoch loss = 2.367\tavg epoch acc = 0.09847\n","epoch 9\tavg epoch loss = 2.367\tavg epoch acc = 0.09847\n","training took 23.45 s\n","Avg test loss = 2.33\tAvg test acc = 0.0967\n","epoch 0\tavg epoch loss = nan\tavg epoch acc = 0.09782\n","epoch 1\tavg epoch loss = nan\tavg epoch acc = 0.09775\n","epoch 2\tavg epoch loss = nan\tavg epoch acc = 0.09775\n","epoch 3\tavg epoch loss = nan\tavg epoch acc = 0.09775\n","epoch 4\tavg epoch loss = nan\tavg epoch acc = 0.09775\n","epoch 5\tavg epoch loss = nan\tavg epoch acc = 0.09775\n","epoch 6\tavg epoch loss = nan\tavg epoch acc = 0.09775\n","epoch 7\tavg epoch loss = nan\tavg epoch acc = 0.09775\n","epoch 8\tavg epoch loss = nan\tavg epoch acc = 0.09775\n","epoch 9\tavg epoch loss = nan\tavg epoch acc = 0.09775\n","training took 23.61 s\n","Avg test loss = nan\tAvg test acc = 0.101\n","epoch 0\tavg epoch loss = 5.584e+14\tavg epoch acc = 0.09692\n","epoch 1\tavg epoch loss = 2.367\tavg epoch acc = 0.09785\n","epoch 2\tavg epoch loss = 2.367\tavg epoch acc = 0.0979\n","epoch 3\tavg epoch loss = 2.367\tavg epoch acc = 0.0979\n","epoch 4\tavg epoch loss = 2.368\tavg epoch acc = 0.0979\n","epoch 5\tavg epoch loss = 2.368\tavg epoch acc = 0.0979\n","epoch 6\tavg epoch loss = 2.368\tavg epoch acc = 0.0979\n","epoch 7\tavg epoch loss = 2.368\tavg epoch acc = 0.0979\n","epoch 8\tavg epoch loss = 2.368\tavg epoch acc = 0.0979\n","epoch 9\tavg epoch loss = 2.368\tavg epoch acc = 0.0979\n","training took 23.41 s\n","Avg test loss = 5.06e+16\tAvg test acc = 0.0973\n","{'lr': 3.72759372031494, 'batch_size': 128}\n","epoch 0\tavg epoch loss = nan\tavg epoch acc = 0.1007\n","epoch 1\tavg epoch loss = nan\tavg epoch acc = 0.09922\n","epoch 2\tavg epoch loss = nan\tavg epoch acc = 0.09922\n","epoch 3\tavg epoch loss = nan\tavg epoch acc = 0.09922\n","epoch 4\tavg epoch loss = nan\tavg epoch acc = 0.09922\n","epoch 5\tavg epoch loss = nan\tavg epoch acc = 0.09922\n","epoch 6\tavg epoch loss = nan\tavg epoch acc = 0.09922\n","epoch 7\tavg epoch loss = nan\tavg epoch acc = 0.09922\n","epoch 8\tavg epoch loss = nan\tavg epoch acc = 0.09922\n","epoch 9\tavg epoch loss = nan\tavg epoch acc = 0.09922\n","training took 15.74 s\n","Avg test loss = nan\tAvg test acc = 0.098\n","epoch 0\tavg epoch loss = nan\tavg epoch acc = 0.09942\n","epoch 1\tavg epoch loss = nan\tavg epoch acc = 0.09919\n","epoch 2\tavg epoch loss = nan\tavg epoch acc = 0.09919\n","epoch 3\tavg epoch loss = nan\tavg epoch acc = 0.09919\n","epoch 4\tavg epoch loss = nan\tavg epoch acc = 0.09919\n","epoch 5\tavg epoch loss = nan\tavg epoch acc = 0.09919\n","epoch 6\tavg epoch loss = nan\tavg epoch acc = 0.09919\n","epoch 7\tavg epoch loss = nan\tavg epoch acc = 0.09919\n","epoch 8\tavg epoch loss = nan\tavg epoch acc = 0.09919\n","epoch 9\tavg epoch loss = nan\tavg epoch acc = 0.09919\n","training took 15.8 s\n","Avg test loss = nan\tAvg test acc = 0.0978\n","epoch 0\tavg epoch loss = nan\tavg epoch acc = 0.09812\n","epoch 1\tavg epoch loss = nan\tavg epoch acc = 0.09777\n","epoch 2\tavg epoch loss = nan\tavg epoch acc = 0.09777\n","epoch 3\tavg epoch loss = nan\tavg epoch acc = 0.09777\n","epoch 4\tavg epoch loss = nan\tavg epoch acc = 0.09777\n","epoch 5\tavg epoch loss = nan\tavg epoch acc = 0.09777\n","epoch 6\tavg epoch loss = nan\tavg epoch acc = 0.09777\n","epoch 7\tavg epoch loss = nan\tavg epoch acc = 0.09777\n","epoch 8\tavg epoch loss = nan\tavg epoch acc = 0.09777\n","epoch 9\tavg epoch loss = nan\tavg epoch acc = 0.09777\n","training took 15.96 s\n","Avg test loss = nan\tAvg test acc = 0.1\n","{'lr': 3.906939937054617, 'batch_size': 32}\n","epoch 0\tavg epoch loss = nan\tavg epoch acc = 0.09897\n","epoch 1\tavg epoch loss = nan\tavg epoch acc = 0.09892\n","epoch 2\tavg epoch loss = nan\tavg epoch acc = 0.09892\n","epoch 3\tavg epoch loss = nan\tavg epoch acc = 0.09892\n","epoch 4\tavg epoch loss = nan\tavg epoch acc = 0.09892\n","epoch 5\tavg epoch loss = nan\tavg epoch acc = 0.09892\n","epoch 6\tavg epoch loss = nan\tavg epoch acc = 0.09892\n","epoch 7\tavg epoch loss = nan\tavg epoch acc = 0.09892\n","epoch 8\tavg epoch loss = nan\tavg epoch acc = 0.09892\n","epoch 9\tavg epoch loss = nan\tavg epoch acc = 0.09892\n","training took 44.94 s\n","Avg test loss = nan\tAvg test acc = 0.0983\n","epoch 0\tavg epoch loss = nan\tavg epoch acc = 0.1002\n","epoch 1\tavg epoch loss = nan\tavg epoch acc = 0.1003\n","epoch 2\tavg epoch loss = nan\tavg epoch acc = 0.1003\n","epoch 3\tavg epoch loss = nan\tavg epoch acc = 0.1003\n","epoch 4\tavg epoch loss = nan\tavg epoch acc = 0.1003\n","epoch 5\tavg epoch loss = nan\tavg epoch acc = 0.1003\n","epoch 6\tavg epoch loss = nan\tavg epoch acc = 0.1003\n","epoch 7\tavg epoch loss = nan\tavg epoch acc = 0.1003\n","epoch 8\tavg epoch loss = nan\tavg epoch acc = 0.1003\n","epoch 9\tavg epoch loss = nan\tavg epoch acc = 0.1003\n","training took 44.89 s\n","Avg test loss = nan\tAvg test acc = 0.0956\n","epoch 0\tavg epoch loss = nan\tavg epoch acc = 0.09703\n","epoch 1\tavg epoch loss = nan\tavg epoch acc = 0.09698\n","epoch 2\tavg epoch loss = nan\tavg epoch acc = 0.09698\n","epoch 3\tavg epoch loss = nan\tavg epoch acc = 0.09698\n","epoch 4\tavg epoch loss = nan\tavg epoch acc = 0.09698\n","epoch 5\tavg epoch loss = nan\tavg epoch acc = 0.09698\n","epoch 6\tavg epoch loss = nan\tavg epoch acc = 0.09698\n","epoch 7\tavg epoch loss = nan\tavg epoch acc = 0.09698\n","epoch 8\tavg epoch loss = nan\tavg epoch acc = 0.09698\n","epoch 9\tavg epoch loss = nan\tavg epoch acc = 0.09698\n","training took 44.91 s\n","Avg test loss = nan\tAvg test acc = 0.102\n","{'lr': 3.906939937054617, 'batch_size': 64}\n","epoch 0\tavg epoch loss = 3.51e+06\tavg epoch acc = 0.09847\n","epoch 1\tavg epoch loss = 9.878e+08\tavg epoch acc = 0.09895\n","epoch 2\tavg epoch loss = 1.621e+04\tavg epoch acc = 0.099\n","epoch 3\tavg epoch loss = 5.755e+03\tavg epoch acc = 0.0992\n","epoch 4\tavg epoch loss = 2.369\tavg epoch acc = 0.09942\n","epoch 5\tavg epoch loss = 2.369\tavg epoch acc = 0.09942\n","epoch 6\tavg epoch loss = 2.369\tavg epoch acc = 0.09942\n","epoch 7\tavg epoch loss = 2.369\tavg epoch acc = 0.09942\n","epoch 8\tavg epoch loss = 2.369\tavg epoch acc = 0.09942\n","epoch 9\tavg epoch loss = 2.369\tavg epoch acc = 0.09942\n","training took 23.47 s\n","Avg test loss = 2.35\tAvg test acc = 0.0966\n","epoch 0\tavg epoch loss = nan\tavg epoch acc = 0.101\n","epoch 1\tavg epoch loss = nan\tavg epoch acc = 0.1009\n","epoch 2\tavg epoch loss = nan\tavg epoch acc = 0.1009\n","epoch 3\tavg epoch loss = nan\tavg epoch acc = 0.1009\n","epoch 4\tavg epoch loss = nan\tavg epoch acc = 0.1009\n","epoch 5\tavg epoch loss = nan\tavg epoch acc = 0.1009\n","epoch 6\tavg epoch loss = nan\tavg epoch acc = 0.1009\n","epoch 7\tavg epoch loss = nan\tavg epoch acc = 0.1009\n","epoch 8\tavg epoch loss = nan\tavg epoch acc = 0.1009\n","epoch 9\tavg epoch loss = nan\tavg epoch acc = 0.1009\n","training took 23.62 s\n","Avg test loss = nan\tAvg test acc = 0.0942\n","epoch 0\tavg epoch loss = nan\tavg epoch acc = 0.09788\n","epoch 1\tavg epoch loss = nan\tavg epoch acc = 0.0977\n","epoch 2\tavg epoch loss = nan\tavg epoch acc = 0.0977\n","epoch 3\tavg epoch loss = nan\tavg epoch acc = 0.0977\n","epoch 4\tavg epoch loss = nan\tavg epoch acc = 0.0977\n","epoch 5\tavg epoch loss = nan\tavg epoch acc = 0.0977\n","epoch 6\tavg epoch loss = nan\tavg epoch acc = 0.0977\n","epoch 7\tavg epoch loss = nan\tavg epoch acc = 0.0977\n","epoch 8\tavg epoch loss = nan\tavg epoch acc = 0.0977\n","epoch 9\tavg epoch loss = nan\tavg epoch acc = 0.0977\n","training took 23.52 s\n","Avg test loss = nan\tAvg test acc = 0.101\n","{'lr': 3.906939937054617, 'batch_size': 128}\n","epoch 0\tavg epoch loss = nan\tavg epoch acc = 0.1001\n","epoch 1\tavg epoch loss = nan\tavg epoch acc = 0.09939\n","epoch 2\tavg epoch loss = nan\tavg epoch acc = 0.09939\n","epoch 3\tavg epoch loss = nan\tavg epoch acc = 0.09939\n","epoch 4\tavg epoch loss = nan\tavg epoch acc = 0.09939\n","epoch 5\tavg epoch loss = nan\tavg epoch acc = 0.09939\n","epoch 6\tavg epoch loss = nan\tavg epoch acc = 0.09939\n","epoch 7\tavg epoch loss = nan\tavg epoch acc = 0.09939\n","epoch 8\tavg epoch loss = nan\tavg epoch acc = 0.09939\n","epoch 9\tavg epoch loss = nan\tavg epoch acc = 0.09939\n","training took 15.73 s\n","Avg test loss = nan\tAvg test acc = 0.0972\n","epoch 0\tavg epoch loss = nan\tavg epoch acc = 0.09722\n","epoch 1\tavg epoch loss = nan\tavg epoch acc = 0.09744\n","epoch 2\tavg epoch loss = nan\tavg epoch acc = 0.09744\n","epoch 3\tavg epoch loss = nan\tavg epoch acc = 0.09744\n","epoch 4\tavg epoch loss = nan\tavg epoch acc = 0.09744\n","epoch 5\tavg epoch loss = nan\tavg epoch acc = 0.09744\n","epoch 6\tavg epoch loss = nan\tavg epoch acc = 0.09744\n","epoch 7\tavg epoch loss = nan\tavg epoch acc = 0.09744\n","epoch 8\tavg epoch loss = nan\tavg epoch acc = 0.09744\n","epoch 9\tavg epoch loss = nan\tavg epoch acc = 0.09744\n","training took 15.76 s\n","Avg test loss = nan\tAvg test acc = 0.101\n","epoch 0\tavg epoch loss = 42.97\tavg epoch acc = 0.09969\n","epoch 1\tavg epoch loss = 917.9\tavg epoch acc = 0.09887\n","epoch 2\tavg epoch loss = 8.857e+03\tavg epoch acc = 0.1016\n","epoch 3\tavg epoch loss = 1.924e+04\tavg epoch acc = 0.09792\n","epoch 4\tavg epoch loss = 2.827\tavg epoch acc = 0.09952\n","epoch 5\tavg epoch loss = 2.333\tavg epoch acc = 0.09962\n","epoch 6\tavg epoch loss = 2.418\tavg epoch acc = 0.09919\n","epoch 7\tavg epoch loss = 2.468\tavg epoch acc = 0.09924\n","epoch 8\tavg epoch loss = 2.333\tavg epoch acc = 0.09962\n","epoch 9\tavg epoch loss = 2.333\tavg epoch acc = 0.09962\n","training took 15.84 s\n","Avg test loss = 2.33\tAvg test acc = 0.113\n","{'lr': 4.094915062380425, 'batch_size': 32}\n","epoch 0\tavg epoch loss = 2.643\tavg epoch acc = 0.0959\n","epoch 1\tavg epoch loss = 2.467\tavg epoch acc = 0.09567\n","epoch 2\tavg epoch loss = 2.467\tavg epoch acc = 0.0956\n","epoch 3\tavg epoch loss = 2.467\tavg epoch acc = 0.0956\n","epoch 4\tavg epoch loss = 2.467\tavg epoch acc = 0.0956\n","epoch 5\tavg epoch loss = 2.467\tavg epoch acc = 0.0956\n","epoch 6\tavg epoch loss = 2.467\tavg epoch acc = 0.0956\n","epoch 7\tavg epoch loss = 2.467\tavg epoch acc = 0.0956\n","epoch 8\tavg epoch loss = 2.467\tavg epoch acc = 0.0956\n","epoch 9\tavg epoch loss = 2.467\tavg epoch acc = 0.0956\n","training took 44.68 s\n","Avg test loss = 2.43\tAvg test acc = 0.103\n","epoch 0\tavg epoch loss = nan\tavg epoch acc = 0.09875\n","epoch 1\tavg epoch loss = nan\tavg epoch acc = 0.09855\n","epoch 2\tavg epoch loss = nan\tavg epoch acc = 0.09855\n","epoch 3\tavg epoch loss = nan\tavg epoch acc = 0.09855\n","epoch 4\tavg epoch loss = nan\tavg epoch acc = 0.09855\n","epoch 5\tavg epoch loss = nan\tavg epoch acc = 0.09855\n","epoch 6\tavg epoch loss = nan\tavg epoch acc = 0.09855\n","epoch 7\tavg epoch loss = nan\tavg epoch acc = 0.09855\n","epoch 8\tavg epoch loss = nan\tavg epoch acc = 0.09855\n","epoch 9\tavg epoch loss = nan\tavg epoch acc = 0.09855\n","training took 44.95 s\n","Avg test loss = nan\tAvg test acc = 0.099\n","epoch 0\tavg epoch loss = 2.822e+04\tavg epoch acc = 0.09665\n","epoch 1\tavg epoch loss = 2.463\tavg epoch acc = 0.09535\n","epoch 2\tavg epoch loss = 2.463\tavg epoch acc = 0.09535\n","epoch 3\tavg epoch loss = 2.463\tavg epoch acc = 0.09535\n","epoch 4\tavg epoch loss = 2.463\tavg epoch acc = 0.09535\n","epoch 5\tavg epoch loss = 2.463\tavg epoch acc = 0.09532\n","epoch 6\tavg epoch loss = 2.463\tavg epoch acc = 0.09532\n","epoch 7\tavg epoch loss = 2.463\tavg epoch acc = 0.09532\n","epoch 8\tavg epoch loss = 2.463\tavg epoch acc = 0.09532\n","epoch 9\tavg epoch loss = 2.463\tavg epoch acc = 0.09532\n","training took 45.01 s\n","Avg test loss = 2.37\tAvg test acc = 0.0943\n","{'lr': 4.094915062380425, 'batch_size': 64}\n","epoch 0\tavg epoch loss = nan\tavg epoch acc = 0.09875\n","epoch 1\tavg epoch loss = nan\tavg epoch acc = 0.0987\n","epoch 2\tavg epoch loss = nan\tavg epoch acc = 0.0987\n","epoch 3\tavg epoch loss = nan\tavg epoch acc = 0.0987\n","epoch 4\tavg epoch loss = nan\tavg epoch acc = 0.0987\n","epoch 5\tavg epoch loss = nan\tavg epoch acc = 0.0987\n","epoch 6\tavg epoch loss = nan\tavg epoch acc = 0.0987\n","epoch 7\tavg epoch loss = nan\tavg epoch acc = 0.0987\n","epoch 8\tavg epoch loss = nan\tavg epoch acc = 0.0987\n","epoch 9\tavg epoch loss = nan\tavg epoch acc = 0.0987\n","training took 23.54 s\n","Avg test loss = nan\tAvg test acc = 0.0987\n","epoch 0\tavg epoch loss = nan\tavg epoch acc = 0.09925\n","epoch 1\tavg epoch loss = nan\tavg epoch acc = 0.09903\n","epoch 2\tavg epoch loss = nan\tavg epoch acc = 0.09903\n","epoch 3\tavg epoch loss = nan\tavg epoch acc = 0.09903\n","epoch 4\tavg epoch loss = nan\tavg epoch acc = 0.09903\n","epoch 5\tavg epoch loss = nan\tavg epoch acc = 0.09903\n","epoch 6\tavg epoch loss = nan\tavg epoch acc = 0.09903\n","epoch 7\tavg epoch loss = nan\tavg epoch acc = 0.09903\n","epoch 8\tavg epoch loss = nan\tavg epoch acc = 0.09903\n","epoch 9\tavg epoch loss = nan\tavg epoch acc = 0.09903\n","training took 23.64 s\n","Avg test loss = nan\tAvg test acc = 0.0981\n","epoch 0\tavg epoch loss = nan\tavg epoch acc = 0.09835\n","epoch 1\tavg epoch loss = nan\tavg epoch acc = 0.09842\n","epoch 2\tavg epoch loss = nan\tavg epoch acc = 0.09842\n","epoch 3\tavg epoch loss = nan\tavg epoch acc = 0.09842\n","epoch 4\tavg epoch loss = nan\tavg epoch acc = 0.09842\n","epoch 5\tavg epoch loss = nan\tavg epoch acc = 0.09842\n","epoch 6\tavg epoch loss = nan\tavg epoch acc = 0.09842\n","epoch 7\tavg epoch loss = nan\tavg epoch acc = 0.09842\n","epoch 8\tavg epoch loss = nan\tavg epoch acc = 0.09842\n","epoch 9\tavg epoch loss = nan\tavg epoch acc = 0.09842\n","training took 23.61 s\n","Avg test loss = nan\tAvg test acc = 0.0993\n","{'lr': 4.094915062380425, 'batch_size': 128}\n","epoch 0\tavg epoch loss = 2.515e+23\tavg epoch acc = 0.1031\n","epoch 1\tavg epoch loss = 5.971e+21\tavg epoch acc = 0.1016\n","epoch 2\tavg epoch loss = 8.323e+19\tavg epoch acc = 0.1018\n","epoch 3\tavg epoch loss = 2.334\tavg epoch acc = 0.1017\n","epoch 4\tavg epoch loss = 2.334\tavg epoch acc = 0.1017\n","epoch 5\tavg epoch loss = 2.334\tavg epoch acc = 0.1017\n","epoch 6\tavg epoch loss = 2.334\tavg epoch acc = 0.1017\n","epoch 7\tavg epoch loss = 2.334\tavg epoch acc = 0.1017\n","epoch 8\tavg epoch loss = 2.334\tavg epoch acc = 0.1017\n","epoch 9\tavg epoch loss = 2.334\tavg epoch acc = 0.1017\n","training took 15.8 s\n","Avg test loss = 2.32\tAvg test acc = 0.116\n","epoch 0\tavg epoch loss = nan\tavg epoch acc = 0.09962\n","epoch 1\tavg epoch loss = nan\tavg epoch acc = 0.09924\n","epoch 2\tavg epoch loss = nan\tavg epoch acc = 0.09924\n","epoch 3\tavg epoch loss = nan\tavg epoch acc = 0.09924\n","epoch 4\tavg epoch loss = nan\tavg epoch acc = 0.09924\n","epoch 5\tavg epoch loss = nan\tavg epoch acc = 0.09924\n","epoch 6\tavg epoch loss = nan\tavg epoch acc = 0.09924\n","epoch 7\tavg epoch loss = nan\tavg epoch acc = 0.09924\n","epoch 8\tavg epoch loss = nan\tavg epoch acc = 0.09924\n","epoch 9\tavg epoch loss = nan\tavg epoch acc = 0.09924\n","training took 15.92 s\n","Avg test loss = nan\tAvg test acc = 0.0978\n","epoch 0\tavg epoch loss = nan\tavg epoch acc = 0.09864\n","epoch 1\tavg epoch loss = nan\tavg epoch acc = 0.09852\n","epoch 2\tavg epoch loss = nan\tavg epoch acc = 0.09852\n","epoch 3\tavg epoch loss = nan\tavg epoch acc = 0.09852\n","epoch 4\tavg epoch loss = nan\tavg epoch acc = 0.09852\n","epoch 5\tavg epoch loss = nan\tavg epoch acc = 0.09852\n","epoch 6\tavg epoch loss = nan\tavg epoch acc = 0.09852\n","epoch 7\tavg epoch loss = nan\tavg epoch acc = 0.09852\n","epoch 8\tavg epoch loss = nan\tavg epoch acc = 0.09852\n","epoch 9\tavg epoch loss = nan\tavg epoch acc = 0.09852\n","training took 15.78 s\n","Avg test loss = nan\tAvg test acc = 0.0989\n","{'lr': 4.2919342601287775, 'batch_size': 32}\n","epoch 0\tavg epoch loss = nan\tavg epoch acc = 0.0981\n","epoch 1\tavg epoch loss = nan\tavg epoch acc = 0.09882\n","epoch 2\tavg epoch loss = nan\tavg epoch acc = 0.09882\n","epoch 3\tavg epoch loss = nan\tavg epoch acc = 0.09882\n","epoch 4\tavg epoch loss = nan\tavg epoch acc = 0.09882\n","epoch 5\tavg epoch loss = nan\tavg epoch acc = 0.09882\n","epoch 6\tavg epoch loss = nan\tavg epoch acc = 0.09882\n","epoch 7\tavg epoch loss = nan\tavg epoch acc = 0.09882\n","epoch 8\tavg epoch loss = nan\tavg epoch acc = 0.09882\n","epoch 9\tavg epoch loss = nan\tavg epoch acc = 0.09882\n","training took 45.05 s\n","Avg test loss = nan\tAvg test acc = 0.0985\n","epoch 0\tavg epoch loss = 1.363e+18\tavg epoch acc = 0.09592\n","epoch 1\tavg epoch loss = 4.586e+24\tavg epoch acc = 0.09538\n","epoch 2\tavg epoch loss = 2.605e+23\tavg epoch acc = 0.09388\n","epoch 3\tavg epoch loss = nan\tavg epoch acc = 0.09815\n","epoch 4\tavg epoch loss = nan\tavg epoch acc = 0.0985\n","epoch 5\tavg epoch loss = nan\tavg epoch acc = 0.0985\n","epoch 6\tavg epoch loss = nan\tavg epoch acc = 0.0985\n","epoch 7\tavg epoch loss = nan\tavg epoch acc = 0.0985\n","epoch 8\tavg epoch loss = nan\tavg epoch acc = 0.0985\n","epoch 9\tavg epoch loss = nan\tavg epoch acc = 0.0985\n","training took 45.17 s\n","Avg test loss = nan\tAvg test acc = 0.0992\n","epoch 0\tavg epoch loss = nan\tavg epoch acc = 0.09867\n","epoch 1\tavg epoch loss = nan\tavg epoch acc = 0.09882\n","epoch 2\tavg epoch loss = nan\tavg epoch acc = 0.09882\n","epoch 3\tavg epoch loss = nan\tavg epoch acc = 0.09882\n","epoch 4\tavg epoch loss = nan\tavg epoch acc = 0.09882\n","epoch 5\tavg epoch loss = nan\tavg epoch acc = 0.09882\n","epoch 6\tavg epoch loss = nan\tavg epoch acc = 0.09882\n","epoch 7\tavg epoch loss = nan\tavg epoch acc = 0.09882\n","epoch 8\tavg epoch loss = nan\tavg epoch acc = 0.09882\n","epoch 9\tavg epoch loss = nan\tavg epoch acc = 0.09882\n","training took 45.38 s\n","Avg test loss = nan\tAvg test acc = 0.0985\n","{'lr': 4.2919342601287775, 'batch_size': 64}\n","epoch 0\tavg epoch loss = nan\tavg epoch acc = 0.1003\n","epoch 1\tavg epoch loss = nan\tavg epoch acc = 0.1001\n","epoch 2\tavg epoch loss = nan\tavg epoch acc = 0.1001\n","epoch 3\tavg epoch loss = nan\tavg epoch acc = 0.1001\n","epoch 4\tavg epoch loss = nan\tavg epoch acc = 0.1001\n","epoch 5\tavg epoch loss = nan\tavg epoch acc = 0.1001\n","epoch 6\tavg epoch loss = nan\tavg epoch acc = 0.1001\n","epoch 7\tavg epoch loss = nan\tavg epoch acc = 0.1001\n","epoch 8\tavg epoch loss = nan\tavg epoch acc = 0.1001\n","epoch 9\tavg epoch loss = nan\tavg epoch acc = 0.1001\n","training took 23.59 s\n","Avg test loss = nan\tAvg test acc = 0.096\n","epoch 0\tavg epoch loss = nan\tavg epoch acc = 0.09935\n","epoch 1\tavg epoch loss = nan\tavg epoch acc = 0.09905\n","epoch 2\tavg epoch loss = nan\tavg epoch acc = 0.09905\n","epoch 3\tavg epoch loss = nan\tavg epoch acc = 0.09905\n","epoch 4\tavg epoch loss = nan\tavg epoch acc = 0.09905\n","epoch 5\tavg epoch loss = nan\tavg epoch acc = 0.09905\n","epoch 6\tavg epoch loss = nan\tavg epoch acc = 0.09905\n","epoch 7\tavg epoch loss = nan\tavg epoch acc = 0.09905\n","epoch 8\tavg epoch loss = nan\tavg epoch acc = 0.09905\n","epoch 9\tavg epoch loss = nan\tavg epoch acc = 0.09905\n","training took 23.68 s\n","Avg test loss = nan\tAvg test acc = 0.0981\n","epoch 0\tavg epoch loss = 9.161e+20\tavg epoch acc = 0.09855\n","epoch 1\tavg epoch loss = 1.672e+15\tavg epoch acc = 0.0974\n","epoch 2\tavg epoch loss = 2.376\tavg epoch acc = 0.09725\n","epoch 3\tavg epoch loss = 2.376\tavg epoch acc = 0.09725\n","epoch 4\tavg epoch loss = 2.376\tavg epoch acc = 0.09725\n","epoch 5\tavg epoch loss = 2.376\tavg epoch acc = 0.09725\n","epoch 6\tavg epoch loss = 2.376\tavg epoch acc = 0.09725\n","epoch 7\tavg epoch loss = 2.376\tavg epoch acc = 0.0972\n","epoch 8\tavg epoch loss = 2.376\tavg epoch acc = 0.0972\n","epoch 9\tavg epoch loss = 2.376\tavg epoch acc = 0.0972\n","training took 23.67 s\n","Avg test loss = 2.36\tAvg test acc = 0.102\n","{'lr': 4.2919342601287775, 'batch_size': 128}\n","epoch 0\tavg epoch loss = 5.741e+04\tavg epoch acc = 0.09869\n","epoch 1\tavg epoch loss = 2.335\tavg epoch acc = 0.09784\n","epoch 2\tavg epoch loss = 2.335\tavg epoch acc = 0.09784\n","epoch 3\tavg epoch loss = 2.335\tavg epoch acc = 0.09794\n","epoch 4\tavg epoch loss = 2.335\tavg epoch acc = 0.09794\n","epoch 5\tavg epoch loss = 2.335\tavg epoch acc = 0.09794\n","epoch 6\tavg epoch loss = 2.335\tavg epoch acc = 0.09794\n","epoch 7\tavg epoch loss = 2.335\tavg epoch acc = 0.09794\n","epoch 8\tavg epoch loss = 2.335\tavg epoch acc = 0.09794\n","epoch 9\tavg epoch loss = 2.335\tavg epoch acc = 0.09794\n","training took 15.96 s\n","Avg test loss = 4.47\tAvg test acc = 0.0973\n","epoch 0\tavg epoch loss = nan\tavg epoch acc = 0.09949\n","epoch 1\tavg epoch loss = nan\tavg epoch acc = 0.09929\n","epoch 2\tavg epoch loss = nan\tavg epoch acc = 0.09929\n","epoch 3\tavg epoch loss = nan\tavg epoch acc = 0.09929\n","epoch 4\tavg epoch loss = nan\tavg epoch acc = 0.09929\n","epoch 5\tavg epoch loss = nan\tavg epoch acc = 0.09929\n","epoch 6\tavg epoch loss = nan\tavg epoch acc = 0.09929\n","epoch 7\tavg epoch loss = nan\tavg epoch acc = 0.09929\n","epoch 8\tavg epoch loss = nan\tavg epoch acc = 0.09929\n","epoch 9\tavg epoch loss = nan\tavg epoch acc = 0.09929\n","training took 15.91 s\n","Avg test loss = nan\tAvg test acc = 0.0975\n","epoch 0\tavg epoch loss = nan\tavg epoch acc = 0.09982\n","epoch 1\tavg epoch loss = nan\tavg epoch acc = 0.09922\n","epoch 2\tavg epoch loss = nan\tavg epoch acc = 0.09922\n","epoch 3\tavg epoch loss = nan\tavg epoch acc = 0.09922\n","epoch 4\tavg epoch loss = nan\tavg epoch acc = 0.09922\n","epoch 5\tavg epoch loss = nan\tavg epoch acc = 0.09922\n","epoch 6\tavg epoch loss = nan\tavg epoch acc = 0.09922\n","epoch 7\tavg epoch loss = nan\tavg epoch acc = 0.09922\n","epoch 8\tavg epoch loss = nan\tavg epoch acc = 0.09922\n","epoch 9\tavg epoch loss = nan\tavg epoch acc = 0.09922\n","training took 15.72 s\n","Avg test loss = nan\tAvg test acc = 0.0978\n","{'lr': 4.498432668969445, 'batch_size': 32}\n","epoch 0\tavg epoch loss = 4.672e+10\tavg epoch acc = 0.09535\n","epoch 1\tavg epoch loss = 9.18e+13\tavg epoch acc = 0.09495\n","epoch 2\tavg epoch loss = 1.198e+11\tavg epoch acc = 0.09542\n","epoch 3\tavg epoch loss = 2.49\tavg epoch acc = 0.0954\n","epoch 4\tavg epoch loss = 2.49\tavg epoch acc = 0.0954\n","epoch 5\tavg epoch loss = 1.873e+07\tavg epoch acc = 0.09552\n","epoch 6\tavg epoch loss = 2.49\tavg epoch acc = 0.0954\n","epoch 7\tavg epoch loss = 1.299e+10\tavg epoch acc = 0.09575\n","epoch 8\tavg epoch loss = 2.49\tavg epoch acc = 0.0954\n","epoch 9\tavg epoch loss = 2.49\tavg epoch acc = 0.0954\n","training took 45.4 s\n","Avg test loss = 4.92e+17\tAvg test acc = 0.096\n","epoch 0\tavg epoch loss = nan\tavg epoch acc = 0.09803\n","epoch 1\tavg epoch loss = nan\tavg epoch acc = 0.09815\n","epoch 2\tavg epoch loss = nan\tavg epoch acc = 0.09815\n","epoch 3\tavg epoch loss = nan\tavg epoch acc = 0.09815\n","epoch 4\tavg epoch loss = nan\tavg epoch acc = 0.09815\n","epoch 5\tavg epoch loss = nan\tavg epoch acc = 0.09815\n","epoch 6\tavg epoch loss = nan\tavg epoch acc = 0.09815\n","epoch 7\tavg epoch loss = nan\tavg epoch acc = 0.09815\n","epoch 8\tavg epoch loss = nan\tavg epoch acc = 0.09815\n","epoch 9\tavg epoch loss = nan\tavg epoch acc = 0.09815\n","training took 44.91 s\n","Avg test loss = nan\tAvg test acc = 0.0998\n","epoch 0\tavg epoch loss = 4.911e+16\tavg epoch acc = 0.09788\n","epoch 1\tavg epoch loss = 7.873e+10\tavg epoch acc = 0.09735\n","epoch 2\tavg epoch loss = 2.488\tavg epoch acc = 0.09673\n","epoch 3\tavg epoch loss = 2.488\tavg epoch acc = 0.09673\n","epoch 4\tavg epoch loss = 2.488\tavg epoch acc = 0.09673\n","epoch 5\tavg epoch loss = 2.488\tavg epoch acc = 0.09673\n","epoch 6\tavg epoch loss = 2.488\tavg epoch acc = 0.09673\n","epoch 7\tavg epoch loss = 2.488\tavg epoch acc = 0.09673\n","epoch 8\tavg epoch loss = 2.488\tavg epoch acc = 0.09673\n","epoch 9\tavg epoch loss = 2.488\tavg epoch acc = 0.09673\n","training took 44.86 s\n","Avg test loss = 2.41\tAvg test acc = 0.0898\n","{'lr': 4.498432668969445, 'batch_size': 64}\n","epoch 0\tavg epoch loss = 1.461e+17\tavg epoch acc = 0.0991\n","epoch 1\tavg epoch loss = 2.381\tavg epoch acc = 0.09795\n","epoch 2\tavg epoch loss = 2.381\tavg epoch acc = 0.09792\n","epoch 3\tavg epoch loss = 2.381\tavg epoch acc = 0.09792\n","epoch 4\tavg epoch loss = 2.381\tavg epoch acc = 0.09792\n","epoch 5\tavg epoch loss = 2.381\tavg epoch acc = 0.09792\n","epoch 6\tavg epoch loss = 2.381\tavg epoch acc = 0.09792\n","epoch 7\tavg epoch loss = 2.381\tavg epoch acc = 0.09792\n","epoch 8\tavg epoch loss = 2.381\tavg epoch acc = 0.09792\n","epoch 9\tavg epoch loss = 2.381\tavg epoch acc = 0.09792\n","training took 23.67 s\n","Avg test loss = 2.32\tAvg test acc = 0.11\n","epoch 0\tavg epoch loss = nan\tavg epoch acc = 0.09853\n","epoch 1\tavg epoch loss = nan\tavg epoch acc = 0.09845\n","epoch 2\tavg epoch loss = nan\tavg epoch acc = 0.09845\n","epoch 3\tavg epoch loss = nan\tavg epoch acc = 0.09845\n","epoch 4\tavg epoch loss = nan\tavg epoch acc = 0.09845\n","epoch 5\tavg epoch loss = nan\tavg epoch acc = 0.09845\n","epoch 6\tavg epoch loss = nan\tavg epoch acc = 0.09845\n","epoch 7\tavg epoch loss = nan\tavg epoch acc = 0.09845\n","epoch 8\tavg epoch loss = nan\tavg epoch acc = 0.09845\n","epoch 9\tavg epoch loss = nan\tavg epoch acc = 0.09845\n","training took 23.44 s\n","Avg test loss = nan\tAvg test acc = 0.0991\n","epoch 0\tavg epoch loss = 9.578e+05\tavg epoch acc = 0.0996\n","epoch 1\tavg epoch loss = 166.5\tavg epoch acc = 0.09715\n","epoch 2\tavg epoch loss = 2.383\tavg epoch acc = 0.09682\n","epoch 3\tavg epoch loss = 2.383\tavg epoch acc = 0.09677\n","epoch 4\tavg epoch loss = 2.383\tavg epoch acc = 0.09677\n","epoch 5\tavg epoch loss = 2.383\tavg epoch acc = 0.09677\n","epoch 6\tavg epoch loss = 2.383\tavg epoch acc = 0.09677\n","epoch 7\tavg epoch loss = 2.383\tavg epoch acc = 0.09677\n","epoch 8\tavg epoch loss = 2.383\tavg epoch acc = 0.09677\n","epoch 9\tavg epoch loss = 2.383\tavg epoch acc = 0.09677\n","training took 23.65 s\n","Avg test loss = 2.35\tAvg test acc = 0.0997\n","{'lr': 4.498432668969445, 'batch_size': 128}\n","epoch 0\tavg epoch loss = nan\tavg epoch acc = 0.09779\n","epoch 1\tavg epoch loss = nan\tavg epoch acc = 0.09779\n","epoch 2\tavg epoch loss = nan\tavg epoch acc = 0.09779\n","epoch 3\tavg epoch loss = nan\tavg epoch acc = 0.09779\n","epoch 4\tavg epoch loss = nan\tavg epoch acc = 0.09779\n","epoch 5\tavg epoch loss = nan\tavg epoch acc = 0.09779\n","epoch 6\tavg epoch loss = nan\tavg epoch acc = 0.09779\n","epoch 7\tavg epoch loss = nan\tavg epoch acc = 0.09779\n","epoch 8\tavg epoch loss = nan\tavg epoch acc = 0.09779\n","epoch 9\tavg epoch loss = nan\tavg epoch acc = 0.09779\n","training took 15.86 s\n","Avg test loss = nan\tAvg test acc = 0.101\n","epoch 0\tavg epoch loss = 6.053e+04\tavg epoch acc = 0.09992\n","epoch 1\tavg epoch loss = 2.457\tavg epoch acc = 0.1017\n","epoch 2\tavg epoch loss = 2.337\tavg epoch acc = 0.1009\n","epoch 3\tavg epoch loss = 2.337\tavg epoch acc = 0.1009\n","epoch 4\tavg epoch loss = 2.337\tavg epoch acc = 0.1009\n","epoch 5\tavg epoch loss = 2.337\tavg epoch acc = 0.1008\n","epoch 6\tavg epoch loss = 2.337\tavg epoch acc = 0.1008\n","epoch 7\tavg epoch loss = 2.337\tavg epoch acc = 0.1008\n","epoch 8\tavg epoch loss = 2.337\tavg epoch acc = 0.1008\n","epoch 9\tavg epoch loss = 2.337\tavg epoch acc = 0.1008\n","training took 15.76 s\n","Avg test loss = 2.33\tAvg test acc = 0.0979\n","epoch 0\tavg epoch loss = nan\tavg epoch acc = 0.1013\n","epoch 1\tavg epoch loss = nan\tavg epoch acc = 0.1006\n","epoch 2\tavg epoch loss = nan\tavg epoch acc = 0.1006\n","epoch 3\tavg epoch loss = nan\tavg epoch acc = 0.1006\n","epoch 4\tavg epoch loss = nan\tavg epoch acc = 0.1006\n","epoch 5\tavg epoch loss = nan\tavg epoch acc = 0.1006\n","epoch 6\tavg epoch loss = nan\tavg epoch acc = 0.1006\n","epoch 7\tavg epoch loss = nan\tavg epoch acc = 0.1006\n","epoch 8\tavg epoch loss = nan\tavg epoch acc = 0.1006\n","epoch 9\tavg epoch loss = nan\tavg epoch acc = 0.1006\n","training took 15.77 s\n","Avg test loss = nan\tAvg test acc = 0.095\n","{'lr': 4.714866363457394, 'batch_size': 32}\n","epoch 0\tavg epoch loss = 7.774e+12\tavg epoch acc = 0.09485\n","epoch 1\tavg epoch loss = 2.15e+07\tavg epoch acc = 0.0955\n","epoch 2\tavg epoch loss = 6.494\tavg epoch acc = 0.0949\n","epoch 3\tavg epoch loss = 2.502\tavg epoch acc = 0.09588\n","epoch 4\tavg epoch loss = 1.577e+05\tavg epoch acc = 0.0958\n","epoch 5\tavg epoch loss = 2.502\tavg epoch acc = 0.09588\n","epoch 6\tavg epoch loss = 330.5\tavg epoch acc = 0.09595\n","epoch 7\tavg epoch loss = 2.502\tavg epoch acc = 0.09588\n","epoch 8\tavg epoch loss = 2.502\tavg epoch acc = 0.09588\n","epoch 9\tavg epoch loss = 2.502\tavg epoch acc = 0.09588\n","training took 46.07 s\n","Avg test loss = 2.39\tAvg test acc = 0.0972\n","epoch 0\tavg epoch loss = 1.56e+07\tavg epoch acc = 0.09677\n","epoch 1\tavg epoch loss = 1.121e+10\tavg epoch acc = 0.0983\n","epoch 2\tavg epoch loss = 2.017e+07\tavg epoch acc = 0.09748\n","epoch 3\tavg epoch loss = 3.443e+05\tavg epoch acc = 0.09728\n","epoch 4\tavg epoch loss = 2.499\tavg epoch acc = 0.09682\n","epoch 5\tavg epoch loss = 2.499\tavg epoch acc = 0.09688\n","epoch 6\tavg epoch loss = 2.499\tavg epoch acc = 0.09688\n","epoch 7\tavg epoch loss = 2.499\tavg epoch acc = 0.09688\n","epoch 8\tavg epoch loss = 2.499\tavg epoch acc = 0.09688\n","epoch 9\tavg epoch loss = 2.499\tavg epoch acc = 0.09688\n","training took 45.14 s\n","Avg test loss = 2.37\tAvg test acc = 0.1\n","epoch 0\tavg epoch loss = 1.599e+16\tavg epoch acc = 0.09413\n","epoch 1\tavg epoch loss = 1.675e+18\tavg epoch acc = 0.09663\n","epoch 2\tavg epoch loss = 1.095e+16\tavg epoch acc = 0.09408\n","epoch 3\tavg epoch loss = 2.503\tavg epoch acc = 0.09348\n","epoch 4\tavg epoch loss = 2.503\tavg epoch acc = 0.09348\n","epoch 5\tavg epoch loss = 2.503\tavg epoch acc = 0.09348\n","epoch 6\tavg epoch loss = 2.503\tavg epoch acc = 0.09348\n","epoch 7\tavg epoch loss = 2.503\tavg epoch acc = 0.09348\n","epoch 8\tavg epoch loss = 2.503\tavg epoch acc = 0.09348\n","epoch 9\tavg epoch loss = 2.503\tavg epoch acc = 0.09348\n","training took 45.11 s\n","Avg test loss = 2.43\tAvg test acc = 0.103\n","{'lr': 4.714866363457394, 'batch_size': 64}\n","epoch 0\tavg epoch loss = nan\tavg epoch acc = 0.0981\n","epoch 1\tavg epoch loss = nan\tavg epoch acc = 0.09798\n","epoch 2\tavg epoch loss = nan\tavg epoch acc = 0.09798\n","epoch 3\tavg epoch loss = nan\tavg epoch acc = 0.09798\n","epoch 4\tavg epoch loss = nan\tavg epoch acc = 0.09798\n","epoch 5\tavg epoch loss = nan\tavg epoch acc = 0.09798\n","epoch 6\tavg epoch loss = nan\tavg epoch acc = 0.09798\n","epoch 7\tavg epoch loss = nan\tavg epoch acc = 0.09798\n","epoch 8\tavg epoch loss = nan\tavg epoch acc = 0.09798\n","epoch 9\tavg epoch loss = nan\tavg epoch acc = 0.09798\n","training took 23.5 s\n","Avg test loss = nan\tAvg test acc = 0.1\n","epoch 0\tavg epoch loss = nan\tavg epoch acc = 0.09957\n","epoch 1\tavg epoch loss = nan\tavg epoch acc = 0.09953\n","epoch 2\tavg epoch loss = nan\tavg epoch acc = 0.09953\n","epoch 3\tavg epoch loss = nan\tavg epoch acc = 0.09953\n","epoch 4\tavg epoch loss = nan\tavg epoch acc = 0.09953\n","epoch 5\tavg epoch loss = nan\tavg epoch acc = 0.09953\n","epoch 6\tavg epoch loss = nan\tavg epoch acc = 0.09953\n","epoch 7\tavg epoch loss = nan\tavg epoch acc = 0.09953\n","epoch 8\tavg epoch loss = nan\tavg epoch acc = 0.09953\n","epoch 9\tavg epoch loss = nan\tavg epoch acc = 0.09953\n","training took 23.69 s\n","Avg test loss = nan\tAvg test acc = 0.0971\n","epoch 0\tavg epoch loss = 5.124e+16\tavg epoch acc = 0.1001\n","epoch 1\tavg epoch loss = 1.044e+13\tavg epoch acc = 0.09738\n","epoch 2\tavg epoch loss = 2.54e+12\tavg epoch acc = 0.09757\n","epoch 3\tavg epoch loss = 2.389\tavg epoch acc = 0.09767\n","epoch 4\tavg epoch loss = 2.389\tavg epoch acc = 0.09767\n","epoch 5\tavg epoch loss = 2.389\tavg epoch acc = 0.09775\n","epoch 6\tavg epoch loss = 2.389\tavg epoch acc = 0.09775\n","epoch 7\tavg epoch loss = 2.389\tavg epoch acc = 0.09775\n","epoch 8\tavg epoch loss = 2.389\tavg epoch acc = 0.09775\n","epoch 9\tavg epoch loss = 2.389\tavg epoch acc = 0.09775\n","training took 23.65 s\n","Avg test loss = 1.78e+22\tAvg test acc = 0.0964\n","{'lr': 4.714866363457394, 'batch_size': 128}\n","epoch 0\tavg epoch loss = nan\tavg epoch acc = 0.101\n","epoch 1\tavg epoch loss = nan\tavg epoch acc = 0.09819\n","epoch 2\tavg epoch loss = nan\tavg epoch acc = 0.09819\n","epoch 3\tavg epoch loss = nan\tavg epoch acc = 0.09819\n","epoch 4\tavg epoch loss = nan\tavg epoch acc = 0.09819\n","epoch 5\tavg epoch loss = nan\tavg epoch acc = 0.09819\n","epoch 6\tavg epoch loss = nan\tavg epoch acc = 0.09819\n","epoch 7\tavg epoch loss = nan\tavg epoch acc = 0.09819\n","epoch 8\tavg epoch loss = nan\tavg epoch acc = 0.09819\n","epoch 9\tavg epoch loss = nan\tavg epoch acc = 0.09819\n","training took 15.77 s\n","Avg test loss = nan\tAvg test acc = 0.0997\n","epoch 0\tavg epoch loss = nan\tavg epoch acc = 0.09842\n","epoch 1\tavg epoch loss = nan\tavg epoch acc = 0.09852\n","epoch 2\tavg epoch loss = nan\tavg epoch acc = 0.09852\n","epoch 3\tavg epoch loss = nan\tavg epoch acc = 0.09852\n","epoch 4\tavg epoch loss = nan\tavg epoch acc = 0.09852\n","epoch 5\tavg epoch loss = nan\tavg epoch acc = 0.09852\n","epoch 6\tavg epoch loss = nan\tavg epoch acc = 0.09852\n","epoch 7\tavg epoch loss = nan\tavg epoch acc = 0.09852\n","epoch 8\tavg epoch loss = nan\tavg epoch acc = 0.09852\n","epoch 9\tavg epoch loss = nan\tavg epoch acc = 0.09852\n","training took 15.77 s\n","Avg test loss = nan\tAvg test acc = 0.0993\n","epoch 0\tavg epoch loss = nan\tavg epoch acc = 0.09972\n","epoch 1\tavg epoch loss = nan\tavg epoch acc = 0.09947\n","epoch 2\tavg epoch loss = nan\tavg epoch acc = 0.09947\n","epoch 3\tavg epoch loss = nan\tavg epoch acc = 0.09947\n","epoch 4\tavg epoch loss = nan\tavg epoch acc = 0.09947\n","epoch 5\tavg epoch loss = nan\tavg epoch acc = 0.09947\n","epoch 6\tavg epoch loss = nan\tavg epoch acc = 0.09947\n","epoch 7\tavg epoch loss = nan\tavg epoch acc = 0.09947\n","epoch 8\tavg epoch loss = nan\tavg epoch acc = 0.09947\n","epoch 9\tavg epoch loss = nan\tavg epoch acc = 0.09947\n","training took 15.9 s\n","Avg test loss = nan\tAvg test acc = 0.0972\n","{'lr': 4.941713361323834, 'batch_size': 32}\n","epoch 0\tavg epoch loss = 2.497e+18\tavg epoch acc = 0.09695\n","epoch 1\tavg epoch loss = 8.736e+21\tavg epoch acc = 0.0952\n","epoch 2\tavg epoch loss = 2.856e+19\tavg epoch acc = 0.09807\n","epoch 3\tavg epoch loss = 71.52\tavg epoch acc = 0.09617\n","epoch 4\tavg epoch loss = 2.524\tavg epoch acc = 0.0958\n","epoch 5\tavg epoch loss = 2.525\tavg epoch acc = 0.0958\n","epoch 6\tavg epoch loss = 2.525\tavg epoch acc = 0.0958\n","epoch 7\tavg epoch loss = 2.525\tavg epoch acc = 0.0958\n","epoch 8\tavg epoch loss = 2.525\tavg epoch acc = 0.0958\n","epoch 9\tavg epoch loss = 2.525\tavg epoch acc = 0.0958\n","training took 44.98 s\n","Avg test loss = 2.5\tAvg test acc = 0.103\n","epoch 0\tavg epoch loss = 2.571e+12\tavg epoch acc = 0.09685\n","epoch 1\tavg epoch loss = 2.519\tavg epoch acc = 0.095\n","epoch 2\tavg epoch loss = 2.52\tavg epoch acc = 0.09502\n","epoch 3\tavg epoch loss = 2.52\tavg epoch acc = 0.09498\n","epoch 4\tavg epoch loss = 2.52\tavg epoch acc = 0.09498\n","epoch 5\tavg epoch loss = 2.52\tavg epoch acc = 0.09498\n","epoch 6\tavg epoch loss = 2.52\tavg epoch acc = 0.09498\n","epoch 7\tavg epoch loss = 2.52\tavg epoch acc = 0.09498\n","epoch 8\tavg epoch loss = 2.52\tavg epoch acc = 0.09498\n","epoch 9\tavg epoch loss = 2.52\tavg epoch acc = 0.09498\n","training took 45.03 s\n","Avg test loss = 2.38\tAvg test acc = 0.114\n","epoch 0\tavg epoch loss = 7.205e+09\tavg epoch acc = 0.1002\n","epoch 1\tavg epoch loss = 5.247e+11\tavg epoch acc = 0.09673\n","epoch 2\tavg epoch loss = 2.515\tavg epoch acc = 0.09532\n","epoch 3\tavg epoch loss = 2.515\tavg epoch acc = 0.09532\n","epoch 4\tavg epoch loss = 2.515\tavg epoch acc = 0.09532\n","epoch 5\tavg epoch loss = 2.516\tavg epoch acc = 0.09532\n","epoch 6\tavg epoch loss = 2.516\tavg epoch acc = 0.09532\n","epoch 7\tavg epoch loss = 2.516\tavg epoch acc = 0.09532\n","epoch 8\tavg epoch loss = 2.516\tavg epoch acc = 0.09532\n","epoch 9\tavg epoch loss = 2.516\tavg epoch acc = 0.09532\n","training took 44.85 s\n","Avg test loss = 2.37\tAvg test acc = 0.101\n","{'lr': 4.941713361323834, 'batch_size': 64}\n","epoch 0\tavg epoch loss = 1.323e+04\tavg epoch acc = 0.09938\n","epoch 1\tavg epoch loss = 2.391\tavg epoch acc = 0.09955\n","epoch 2\tavg epoch loss = 2.391\tavg epoch acc = 0.09955\n","epoch 3\tavg epoch loss = 2.391\tavg epoch acc = 0.09955\n","epoch 4\tavg epoch loss = 2.391\tavg epoch acc = 0.09955\n","epoch 5\tavg epoch loss = 2.391\tavg epoch acc = 0.09955\n","epoch 6\tavg epoch loss = 2.391\tavg epoch acc = 0.09955\n","epoch 7\tavg epoch loss = 2.391\tavg epoch acc = 0.09955\n","epoch 8\tavg epoch loss = 2.391\tavg epoch acc = 0.09955\n","epoch 9\tavg epoch loss = 2.391\tavg epoch acc = 0.09955\n","training took 23.49 s\n","Avg test loss = 2.34\tAvg test acc = 0.0971\n","epoch 0\tavg epoch loss = nan\tavg epoch acc = 0.09835\n","epoch 1\tavg epoch loss = nan\tavg epoch acc = 0.09823\n","epoch 2\tavg epoch loss = nan\tavg epoch acc = 0.09823\n","epoch 3\tavg epoch loss = nan\tavg epoch acc = 0.09823\n","epoch 4\tavg epoch loss = nan\tavg epoch acc = 0.09823\n","epoch 5\tavg epoch loss = nan\tavg epoch acc = 0.09823\n","epoch 6\tavg epoch loss = nan\tavg epoch acc = 0.09823\n","epoch 7\tavg epoch loss = nan\tavg epoch acc = 0.09823\n","epoch 8\tavg epoch loss = nan\tavg epoch acc = 0.09823\n","epoch 9\tavg epoch loss = nan\tavg epoch acc = 0.09823\n","training took 23.69 s\n","Avg test loss = nan\tAvg test acc = 0.0996\n","epoch 0\tavg epoch loss = 2.458e+08\tavg epoch acc = 0.09788\n","epoch 1\tavg epoch loss = 3.069e+03\tavg epoch acc = 0.09605\n","epoch 2\tavg epoch loss = 2.39\tavg epoch acc = 0.09673\n","epoch 3\tavg epoch loss = 2.39\tavg epoch acc = 0.09673\n","epoch 4\tavg epoch loss = 2.39\tavg epoch acc = 0.09673\n","epoch 5\tavg epoch loss = 2.39\tavg epoch acc = 0.09673\n","epoch 6\tavg epoch loss = 2.39\tavg epoch acc = 0.09673\n","epoch 7\tavg epoch loss = 2.391\tavg epoch acc = 0.09673\n","epoch 8\tavg epoch loss = 2.391\tavg epoch acc = 0.09673\n","epoch 9\tavg epoch loss = 2.391\tavg epoch acc = 0.09673\n","training took 23.53 s\n","Avg test loss = 3.72e+08\tAvg test acc = 0.0992\n","{'lr': 4.941713361323834, 'batch_size': 128}\n","epoch 0\tavg epoch loss = 1.2e+04\tavg epoch acc = 0.09982\n","epoch 1\tavg epoch loss = 2.338\tavg epoch acc = 0.1\n","epoch 2\tavg epoch loss = 2.338\tavg epoch acc = 0.1\n","epoch 3\tavg epoch loss = 2.338\tavg epoch acc = 0.1\n","epoch 4\tavg epoch loss = 2.338\tavg epoch acc = 0.1\n","epoch 5\tavg epoch loss = 2.338\tavg epoch acc = 0.1\n","epoch 6\tavg epoch loss = 2.338\tavg epoch acc = 0.1\n","epoch 7\tavg epoch loss = 2.338\tavg epoch acc = 0.1\n","epoch 8\tavg epoch loss = 2.338\tavg epoch acc = 0.1\n","epoch 9\tavg epoch loss = 2.338\tavg epoch acc = 0.1\n","training took 15.77 s\n","Avg test loss = 2.35\tAvg test acc = 0.101\n","epoch 0\tavg epoch loss = nan\tavg epoch acc = 0.09967\n","epoch 1\tavg epoch loss = nan\tavg epoch acc = 0.09902\n","epoch 2\tavg epoch loss = nan\tavg epoch acc = 0.09902\n","epoch 3\tavg epoch loss = nan\tavg epoch acc = 0.09902\n","epoch 4\tavg epoch loss = nan\tavg epoch acc = 0.09902\n","epoch 5\tavg epoch loss = nan\tavg epoch acc = 0.09902\n","epoch 6\tavg epoch loss = nan\tavg epoch acc = 0.09902\n","epoch 7\tavg epoch loss = nan\tavg epoch acc = 0.09902\n","epoch 8\tavg epoch loss = nan\tavg epoch acc = 0.09902\n","epoch 9\tavg epoch loss = nan\tavg epoch acc = 0.09902\n","training took 15.87 s\n","Avg test loss = nan\tAvg test acc = 0.0983\n","epoch 0\tavg epoch loss = nan\tavg epoch acc = 0.1003\n","epoch 1\tavg epoch loss = nan\tavg epoch acc = 0.09962\n","epoch 2\tavg epoch loss = nan\tavg epoch acc = 0.09962\n","epoch 3\tavg epoch loss = nan\tavg epoch acc = 0.09962\n","epoch 4\tavg epoch loss = nan\tavg epoch acc = 0.09962\n","epoch 5\tavg epoch loss = nan\tavg epoch acc = 0.09962\n","epoch 6\tavg epoch loss = nan\tavg epoch acc = 0.09962\n","epoch 7\tavg epoch loss = nan\tavg epoch acc = 0.09962\n","epoch 8\tavg epoch loss = nan\tavg epoch acc = 0.09962\n","epoch 9\tavg epoch loss = nan\tavg epoch acc = 0.09962\n","training took 15.8 s\n","Avg test loss = nan\tAvg test acc = 0.0972\n","{'lr': 5.17947467923121, 'batch_size': 32}\n","epoch 0\tavg epoch loss = nan\tavg epoch acc = 0.09735\n","epoch 1\tavg epoch loss = nan\tavg epoch acc = 0.09835\n","epoch 2\tavg epoch loss = nan\tavg epoch acc = 0.09835\n","epoch 3\tavg epoch loss = nan\tavg epoch acc = 0.09835\n","epoch 4\tavg epoch loss = nan\tavg epoch acc = 0.09835\n","epoch 5\tavg epoch loss = nan\tavg epoch acc = 0.09835\n","epoch 6\tavg epoch loss = nan\tavg epoch acc = 0.09835\n","epoch 7\tavg epoch loss = nan\tavg epoch acc = 0.09835\n","epoch 8\tavg epoch loss = nan\tavg epoch acc = 0.09835\n","epoch 9\tavg epoch loss = nan\tavg epoch acc = 0.09835\n","training took 44.84 s\n","Avg test loss = nan\tAvg test acc = 0.0994\n","epoch 0\tavg epoch loss = nan\tavg epoch acc = 0.09965\n","epoch 1\tavg epoch loss = nan\tavg epoch acc = 0.09975\n","epoch 2\tavg epoch loss = nan\tavg epoch acc = 0.09975\n","epoch 3\tavg epoch loss = nan\tavg epoch acc = 0.09975\n","epoch 4\tavg epoch loss = nan\tavg epoch acc = 0.09975\n","epoch 5\tavg epoch loss = nan\tavg epoch acc = 0.09975\n","epoch 6\tavg epoch loss = nan\tavg epoch acc = 0.09975\n","epoch 7\tavg epoch loss = nan\tavg epoch acc = 0.09975\n","epoch 8\tavg epoch loss = nan\tavg epoch acc = 0.09975\n","epoch 9\tavg epoch loss = nan\tavg epoch acc = 0.09975\n","training took 44.92 s\n","Avg test loss = nan\tAvg test acc = 0.0966\n","epoch 0\tavg epoch loss = nan\tavg epoch acc = 0.09957\n","epoch 1\tavg epoch loss = nan\tavg epoch acc = 0.09805\n","epoch 2\tavg epoch loss = nan\tavg epoch acc = 0.09805\n","epoch 3\tavg epoch loss = nan\tavg epoch acc = 0.09805\n","epoch 4\tavg epoch loss = nan\tavg epoch acc = 0.09805\n","epoch 5\tavg epoch loss = nan\tavg epoch acc = 0.09805\n","epoch 6\tavg epoch loss = nan\tavg epoch acc = 0.09805\n","epoch 7\tavg epoch loss = nan\tavg epoch acc = 0.09805\n","epoch 8\tavg epoch loss = nan\tavg epoch acc = 0.09805\n","epoch 9\tavg epoch loss = nan\tavg epoch acc = 0.09805\n","training took 44.9 s\n","Avg test loss = nan\tAvg test acc = 0.1\n","{'lr': 5.17947467923121, 'batch_size': 64}\n","epoch 0\tavg epoch loss = nan\tavg epoch acc = 0.09892\n","epoch 1\tavg epoch loss = nan\tavg epoch acc = 0.09907\n","epoch 2\tavg epoch loss = nan\tavg epoch acc = 0.09907\n","epoch 3\tavg epoch loss = nan\tavg epoch acc = 0.09907\n","epoch 4\tavg epoch loss = nan\tavg epoch acc = 0.09907\n","epoch 5\tavg epoch loss = nan\tavg epoch acc = 0.09907\n","epoch 6\tavg epoch loss = nan\tavg epoch acc = 0.09907\n","epoch 7\tavg epoch loss = nan\tavg epoch acc = 0.09907\n","epoch 8\tavg epoch loss = nan\tavg epoch acc = 0.09907\n","epoch 9\tavg epoch loss = nan\tavg epoch acc = 0.09907\n","training took 23.73 s\n","Avg test loss = nan\tAvg test acc = 0.098\n","epoch 0\tavg epoch loss = nan\tavg epoch acc = 0.09717\n","epoch 1\tavg epoch loss = nan\tavg epoch acc = 0.09715\n","epoch 2\tavg epoch loss = nan\tavg epoch acc = 0.09715\n","epoch 3\tavg epoch loss = nan\tavg epoch acc = 0.09715\n","epoch 4\tavg epoch loss = nan\tavg epoch acc = 0.09715\n","epoch 5\tavg epoch loss = nan\tavg epoch acc = 0.09715\n","epoch 6\tavg epoch loss = nan\tavg epoch acc = 0.09715\n","epoch 7\tavg epoch loss = nan\tavg epoch acc = 0.09715\n","epoch 8\tavg epoch loss = nan\tavg epoch acc = 0.09715\n","epoch 9\tavg epoch loss = nan\tavg epoch acc = 0.09715\n","training took 23.48 s\n","Avg test loss = nan\tAvg test acc = 0.102\n","epoch 0\tavg epoch loss = 6.08e+11\tavg epoch acc = 0.09788\n","epoch 1\tavg epoch loss = 1.17e+15\tavg epoch acc = 0.09875\n","epoch 2\tavg epoch loss = 2.555e+11\tavg epoch acc = 0.0974\n","epoch 3\tavg epoch loss = 7.549e+03\tavg epoch acc = 0.0971\n","epoch 4\tavg epoch loss = 2.402\tavg epoch acc = 0.0971\n","epoch 5\tavg epoch loss = 2.402\tavg epoch acc = 0.0971\n","epoch 6\tavg epoch loss = 2.402\tavg epoch acc = 0.0971\n","epoch 7\tavg epoch loss = 2.402\tavg epoch acc = 0.0971\n","epoch 8\tavg epoch loss = 2.402\tavg epoch acc = 0.0971\n","epoch 9\tavg epoch loss = 2.402\tavg epoch acc = 0.09732\n","training took 23.56 s\n","Avg test loss = 2.37\tAvg test acc = 0.096\n","{'lr': 5.17947467923121, 'batch_size': 128}\n","epoch 0\tavg epoch loss = nan\tavg epoch acc = 0.09924\n","epoch 1\tavg epoch loss = nan\tavg epoch acc = 0.09902\n","epoch 2\tavg epoch loss = nan\tavg epoch acc = 0.09902\n","epoch 3\tavg epoch loss = nan\tavg epoch acc = 0.09902\n","epoch 4\tavg epoch loss = nan\tavg epoch acc = 0.09902\n","epoch 5\tavg epoch loss = nan\tavg epoch acc = 0.09902\n","epoch 6\tavg epoch loss = nan\tavg epoch acc = 0.09902\n","epoch 7\tavg epoch loss = nan\tavg epoch acc = 0.09902\n","epoch 8\tavg epoch loss = nan\tavg epoch acc = 0.09902\n","epoch 9\tavg epoch loss = nan\tavg epoch acc = 0.09902\n","training took 15.84 s\n","Avg test loss = nan\tAvg test acc = 0.0979\n","epoch 0\tavg epoch loss = nan\tavg epoch acc = 0.09814\n","epoch 1\tavg epoch loss = nan\tavg epoch acc = 0.09832\n","epoch 2\tavg epoch loss = nan\tavg epoch acc = 0.09832\n","epoch 3\tavg epoch loss = nan\tavg epoch acc = 0.09832\n","epoch 4\tavg epoch loss = nan\tavg epoch acc = 0.09832\n","epoch 5\tavg epoch loss = nan\tavg epoch acc = 0.09832\n","epoch 6\tavg epoch loss = nan\tavg epoch acc = 0.09832\n","epoch 7\tavg epoch loss = nan\tavg epoch acc = 0.09832\n","epoch 8\tavg epoch loss = nan\tavg epoch acc = 0.09832\n","epoch 9\tavg epoch loss = nan\tavg epoch acc = 0.09832\n","training took 15.77 s\n","Avg test loss = nan\tAvg test acc = 0.0998\n","epoch 0\tavg epoch loss = nan\tavg epoch acc = 0.09932\n","epoch 1\tavg epoch loss = nan\tavg epoch acc = 0.09882\n","epoch 2\tavg epoch loss = nan\tavg epoch acc = 0.09882\n","epoch 3\tavg epoch loss = nan\tavg epoch acc = 0.09882\n","epoch 4\tavg epoch loss = nan\tavg epoch acc = 0.09882\n","epoch 5\tavg epoch loss = nan\tavg epoch acc = 0.09882\n","epoch 6\tavg epoch loss = nan\tavg epoch acc = 0.09882\n","epoch 7\tavg epoch loss = nan\tavg epoch acc = 0.09882\n","epoch 8\tavg epoch loss = nan\tavg epoch acc = 0.09882\n","epoch 9\tavg epoch loss = nan\tavg epoch acc = 0.09882\n","training took 15.77 s\n","Avg test loss = nan\tAvg test acc = 0.0986\n","{'lr': 5.428675439323859, 'batch_size': 32}\n","epoch 0\tavg epoch loss = 409.0\tavg epoch acc = 0.09828\n","epoch 1\tavg epoch loss = 6.14e+08\tavg epoch acc = 0.09815\n","epoch 2\tavg epoch loss = 383.0\tavg epoch acc = 0.09605\n","epoch 3\tavg epoch loss = 2.561\tavg epoch acc = 0.09677\n","epoch 4\tavg epoch loss = 173.3\tavg epoch acc = 0.09717\n","epoch 5\tavg epoch loss = 2.561\tavg epoch acc = 0.09677\n","epoch 6\tavg epoch loss = 2.561\tavg epoch acc = 0.09677\n","epoch 7\tavg epoch loss = 2.561\tavg epoch acc = 0.09677\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"6wdJaMVu8YKC"},"source":["with open('./res/prot_res_nesterov_new1.json', 'w', encoding ='utf8') as json_file:\n","    json.dump(results_nesterov_prot, json_file, indent=2)"],"id":"6wdJaMVu8YKC","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rental-bidding"},"source":["### Minibatch"],"id":"rental-bidding"},{"cell_type":"code","metadata":{"id":"liberal-tucson"},"source":["search_grid_mini  = {\n","        'lr': np.logspace(0,1,num=15),\n","        #'lr': np.linspace(0.00001, 0.01, 5),\n","        'batch_size': [32, 64, 128],\n","        'decreasing_lr': [0, 1],\n","    }\n","if prot_hyperparameter_tune:\n","    results_minibatch_prot = tune_optimizer(\n","        model=Net().to(device),\n","        optim_fun=MiniBatchOptimizer,\n","        xtrain=train_dataset.data,\n","        ytrain=train_dataset.targets,\n","        search_grid=search_grid_mini,\n","        nfolds=3,\n","        func=protected_training,\n","        **training_config\n","    )\n","\n","else:\n","    results_minibatch_prot = optimizers[MiniBatchOptimizer]"],"id":"liberal-tucson","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ePsa3cis9uFZ"},"source":["with open('./res/prot_res_minibatch_new1.json', 'w', encoding ='utf8') as json_file:\n","    json.dump(results_minibatch_prot, json_file, indent=2)"],"id":"ePsa3cis9uFZ","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pretty-hotel"},"source":["## Train & Attack robust models"],"id":"pretty-hotel"},{"cell_type":"code","metadata":{"id":"modular-commander"},"source":["from adversary import protected_training"],"id":"modular-commander","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"coordinated-letters","outputId":"140d3e39-aff4-4c2b-fe46-f19b87d6183b"},"source":["# Logging data structures\n","data_robust = list()\n","data_robust_attack = list()\n","\n","# Training / attack config\n","n_try = 3\n","batch_log_interval = -1\n","epsilons = np.arange(0, 0.6, 0.05)\n","\n","for optimizer, optimizer_params in optimizers.items():\n","    print(f'--- {optimizer.__name__}')\n","    # --------- SETUP OPTIMIZER\n","    optimizer_params = optimizer_params.copy()\n","    # Instantiate data loaders with selected batch size\n","    batch_size = int(optimizer_params.pop('batch_size'))\n","    train_loader, test_loader = build_data_loaders(train_dataset, test_dataset, batch_size)\n","\n","    # --------- Train & Attack several times per optimizer\n","    for n in range(1, n_try + 1):\n","        net = Net().to(device)\n","        optimizer_instance = optimizer(net.parameters(), **optimizer_params)\n","        # --------- TRAIN MODEL\n","        loss_train, acc_train = protected_training(\n","            model=net,\n","            dataset=train_loader,\n","            optim=optimizer_instance,\n","            batch_log_interval=batch_log_interval,\n","            **training_config\n","        )\n","        # --------- TEST MODEL\n","        loss_test, acc_test = testing(\n","            model=net,\n","            dataset=test_loader,\n","            **test_config\n","        )\n","        # Log\n","        data_robust.append({\n","            'optimizer': str(optimizer_instance),\n","            'n': n,\n","            'loss_train': loss_train,\n","            'acc_train': acc_train,\n","            'loss_test': loss_test,\n","            'acc_test': acc_test\n","        })\n","\n","        # --------- ATTACK MODEL\n","        print(f'Launching attacks', end=' ')\n","        for eps in epsilons:\n","            print('', end='.')\n","            loss_attack, acc_attack = attack(\n","                model=net,\n","                test_loader=test_loader,\n","                epsilon=eps,\n","                verbose=False,\n","                **test_config\n","            )\n","            # Log\n","            data_robust_attack.append({\n","                'optimizer': str(optimizer_instance),\n","                'n': n,\n","                'epsilon': eps,\n","                'loss': loss_attack,\n","                'acc': acc_attack\n","            })\n","\n","        print()"],"id":"coordinated-letters","execution_count":null,"outputs":[{"output_type":"stream","text":["--- AdamOptimizer\n",". . . . . . . . . . training took 65.65 s\n","Avg test loss = 0.263\tAvg test acc = 0.957\n","Launching attacks ............\n",". . . . . . . . . . training took 64.88 s\n","Avg test loss = 0.198\tAvg test acc = 0.967\n","Launching attacks ............\n",". . . . . . . . . . training took 65.32 s\n","Avg test loss = 0.218\tAvg test acc = 0.964\n","Launching attacks ............\n","--- NesterovOptimizer\n",". . . . . . . . . . training took 29.39 s\n","Avg test loss = 0.0926\tAvg test acc = 0.985\n","Launching attacks ............\n",". . . . . . . . . . training took 28.17 s\n","Avg test loss = 0.0873\tAvg test acc = 0.985\n","Launching attacks ............\n",". . . . . . . . . . training took 27.97 s\n","Avg test loss = 0.174\tAvg test acc = 0.977\n","Launching attacks ............\n","--- MiniBatchOptimizer\n",". . . . . . . . . . training took 17.09 s\n","Avg test loss = 0.147\tAvg test acc = 0.985\n","Launching attacks ............\n",". . . . . . . . . . training took 16.96 s\n","Avg test loss = 0.102\tAvg test acc = 0.986\n","Launching attacks ............\n",". . . . . . . . . . training took 17.06 s\n","Avg test loss = 0.128\tAvg test acc = 0.986\n","Launching attacks ............\n"],"name":"stdout"}]},{"cell_type":"raw","metadata":{"id":"blocked-child","tags":[]},"source":["# non-loopy train\n","robust_networks = dict()\n","data_robust = list()\n","batch_log_interval = 0\n","epsilon = 0.25\n","\n","for optimizer, optimizer_params in prot_optimizers.items():\n","    name = optimizer_names[optimizer]\n","    print(f'--- {name}')\n","    # Instantiate model\n","    net = Net().to(device)\n","    # Instantiate optimizer\n","    optimizer_params = optimizer_params.copy()\n","    batch_size = int(optimizer_params.pop('batch_size'))\n","    metric_test = optimizer_params.pop('metric_test')\n","    metric_test_std = optimizer_params.pop('metric_test_std')\n","    optimizer_instance = optimizer(net.parameters(), **optimizer_params)\n","    # Instantiate data loaders\n","    train_loader, test_loader = build_data_loaders(train_dataset, test_dataset, batch_size)\n","    # Train robust model\n","    losses, metrics = protected_training(\n","        model=net,\n","        dataset=train_loader,\n","        optim=optimizer_instance,\n","        batch_log_interval=batch_log_interval,\n","        **training_config\n","    )\n","    # Log\n","    data_robust.append({\n","        'optimizer': name, \n","        'loss': losses,\n","        'acc': metrics\n","    })\n","    # Save robust net\n","    robust_networks[optimizer] = net"],"id":"blocked-child"},{"cell_type":"raw","metadata":{"tags":[],"id":"phantom-strategy"},"source":["# NON LOOPY ATTACK ON ROBUST MODELS\n","data_robust_attack = list()\n","epsilons = np.arange(0, 0.6, 0.05)\n","\n","# Attack all models\n","for optimizer, network in robust_networks.items():\n","    name = optimizer_names[optimizer]\n","    print(f'\\n{name:<10}', end='')\n","    \n","    for eps in epsilons:\n","        print('', end='.')\n","        # Attack\n","        loss_attack, acc_attack = attack(\n","            model=network,\n","            test_loader=test_loader,\n","            epsilon=eps,\n","            verbose=False,\n","            **test_config\n","        )\n","        # Log\n","        data_robust_attack.append({\n","            'optimizer': name,\n","            'epsilon': eps,\n","            'loss': loss_attack,\n","            'acc': acc_attack\n","        })"],"id":"phantom-strategy"},{"cell_type":"markdown","metadata":{"id":"institutional-partnership"},"source":["### Training curves"],"id":"institutional-partnership"},{"cell_type":"code","metadata":{"id":"adequate-dispute","outputId":"a690d323-6724-40bb-d180-fc70cac1f889"},"source":["df_naive = pd.DataFrame(data_robust).sort_values(['optimizer', 'n'])\n","# Average training loss per epoch\n","df_naive.loss_train = df_naive.loss_train.apply(lambda s: np.mean(s, axis=1))\n","\n","colors = {'AdamOptimizer': 'r', 'MiniBatchOptimizer': 'b', 'NesterovOptimizer': 'm'}\n","for _, row in df_naive.iterrows():\n","    plt.plot(range(1, training_config['epochs'] + 1), row.loss_train, '-o', label=row.optimizer, color=colors[row.optimizer])\n","\n","plt.grid(alpha=.6)\n","plt.legend();\n","plt.yscale('log')\n","plt.xlabel('Epoch'); plt.ylabel('Training Loss')\n","plt.title('Training curves of naive models');"],"id":"adequate-dispute","execution_count":null,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"continued-nowhere"},"source":["### Attack plots"],"id":"continued-nowhere"},{"cell_type":"code","metadata":{"id":"portable-billion","outputId":"4899cd23-2960-4eb4-9680-feeb7cc21375"},"source":["df_robust = pd.DataFrame(data_robust_attack).sort_values(['optimizer', 'epsilon'])\n","# Raw accuracy in function of attack stength\n","sns.lineplot(x='epsilon', y='acc', data=df, hue='optimizer', marker='o')\n","plt.grid(alpha=.6)\n","plt.ylabel('Accuracy');\n","plt.title('Attack on robust models');"],"id":"portable-billion","execution_count":null,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"raising-barrel"},"source":["df_robust.T.to_json('res/log_attack_robust.json', indent=2)"],"id":"raising-barrel","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"headed-hamburg"},"source":["# Comparative analysis"],"id":"headed-hamburg"},{"cell_type":"code","metadata":{"id":"informational-toilet","outputId":"42807108-e91d-4657-8197-ccdf9a7a5360"},"source":["%%capture --no-stderr\n","# Whether to generate fancy plots for the report. Warning: this lengthens image rendering time\n","# This requires the `ipypublish` library\n","fancy_plots = True\n","\n","if fancy_plots:\n","    from ipypublish import nb_setup\n","    plt = nb_setup.setup_matplotlib()\n","    # Override with seaborn defaults\n","    sns.set(style='whitegrid')"],"id":"informational-toilet","execution_count":null,"outputs":[{"output_type":"stream","text":["/home/maousi/miniconda3/envs/ml/lib/python3.8/site-packages/ipypublish/scripts/nb_setup.py:226: MatplotlibDeprecationWarning: Support for setting the 'text.latex.preamble' or 'pgf.preamble' rcParam to a list of strings is deprecated since 3.3 and will be removed two minor releases later; set it to a single string instead.\n","  mpl.rcParams[key] = val\n","/home/maousi/miniconda3/envs/ml/lib/python3.8/site-packages/ipypublish/scripts/nb_setup.py:226: MatplotlibDeprecationWarning: \n","The text.latex.preview rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n","  mpl.rcParams[key] = val\n","/home/maousi/miniconda3/envs/ml/lib/python3.8/site-packages/ipypublish/scripts/nb_setup.py:226: MatplotlibDeprecationWarning: \n","The mathtext.fallback_to_cm rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n","  mpl.rcParams[key] = val\n","/home/maousi/miniconda3/envs/ml/lib/python3.8/site-packages/ipypublish/scripts/nb_setup.py:226: MatplotlibDeprecationWarning: Support for setting the 'mathtext.fallback_to_cm' rcParam is deprecated since 3.3 and will be removed two minor releases later; use 'mathtext.fallback : 'cm' instead.\n","  mpl.rcParams[key] = val\n","/home/maousi/miniconda3/envs/ml/lib/python3.8/site-packages/ipypublish/scripts/nb_setup.py:226: MatplotlibDeprecationWarning: \n","The validate_bool_maybe_none function was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n","  mpl.rcParams[key] = val\n","/home/maousi/miniconda3/envs/ml/lib/python3.8/site-packages/ipypublish/scripts/nb_setup.py:226: MatplotlibDeprecationWarning: \n","The savefig.jpeg_quality rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n","  mpl.rcParams[key] = val\n","/home/maousi/miniconda3/envs/ml/lib/python3.8/site-packages/ipypublish/scripts/nb_setup.py:226: MatplotlibDeprecationWarning: \n","The animation.html_args rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n","  mpl.rcParams[key] = val\n","/home/maousi/miniconda3/envs/ml/lib/python3.8/site-packages/ipypublish/scripts/nb_setup.py:226: MatplotlibDeprecationWarning: \n","The animation.avconv_args rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n","  mpl.rcParams[key] = val\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"artificial-quarter"},"source":["from pathlib import Path\n","\n","fig_path = Path('fig')\n","if not fig_path.exists():\n","    fig_path.mkdir()"],"id":"artificial-quarter","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"monetary-registrar"},"source":["df_naive = pd.read_json('res/log_attack_naive.json').T.drop(columns=['loss', 'n'])\n","df_robust = pd.read_json('res/log_attack_robust.json').T\n","# For some reason this has to be done after parsing from json\n","df_naive.epsilon = df_naive.epsilon.astype(float)\n","df_naive.acc = df_naive.acc.astype(float)\n","df_robust.acc = df_robust.acc.astype(float)\n","df_robust.epsilon = df_robust.epsilon.astype(float)"],"id":"monetary-registrar","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dated-consciousness","outputId":"cd8b6584-82a8-4789-f31b-7d4c2e27c001"},"source":["_, ax = plt.subplots(1, 2, figsize=(10, 4), sharex=True)\n","\n","plt.axes(ax[0])\n","sns.lineplot(x='epsilon', y='acc', data=df_naive, hue='optimizer', marker='o', ci='sd')\n","plt.yscale('log')\n","plt.ylabel('Accuracy');\n","plt.title('Attack on naive models');\n","plt.xlabel('Attack strength $\\epsilon$')\n","\n","plt.axes(ax[1])\n","sns.lineplot(x='epsilon', y='acc', data=df_robust, hue='optimizer', marker='o', ci='sd')\n","plt.grid(alpha=.6)\n","plt.ylabel('Accuracy');\n","plt.title('Attack on robust models')\n","plt.xlabel('Attack strength $\\epsilon$')\n","plt.tight_layout();\n","sns.despine()\n","plt.savefig('fig/attacks.pdf', bbox_inches='tight')"],"id":"dated-consciousness","execution_count":null,"outputs":[{"output_type":"display_data","data":{"image/svg+xml":"<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Created with matplotlib (https://matplotlib.org/) -->\n<svg height=\"276.48pt\" version=\"1.1\" viewBox=\"0 0 708.48 276.48\" width=\"708.48pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <metadata>\n  <rdf:RDF xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n   <cc:Work>\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n    <dc:date>2021-06-16T11:52:23.846758</dc:date>\n    <dc:format>image/svg+xml</dc:format>\n    <dc:creator>\n     <cc:Agent>\n      <dc:title>Matplotlib v3.3.4, https://matplotlib.org/</dc:title>\n     </cc:Agent>\n    </dc:creator>\n   </cc:Work>\n  </rdf:RDF>\n </metadata>\n <defs>\n  <style type=\"text/css\">*{stroke-linecap:butt;stroke-linejoin:round;}</style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M -0 276.48 \nL 708.48 276.48 \nL 708.48 0 \nL -0 0 \nz\n\" style=\"fill:#ffffff;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 70.276969 235.411983 \nL 354.754092 235.411983 \nL 354.754092 21.50218 \nL 70.276969 21.50218 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <path clip-path=\"url(#paf76286ffa)\" d=\"M 83.207748 235.411983 \nL 83.207748 21.50218 \n\" style=\"fill:none;stroke:#cccccc;stroke-linecap:round;\"/>\n     </g>\n     <g id=\"text_1\">\n      <!-- $\\mathdefault{0.0}$ -->\n      <g style=\"fill:#262626;\" transform=\"translate(76.20621 252.52233)scale(0.11 -0.11)\">\n       <defs>\n        <path d=\"M 42 31.640625 \nC 42 37.75 41.90625 48.125 37.703125 56.109375 \nC 34 63.109375 28.09375 65.59375 22.90625 65.59375 \nC 18.09375 65.59375 12 63.40625 8.203125 56.203125 \nC 4.203125 48.71875 3.796875 39.4375 3.796875 31.640625 \nC 3.796875 25.953125 3.90625 17.28125 7 9.671875 \nC 11.296875 -0.609375 19 -2 22.90625 -2 \nC 27.5 -2 34.5 -0.109375 38.59375 9.375 \nC 41.59375 16.28125 42 24.359375 42 31.640625 \nz\nM 22.90625 -0.40625 \nC 16.5 -0.40625 12.703125 5.078125 11.296875 12.6875 \nC 10.203125 18.5625 10.203125 27.15625 10.203125 32.75 \nC 10.203125 40.4375 10.203125 46.828125 11.5 52.921875 \nC 13.40625 61.390625 19 64 22.90625 64 \nC 27 64 32.296875 61.296875 34.203125 53.125 \nC 35.5 47.4375 35.59375 40.734375 35.59375 32.75 \nC 35.59375 26.25 35.59375 18.265625 34.40625 12.375 \nC 32.296875 1.484375 26.40625 -0.40625 22.90625 -0.40625 \nz\n\" id=\"CMR17-48\"/>\n        <path d=\"M 18.40625 4.796875 \nC 18.40625 7.6875 16 9.671875 13.59375 9.671875 \nC 10.703125 9.671875 8.703125 7.28125 8.703125 4.890625 \nC 8.703125 2 11.09375 0 13.5 0 \nC 16.40625 0 18.40625 2.390625 18.40625 4.796875 \nz\n\" id=\"CMMI12-58\"/>\n       </defs>\n       <use transform=\"scale(0.996264)\" xlink:href=\"#CMR17-48\"/>\n       <use transform=\"translate(45.690477 0)scale(0.996264)\" xlink:href=\"#CMMI12-58\"/>\n       <use transform=\"translate(72.787654 0)scale(0.996264)\" xlink:href=\"#CMR17-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <path clip-path=\"url(#paf76286ffa)\" d=\"M 130.22876 235.411983 \nL 130.22876 21.50218 \n\" style=\"fill:none;stroke:#cccccc;stroke-linecap:round;\"/>\n     </g>\n     <g id=\"text_2\">\n      <!-- $\\mathdefault{0.1}$ -->\n      <g style=\"fill:#262626;\" transform=\"translate(123.227222 252.52233)scale(0.11 -0.11)\">\n       <defs>\n        <path d=\"M 26.59375 63.40625 \nC 26.59375 65.5 26.5 65.5 25.09375 65.5 \nC 21.203125 61.1875 15.296875 59.796875 9.703125 59.796875 \nC 9.40625 59.796875 8.90625 59.796875 8.796875 59.5 \nC 8.703125 59.296875 8.703125 59.09375 8.703125 57 \nC 11.796875 57 17 57.59375 21 59.984375 \nL 21 7.203125 \nC 21 3.6875 20.796875 2.5 12.203125 2.5 \nL 9.203125 2.5 \nL 9.203125 0 \nC 14 0 19 0 23.796875 0 \nC 28.59375 0 33.59375 0 38.40625 0 \nL 38.40625 2.5 \nL 35.40625 2.5 \nC 26.796875 2.5 26.59375 3.59375 26.59375 7.15625 \nz\n\" id=\"CMR17-49\"/>\n       </defs>\n       <use transform=\"scale(0.996264)\" xlink:href=\"#CMR17-48\"/>\n       <use transform=\"translate(45.690477 0)scale(0.996264)\" xlink:href=\"#CMMI12-58\"/>\n       <use transform=\"translate(72.787654 0)scale(0.996264)\" xlink:href=\"#CMR17-49\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <path clip-path=\"url(#paf76286ffa)\" d=\"M 177.249772 235.411983 \nL 177.249772 21.50218 \n\" style=\"fill:none;stroke:#cccccc;stroke-linecap:round;\"/>\n     </g>\n     <g id=\"text_3\">\n      <!-- $\\mathdefault{0.2}$ -->\n      <g style=\"fill:#262626;\" transform=\"translate(170.248233 252.52233)scale(0.11 -0.11)\">\n       <defs>\n        <path d=\"M 41.703125 15.453125 \nL 39.90625 15.453125 \nC 38.90625 8.375 38.09375 7.171875 37.703125 6.5625 \nC 37.203125 5.765625 30 5.765625 28.59375 5.765625 \nL 9.40625 5.765625 \nC 13 9.671875 20 16.75 28.5 24.953125 \nC 34.59375 30.734375 41.703125 37.53125 41.703125 47.421875 \nC 41.703125 59.21875 32.296875 66 21.796875 66 \nC 10.796875 66 4.09375 56.3125 4.09375 47.34375 \nC 4.09375 43.4375 7 42.9375 8.203125 42.9375 \nC 9.203125 42.9375 12.203125 43.546875 12.203125 47.03125 \nC 12.203125 50.109375 9.59375 51 8.203125 51 \nC 7.59375 51 7 50.90625 6.59375 50.703125 \nC 8.5 59.21875 14.296875 63.40625 20.40625 63.40625 \nC 29.09375 63.40625 34.796875 56.515625 34.796875 47.421875 \nC 34.796875 38.734375 29.703125 31.25 24 24.75 \nL 4.09375 2.28125 \nL 4.09375 0 \nL 39.296875 0 \nz\n\" id=\"CMR17-50\"/>\n       </defs>\n       <use transform=\"scale(0.996264)\" xlink:href=\"#CMR17-48\"/>\n       <use transform=\"translate(45.690477 0)scale(0.996264)\" xlink:href=\"#CMMI12-58\"/>\n       <use transform=\"translate(72.787654 0)scale(0.996264)\" xlink:href=\"#CMR17-50\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <path clip-path=\"url(#paf76286ffa)\" d=\"M 224.270783 235.411983 \nL 224.270783 21.50218 \n\" style=\"fill:none;stroke:#cccccc;stroke-linecap:round;\"/>\n     </g>\n     <g id=\"text_4\">\n      <!-- $\\mathdefault{0.3}$ -->\n      <g style=\"fill:#262626;\" transform=\"translate(217.269245 252.52233)scale(0.11 -0.11)\">\n       <defs>\n        <path d=\"M 22.09375 33.703125 \nC 31 33.703125 34.90625 25.96875 34.90625 17.03125 \nC 34.90625 5 28.5 0.390625 22.703125 0.390625 \nC 17.40625 0.390625 8.796875 3.03125 6.09375 10.828125 \nC 6.59375 10.625 7.09375 10.625 7.59375 10.625 \nC 10 10.625 11.796875 12.21875 11.796875 14.8125 \nC 11.796875 17.703125 9.59375 19 7.59375 19 \nC 5.90625 19 3.296875 18.203125 3.296875 14.46875 \nC 3.296875 5.234375 12.296875 -2 22.90625 -2 \nC 34 -2 42.5 6.71875 42.5 16.953125 \nC 42.5 26.671875 34.5 33.703125 25 34.796875 \nC 32.59375 36.375 39.90625 43.0625 39.90625 52.015625 \nC 39.90625 59.6875 32 65.296875 23 65.296875 \nC 13.90625 65.296875 5.90625 59.828125 5.90625 52.015625 \nC 5.90625 48.59375 8.5 48 9.796875 48 \nC 11.90625 48 13.703125 49.296875 13.703125 51.890625 \nC 13.703125 54.46875 11.90625 55.765625 9.796875 55.765625 \nC 9.40625 55.765625 8.90625 55.765625 8.5 55.578125 \nC 11.40625 61.859375 19.296875 63 22.796875 63 \nC 26.296875 63 32.90625 61.328125 32.90625 51.875 \nC 32.90625 49.109375 32.5 44.1875 29.09375 39.84375 \nC 26.09375 36 22.703125 36 19.40625 35.6875 \nC 18.90625 35.6875 16.59375 35.453125 16.203125 35.453125 \nC 15.5 35.359375 15.09375 35.265625 15.09375 34.5 \nC 15.09375 33.796875 15.203125 33.703125 17.203125 33.703125 \nz\n\" id=\"CMR17-51\"/>\n       </defs>\n       <use transform=\"scale(0.996264)\" xlink:href=\"#CMR17-48\"/>\n       <use transform=\"translate(45.690477 0)scale(0.996264)\" xlink:href=\"#CMMI12-58\"/>\n       <use transform=\"translate(72.787654 0)scale(0.996264)\" xlink:href=\"#CMR17-51\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\">\n      <path clip-path=\"url(#paf76286ffa)\" d=\"M 271.291795 235.411983 \nL 271.291795 21.50218 \n\" style=\"fill:none;stroke:#cccccc;stroke-linecap:round;\"/>\n     </g>\n     <g id=\"text_5\">\n      <!-- $\\mathdefault{0.4}$ -->\n      <g style=\"fill:#262626;\" transform=\"translate(264.290257 252.52233)scale(0.11 -0.11)\">\n       <defs>\n        <path d=\"M 33.59375 64.40625 \nC 33.59375 66.5 33.5 66.5 31.703125 66.5 \nL 2 19.59375 \nL 2 17 \nL 27.796875 17 \nL 27.796875 7.140625 \nC 27.796875 3.5 27.59375 2.5 20.59375 2.5 \nL 18.703125 2.5 \nL 18.703125 0 \nC 21.90625 0 27.296875 0 30.703125 0 \nC 34.09375 0 39.5 0 42.703125 0 \nL 42.703125 2.5 \nL 40.796875 2.5 \nC 33.796875 2.5 33.59375 3.5 33.59375 7.140625 \nL 33.59375 17 \nL 43.796875 17 \nL 43.796875 19.59375 \nL 33.59375 19.59375 \nz\nM 28.09375 57.859375 \nL 28.09375 19.59375 \nL 4 19.59375 \nz\n\" id=\"CMR17-52\"/>\n       </defs>\n       <use transform=\"scale(0.996264)\" xlink:href=\"#CMR17-48\"/>\n       <use transform=\"translate(45.690477 0)scale(0.996264)\" xlink:href=\"#CMMI12-58\"/>\n       <use transform=\"translate(72.787654 0)scale(0.996264)\" xlink:href=\"#CMR17-52\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_6\">\n      <path clip-path=\"url(#paf76286ffa)\" d=\"M 318.312807 235.411983 \nL 318.312807 21.50218 \n\" style=\"fill:none;stroke:#cccccc;stroke-linecap:round;\"/>\n     </g>\n     <g id=\"text_6\">\n      <!-- $\\mathdefault{0.5}$ -->\n      <g style=\"fill:#262626;\" transform=\"translate(311.311269 252.52233)scale(0.11 -0.11)\">\n       <defs>\n        <path d=\"M 11.40625 57.6875 \nC 12.40625 57.28125 16.5 56 20.703125 56 \nC 30 56 35.09375 61.109375 38 64.0625 \nC 38 64.953125 38 65.5 37.40625 65.5 \nC 37.296875 65.5 37.09375 65.5 36.296875 65.046875 \nC 32.796875 63.40625 28.703125 62.078125 23.703125 62.078125 \nC 20.703125 62.078125 16.203125 62.484375 11.296875 64.671875 \nC 10.203125 65.171875 10 65.171875 9.90625 65.171875 \nC 9.40625 65.171875 9.296875 65.0625 9.296875 63.078125 \nL 9.296875 34.421875 \nC 9.296875 32.640625 9.296875 32.140625 10.296875 32.140625 \nC 10.796875 32.140625 11 32.34375 11.5 33.03125 \nC 14.703125 37.515625 19.09375 39.40625 24.09375 39.40625 \nC 27.59375 39.40625 35.09375 37.21875 35.09375 20.140625 \nC 35.09375 16.953125 35.09375 11.171875 32.09375 6.578125 \nC 29.59375 2.484375 25.703125 0.390625 21.40625 0.390625 \nC 14.796875 0.390625 8.09375 5 6.296875 12.71875 \nC 6.703125 12.609375 7.5 12.421875 7.90625 12.421875 \nC 9.203125 12.421875 11.703125 13.125 11.703125 16.21875 \nC 11.703125 18.90625 9.796875 20 7.90625 20 \nC 5.59375 20 4.09375 18.59375 4.09375 15.796875 \nC 4.09375 7.09375 11 -2 21.59375 -2 \nC 31.90625 -2 41.703125 6.875 41.703125 19.75 \nC 41.703125 31.71875 33.90625 41 24.203125 41 \nC 19.09375 41 14.796875 39.109375 11.40625 35.53125 \nz\n\" id=\"CMR17-53\"/>\n       </defs>\n       <use transform=\"scale(0.996264)\" xlink:href=\"#CMR17-48\"/>\n       <use transform=\"translate(45.690477 0)scale(0.996264)\" xlink:href=\"#CMMI12-58\"/>\n       <use transform=\"translate(72.787654 0)scale(0.996264)\" xlink:href=\"#CMR17-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_7\">\n     <!-- Attack strength $\\epsilon$ -->\n     <g style=\"fill:#262626;\" transform=\"translate(170.082081 266.955404)scale(0.12 -0.12)\">\n      <defs>\n       <path d=\"M 35.5 69 \nL 26.90625 69 \nL 2.59375 0 \nL 10.203125 0 \nL 17.203125 20 \nL 44 20 \nL 51.09375 0 \nL 59.796875 0 \nz\nM 42.09375 25.578125 \nL 19.09375 25.578125 \nC 23.90625 39.5 29.90625 56.84375 30.59375 61.328125 \nL 30.703125 61.328125 \nC 31.40625 57.234375 33.40625 51.265625 35.09375 46.1875 \nz\n\" id=\"CMSS17-65\"/>\n       <path d=\"M 16.703125 37 \nL 29.703125 37 \nL 29.703125 42.765625 \nL 16.703125 42.765625 \nL 16.703125 55 \nL 9.59375 55 \nL 9.59375 42.765625 \nL 1.703125 42.765625 \nL 1.703125 37 \nL 9.40625 37 \nL 9.40625 11.703125 \nC 9.40625 6 10.703125 -1 17.296875 -1 \nC 22.296875 -1 26.90625 0.390625 31.296875 2.6875 \nL 29.703125 8.5625 \nC 27.296875 6.46875 24.40625 5.265625 21.296875 5.265625 \nC 16.90625 5.265625 16.703125 10.875 16.703125 13.375 \nz\n\" id=\"CMSS17-116\"/>\n       <path d=\"M 37.59375 27.984375 \nC 37.59375 37.375 30.90625 43.875 21.90625 43.875 \nC 17.5 43.875 12.703125 43.078125 7.203125 39.890625 \nL 7.796875 33.359375 \nC 10.296875 35.125 14.59375 38 21.796875 38 \nC 26.90625 38 30 34.0625 30 27.84375 \nL 30 24 \nC 14 24 4 19.34375 4 11.34375 \nC 4 7.203125 6.5 -1 14.796875 -1 \nC 16.296875 -1 24.40625 -1 30.203125 3.390625 \nL 30.203125 -0.296875 \nL 37.59375 -0.296875 \nz\nM 30 12.75 \nC 30 10.953125 30 8.5625 27 6.78125 \nC 24.40625 5.078125 21.09375 5.078125 19.703125 5.078125 \nC 14.703125 5.078125 11.296875 7.984375 11.296875 11.625 \nC 11.296875 18.921875 26.90625 18.921875 30 18.921875 \nz\n\" id=\"CMSS17-97\"/>\n       <path d=\"M 38.5 39.703125 \nC 38.5 40.390625 33.90625 42.40625 32.703125 42.796875 \nC 29.40625 44 25.203125 44 24.09375 44 \nC 11.09375 44 3.296875 32.703125 3.296875 21.296875 \nC 3.296875 9.296875 12 -1 23.703125 -1 \nC 30.40625 -1 35.203125 1.1875 39.09375 3.78125 \nL 38.5 10.375 \nC 34.203125 7.078125 29.203125 5.265625 23.796875 5.265625 \nC 16 5.265625 10.90625 12.09375 10.90625 21.390625 \nC 10.90625 28.609375 14.203125 37.71875 24.203125 37.71875 \nC 29.703125 37.71875 32.796875 36.609375 37.40625 33.515625 \nz\n\" id=\"CMSS17-99\"/>\n       <path d=\"M 26.5 26.375 \nL 42 42.796875 \nL 32.40625 42.796875 \nL 14.90625 24.28125 \nL 14.90625 69 \nL 7.5 69 \nL 7.5 0 \nL 14.796875 0 \nL 14.796875 13.9375 \nL 21.5 21 \nL 35.59375 0 \nL 44.09375 0 \nz\n\" id=\"CMSS17-107\"/>\n       <path d=\"M 32.203125 41.046875 \nC 26.296875 43.859375 21.703125 43.859375 18.703125 43.859375 \nC 11.59375 43.859375 3.09375 41.375 3.09375 31.296875 \nC 3.09375 21.234375 14.09375 19.03125 17.09375 18.421875 \nC 21.703125 17.53125 26.796875 16.53125 26.796875 11.5625 \nC 26.796875 5.265625 19.59375 5.265625 18.296875 5.265625 \nC 14.296875 5.265625 8.796875 6.359375 3.796875 9.96875 \nL 2.59375 3.28125 \nC 8.296875 0 13.796875 -1 18.40625 -1 \nC 30.703125 -1 33.796875 6.5 33.796875 12.203125 \nC 33.796875 17.09375 31 20.390625 29.09375 21.890625 \nC 25.796875 24.5 24.59375 24.796875 16.40625 26.5 \nC 15 26.703125 10.09375 27.796875 10.09375 32.28125 \nC 10.09375 38 16.40625 38 17.796875 38 \nC 24.296875 38 28.296875 35.984375 31 34.5 \nz\n\" id=\"CMSS17-115\"/>\n       <path d=\"M 14.90625 21.296875 \nC 14.90625 30.703125 21.796875 37 30.59375 37 \nL 30.59375 43.578125 \nC 24.203125 43.578125 18.203125 40.390625 14.59375 35.203125 \nL 14.59375 43.09375 \nL 7.5 43.09375 \nL 7.5 0 \nL 14.90625 0 \nz\n\" id=\"CMSS17-114\"/>\n       <path d=\"M 39.09375 21.515625 \nC 39.09375 24.84375 38.90625 31.296875 35.703125 36.640625 \nC 32.203125 42.390625 26.5 44 22.203125 44 \nC 11.796875 44 3 34.1875 3 21.484375 \nC 3 9.09375 12.09375 -1 23.59375 -1 \nC 28.09375 -1 33.59375 0.296875 38.59375 3.875 \nC 38.59375 4.28125 38.40625 6.46875 38.296875 6.5625 \nC 38.296875 6.765625 38 9.84375 38 10.25 \nC 33.203125 6.359375 27.703125 5.078125 23.703125 5.078125 \nC 17.296875 5.078125 10.40625 10.421875 10.09375 21.515625 \nz\nM 10.90625 27 \nC 12.203125 32.5625 16.59375 37.828125 22.203125 37.828125 \nC 23.703125 37.828125 30.703125 37.828125 32.5 27 \nz\n\" id=\"CMSS17-101\"/>\n       <path d=\"M 40.90625 29.328125 \nC 40.90625 35.671875 39.40625 44 28.09375 44 \nC 21.703125 44 17.5 40.71875 14.703125 37.328125 \nL 14.703125 43.09375 \nL 7.40625 43.09375 \nL 7.40625 0 \nL 15 0 \nL 15 24.359375 \nC 15 30.6875 17.40625 37.9375 24.203125 37.9375 \nC 33 37.9375 33.296875 32 33.296875 28.578125 \nL 33.296875 0 \nL 40.90625 0 \nz\n\" id=\"CMSS17-110\"/>\n       <path d=\"M 44.5 43.875 \nC 38.796875 43.875 33.90625 42.78125 29.90625 40.890625 \nC 26.59375 43.390625 23.203125 43.875 20.90625 43.875 \nC 12.203125 43.875 5.59375 36.703125 5.59375 28.34375 \nC 5.59375 22.9375 8.59375 18.859375 8.796875 18.671875 \nC 7 16.171875 6 13.484375 6 10.5 \nC 6 7 7.40625 4.515625 8.5 3.125 \nC 3.296875 -0.046875 2.59375 -4.90625 2.59375 -6.796875 \nC 2.59375 -14.03125 11.703125 -20 23.40625 -20 \nC 35.203125 -20 44.296875 -14.03125 44.296875 -6.6875 \nC 44.296875 7 29 7 24.796875 7 \nL 16.703125 7 \nC 15.203125 7 11.203125 7 11.203125 12.359375 \nC 11.203125 14.390625 12.09375 15.6875 12.203125 15.78125 \nC 13.703125 14.6875 16.796875 13 20.90625 13 \nC 29.203125 13 36.09375 19.96875 36.09375 28.546875 \nC 36.09375 33.3125 33.90625 36.796875 33 38 \nL 33.296875 38 \nC 33.59375 38 37.796875 38 39.296875 38 \nC 42.5 38 42.796875 37.953125 45.59375 37.796875 \nz\nM 20.90625 18.46875 \nC 17.5 18.46875 12.703125 20.546875 12.703125 28.484375 \nC 12.703125 37.109375 18.203125 38.5 20.796875 38.5 \nC 24.203125 38.5 29 36.421875 29 28.484375 \nC 29 19.859375 23.5 18.46875 20.90625 18.46875 \nz\nM 24.703125 -0.15625 \nC 27.09375 -0.15625 37.203125 -0.15625 37.203125 -6.90625 \nC 37.203125 -11.15625 31 -14.515625 23.5 -14.515625 \nC 15.90625 -14.515625 9.703125 -11.25 9.703125 -6.796875 \nC 9.703125 -6.296875 9.703125 -0.15625 16.59375 -0.15625 \nz\n\" id=\"CMSS17-103\"/>\n       <path d=\"M 40.90625 29.546875 \nC 40.90625 35.8125 39.40625 44.0625 28.09375 44.0625 \nC 21.796875 44.0625 17.703125 40.984375 14.796875 37.609375 \nL 14.796875 69.5 \nL 7.40625 69.5 \nL 7.40625 0.5 \nL 15 0.5 \nL 15 24.578125 \nC 15 30.828125 17.40625 38 24.203125 38 \nC 33 38 33.296875 32.125 33.296875 28.734375 \nL 33.296875 0.5 \nL 40.90625 0.5 \nz\n\" id=\"CMSS17-104\"/>\n       <path d=\"M 29.09375 22.921875 \nC 30.59375 22.921875 32.296875 22.921875 32.296875 24.515625 \nC 32.296875 25.8125 31.296875 25.8125 29.5 25.8125 \nL 13.296875 25.8125 \nC 15.796875 34.78125 21.703125 40.203125 30.59375 40.203125 \nL 33.5 40.203125 \nC 35.203125 40.203125 36.703125 40.203125 36.703125 41.796875 \nC 36.703125 43.09375 35.59375 43.09375 33.796875 43.09375 \nL 30.40625 43.09375 \nC 18.09375 43.09375 4.59375 33.296875 4.59375 17.59375 \nC 4.59375 6.5 12.09375 -1 22 -1 \nC 28.40625 -1 34.703125 3.03125 34.703125 4.03125 \nC 34.703125 4.625 34.40625 5.25 33.796875 5.25 \nC 33.5 5.25 33.296875 5.140625 32.796875 4.75 \nC 29 2.21875 25.296875 1 22.296875 1 \nC 17 1 11.40625 4.53125 11.40625 14.34375 \nC 11.40625 16.25 11.59375 18.875 12.5 22.921875 \nz\n\" id=\"CMMI12-15\"/>\n      </defs>\n      <use transform=\"scale(0.996264)\" xlink:href=\"#CMSS17-65\"/>\n      <use transform=\"translate(59.615401 0)scale(0.996264)\" xlink:href=\"#CMSS17-116\"/>\n      <use transform=\"translate(93.446968 0)scale(0.996264)\" xlink:href=\"#CMSS17-116\"/>\n      <use transform=\"translate(127.278534 0)scale(0.996264)\" xlink:href=\"#CMSS17-97\"/>\n      <use transform=\"translate(172.200455 0)scale(0.996264)\" xlink:href=\"#CMSS17-99\"/>\n      <use transform=\"translate(213.839277 0)scale(0.996264)\" xlink:href=\"#CMSS17-107\"/>\n      <use transform=\"translate(290.670879 0)scale(0.996264)\" xlink:href=\"#CMSS17-115\"/>\n      <use transform=\"translate(326.584421 0)scale(0.996264)\" xlink:href=\"#CMSS17-116\"/>\n      <use transform=\"translate(360.415988 0)scale(0.996264)\" xlink:href=\"#CMSS17-114\"/>\n      <use transform=\"translate(392.32576 0)scale(0.996264)\" xlink:href=\"#CMSS17-101\"/>\n      <use transform=\"translate(433.964582 0)scale(0.996264)\" xlink:href=\"#CMSS17-110\"/>\n      <use transform=\"translate(482.169525 0)scale(0.996264)\" xlink:href=\"#CMSS17-103\"/>\n      <use transform=\"translate(529.013149 0)scale(0.996264)\" xlink:href=\"#CMSS17-116\"/>\n      <use transform=\"translate(562.844716 0)scale(0.996264)\" xlink:href=\"#CMSS17-104\"/>\n      <use transform=\"translate(642.278772 0)scale(0.996264)\" xlink:href=\"#CMMI12-15\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_7\">\n      <path clip-path=\"url(#paf76286ffa)\" d=\"M 70.276969 27.210864 \nL 354.754092 27.210864 \n\" style=\"fill:none;stroke:#cccccc;stroke-linecap:round;\"/>\n     </g>\n     <g id=\"text_8\">\n      <!-- $\\mathdefault{10^{0}}$ -->\n      <g style=\"fill:#262626;\" transform=\"translate(45.449696 31.280845)scale(0.11 -0.11)\">\n       <use transform=\"scale(0.996264)\" xlink:href=\"#CMR17-49\"/>\n       <use transform=\"translate(45.690477 0)scale(0.996264)\" xlink:href=\"#CMR17-48\"/>\n       <use transform=\"translate(91.380954 44.560802)scale(0.697382)\" xlink:href=\"#CMR17-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"text_9\">\n      <!-- $\\mathdefault{4\\times10^{-1}}$ -->\n      <g style=\"fill:#262626;\" transform=\"translate(21.826776 212.812022)scale(0.11 -0.11)\">\n       <defs>\n        <path d=\"M 38.90625 27.890625 \nL 18.90625 47.796875 \nC 17.703125 49 17.5 49.1875 16.703125 49.1875 \nC 15.703125 49.1875 14.703125 48.296875 14.703125 47.1875 \nC 14.703125 46.5 14.90625 46.296875 16 45.1875 \nL 36 25.09375 \nL 16 5 \nC 14.90625 3.890625 14.703125 3.6875 14.703125 3 \nC 14.703125 1.890625 15.703125 1 16.703125 1 \nC 17.5 1 17.703125 1.1875 18.90625 2.390625 \nL 38.796875 22.296875 \nL 59.5 1.59375 \nC 59.703125 1.5 60.40625 1 61 1 \nC 62.203125 1 63 1.890625 63 3 \nC 63 3.1875 63 3.59375 62.703125 4.09375 \nC 62.59375 4.296875 46.703125 20 41.703125 25.09375 \nL 60 43.390625 \nC 60.5 44 62 45.296875 62.5 45.890625 \nC 62.59375 46.09375 63 46.5 63 47.1875 \nC 63 48.296875 62.203125 49.1875 61 49.1875 \nC 60.203125 49.1875 59.796875 48.796875 58.703125 47.6875 \nz\n\" id=\"CMSY10-2\"/>\n        <path d=\"M 65.90625 23 \nC 67.59375 23 69.40625 23 69.40625 25 \nC 69.40625 27 67.59375 27 65.90625 27 \nL 11.796875 27 \nC 10.09375 27 8.296875 27 8.296875 25 \nC 8.296875 23 10.09375 23 11.796875 23 \nz\n\" id=\"CMSY10-0\"/>\n       </defs>\n       <use transform=\"scale(0.996264)\" xlink:href=\"#CMR17-52\"/>\n       <use transform=\"translate(67.829684 0)scale(0.996264)\" xlink:href=\"#CMSY10-2\"/>\n       <use transform=\"translate(167.456359 0)scale(0.996264)\" xlink:href=\"#CMR17-49\"/>\n       <use transform=\"translate(213.146836 0)scale(0.996264)\" xlink:href=\"#CMR17-48\"/>\n       <use transform=\"translate(258.837313 44.560802)scale(0.697382)\" xlink:href=\"#CMSY10-0\"/>\n       <use transform=\"translate(313.078306 44.560802)scale(0.697382)\" xlink:href=\"#CMR17-49\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\"/>\n    <g id=\"ytick_4\">\n     <g id=\"text_10\">\n      <!-- $\\mathdefault{6\\times10^{-1}}$ -->\n      <g style=\"fill:#262626;\" transform=\"translate(21.826776 132.685256)scale(0.11 -0.11)\">\n       <defs>\n        <path d=\"M 10.59375 34 \nC 10.59375 57.65625 21.796875 63 28.296875 63 \nC 30.40625 63 35.5 62.640625 37.5 59 \nC 35.90625 59 32.90625 59 32.90625 55.515625 \nC 32.90625 52.828125 35.09375 51.921875 36.5 51.921875 \nC 37.40625 51.921875 40.09375 52.3125 40.09375 55.625 \nC 40.09375 61.78125 35.09375 65.296875 28.203125 65.296875 \nC 16.296875 65.296875 3.796875 52.96875 3.796875 31 \nC 3.796875 3.953125 15.09375 -2 23.09375 -2 \nC 32.796875 -2 42 6.671875 42 20.046875 \nC 42 32.515625 33.90625 41.59375 23.703125 41.59375 \nC 17.59375 41.59375 13.09375 37.609375 10.59375 30.625 \nz\nM 23.09375 0.390625 \nC 10.796875 0.390625 10.796875 18.75 10.796875 22.4375 \nC 10.796875 29.625 14.203125 40 23.5 40 \nC 25.203125 40 30.09375 40 33.40625 33.125 \nC 35.203125 29.21875 35.203125 25.140625 35.203125 20.140625 \nC 35.203125 14.75 35.203125 10.78125 33.09375 6.78125 \nC 30.90625 2.671875 27.703125 0.390625 23.09375 0.390625 \nz\n\" id=\"CMR17-54\"/>\n       </defs>\n       <use transform=\"scale(0.996264)\" xlink:href=\"#CMR17-54\"/>\n       <use transform=\"translate(67.829684 0)scale(0.996264)\" xlink:href=\"#CMSY10-2\"/>\n       <use transform=\"translate(167.456359 0)scale(0.996264)\" xlink:href=\"#CMR17-49\"/>\n       <use transform=\"translate(213.146836 0)scale(0.996264)\" xlink:href=\"#CMR17-48\"/>\n       <use transform=\"translate(258.837313 44.560802)scale(0.697382)\" xlink:href=\"#CMSY10-0\"/>\n       <use transform=\"translate(313.078306 44.560802)scale(0.697382)\" xlink:href=\"#CMR17-49\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\"/>\n    <g id=\"ytick_6\"/>\n    <g id=\"ytick_7\"/>\n    <g id=\"text_11\">\n     <!-- Accuracy -->\n     <g style=\"fill:#262626;\" transform=\"translate(15.50218 150.599481)rotate(-90)scale(0.12 -0.12)\">\n      <defs>\n       <path d=\"M 40.90625 42.796875 \nL 33.296875 42.796875 \nL 33.296875 15.1875 \nC 33.296875 7.78125 27.90625 4.78125 22.203125 4.78125 \nC 15.59375 4.78125 15 6.984375 15 11.078125 \nL 15 42.796875 \nL 7.40625 42.796875 \nL 7.40625 10.59375 \nC 7.40625 2.796875 10.09375 -1 17 -1 \nC 20.40625 -1 28.09375 -0.203125 33.5 4.78125 \nL 33.5 0 \nL 40.90625 0 \nz\n\" id=\"CMSS17-117\"/>\n       <path d=\"M 41.796875 43 \nL 34 43 \nC 25.5 20.21875 22.59375 10.96875 22.40625 5.984375 \nL 22.296875 5.984375 \nC 22 10.875 17.59375 22.8125 14.09375 31.359375 \nL 9.40625 43 \nL 1.296875 43 \nL 19 0.203125 \nC 17.90625 -2.78125 16.296875 -7.265625 15.796875 -8.265625 \nC 13.59375 -13.828125 12.09375 -13.828125 10.5 -13.828125 \nC 10.09375 -13.828125 6.90625 -13.828125 3.296875 -12.640625 \nL 3.90625 -19.203125 \nC 6.40625 -19.703125 8.90625 -20 10.703125 -20 \nC 13.203125 -20 18.203125 -20 22.796875 -7.765625 \nz\n\" id=\"CMSS17-121\"/>\n      </defs>\n      <use transform=\"scale(0.996264)\" xlink:href=\"#CMSS17-65\"/>\n      <use transform=\"translate(62.217855 0)scale(0.996264)\" xlink:href=\"#CMSS17-99\"/>\n      <use transform=\"translate(103.856677 0)scale(0.996264)\" xlink:href=\"#CMSS17-99\"/>\n      <use transform=\"translate(145.495499 0)scale(0.996264)\" xlink:href=\"#CMSS17-117\"/>\n      <use transform=\"translate(193.700442 0)scale(0.996264)\" xlink:href=\"#CMSS17-114\"/>\n      <use transform=\"translate(225.610215 0)scale(0.996264)\" xlink:href=\"#CMSS17-97\"/>\n      <use transform=\"translate(270.532135 0)scale(0.996264)\" xlink:href=\"#CMSS17-99\"/>\n      <use transform=\"translate(312.170957 0)scale(0.996264)\" xlink:href=\"#CMSS17-121\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"PolyCollection_1\">\n    <defs>\n     <path d=\"M 83.207748 -241.353701 \nL 83.207748 -234.184935 \nL 106.718254 -232.011042 \nL 130.22876 -229.282698 \nL 153.739266 -225.249456 \nL 177.249772 -220.213417 \nL 200.760278 -213.041066 \nL 224.270783 -202.946245 \nL 247.781289 -191.459619 \nL 271.291795 -174.441184 \nL 294.802301 -151.306393 \nL 318.312807 -119.45835 \nL 341.823313 -76.464089 \nL 341.823313 -118.419342 \nL 341.823313 -118.419342 \nL 318.312807 -154.858181 \nL 294.802301 -181.501314 \nL 271.291795 -198.578819 \nL 247.781289 -211.647093 \nL 224.270783 -221.802171 \nL 200.760278 -228.578926 \nL 177.249772 -232.450768 \nL 153.739266 -235.918057 \nL 130.22876 -237.901803 \nL 106.718254 -239.997584 \nL 83.207748 -241.353701 \nz\n\" id=\"m023ca32cf9\" style=\"stroke:#4c72b0;stroke-opacity:0.2;\"/>\n    </defs>\n    <g clip-path=\"url(#paf76286ffa)\">\n     <use style=\"fill:#4c72b0;fill-opacity:0.2;stroke:#4c72b0;stroke-opacity:0.2;\" x=\"0\" xlink:href=\"#m023ca32cf9\" y=\"276.48\"/>\n    </g>\n   </g>\n   <g id=\"PolyCollection_2\">\n    <defs>\n     <path d=\"M 83.207748 -245.254647 \nL 83.207748 -242.780049 \nL 106.718254 -241.651514 \nL 130.22876 -240.114689 \nL 153.739266 -237.913259 \nL 177.249772 -234.499126 \nL 200.760278 -230.21124 \nL 224.270783 -223.787028 \nL 247.781289 -214.105576 \nL 271.291795 -201.048929 \nL 294.802301 -183.177536 \nL 318.312807 -158.372009 \nL 341.823313 -121.259144 \nL 341.823313 -157.675012 \nL 341.823313 -157.675012 \nL 318.312807 -184.105054 \nL 294.802301 -203.90284 \nL 271.291795 -217.234792 \nL 247.781289 -226.385687 \nL 224.270783 -232.330112 \nL 200.760278 -236.382608 \nL 177.249772 -239.594839 \nL 153.739266 -241.564923 \nL 130.22876 -243.070613 \nL 106.718254 -244.276084 \nL 83.207748 -245.254647 \nz\n\" id=\"mf1c05340d5\" style=\"stroke:#dd8452;stroke-opacity:0.2;\"/>\n    </defs>\n    <g clip-path=\"url(#paf76286ffa)\">\n     <use style=\"fill:#dd8452;fill-opacity:0.2;stroke:#dd8452;stroke-opacity:0.2;\" x=\"0\" xlink:href=\"#mf1c05340d5\" y=\"276.48\"/>\n    </g>\n   </g>\n   <g id=\"PolyCollection_3\">\n    <defs>\n     <path d=\"M 83.207748 -241.739706 \nL 83.207748 -225.093229 \nL 106.718254 -222.284536 \nL 130.22876 -218.521875 \nL 153.739266 -214.591451 \nL 177.249772 -208.053672 \nL 200.760278 -199.01162 \nL 224.270783 -186.479201 \nL 247.781289 -170.569754 \nL 271.291795 -147.998548 \nL 294.802301 -121.143448 \nL 318.312807 -90.405419 \nL 341.823313 -50.79119 \nL 341.823313 -94.822555 \nL 341.823313 -94.822555 \nL 318.312807 -132.278223 \nL 294.802301 -161.027776 \nL 271.291795 -184.090951 \nL 247.781289 -201.759477 \nL 224.270783 -214.191601 \nL 200.760278 -224.113287 \nL 177.249772 -229.993565 \nL 153.739266 -234.487676 \nL 130.22876 -237.821731 \nL 106.718254 -240.046333 \nL 83.207748 -241.739706 \nz\n\" id=\"ma27e5d5ea1\" style=\"stroke:#55a868;stroke-opacity:0.2;\"/>\n    </defs>\n    <g clip-path=\"url(#paf76286ffa)\">\n     <use style=\"fill:#55a868;fill-opacity:0.2;stroke:#55a868;stroke-opacity:0.2;\" x=\"0\" xlink:href=\"#ma27e5d5ea1\" y=\"276.48\"/>\n    </g>\n   </g>\n   <g id=\"line2d_8\">\n    <path clip-path=\"url(#paf76286ffa)\" d=\"M 83.207748 38.678177 \nL 106.718254 40.435343 \nL 130.22876 42.840763 \nL 153.739266 45.824258 \nL 177.249772 50.053198 \nL 200.760278 55.517333 \nL 224.270783 63.880981 \nL 247.781289 74.668976 \nL 271.291795 89.601695 \nL 294.802301 109.500002 \nL 318.312807 138.53013 \nL 341.823313 177.926951 \n\" style=\"fill:none;stroke:#4c72b0;stroke-linecap:round;stroke-width:1.5;\"/>\n    <defs>\n     <path d=\"M 0 3 \nC 0.795609 3 1.55874 2.683901 2.12132 2.12132 \nC 2.683901 1.55874 3 0.795609 3 0 \nC 3 -0.795609 2.683901 -1.55874 2.12132 -2.12132 \nC 1.55874 -2.683901 0.795609 -3 0 -3 \nC -0.795609 -3 -1.55874 -2.683901 -2.12132 -2.12132 \nC -2.683901 -1.55874 -3 -0.795609 -3 0 \nC -3 0.795609 -2.683901 1.55874 -2.12132 2.12132 \nC -1.55874 2.683901 -0.795609 3 0 3 \nz\n\" id=\"m36c057cb21\" style=\"stroke:#ffffff;stroke-width:0.75;\"/>\n    </defs>\n    <g clip-path=\"url(#paf76286ffa)\">\n     <use style=\"fill:#4c72b0;stroke:#ffffff;stroke-width:0.75;\" x=\"83.207748\" xlink:href=\"#m36c057cb21\" y=\"38.678177\"/>\n     <use style=\"fill:#4c72b0;stroke:#ffffff;stroke-width:0.75;\" x=\"106.718254\" xlink:href=\"#m36c057cb21\" y=\"40.435343\"/>\n     <use style=\"fill:#4c72b0;stroke:#ffffff;stroke-width:0.75;\" x=\"130.22876\" xlink:href=\"#m36c057cb21\" y=\"42.840763\"/>\n     <use style=\"fill:#4c72b0;stroke:#ffffff;stroke-width:0.75;\" x=\"153.739266\" xlink:href=\"#m36c057cb21\" y=\"45.824258\"/>\n     <use style=\"fill:#4c72b0;stroke:#ffffff;stroke-width:0.75;\" x=\"177.249772\" xlink:href=\"#m36c057cb21\" y=\"50.053198\"/>\n     <use style=\"fill:#4c72b0;stroke:#ffffff;stroke-width:0.75;\" x=\"200.760278\" xlink:href=\"#m36c057cb21\" y=\"55.517333\"/>\n     <use style=\"fill:#4c72b0;stroke:#ffffff;stroke-width:0.75;\" x=\"224.270783\" xlink:href=\"#m36c057cb21\" y=\"63.880981\"/>\n     <use style=\"fill:#4c72b0;stroke:#ffffff;stroke-width:0.75;\" x=\"247.781289\" xlink:href=\"#m36c057cb21\" y=\"74.668976\"/>\n     <use style=\"fill:#4c72b0;stroke:#ffffff;stroke-width:0.75;\" x=\"271.291795\" xlink:href=\"#m36c057cb21\" y=\"89.601695\"/>\n     <use style=\"fill:#4c72b0;stroke:#ffffff;stroke-width:0.75;\" x=\"294.802301\" xlink:href=\"#m36c057cb21\" y=\"109.500002\"/>\n     <use style=\"fill:#4c72b0;stroke:#ffffff;stroke-width:0.75;\" x=\"318.312807\" xlink:href=\"#m36c057cb21\" y=\"138.53013\"/>\n     <use style=\"fill:#4c72b0;stroke:#ffffff;stroke-width:0.75;\" x=\"341.823313\" xlink:href=\"#m36c057cb21\" y=\"177.926951\"/>\n    </g>\n   </g>\n   <g id=\"line2d_9\">\n    <path clip-path=\"url(#paf76286ffa)\" d=\"M 83.207748 32.458779 \nL 106.718254 33.511844 \nL 130.22876 34.881822 \nL 153.739266 36.732475 \nL 177.249772 39.416593 \nL 200.760278 43.158986 \nL 224.270783 48.375268 \nL 247.781289 56.138996 \nL 271.291795 67.172473 \nL 294.802301 82.668238 \nL 318.312807 104.822905 \nL 341.823313 136.175289 \n\" style=\"fill:none;stroke:#dd8452;stroke-linecap:round;stroke-width:1.5;\"/>\n    <defs>\n     <path d=\"M 0 3 \nC 0.795609 3 1.55874 2.683901 2.12132 2.12132 \nC 2.683901 1.55874 3 0.795609 3 0 \nC 3 -0.795609 2.683901 -1.55874 2.12132 -2.12132 \nC 1.55874 -2.683901 0.795609 -3 0 -3 \nC -0.795609 -3 -1.55874 -2.683901 -2.12132 -2.12132 \nC -2.683901 -1.55874 -3 -0.795609 -3 0 \nC -3 0.795609 -2.683901 1.55874 -2.12132 2.12132 \nC -1.55874 2.683901 -0.795609 3 0 3 \nz\n\" id=\"mfb9088fc74\" style=\"stroke:#ffffff;stroke-width:0.75;\"/>\n    </defs>\n    <g clip-path=\"url(#paf76286ffa)\">\n     <use style=\"fill:#dd8452;stroke:#ffffff;stroke-width:0.75;\" x=\"83.207748\" xlink:href=\"#mfb9088fc74\" y=\"32.458779\"/>\n     <use style=\"fill:#dd8452;stroke:#ffffff;stroke-width:0.75;\" x=\"106.718254\" xlink:href=\"#mfb9088fc74\" y=\"33.511844\"/>\n     <use style=\"fill:#dd8452;stroke:#ffffff;stroke-width:0.75;\" x=\"130.22876\" xlink:href=\"#mfb9088fc74\" y=\"34.881822\"/>\n     <use style=\"fill:#dd8452;stroke:#ffffff;stroke-width:0.75;\" x=\"153.739266\" xlink:href=\"#mfb9088fc74\" y=\"36.732475\"/>\n     <use style=\"fill:#dd8452;stroke:#ffffff;stroke-width:0.75;\" x=\"177.249772\" xlink:href=\"#mfb9088fc74\" y=\"39.416593\"/>\n     <use style=\"fill:#dd8452;stroke:#ffffff;stroke-width:0.75;\" x=\"200.760278\" xlink:href=\"#mfb9088fc74\" y=\"43.158986\"/>\n     <use style=\"fill:#dd8452;stroke:#ffffff;stroke-width:0.75;\" x=\"224.270783\" xlink:href=\"#mfb9088fc74\" y=\"48.375268\"/>\n     <use style=\"fill:#dd8452;stroke:#ffffff;stroke-width:0.75;\" x=\"247.781289\" xlink:href=\"#mfb9088fc74\" y=\"56.138996\"/>\n     <use style=\"fill:#dd8452;stroke:#ffffff;stroke-width:0.75;\" x=\"271.291795\" xlink:href=\"#mfb9088fc74\" y=\"67.172473\"/>\n     <use style=\"fill:#dd8452;stroke:#ffffff;stroke-width:0.75;\" x=\"294.802301\" xlink:href=\"#mfb9088fc74\" y=\"82.668238\"/>\n     <use style=\"fill:#dd8452;stroke:#ffffff;stroke-width:0.75;\" x=\"318.312807\" xlink:href=\"#mfb9088fc74\" y=\"104.822905\"/>\n     <use style=\"fill:#dd8452;stroke:#ffffff;stroke-width:0.75;\" x=\"341.823313\" xlink:href=\"#mfb9088fc74\" y=\"136.175289\"/>\n    </g>\n   </g>\n   <g id=\"line2d_10\">\n    <path clip-path=\"url(#paf76286ffa)\" d=\"M 83.207748 42.888305 \nL 106.718254 45.115079 \nL 130.22876 48.072681 \nL 153.739266 51.690146 \nL 177.249772 57.15206 \nL 200.760278 64.519257 \nL 224.270783 75.659223 \nL 247.781289 89.700691 \nL 271.291795 109.612411 \nL 294.802301 134.389877 \nL 318.312807 164.031201 \nL 341.823313 202.449318 \n\" style=\"fill:none;stroke:#55a868;stroke-linecap:round;stroke-width:1.5;\"/>\n    <defs>\n     <path d=\"M 0 3 \nC 0.795609 3 1.55874 2.683901 2.12132 2.12132 \nC 2.683901 1.55874 3 0.795609 3 0 \nC 3 -0.795609 2.683901 -1.55874 2.12132 -2.12132 \nC 1.55874 -2.683901 0.795609 -3 0 -3 \nC -0.795609 -3 -1.55874 -2.683901 -2.12132 -2.12132 \nC -2.683901 -1.55874 -3 -0.795609 -3 0 \nC -3 0.795609 -2.683901 1.55874 -2.12132 2.12132 \nC -1.55874 2.683901 -0.795609 3 0 3 \nz\n\" id=\"m2ae3b41cec\" style=\"stroke:#ffffff;stroke-width:0.75;\"/>\n    </defs>\n    <g clip-path=\"url(#paf76286ffa)\">\n     <use style=\"fill:#55a868;stroke:#ffffff;stroke-width:0.75;\" x=\"83.207748\" xlink:href=\"#m2ae3b41cec\" y=\"42.888305\"/>\n     <use style=\"fill:#55a868;stroke:#ffffff;stroke-width:0.75;\" x=\"106.718254\" xlink:href=\"#m2ae3b41cec\" y=\"45.115079\"/>\n     <use style=\"fill:#55a868;stroke:#ffffff;stroke-width:0.75;\" x=\"130.22876\" xlink:href=\"#m2ae3b41cec\" y=\"48.072681\"/>\n     <use style=\"fill:#55a868;stroke:#ffffff;stroke-width:0.75;\" x=\"153.739266\" xlink:href=\"#m2ae3b41cec\" y=\"51.690146\"/>\n     <use style=\"fill:#55a868;stroke:#ffffff;stroke-width:0.75;\" x=\"177.249772\" xlink:href=\"#m2ae3b41cec\" y=\"57.15206\"/>\n     <use style=\"fill:#55a868;stroke:#ffffff;stroke-width:0.75;\" x=\"200.760278\" xlink:href=\"#m2ae3b41cec\" y=\"64.519257\"/>\n     <use style=\"fill:#55a868;stroke:#ffffff;stroke-width:0.75;\" x=\"224.270783\" xlink:href=\"#m2ae3b41cec\" y=\"75.659223\"/>\n     <use style=\"fill:#55a868;stroke:#ffffff;stroke-width:0.75;\" x=\"247.781289\" xlink:href=\"#m2ae3b41cec\" y=\"89.700691\"/>\n     <use style=\"fill:#55a868;stroke:#ffffff;stroke-width:0.75;\" x=\"271.291795\" xlink:href=\"#m2ae3b41cec\" y=\"109.612411\"/>\n     <use style=\"fill:#55a868;stroke:#ffffff;stroke-width:0.75;\" x=\"294.802301\" xlink:href=\"#m2ae3b41cec\" y=\"134.389877\"/>\n     <use style=\"fill:#55a868;stroke:#ffffff;stroke-width:0.75;\" x=\"318.312807\" xlink:href=\"#m2ae3b41cec\" y=\"164.031201\"/>\n     <use style=\"fill:#55a868;stroke:#ffffff;stroke-width:0.75;\" x=\"341.823313\" xlink:href=\"#m2ae3b41cec\" y=\"202.449318\"/>\n    </g>\n   </g>\n   <g id=\"line2d_11\"/>\n   <g id=\"line2d_12\"/>\n   <g id=\"line2d_13\"/>\n   <g id=\"patch_3\">\n    <path d=\"M 70.276969 235.411983 \nL 70.276969 21.50218 \n\" style=\"fill:none;stroke:#cccccc;stroke-linecap:square;stroke-linejoin:miter;stroke-width:1.25;\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 70.276969 235.411983 \nL 354.754092 235.411983 \n\" style=\"fill:none;stroke:#cccccc;stroke-linecap:square;stroke-linejoin:miter;stroke-width:1.25;\"/>\n   </g>\n   <g id=\"text_12\">\n    <!-- Attack on naive models -->\n    <g style=\"fill:#262626;\" transform=\"translate(155.156317 15.50218)scale(0.12 -0.12)\">\n     <defs>\n      <path d=\"M 44.203125 21.1875 \nC 44.203125 34 34.703125 44 23.5 44 \nC 12 44 2.703125 33.703125 2.703125 21.1875 \nC 2.703125 8.5 12.296875 -1 23.40625 -1 \nC 34.796875 -1 44.203125 8.796875 44.203125 21.1875 \nz\nM 23.5 5.265625 \nC 16.40625 5.265625 10.296875 11.078125 10.296875 22 \nC 10.296875 33.609375 17.40625 37.921875 23.40625 37.921875 \nC 29.90625 37.921875 36.59375 33.21875 36.59375 22 \nC 36.59375 10.671875 30.09375 5.265625 23.5 5.265625 \nz\n\" id=\"CMSS17-111\"/>\n      <path d=\"M 15.296875 65.359375 \nL 6.90625 65.359375 \nL 6.90625 57 \nL 15.296875 57 \nz\nM 14.796875 42.796875 \nL 7.40625 42.796875 \nL 7.40625 0 \nL 14.796875 0 \nz\n\" id=\"CMSS17-105\"/>\n      <path d=\"M 41.796875 43 \nL 34 43 \nL 27.296875 24.3125 \nC 25.203125 18.203125 22.203125 9.796875 21.703125 5.5 \nL 21.59375 5.5 \nC 21.40625 7.3125 20.59375 9.90625 20.09375 11.703125 \nC 19.5 13.90625 18.703125 16.5 18.09375 18.3125 \nL 9.296875 43 \nL 1.296875 43 \nL 17.09375 0 \nL 26 0 \nz\n\" id=\"CMSS17-118\"/>\n      <path d=\"M 67 29.328125 \nC 67 36.0625 65.296875 44 54.09375 44 \nC 46.59375 44 42.09375 39.3125 40.09375 36.421875 \nC 38.296875 41.71875 34.09375 44 28.09375 44 \nC 21.296875 44 17 40.125 14.703125 37.328125 \nL 14.703125 43.09375 \nL 7.40625 43.09375 \nL 7.40625 0 \nL 15 0 \nL 15 24.359375 \nC 15 30.296875 17.203125 37.9375 24.296875 37.9375 \nC 33.40625 37.9375 33.40625 31.5 33.40625 28.578125 \nL 33.40625 0 \nL 41 0 \nL 41 24.359375 \nC 41 30.296875 43.203125 37.9375 50.296875 37.9375 \nC 59.40625 37.9375 59.40625 31.5 59.40625 28.578125 \nL 59.40625 0 \nL 67 0 \nz\n\" id=\"CMSS17-109\"/>\n      <path d=\"M 40.796875 69 \nL 33.40625 69 \nL 33.40625 38.09375 \nC 30.296875 40.671875 25.203125 43.0625 19.59375 43.0625 \nC 10.5 43.0625 3.296875 33.296875 3.296875 21.046875 \nC 3.296875 8.78125 10.40625 -1 19.296875 -1 \nC 26.203125 -1 30.796875 2.6875 33.203125 4.78125 \nL 33.203125 -0.203125 \nL 40.796875 -0.203125 \nz\nM 33.203125 13.0625 \nC 33.203125 11.671875 33.203125 10.203125 30.09375 7.53125 \nC 28.09375 5.859375 25.703125 5.078125 23.40625 5.078125 \nC 18 5.078125 10.90625 9 10.90625 20.9375 \nC 10.90625 33.34375 18.90625 37 24.40625 37 \nC 28.09375 37 31.09375 35.21875 33.203125 32.265625 \nz\n\" id=\"CMSS17-100\"/>\n      <path d=\"M 14.796875 69 \nL 7.40625 69 \nL 7.40625 0 \nL 14.796875 0 \nz\n\" id=\"CMSS17-108\"/>\n     </defs>\n     <use transform=\"scale(0.996264)\" xlink:href=\"#CMSS17-65\"/>\n     <use transform=\"translate(59.615401 0)scale(0.996264)\" xlink:href=\"#CMSS17-116\"/>\n     <use transform=\"translate(93.446968 0)scale(0.996264)\" xlink:href=\"#CMSS17-116\"/>\n     <use transform=\"translate(127.278534 0)scale(0.996264)\" xlink:href=\"#CMSS17-97\"/>\n     <use transform=\"translate(172.200455 0)scale(0.996264)\" xlink:href=\"#CMSS17-99\"/>\n     <use transform=\"translate(213.839277 0)scale(0.996264)\" xlink:href=\"#CMSS17-107\"/>\n     <use transform=\"translate(290.670879 0)scale(0.996264)\" xlink:href=\"#CMSS17-111\"/>\n     <use transform=\"translate(337.514503 0)scale(0.996264)\" xlink:href=\"#CMSS17-110\"/>\n     <use transform=\"translate(416.948558 0)scale(0.996264)\" xlink:href=\"#CMSS17-110\"/>\n     <use transform=\"translate(465.153502 0)scale(0.996264)\" xlink:href=\"#CMSS17-97\"/>\n     <use transform=\"translate(510.075422 0)scale(0.996264)\" xlink:href=\"#CMSS17-105\"/>\n     <use transform=\"translate(532.256145 0)scale(0.996264)\" xlink:href=\"#CMSS17-118\"/>\n     <use transform=\"translate(575.256287 0)scale(0.996264)\" xlink:href=\"#CMSS17-101\"/>\n     <use transform=\"translate(648.124222 0)scale(0.996264)\" xlink:href=\"#CMSS17-109\"/>\n     <use transform=\"translate(722.353476 0)scale(0.996264)\" xlink:href=\"#CMSS17-111\"/>\n     <use transform=\"translate(771.799538 0)scale(0.996264)\" xlink:href=\"#CMSS17-100\"/>\n     <use transform=\"translate(820.004481 0)scale(0.996264)\" xlink:href=\"#CMSS17-101\"/>\n     <use transform=\"translate(861.643304 0)scale(0.996264)\" xlink:href=\"#CMSS17-108\"/>\n     <use transform=\"translate(883.824027 0)scale(0.996264)\" xlink:href=\"#CMSS17-115\"/>\n    </g>\n   </g>\n   <g id=\"legend_1\">\n    <g id=\"patch_5\">\n     <path d=\"M 77.976969 229.911983 \nL 205.734222 229.911983 \nQ 207.934222 229.911983 207.934222 227.711983 \nL 207.934222 163.417182 \nQ 207.934222 161.217182 205.734222 161.217182 \nL 77.976969 161.217182 \nQ 75.776969 161.217182 75.776969 163.417182 \nL 75.776969 227.711983 \nQ 75.776969 229.911983 77.976969 229.911983 \nz\n\" style=\"fill:#ffffff;opacity:0.8;stroke:#cccccc;stroke-linejoin:miter;\"/>\n    </g>\n    <g id=\"text_13\">\n     <!-- optimizer -->\n     <g style=\"fill:#262626;\" transform=\"translate(119.30157 174.735307)scale(0.12 -0.12)\">\n      <defs>\n       <path d=\"M 15.09375 5.203125 \nC 18.40625 2.015625 22.90625 -0.078125 27.703125 -0.078125 \nC 37 -0.078125 45 9.421875 45 22.0625 \nC 45 33.734375 39 44 30.40625 44 \nC 25.40625 44 19.40625 42.21875 14.90625 38.625 \nL 14.90625 43.203125 \nL 7.5 43.203125 \nL 7.5 -19 \nL 15.09375 -19 \nz\nM 15.09375 32.8125 \nC 15.90625 34 19.296875 37.734375 24.796875 37.734375 \nC 31.796875 37.734375 37.40625 30.625 37.40625 22.0625 \nC 37.40625 12.296875 30.59375 6 23.90625 6 \nC 21.90625 6 19.796875 6.484375 17.796875 8.171875 \nC 15.09375 10.53125 15.09375 12 15.09375 13.390625 \nz\n\" id=\"CMSS17-112\"/>\n       <path d=\"M 37.5 39.09375 \nL 37.5 42.96875 \nL 3.90625 42.96875 \nL 3.90625 37 \nL 16.703125 37 \nC 17.90625 37 19.09375 37 20.296875 37 \nL 27.296875 37 \nL 2.59375 4.078125 \nL 2.59375 0 \nL 37.796875 0 \nL 37.796875 6.171875 \nL 24.203125 6.171875 \nC 23 6.171875 21.796875 6.171875 20.59375 6.171875 \nL 12.90625 6.171875 \nz\n\" id=\"CMSS17-122\"/>\n      </defs>\n      <use transform=\"scale(0.996264)\" xlink:href=\"#CMSS17-111\"/>\n      <use transform=\"translate(46.843624 0)scale(0.996264)\" xlink:href=\"#CMSS17-112\"/>\n      <use transform=\"translate(95.048567 0)scale(0.996264)\" xlink:href=\"#CMSS17-116\"/>\n      <use transform=\"translate(128.880133 0)scale(0.996264)\" xlink:href=\"#CMSS17-105\"/>\n      <use transform=\"translate(151.060856 0)scale(0.996264)\" xlink:href=\"#CMSS17-109\"/>\n      <use transform=\"translate(225.290111 0)scale(0.996264)\" xlink:href=\"#CMSS17-105\"/>\n      <use transform=\"translate(247.470834 0)scale(0.996264)\" xlink:href=\"#CMSS17-122\"/>\n      <use transform=\"translate(288.148706 0)scale(0.996264)\" xlink:href=\"#CMSS17-101\"/>\n      <use transform=\"translate(329.787528 0)scale(0.996264)\" xlink:href=\"#CMSS17-114\"/>\n     </g>\n    </g>\n    <g id=\"line2d_14\">\n     <path d=\"M 80.176969 187.239213 \nL 102.176969 187.239213 \n\" style=\"fill:none;stroke:#4c72b0;stroke-linecap:round;stroke-width:1.5;\"/>\n    </g>\n    <g id=\"line2d_15\"/>\n    <g id=\"text_14\">\n     <!-- AdamOptimizer -->\n     <g style=\"fill:#262626;\" transform=\"translate(110.976969 191.089213)scale(0.11 -0.11)\">\n      <defs>\n       <path d=\"M 64 34.03125 \nC 64 54.734375 50.296875 70.265625 34.59375 70.265625 \nC 18.90625 70.265625 5.203125 54.640625 5.203125 34.03125 \nC 5.203125 13.234375 19.09375 -2 34.59375 -2 \nC 50.09375 -2 64 13.234375 64 34.03125 \nz\nM 34.59375 4.265625 \nC 23.59375 4.265625 13.59375 16.515625 13.59375 35.328125 \nC 13.59375 53.640625 24.203125 64 34.59375 64 \nC 45 64 55.59375 53.640625 55.59375 35.328125 \nC 55.59375 16.421875 45.5 4.265625 34.59375 4.265625 \nz\n\" id=\"CMSS17-79\"/>\n      </defs>\n      <use transform=\"scale(0.996264)\" xlink:href=\"#CMSS17-65\"/>\n      <use transform=\"translate(62.217855 0)scale(0.996264)\" xlink:href=\"#CMSS17-100\"/>\n      <use transform=\"translate(110.422798 0)scale(0.996264)\" xlink:href=\"#CMSS17-97\"/>\n      <use transform=\"translate(155.344719 0)scale(0.996264)\" xlink:href=\"#CMSS17-109\"/>\n      <use transform=\"translate(229.573973 0)scale(0.996264)\" xlink:href=\"#CMSS17-79\"/>\n      <use transform=\"translate(298.598228 0)scale(0.996264)\" xlink:href=\"#CMSS17-112\"/>\n      <use transform=\"translate(346.803172 0)scale(0.996264)\" xlink:href=\"#CMSS17-116\"/>\n      <use transform=\"translate(380.634738 0)scale(0.996264)\" xlink:href=\"#CMSS17-105\"/>\n      <use transform=\"translate(402.815461 0)scale(0.996264)\" xlink:href=\"#CMSS17-109\"/>\n      <use transform=\"translate(477.044716 0)scale(0.996264)\" xlink:href=\"#CMSS17-105\"/>\n      <use transform=\"translate(499.225439 0)scale(0.996264)\" xlink:href=\"#CMSS17-122\"/>\n      <use transform=\"translate(539.903311 0)scale(0.996264)\" xlink:href=\"#CMSS17-101\"/>\n      <use transform=\"translate(581.542133 0)scale(0.996264)\" xlink:href=\"#CMSS17-114\"/>\n     </g>\n    </g>\n    <g id=\"line2d_16\">\n     <path d=\"M 80.176969 203.385151 \nL 102.176969 203.385151 \n\" style=\"fill:none;stroke:#dd8452;stroke-linecap:round;stroke-width:1.5;\"/>\n    </g>\n    <g id=\"line2d_17\"/>\n    <g id=\"text_15\">\n     <!-- MiniBatchOptimizer -->\n     <g style=\"fill:#262626;\" transform=\"translate(110.976969 207.235151)scale(0.11 -0.11)\">\n      <defs>\n       <path d=\"M 49.90625 37.046875 \nL 45.09375 23.015625 \nC 44.296875 20.421875 41.59375 12.359375 41 9.171875 \nL 40.90625 9.171875 \nC 40.59375 11.171875 40 13.265625 38.40625 18.34375 \nC 37.5 21.328125 36.5 24.40625 35.5 27.203125 \nL 20.703125 69 \nL 9 69 \nL 9 0 \nL 16.796875 0 \nL 16.796875 60.9375 \nL 16.90625 60.9375 \nC 16.90625 60.84375 17.796875 56.453125 23.90625 39.046875 \nL 37.09375 1.5 \nL 44.5 1.5 \nL 56.40625 34.859375 \nC 57.203125 37.15625 59.703125 44.421875 60.796875 47.90625 \nC 61.796875 50.890625 64.296875 58.25 64.90625 61.140625 \nL 65 61.140625 \nL 65 0 \nL 72.90625 0 \nL 72.90625 69 \nL 61.296875 69 \nz\n\" id=\"CMSS17-77\"/>\n       <path d=\"M 8.90625 69 \nL 8.90625 0 \nL 33.796875 0 \nC 47.40625 0 57.296875 8.96875 57.296875 18.75 \nC 57.296875 26.328125 50.796875 34 39.09375 36.203125 \nC 52.09375 39.96875 54.703125 47.5 54.703125 51.765625 \nC 54.703125 60.671875 44.90625 69 31.203125 69 \nz\nM 17 39 \nL 17 63.421875 \nL 28.5 63.421875 \nC 38.796875 63.421875 46.90625 58.1875 46.90625 51.65625 \nC 46.90625 45.71875 40.5 39 27.59375 39 \nz\nM 17 5.578125 \nL 17 32.921875 \nL 30.296875 32.921875 \nC 41.09375 32.921875 49.40625 26.234375 49.40625 18.84375 \nC 49.40625 12.0625 42.09375 5.578125 31 5.578125 \nz\n\" id=\"CMSS17-66\"/>\n      </defs>\n      <use transform=\"scale(0.996264)\" xlink:href=\"#CMSS17-77\"/>\n      <use transform=\"translate(81.67603 0)scale(0.996264)\" xlink:href=\"#CMSS17-105\"/>\n      <use transform=\"translate(103.856753 0)scale(0.996264)\" xlink:href=\"#CMSS17-110\"/>\n      <use transform=\"translate(152.061696 0)scale(0.996264)\" xlink:href=\"#CMSS17-105\"/>\n      <use transform=\"translate(174.242419 0)scale(0.996264)\" xlink:href=\"#CMSS17-66\"/>\n      <use transform=\"translate(236.580459 0)scale(0.996264)\" xlink:href=\"#CMSS17-97\"/>\n      <use transform=\"translate(281.50238 0)scale(0.996264)\" xlink:href=\"#CMSS17-116\"/>\n      <use transform=\"translate(315.333947 0)scale(0.996264)\" xlink:href=\"#CMSS17-99\"/>\n      <use transform=\"translate(356.972769 0)scale(0.996264)\" xlink:href=\"#CMSS17-104\"/>\n      <use transform=\"translate(405.177712 0)scale(0.996264)\" xlink:href=\"#CMSS17-79\"/>\n      <use transform=\"translate(474.201967 0)scale(0.996264)\" xlink:href=\"#CMSS17-112\"/>\n      <use transform=\"translate(522.40691 0)scale(0.996264)\" xlink:href=\"#CMSS17-116\"/>\n      <use transform=\"translate(556.238477 0)scale(0.996264)\" xlink:href=\"#CMSS17-105\"/>\n      <use transform=\"translate(578.4192 0)scale(0.996264)\" xlink:href=\"#CMSS17-109\"/>\n      <use transform=\"translate(652.648455 0)scale(0.996264)\" xlink:href=\"#CMSS17-105\"/>\n      <use transform=\"translate(674.829178 0)scale(0.996264)\" xlink:href=\"#CMSS17-122\"/>\n      <use transform=\"translate(715.507049 0)scale(0.996264)\" xlink:href=\"#CMSS17-101\"/>\n      <use transform=\"translate(757.145871 0)scale(0.996264)\" xlink:href=\"#CMSS17-114\"/>\n     </g>\n    </g>\n    <g id=\"line2d_18\">\n     <path d=\"M 80.176969 219.531088 \nL 102.176969 219.531088 \n\" style=\"fill:none;stroke:#55a868;stroke-linecap:round;stroke-width:1.5;\"/>\n    </g>\n    <g id=\"line2d_19\"/>\n    <g id=\"text_16\">\n     <!-- NesterovOptimizer -->\n     <g style=\"fill:#262626;\" transform=\"translate(110.976969 223.381088)scale(0.11 -0.11)\">\n      <defs>\n       <path d=\"M 22.90625 65.3125 \nL 21.09375 69 \nL 8.796875 69 \nL 8.796875 0 \nL 16.59375 0 \nL 16.59375 61.34375 \nL 16.703125 61.4375 \nC 17.40625 59.640625 17.796875 58.75 21.90625 49.90625 \nL 43.296875 3.6875 \nL 45.09375 0 \nL 57.40625 0 \nL 57.40625 69 \nL 49.59375 69 \nL 49.59375 7.65625 \nL 49.5 7.546875 \nC 48.796875 9.34375 48.40625 10.234375 44.296875 19.078125 \nz\n\" id=\"CMSS17-78\"/>\n      </defs>\n      <use transform=\"scale(0.996264)\" xlink:href=\"#CMSS17-78\"/>\n      <use transform=\"translate(66.061519 0)scale(0.996264)\" xlink:href=\"#CMSS17-101\"/>\n      <use transform=\"translate(107.700341 0)scale(0.996264)\" xlink:href=\"#CMSS17-115\"/>\n      <use transform=\"translate(143.613883 0)scale(0.996264)\" xlink:href=\"#CMSS17-116\"/>\n      <use transform=\"translate(177.44545 0)scale(0.996264)\" xlink:href=\"#CMSS17-101\"/>\n      <use transform=\"translate(219.084272 0)scale(0.996264)\" xlink:href=\"#CMSS17-114\"/>\n      <use transform=\"translate(250.994045 0)scale(0.996264)\" xlink:href=\"#CMSS17-111\"/>\n      <use transform=\"translate(297.837668 0)scale(0.996264)\" xlink:href=\"#CMSS17-118\"/>\n      <use transform=\"translate(340.83781 0)scale(0.996264)\" xlink:href=\"#CMSS17-79\"/>\n      <use transform=\"translate(409.862065 0)scale(0.996264)\" xlink:href=\"#CMSS17-112\"/>\n      <use transform=\"translate(458.067008 0)scale(0.996264)\" xlink:href=\"#CMSS17-116\"/>\n      <use transform=\"translate(491.898575 0)scale(0.996264)\" xlink:href=\"#CMSS17-105\"/>\n      <use transform=\"translate(514.079298 0)scale(0.996264)\" xlink:href=\"#CMSS17-109\"/>\n      <use transform=\"translate(588.308552 0)scale(0.996264)\" xlink:href=\"#CMSS17-105\"/>\n      <use transform=\"translate(610.489275 0)scale(0.996264)\" xlink:href=\"#CMSS17-122\"/>\n      <use transform=\"translate(651.167147 0)scale(0.996264)\" xlink:href=\"#CMSS17-101\"/>\n      <use transform=\"translate(692.805969 0)scale(0.996264)\" xlink:href=\"#CMSS17-114\"/>\n     </g>\n    </g>\n   </g>\n  </g>\n  <g id=\"axes_2\">\n   <g id=\"patch_6\">\n    <path d=\"M 416.802878 235.411983 \nL 701.28 235.411983 \nL 701.28 21.50218 \nL 416.802878 21.50218 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g id=\"matplotlib.axis_3\">\n    <g id=\"xtick_7\">\n     <g id=\"text_17\">\n      <!-- $\\mathdefault{0.0}$ -->\n      <g style=\"fill:#262626;\" transform=\"translate(422.732118 252.52233)scale(0.11 -0.11)\">\n       <use transform=\"scale(0.996264)\" xlink:href=\"#CMR17-48\"/>\n       <use transform=\"translate(45.690477 0)scale(0.996264)\" xlink:href=\"#CMMI12-58\"/>\n       <use transform=\"translate(72.787654 0)scale(0.996264)\" xlink:href=\"#CMR17-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_8\">\n     <g id=\"text_18\">\n      <!-- $\\mathdefault{0.1}$ -->\n      <g style=\"fill:#262626;\" transform=\"translate(469.75313 252.52233)scale(0.11 -0.11)\">\n       <use transform=\"scale(0.996264)\" xlink:href=\"#CMR17-48\"/>\n       <use transform=\"translate(45.690477 0)scale(0.996264)\" xlink:href=\"#CMMI12-58\"/>\n       <use transform=\"translate(72.787654 0)scale(0.996264)\" xlink:href=\"#CMR17-49\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_9\">\n     <g id=\"text_19\">\n      <!-- $\\mathdefault{0.2}$ -->\n      <g style=\"fill:#262626;\" transform=\"translate(516.774142 252.52233)scale(0.11 -0.11)\">\n       <use transform=\"scale(0.996264)\" xlink:href=\"#CMR17-48\"/>\n       <use transform=\"translate(45.690477 0)scale(0.996264)\" xlink:href=\"#CMMI12-58\"/>\n       <use transform=\"translate(72.787654 0)scale(0.996264)\" xlink:href=\"#CMR17-50\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_10\">\n     <g id=\"text_20\">\n      <!-- $\\mathdefault{0.3}$ -->\n      <g style=\"fill:#262626;\" transform=\"translate(563.795154 252.52233)scale(0.11 -0.11)\">\n       <use transform=\"scale(0.996264)\" xlink:href=\"#CMR17-48\"/>\n       <use transform=\"translate(45.690477 0)scale(0.996264)\" xlink:href=\"#CMMI12-58\"/>\n       <use transform=\"translate(72.787654 0)scale(0.996264)\" xlink:href=\"#CMR17-51\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_11\">\n     <g id=\"text_21\">\n      <!-- $\\mathdefault{0.4}$ -->\n      <g style=\"fill:#262626;\" transform=\"translate(610.816166 252.52233)scale(0.11 -0.11)\">\n       <use transform=\"scale(0.996264)\" xlink:href=\"#CMR17-48\"/>\n       <use transform=\"translate(45.690477 0)scale(0.996264)\" xlink:href=\"#CMMI12-58\"/>\n       <use transform=\"translate(72.787654 0)scale(0.996264)\" xlink:href=\"#CMR17-52\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_12\">\n     <g id=\"text_22\">\n      <!-- $\\mathdefault{0.5}$ -->\n      <g style=\"fill:#262626;\" transform=\"translate(657.837178 252.52233)scale(0.11 -0.11)\">\n       <use transform=\"scale(0.996264)\" xlink:href=\"#CMR17-48\"/>\n       <use transform=\"translate(45.690477 0)scale(0.996264)\" xlink:href=\"#CMMI12-58\"/>\n       <use transform=\"translate(72.787654 0)scale(0.996264)\" xlink:href=\"#CMR17-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_23\">\n     <!-- Attack strength $\\epsilon$ -->\n     <g style=\"fill:#262626;\" transform=\"translate(516.607989 266.955404)scale(0.12 -0.12)\">\n      <use transform=\"scale(0.996264)\" xlink:href=\"#CMSS17-65\"/>\n      <use transform=\"translate(59.615401 0)scale(0.996264)\" xlink:href=\"#CMSS17-116\"/>\n      <use transform=\"translate(93.446968 0)scale(0.996264)\" xlink:href=\"#CMSS17-116\"/>\n      <use transform=\"translate(127.278534 0)scale(0.996264)\" xlink:href=\"#CMSS17-97\"/>\n      <use transform=\"translate(172.200455 0)scale(0.996264)\" xlink:href=\"#CMSS17-99\"/>\n      <use transform=\"translate(213.839277 0)scale(0.996264)\" xlink:href=\"#CMSS17-107\"/>\n      <use transform=\"translate(290.670879 0)scale(0.996264)\" xlink:href=\"#CMSS17-115\"/>\n      <use transform=\"translate(326.584421 0)scale(0.996264)\" xlink:href=\"#CMSS17-116\"/>\n      <use transform=\"translate(360.415988 0)scale(0.996264)\" xlink:href=\"#CMSS17-114\"/>\n      <use transform=\"translate(392.32576 0)scale(0.996264)\" xlink:href=\"#CMSS17-101\"/>\n      <use transform=\"translate(433.964582 0)scale(0.996264)\" xlink:href=\"#CMSS17-110\"/>\n      <use transform=\"translate(482.169525 0)scale(0.996264)\" xlink:href=\"#CMSS17-103\"/>\n      <use transform=\"translate(529.013149 0)scale(0.996264)\" xlink:href=\"#CMSS17-116\"/>\n      <use transform=\"translate(562.844716 0)scale(0.996264)\" xlink:href=\"#CMSS17-104\"/>\n      <use transform=\"translate(642.278772 0)scale(0.996264)\" xlink:href=\"#CMMI12-15\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_4\">\n    <g id=\"ytick_8\">\n     <g id=\"text_24\">\n      <!-- $\\mathdefault{0.825}$ -->\n      <g style=\"fill:#262626;\" transform=\"translate(382.340867 215.637365)scale(0.11 -0.11)\">\n       <defs>\n        <path d=\"M 27.203125 35.375 \nC 33.5 38.546875 39.90625 43.328125 39.90625 50.984375 \nC 39.90625 60.015625 31.09375 65.296875 23 65.296875 \nC 13.90625 65.296875 5.90625 58.734375 5.90625 49.6875 \nC 5.90625 47.203125 6.5 42.921875 10.40625 39.140625 \nC 11.40625 38.15625 15.59375 35.171875 18.296875 33.28125 \nC 13.796875 30.984375 3.296875 25.53125 3.296875 14.59375 \nC 3.296875 4.359375 13.09375 -2 22.796875 -2 \nC 33.5 -2 42.5 5.65625 42.5 15.78125 \nC 42.5 24.84375 36.40625 29.015625 32.40625 31.703125 \nz\nM 14.09375 44.09375 \nC 13.296875 44.59375 9.296875 47.671875 9.296875 52.359375 \nC 9.296875 58.421875 15.59375 63 22.796875 63 \nC 30.703125 63 36.5 57.4375 36.5 50.96875 \nC 36.5 41.703125 26.09375 36.421875 25.59375 36.421875 \nC 25.5 36.421875 25.40625 36.421875 24.59375 37.03125 \nz\nM 32.5 23.734375 \nC 34 22.640625 38.796875 19.375 38.796875 13.296875 \nC 38.796875 5.953125 31.40625 0.390625 23 0.390625 \nC 13.90625 0.390625 7 6.84375 7 14.6875 \nC 7 22.546875 13.09375 29.09375 20 32.1875 \nz\n\" id=\"CMR17-56\"/>\n       </defs>\n       <use transform=\"scale(0.996264)\" xlink:href=\"#CMR17-48\"/>\n       <use transform=\"translate(45.690477 0)scale(0.996264)\" xlink:href=\"#CMMI12-58\"/>\n       <use transform=\"translate(72.787654 0)scale(0.996264)\" xlink:href=\"#CMR17-56\"/>\n       <use transform=\"translate(118.478131 0)scale(0.996264)\" xlink:href=\"#CMR17-50\"/>\n       <use transform=\"translate(164.168608 0)scale(0.996264)\" xlink:href=\"#CMR17-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_9\">\n     <g id=\"text_25\">\n      <!-- $\\mathdefault{0.850}$ -->\n      <g style=\"fill:#262626;\" transform=\"translate(382.340867 188.61044)scale(0.11 -0.11)\">\n       <use transform=\"scale(0.996264)\" xlink:href=\"#CMR17-48\"/>\n       <use transform=\"translate(45.690477 0)scale(0.996264)\" xlink:href=\"#CMMI12-58\"/>\n       <use transform=\"translate(72.787654 0)scale(0.996264)\" xlink:href=\"#CMR17-56\"/>\n       <use transform=\"translate(118.478131 0)scale(0.996264)\" xlink:href=\"#CMR17-53\"/>\n       <use transform=\"translate(164.168608 0)scale(0.996264)\" xlink:href=\"#CMR17-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_10\">\n     <g id=\"text_26\">\n      <!-- $\\mathdefault{0.875}$ -->\n      <g style=\"fill:#262626;\" transform=\"translate(382.340867 161.583515)scale(0.11 -0.11)\">\n       <defs>\n        <path d=\"M 45.09375 61.578125 \nL 45.09375 63.765625 \nL 21.59375 63.765625 \nC 9.90625 63.765625 9.703125 65.078125 9.296875 67 \nL 7.5 67 \nL 4.59375 48.34375 \nL 6.40625 48.34375 \nC 6.703125 50.234375 7.40625 55.3125 8.59375 57.203125 \nC 9.203125 58 16.59375 58 18.296875 58 \nL 40.296875 58 \nL 29.203125 41.578125 \nC 21.796875 30.53125 16.703125 15.609375 16.703125 2.578125 \nC 16.703125 1.390625 16.703125 -2 20.296875 -2 \nC 23.90625 -2 23.90625 1.390625 23.90625 2.671875 \nL 23.90625 7.265625 \nC 23.90625 23.5625 26.703125 34.3125 31.296875 41.1875 \nz\n\" id=\"CMR17-55\"/>\n       </defs>\n       <use transform=\"scale(0.996264)\" xlink:href=\"#CMR17-48\"/>\n       <use transform=\"translate(45.690477 0)scale(0.996264)\" xlink:href=\"#CMMI12-58\"/>\n       <use transform=\"translate(72.787654 0)scale(0.996264)\" xlink:href=\"#CMR17-56\"/>\n       <use transform=\"translate(118.478131 0)scale(0.996264)\" xlink:href=\"#CMR17-55\"/>\n       <use transform=\"translate(164.168608 0)scale(0.996264)\" xlink:href=\"#CMR17-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_11\">\n     <g id=\"text_27\">\n      <!-- $\\mathdefault{0.900}$ -->\n      <g style=\"fill:#262626;\" transform=\"translate(382.340867 134.55659)scale(0.11 -0.11)\">\n       <defs>\n        <path d=\"M 35.203125 29.125 \nC 35.203125 7.25 26.09375 0.484375 18.59375 0.484375 \nC 16.296875 0.484375 10.703125 0.484375 8.40625 4.59375 \nC 11 4.1875 12.90625 5.578125 12.90625 8.09375 \nC 12.90625 10.8125 10.703125 11.703125 9.296875 11.703125 \nC 8.40625 11.703125 5.703125 11.296875 5.703125 7.90625 \nC 5.703125 1.109375 11.59375 -2 18.796875 -2 \nC 30.296875 -2 42 10.53125 42 32.390625 \nC 42 59.640625 30.796875 65.296875 23.203125 65.296875 \nC 13.296875 65.296875 3.796875 56.6875 3.796875 43.40625 \nC 3.796875 31.109375 11.90625 22 22.09375 22 \nC 30.5 22 34.203125 29.734375 35.203125 33 \nz\nM 22.296875 23.59375 \nC 19.59375 23.59375 15.796875 24.09375 12.703125 30.03125 \nC 10.59375 33.890625 10.59375 38.453125 10.59375 43.296875 \nC 10.59375 49.15625 10.59375 53.203125 13.40625 57.5625 \nC 14.796875 59.640625 17.40625 63 23.203125 63 \nC 35 63 35 45.078125 35 41.125 \nC 35 34.09375 31.796875 23.59375 22.296875 23.59375 \nz\n\" id=\"CMR17-57\"/>\n       </defs>\n       <use transform=\"scale(0.996264)\" xlink:href=\"#CMR17-48\"/>\n       <use transform=\"translate(45.690477 0)scale(0.996264)\" xlink:href=\"#CMMI12-58\"/>\n       <use transform=\"translate(72.787654 0)scale(0.996264)\" xlink:href=\"#CMR17-57\"/>\n       <use transform=\"translate(118.478131 0)scale(0.996264)\" xlink:href=\"#CMR17-48\"/>\n       <use transform=\"translate(164.168608 0)scale(0.996264)\" xlink:href=\"#CMR17-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_12\">\n     <g id=\"text_28\">\n      <!-- $\\mathdefault{0.925}$ -->\n      <g style=\"fill:#262626;\" transform=\"translate(382.340867 107.529665)scale(0.11 -0.11)\">\n       <use transform=\"scale(0.996264)\" xlink:href=\"#CMR17-48\"/>\n       <use transform=\"translate(45.690477 0)scale(0.996264)\" xlink:href=\"#CMMI12-58\"/>\n       <use transform=\"translate(72.787654 0)scale(0.996264)\" xlink:href=\"#CMR17-57\"/>\n       <use transform=\"translate(118.478131 0)scale(0.996264)\" xlink:href=\"#CMR17-50\"/>\n       <use transform=\"translate(164.168608 0)scale(0.996264)\" xlink:href=\"#CMR17-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_13\">\n     <g id=\"text_29\">\n      <!-- $\\mathdefault{0.950}$ -->\n      <g style=\"fill:#262626;\" transform=\"translate(382.340867 80.50274)scale(0.11 -0.11)\">\n       <use transform=\"scale(0.996264)\" xlink:href=\"#CMR17-48\"/>\n       <use transform=\"translate(45.690477 0)scale(0.996264)\" xlink:href=\"#CMMI12-58\"/>\n       <use transform=\"translate(72.787654 0)scale(0.996264)\" xlink:href=\"#CMR17-57\"/>\n       <use transform=\"translate(118.478131 0)scale(0.996264)\" xlink:href=\"#CMR17-53\"/>\n       <use transform=\"translate(164.168608 0)scale(0.996264)\" xlink:href=\"#CMR17-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_14\">\n     <g id=\"text_30\">\n      <!-- $\\mathdefault{0.975}$ -->\n      <g style=\"fill:#262626;\" transform=\"translate(382.340867 53.475815)scale(0.11 -0.11)\">\n       <use transform=\"scale(0.996264)\" xlink:href=\"#CMR17-48\"/>\n       <use transform=\"translate(45.690477 0)scale(0.996264)\" xlink:href=\"#CMMI12-58\"/>\n       <use transform=\"translate(72.787654 0)scale(0.996264)\" xlink:href=\"#CMR17-57\"/>\n       <use transform=\"translate(118.478131 0)scale(0.996264)\" xlink:href=\"#CMR17-55\"/>\n       <use transform=\"translate(164.168608 0)scale(0.996264)\" xlink:href=\"#CMR17-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_15\">\n     <g id=\"text_31\">\n      <!-- $\\mathdefault{1.000}$ -->\n      <g style=\"fill:#262626;\" transform=\"translate(382.340867 26.44889)scale(0.11 -0.11)\">\n       <use transform=\"scale(0.996264)\" xlink:href=\"#CMR17-49\"/>\n       <use transform=\"translate(45.690477 0)scale(0.996264)\" xlink:href=\"#CMMI12-58\"/>\n       <use transform=\"translate(72.787654 0)scale(0.996264)\" xlink:href=\"#CMR17-48\"/>\n       <use transform=\"translate(118.478131 0)scale(0.996264)\" xlink:href=\"#CMR17-48\"/>\n       <use transform=\"translate(164.168608 0)scale(0.996264)\" xlink:href=\"#CMR17-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_32\">\n     <!-- Accuracy -->\n     <g style=\"fill:#262626;\" transform=\"translate(376.016271 150.599481)rotate(-90)scale(0.12 -0.12)\">\n      <use transform=\"scale(0.996264)\" xlink:href=\"#CMSS17-65\"/>\n      <use transform=\"translate(62.217855 0)scale(0.996264)\" xlink:href=\"#CMSS17-99\"/>\n      <use transform=\"translate(103.856677 0)scale(0.996264)\" xlink:href=\"#CMSS17-99\"/>\n      <use transform=\"translate(145.495499 0)scale(0.996264)\" xlink:href=\"#CMSS17-117\"/>\n      <use transform=\"translate(193.700442 0)scale(0.996264)\" xlink:href=\"#CMSS17-114\"/>\n      <use transform=\"translate(225.610215 0)scale(0.996264)\" xlink:href=\"#CMSS17-97\"/>\n      <use transform=\"translate(270.532135 0)scale(0.996264)\" xlink:href=\"#CMSS17-99\"/>\n      <use transform=\"translate(312.170957 0)scale(0.996264)\" xlink:href=\"#CMSS17-121\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"PolyCollection_4\">\n    <defs>\n     <path d=\"M 429.733656 -242.875765 \nL 429.733656 -242.058494 \nL 453.244162 -240.188963 \nL 476.754668 -238.686645 \nL 500.265174 -236.545722 \nL 523.77568 -232.230764 \nL 547.286186 -227.64654 \nL 570.796692 -220.749952 \nL 594.307198 -211.395041 \nL 617.817704 -192.963641 \nL 641.32821 -167.275922 \nL 664.838716 -125.045801 \nL 688.349222 -70.576561 \nL 688.349222 -84.796152 \nL 688.349222 -84.796152 \nL 664.838716 -132.937122 \nL 641.32821 -173.169344 \nL 617.817704 -197.275641 \nL 594.307198 -212.951702 \nL 570.796692 -222.809221 \nL 547.286186 -229.728315 \nL 523.77568 -234.066717 \nL 500.265174 -236.875469 \nL 476.754668 -239.6276 \nL 453.244162 -241.435289 \nL 429.733656 -242.875765 \nz\n\" id=\"m273f7734eb\" style=\"stroke:#4c72b0;stroke-opacity:0.2;\"/>\n    </defs>\n    <g clip-path=\"url(#pb1e0c9dc0b)\">\n     <use style=\"fill:#4c72b0;fill-opacity:0.2;stroke:#4c72b0;stroke-opacity:0.2;\" x=\"0\" xlink:href=\"#m273f7734eb\" y=\"276.48\"/>\n    </g>\n   </g>\n   <g id=\"PolyCollection_5\">\n    <defs>\n     <path d=\"M 429.733656 -243.378889 \nL 429.733656 -241.628692 \nL 453.244162 -239.330338 \nL 476.754668 -236.448001 \nL 500.265174 -233.767316 \nL 523.77568 -229.470891 \nL 547.286186 -222.487735 \nL 570.796692 -215.735106 \nL 594.307198 -202.414439 \nL 617.817704 -181.319103 \nL 641.32821 -151.451305 \nL 664.838716 -108.071691 \nL 688.349222 -50.79119 \nL 688.349222 -74.712674 \nL 688.349222 -74.712674 \nL 664.838716 -123.629742 \nL 641.32821 -163.141251 \nL 617.817704 -191.076291 \nL 594.307198 -206.829373 \nL 570.796692 -218.525717 \nL 547.286186 -226.455437 \nL 523.77568 -232.586612 \nL 500.265174 -235.631361 \nL 476.754668 -238.510012 \nL 453.244162 -241.472105 \nL 429.733656 -243.378889 \nz\n\" id=\"ma7cf984d8a\" style=\"stroke:#dd8452;stroke-opacity:0.2;\"/>\n    </defs>\n    <g clip-path=\"url(#pb1e0c9dc0b)\">\n     <use style=\"fill:#dd8452;fill-opacity:0.2;stroke:#dd8452;stroke-opacity:0.2;\" x=\"0\" xlink:href=\"#ma7cf984d8a\" y=\"276.48\"/>\n    </g>\n   </g>\n   <g id=\"PolyCollection_6\">\n    <defs>\n     <path d=\"M 429.733656 -245.254647 \nL 429.733656 -243.625312 \nL 453.244162 -242.005737 \nL 476.754668 -239.242211 \nL 500.265174 -235.176128 \nL 523.77568 -231.18138 \nL 547.286186 -225.770537 \nL 570.796692 -217.983673 \nL 594.307198 -205.607245 \nL 617.817704 -188.529952 \nL 641.32821 -162.480405 \nL 664.838716 -127.85143 \nL 688.349222 -80.291577 \nL 688.349222 -99.873187 \nL 688.349222 -99.873187 \nL 664.838716 -148.643378 \nL 641.32821 -178.425705 \nL 617.817704 -199.214221 \nL 594.307198 -214.772943 \nL 570.796692 -223.627858 \nL 547.286186 -230.545133 \nL 523.77568 -235.032686 \nL 500.265174 -238.927964 \nL 476.754668 -241.317356 \nL 453.244162 -244.005121 \nL 429.733656 -245.254647 \nz\n\" id=\"m450b49cfba\" style=\"stroke:#55a868;stroke-opacity:0.2;\"/>\n    </defs>\n    <g clip-path=\"url(#pb1e0c9dc0b)\">\n     <use style=\"fill:#55a868;fill-opacity:0.2;stroke:#55a868;stroke-opacity:0.2;\" x=\"0\" xlink:href=\"#m450b49cfba\" y=\"276.48\"/>\n    </g>\n   </g>\n   <g id=\"line2d_20\">\n    <path clip-path=\"url(#pb1e0c9dc0b)\" d=\"M 429.733656 34.012871 \nL 453.244162 35.667874 \nL 476.754668 37.322878 \nL 500.265174 39.769404 \nL 523.77568 43.331259 \nL 547.286186 47.792573 \nL 570.796692 54.700413 \nL 594.307198 64.306629 \nL 617.817704 81.360359 \nL 641.32821 106.257367 \nL 664.838716 147.488538 \nL 688.349222 198.793644 \n\" style=\"fill:none;stroke:#4c72b0;stroke-linecap:round;stroke-width:1.5;\"/>\n    <g clip-path=\"url(#pb1e0c9dc0b)\">\n     <use style=\"fill:#4c72b0;stroke:#ffffff;stroke-width:0.75;\" x=\"429.733656\" xlink:href=\"#m36c057cb21\" y=\"34.012871\"/>\n     <use style=\"fill:#4c72b0;stroke:#ffffff;stroke-width:0.75;\" x=\"453.244162\" xlink:href=\"#m36c057cb21\" y=\"35.667874\"/>\n     <use style=\"fill:#4c72b0;stroke:#ffffff;stroke-width:0.75;\" x=\"476.754668\" xlink:href=\"#m36c057cb21\" y=\"37.322878\"/>\n     <use style=\"fill:#4c72b0;stroke:#ffffff;stroke-width:0.75;\" x=\"500.265174\" xlink:href=\"#m36c057cb21\" y=\"39.769404\"/>\n     <use style=\"fill:#4c72b0;stroke:#ffffff;stroke-width:0.75;\" x=\"523.77568\" xlink:href=\"#m36c057cb21\" y=\"43.331259\"/>\n     <use style=\"fill:#4c72b0;stroke:#ffffff;stroke-width:0.75;\" x=\"547.286186\" xlink:href=\"#m36c057cb21\" y=\"47.792573\"/>\n     <use style=\"fill:#4c72b0;stroke:#ffffff;stroke-width:0.75;\" x=\"570.796692\" xlink:href=\"#m36c057cb21\" y=\"54.700413\"/>\n     <use style=\"fill:#4c72b0;stroke:#ffffff;stroke-width:0.75;\" x=\"594.307198\" xlink:href=\"#m36c057cb21\" y=\"64.306629\"/>\n     <use style=\"fill:#4c72b0;stroke:#ffffff;stroke-width:0.75;\" x=\"617.817704\" xlink:href=\"#m36c057cb21\" y=\"81.360359\"/>\n     <use style=\"fill:#4c72b0;stroke:#ffffff;stroke-width:0.75;\" x=\"641.32821\" xlink:href=\"#m36c057cb21\" y=\"106.257367\"/>\n     <use style=\"fill:#4c72b0;stroke:#ffffff;stroke-width:0.75;\" x=\"664.838716\" xlink:href=\"#m36c057cb21\" y=\"147.488538\"/>\n     <use style=\"fill:#4c72b0;stroke:#ffffff;stroke-width:0.75;\" x=\"688.349222\" xlink:href=\"#m36c057cb21\" y=\"198.793644\"/>\n    </g>\n   </g>\n   <g id=\"line2d_21\">\n    <path clip-path=\"url(#pb1e0c9dc0b)\" d=\"M 429.733656 33.976209 \nL 453.244162 36.078779 \nL 476.754668 39.000994 \nL 500.265174 41.780662 \nL 523.77568 45.451249 \nL 547.286186 52.008414 \nL 570.796692 59.349588 \nL 594.307198 71.858094 \nL 617.817704 90.282303 \nL 641.32821 119.183722 \nL 664.838716 160.629284 \nL 688.349222 213.728068 \n\" style=\"fill:none;stroke:#dd8452;stroke-linecap:round;stroke-width:1.5;\"/>\n    <g clip-path=\"url(#pb1e0c9dc0b)\">\n     <use style=\"fill:#dd8452;stroke:#ffffff;stroke-width:0.75;\" x=\"429.733656\" xlink:href=\"#mfb9088fc74\" y=\"33.976209\"/>\n     <use style=\"fill:#dd8452;stroke:#ffffff;stroke-width:0.75;\" x=\"453.244162\" xlink:href=\"#mfb9088fc74\" y=\"36.078779\"/>\n     <use style=\"fill:#dd8452;stroke:#ffffff;stroke-width:0.75;\" x=\"476.754668\" xlink:href=\"#mfb9088fc74\" y=\"39.000994\"/>\n     <use style=\"fill:#dd8452;stroke:#ffffff;stroke-width:0.75;\" x=\"500.265174\" xlink:href=\"#mfb9088fc74\" y=\"41.780662\"/>\n     <use style=\"fill:#dd8452;stroke:#ffffff;stroke-width:0.75;\" x=\"523.77568\" xlink:href=\"#mfb9088fc74\" y=\"45.451249\"/>\n     <use style=\"fill:#dd8452;stroke:#ffffff;stroke-width:0.75;\" x=\"547.286186\" xlink:href=\"#mfb9088fc74\" y=\"52.008414\"/>\n     <use style=\"fill:#dd8452;stroke:#ffffff;stroke-width:0.75;\" x=\"570.796692\" xlink:href=\"#mfb9088fc74\" y=\"59.349588\"/>\n     <use style=\"fill:#dd8452;stroke:#ffffff;stroke-width:0.75;\" x=\"594.307198\" xlink:href=\"#mfb9088fc74\" y=\"71.858094\"/>\n     <use style=\"fill:#dd8452;stroke:#ffffff;stroke-width:0.75;\" x=\"617.817704\" xlink:href=\"#mfb9088fc74\" y=\"90.282303\"/>\n     <use style=\"fill:#dd8452;stroke:#ffffff;stroke-width:0.75;\" x=\"641.32821\" xlink:href=\"#mfb9088fc74\" y=\"119.183722\"/>\n     <use style=\"fill:#dd8452;stroke:#ffffff;stroke-width:0.75;\" x=\"664.838716\" xlink:href=\"#mfb9088fc74\" y=\"160.629284\"/>\n     <use style=\"fill:#dd8452;stroke:#ffffff;stroke-width:0.75;\" x=\"688.349222\" xlink:href=\"#mfb9088fc74\" y=\"213.728068\"/>\n    </g>\n   </g>\n   <g id=\"line2d_22\">\n    <path clip-path=\"url(#pb1e0c9dc0b)\" d=\"M 429.733656 32.040021 \nL 453.244162 33.474571 \nL 476.754668 36.200216 \nL 500.265174 39.427954 \nL 523.77568 43.372967 \nL 547.286186 48.322165 \nL 570.796692 55.674234 \nL 594.307198 66.289906 \nL 617.817704 82.607914 \nL 641.32821 106.026945 \nL 664.838716 138.232596 \nL 688.349222 186.397618 \n\" style=\"fill:none;stroke:#55a868;stroke-linecap:round;stroke-width:1.5;\"/>\n    <g clip-path=\"url(#pb1e0c9dc0b)\">\n     <use style=\"fill:#55a868;stroke:#ffffff;stroke-width:0.75;\" x=\"429.733656\" xlink:href=\"#m2ae3b41cec\" y=\"32.040021\"/>\n     <use style=\"fill:#55a868;stroke:#ffffff;stroke-width:0.75;\" x=\"453.244162\" xlink:href=\"#m2ae3b41cec\" y=\"33.474571\"/>\n     <use style=\"fill:#55a868;stroke:#ffffff;stroke-width:0.75;\" x=\"476.754668\" xlink:href=\"#m2ae3b41cec\" y=\"36.200216\"/>\n     <use style=\"fill:#55a868;stroke:#ffffff;stroke-width:0.75;\" x=\"500.265174\" xlink:href=\"#m2ae3b41cec\" y=\"39.427954\"/>\n     <use style=\"fill:#55a868;stroke:#ffffff;stroke-width:0.75;\" x=\"523.77568\" xlink:href=\"#m2ae3b41cec\" y=\"43.372967\"/>\n     <use style=\"fill:#55a868;stroke:#ffffff;stroke-width:0.75;\" x=\"547.286186\" xlink:href=\"#m2ae3b41cec\" y=\"48.322165\"/>\n     <use style=\"fill:#55a868;stroke:#ffffff;stroke-width:0.75;\" x=\"570.796692\" xlink:href=\"#m2ae3b41cec\" y=\"55.674234\"/>\n     <use style=\"fill:#55a868;stroke:#ffffff;stroke-width:0.75;\" x=\"594.307198\" xlink:href=\"#m2ae3b41cec\" y=\"66.289906\"/>\n     <use style=\"fill:#55a868;stroke:#ffffff;stroke-width:0.75;\" x=\"617.817704\" xlink:href=\"#m2ae3b41cec\" y=\"82.607914\"/>\n     <use style=\"fill:#55a868;stroke:#ffffff;stroke-width:0.75;\" x=\"641.32821\" xlink:href=\"#m2ae3b41cec\" y=\"106.026945\"/>\n     <use style=\"fill:#55a868;stroke:#ffffff;stroke-width:0.75;\" x=\"664.838716\" xlink:href=\"#m2ae3b41cec\" y=\"138.232596\"/>\n     <use style=\"fill:#55a868;stroke:#ffffff;stroke-width:0.75;\" x=\"688.349222\" xlink:href=\"#m2ae3b41cec\" y=\"186.397618\"/>\n    </g>\n   </g>\n   <g id=\"line2d_23\"/>\n   <g id=\"line2d_24\"/>\n   <g id=\"line2d_25\"/>\n   <g id=\"patch_7\">\n    <path d=\"M 416.802878 235.411983 \nL 416.802878 21.50218 \n\" style=\"fill:none;stroke:#cccccc;stroke-linecap:square;stroke-linejoin:miter;stroke-width:1.25;\"/>\n   </g>\n   <g id=\"patch_8\">\n    <path d=\"M 416.802878 235.411983 \nL 701.28 235.411983 \n\" style=\"fill:none;stroke:#cccccc;stroke-linecap:square;stroke-linejoin:miter;stroke-width:1.25;\"/>\n   </g>\n   <g id=\"text_33\">\n    <!-- Attack on robust models -->\n    <g style=\"fill:#262626;\" transform=\"translate(498.86434 15.50218)scale(0.12 -0.12)\">\n     <defs>\n      <path d=\"M 14.90625 69 \nL 7.5 69 \nL 7.5 -0.203125 \nL 15.09375 -0.203125 \nL 15.09375 4.28125 \nC 18.90625 0.59375 23.5 -1 27.59375 -1 \nC 37.203125 -1 45 8.578125 45 21.125 \nC 45 32.59375 39 43.0625 30.09375 43.0625 \nC 23.796875 43.0625 18.203125 40.484375 14.90625 37.796875 \nz\nM 15.09375 31.96875 \nC 17.296875 34.71875 20.40625 37 24.796875 37 \nC 30.703125 37 37.40625 32.765625 37.40625 21.125 \nC 37.40625 8.71875 29.40625 5.078125 23.90625 5.078125 \nC 21.90625 5.078125 19.796875 5.5625 17.796875 7.25 \nC 15.09375 9.609375 15.09375 11.078125 15.09375 12.453125 \nz\n\" id=\"CMSS17-98\"/>\n     </defs>\n     <use transform=\"scale(0.996264)\" xlink:href=\"#CMSS17-65\"/>\n     <use transform=\"translate(59.615401 0)scale(0.996264)\" xlink:href=\"#CMSS17-116\"/>\n     <use transform=\"translate(93.446968 0)scale(0.996264)\" xlink:href=\"#CMSS17-116\"/>\n     <use transform=\"translate(127.278534 0)scale(0.996264)\" xlink:href=\"#CMSS17-97\"/>\n     <use transform=\"translate(172.200455 0)scale(0.996264)\" xlink:href=\"#CMSS17-99\"/>\n     <use transform=\"translate(213.839277 0)scale(0.996264)\" xlink:href=\"#CMSS17-107\"/>\n     <use transform=\"translate(290.670879 0)scale(0.996264)\" xlink:href=\"#CMSS17-111\"/>\n     <use transform=\"translate(337.514503 0)scale(0.996264)\" xlink:href=\"#CMSS17-110\"/>\n     <use transform=\"translate(416.948558 0)scale(0.996264)\" xlink:href=\"#CMSS17-114\"/>\n     <use transform=\"translate(448.858331 0)scale(0.996264)\" xlink:href=\"#CMSS17-111\"/>\n     <use transform=\"translate(495.701954 0)scale(0.996264)\" xlink:href=\"#CMSS17-98\"/>\n     <use transform=\"translate(543.906898 0)scale(0.996264)\" xlink:href=\"#CMSS17-117\"/>\n     <use transform=\"translate(592.111841 0)scale(0.996264)\" xlink:href=\"#CMSS17-115\"/>\n     <use transform=\"translate(628.025383 0)scale(0.996264)\" xlink:href=\"#CMSS17-116\"/>\n     <use transform=\"translate(693.086062 0)scale(0.996264)\" xlink:href=\"#CMSS17-109\"/>\n     <use transform=\"translate(767.315317 0)scale(0.996264)\" xlink:href=\"#CMSS17-111\"/>\n     <use transform=\"translate(816.761379 0)scale(0.996264)\" xlink:href=\"#CMSS17-100\"/>\n     <use transform=\"translate(864.966322 0)scale(0.996264)\" xlink:href=\"#CMSS17-101\"/>\n     <use transform=\"translate(906.605144 0)scale(0.996264)\" xlink:href=\"#CMSS17-108\"/>\n     <use transform=\"translate(928.785867 0)scale(0.996264)\" xlink:href=\"#CMSS17-115\"/>\n    </g>\n   </g>\n   <g id=\"legend_2\">\n    <g id=\"patch_9\">\n     <path d=\"M 424.502878 229.911983 \nL 552.260131 229.911983 \nQ 554.460131 229.911983 554.460131 227.711983 \nL 554.460131 163.417182 \nQ 554.460131 161.217182 552.260131 161.217182 \nL 424.502878 161.217182 \nQ 422.302878 161.217182 422.302878 163.417182 \nL 422.302878 227.711983 \nQ 422.302878 229.911983 424.502878 229.911983 \nz\n\" style=\"fill:#ffffff;opacity:0.8;stroke:#cccccc;stroke-linejoin:miter;\"/>\n    </g>\n    <g id=\"text_34\">\n     <!-- optimizer -->\n     <g style=\"fill:#262626;\" transform=\"translate(465.827479 174.735307)scale(0.12 -0.12)\">\n      <use transform=\"scale(0.996264)\" xlink:href=\"#CMSS17-111\"/>\n      <use transform=\"translate(46.843624 0)scale(0.996264)\" xlink:href=\"#CMSS17-112\"/>\n      <use transform=\"translate(95.048567 0)scale(0.996264)\" xlink:href=\"#CMSS17-116\"/>\n      <use transform=\"translate(128.880133 0)scale(0.996264)\" xlink:href=\"#CMSS17-105\"/>\n      <use transform=\"translate(151.060856 0)scale(0.996264)\" xlink:href=\"#CMSS17-109\"/>\n      <use transform=\"translate(225.290111 0)scale(0.996264)\" xlink:href=\"#CMSS17-105\"/>\n      <use transform=\"translate(247.470834 0)scale(0.996264)\" xlink:href=\"#CMSS17-122\"/>\n      <use transform=\"translate(288.148706 0)scale(0.996264)\" xlink:href=\"#CMSS17-101\"/>\n      <use transform=\"translate(329.787528 0)scale(0.996264)\" xlink:href=\"#CMSS17-114\"/>\n     </g>\n    </g>\n    <g id=\"line2d_26\">\n     <path d=\"M 426.702878 187.239213 \nL 448.702878 187.239213 \n\" style=\"fill:none;stroke:#4c72b0;stroke-linecap:round;stroke-width:1.5;\"/>\n    </g>\n    <g id=\"line2d_27\"/>\n    <g id=\"text_35\">\n     <!-- AdamOptimizer -->\n     <g style=\"fill:#262626;\" transform=\"translate(457.502878 191.089213)scale(0.11 -0.11)\">\n      <use transform=\"scale(0.996264)\" xlink:href=\"#CMSS17-65\"/>\n      <use transform=\"translate(62.217855 0)scale(0.996264)\" xlink:href=\"#CMSS17-100\"/>\n      <use transform=\"translate(110.422798 0)scale(0.996264)\" xlink:href=\"#CMSS17-97\"/>\n      <use transform=\"translate(155.344719 0)scale(0.996264)\" xlink:href=\"#CMSS17-109\"/>\n      <use transform=\"translate(229.573973 0)scale(0.996264)\" xlink:href=\"#CMSS17-79\"/>\n      <use transform=\"translate(298.598228 0)scale(0.996264)\" xlink:href=\"#CMSS17-112\"/>\n      <use transform=\"translate(346.803172 0)scale(0.996264)\" xlink:href=\"#CMSS17-116\"/>\n      <use transform=\"translate(380.634738 0)scale(0.996264)\" xlink:href=\"#CMSS17-105\"/>\n      <use transform=\"translate(402.815461 0)scale(0.996264)\" xlink:href=\"#CMSS17-109\"/>\n      <use transform=\"translate(477.044716 0)scale(0.996264)\" xlink:href=\"#CMSS17-105\"/>\n      <use transform=\"translate(499.225439 0)scale(0.996264)\" xlink:href=\"#CMSS17-122\"/>\n      <use transform=\"translate(539.903311 0)scale(0.996264)\" xlink:href=\"#CMSS17-101\"/>\n      <use transform=\"translate(581.542133 0)scale(0.996264)\" xlink:href=\"#CMSS17-114\"/>\n     </g>\n    </g>\n    <g id=\"line2d_28\">\n     <path d=\"M 426.702878 203.385151 \nL 448.702878 203.385151 \n\" style=\"fill:none;stroke:#dd8452;stroke-linecap:round;stroke-width:1.5;\"/>\n    </g>\n    <g id=\"line2d_29\"/>\n    <g id=\"text_36\">\n     <!-- MiniBatchOptimizer -->\n     <g style=\"fill:#262626;\" transform=\"translate(457.502878 207.235151)scale(0.11 -0.11)\">\n      <use transform=\"scale(0.996264)\" xlink:href=\"#CMSS17-77\"/>\n      <use transform=\"translate(81.67603 0)scale(0.996264)\" xlink:href=\"#CMSS17-105\"/>\n      <use transform=\"translate(103.856753 0)scale(0.996264)\" xlink:href=\"#CMSS17-110\"/>\n      <use transform=\"translate(152.061696 0)scale(0.996264)\" xlink:href=\"#CMSS17-105\"/>\n      <use transform=\"translate(174.242419 0)scale(0.996264)\" xlink:href=\"#CMSS17-66\"/>\n      <use transform=\"translate(236.580459 0)scale(0.996264)\" xlink:href=\"#CMSS17-97\"/>\n      <use transform=\"translate(281.50238 0)scale(0.996264)\" xlink:href=\"#CMSS17-116\"/>\n      <use transform=\"translate(315.333947 0)scale(0.996264)\" xlink:href=\"#CMSS17-99\"/>\n      <use transform=\"translate(356.972769 0)scale(0.996264)\" xlink:href=\"#CMSS17-104\"/>\n      <use transform=\"translate(405.177712 0)scale(0.996264)\" xlink:href=\"#CMSS17-79\"/>\n      <use transform=\"translate(474.201967 0)scale(0.996264)\" xlink:href=\"#CMSS17-112\"/>\n      <use transform=\"translate(522.40691 0)scale(0.996264)\" xlink:href=\"#CMSS17-116\"/>\n      <use transform=\"translate(556.238477 0)scale(0.996264)\" xlink:href=\"#CMSS17-105\"/>\n      <use transform=\"translate(578.4192 0)scale(0.996264)\" xlink:href=\"#CMSS17-109\"/>\n      <use transform=\"translate(652.648455 0)scale(0.996264)\" xlink:href=\"#CMSS17-105\"/>\n      <use transform=\"translate(674.829178 0)scale(0.996264)\" xlink:href=\"#CMSS17-122\"/>\n      <use transform=\"translate(715.507049 0)scale(0.996264)\" xlink:href=\"#CMSS17-101\"/>\n      <use transform=\"translate(757.145871 0)scale(0.996264)\" xlink:href=\"#CMSS17-114\"/>\n     </g>\n    </g>\n    <g id=\"line2d_30\">\n     <path d=\"M 426.702878 219.531088 \nL 448.702878 219.531088 \n\" style=\"fill:none;stroke:#55a868;stroke-linecap:round;stroke-width:1.5;\"/>\n    </g>\n    <g id=\"line2d_31\"/>\n    <g id=\"text_37\">\n     <!-- NesterovOptimizer -->\n     <g style=\"fill:#262626;\" transform=\"translate(457.502878 223.381088)scale(0.11 -0.11)\">\n      <use transform=\"scale(0.996264)\" xlink:href=\"#CMSS17-78\"/>\n      <use transform=\"translate(66.061519 0)scale(0.996264)\" xlink:href=\"#CMSS17-101\"/>\n      <use transform=\"translate(107.700341 0)scale(0.996264)\" xlink:href=\"#CMSS17-115\"/>\n      <use transform=\"translate(143.613883 0)scale(0.996264)\" xlink:href=\"#CMSS17-116\"/>\n      <use transform=\"translate(177.44545 0)scale(0.996264)\" xlink:href=\"#CMSS17-101\"/>\n      <use transform=\"translate(219.084272 0)scale(0.996264)\" xlink:href=\"#CMSS17-114\"/>\n      <use transform=\"translate(250.994045 0)scale(0.996264)\" xlink:href=\"#CMSS17-111\"/>\n      <use transform=\"translate(297.837668 0)scale(0.996264)\" xlink:href=\"#CMSS17-118\"/>\n      <use transform=\"translate(340.83781 0)scale(0.996264)\" xlink:href=\"#CMSS17-79\"/>\n      <use transform=\"translate(409.862065 0)scale(0.996264)\" xlink:href=\"#CMSS17-112\"/>\n      <use transform=\"translate(458.067008 0)scale(0.996264)\" xlink:href=\"#CMSS17-116\"/>\n      <use transform=\"translate(491.898575 0)scale(0.996264)\" xlink:href=\"#CMSS17-105\"/>\n      <use transform=\"translate(514.079298 0)scale(0.996264)\" xlink:href=\"#CMSS17-109\"/>\n      <use transform=\"translate(588.308552 0)scale(0.996264)\" xlink:href=\"#CMSS17-105\"/>\n      <use transform=\"translate(610.489275 0)scale(0.996264)\" xlink:href=\"#CMSS17-122\"/>\n      <use transform=\"translate(651.167147 0)scale(0.996264)\" xlink:href=\"#CMSS17-101\"/>\n      <use transform=\"translate(692.805969 0)scale(0.996264)\" xlink:href=\"#CMSS17-114\"/>\n     </g>\n    </g>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"paf76286ffa\">\n   <rect height=\"213.909803\" width=\"284.477122\" x=\"70.276969\" y=\"21.50218\"/>\n  </clipPath>\n  <clipPath id=\"pb1e0c9dc0b\">\n   <rect height=\"213.909803\" width=\"284.477122\" x=\"416.802878\" y=\"21.50218\"/>\n  </clipPath>\n </defs>\n</svg>\n","text/plain":["<Figure size 1000x400 with 2 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"western-album","outputId":"8a594e6c-f613-4cc8-90b4-bfb994157824"},"source":["df_naive[df_naive.epsilon==0]"],"id":"western-album","execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>optimizer</th>\n","      <th>epsilon</th>\n","      <th>acc</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>AdamOptimizer</td>\n","      <td>0.0</td>\n","      <td>0.941094</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>AdamOptimizer</td>\n","      <td>0.0</td>\n","      <td>0.927915</td>\n","    </tr>\n","    <tr>\n","      <th>24</th>\n","      <td>AdamOptimizer</td>\n","      <td>0.0</td>\n","      <td>0.961861</td>\n","    </tr>\n","    <tr>\n","      <th>72</th>\n","      <td>MiniBatchOptimizer</td>\n","      <td>0.0</td>\n","      <td>0.973299</td>\n","    </tr>\n","    <tr>\n","      <th>84</th>\n","      <td>MiniBatchOptimizer</td>\n","      <td>0.0</td>\n","      <td>0.980123</td>\n","    </tr>\n","    <tr>\n","      <th>96</th>\n","      <td>MiniBatchOptimizer</td>\n","      <td>0.0</td>\n","      <td>0.967959</td>\n","    </tr>\n","    <tr>\n","      <th>36</th>\n","      <td>NesterovOptimizer</td>\n","      <td>0.0</td>\n","      <td>0.942974</td>\n","    </tr>\n","    <tr>\n","      <th>48</th>\n","      <td>NesterovOptimizer</td>\n","      <td>0.0</td>\n","      <td>0.949244</td>\n","    </tr>\n","    <tr>\n","      <th>60</th>\n","      <td>NesterovOptimizer</td>\n","      <td>0.0</td>\n","      <td>0.878981</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["             optimizer  epsilon       acc\n","0        AdamOptimizer      0.0  0.941094\n","12       AdamOptimizer      0.0  0.927915\n","24       AdamOptimizer      0.0  0.961861\n","72  MiniBatchOptimizer      0.0  0.973299\n","84  MiniBatchOptimizer      0.0  0.980123\n","96  MiniBatchOptimizer      0.0  0.967959\n","36   NesterovOptimizer      0.0  0.942974\n","48   NesterovOptimizer      0.0  0.949244\n","60   NesterovOptimizer      0.0  0.878981"]},"metadata":{"tags":[]},"execution_count":50}]},{"cell_type":"code","metadata":{"id":"silent-staff","outputId":"c690a802-5a76-49ef-f35c-3832d8c6ab0e"},"source":["df_robust[df_robust.epsilon == 0]"],"id":"silent-staff","execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>optimizer</th>\n","      <th>n</th>\n","      <th>epsilon</th>\n","      <th>loss</th>\n","      <th>acc</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>AdamOptimizer</td>\n","      <td>1</td>\n","      <td>0.0</td>\n","      <td>[0.0018492619000000001, 0.0349977985, 0.105498...</td>\n","      <td>0.989916</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>AdamOptimizer</td>\n","      <td>2</td>\n","      <td>0.0</td>\n","      <td>[8.23563e-05, 0.0751273111, 0.127101779, 0.025...</td>\n","      <td>0.989317</td>\n","    </tr>\n","    <tr>\n","      <th>24</th>\n","      <td>AdamOptimizer</td>\n","      <td>3</td>\n","      <td>0.0</td>\n","      <td>[0.000659264, 0.0679881126, 0.2566815317, 0.01...</td>\n","      <td>0.989217</td>\n","    </tr>\n","    <tr>\n","      <th>72</th>\n","      <td>MiniBatchOptimizer</td>\n","      <td>1</td>\n","      <td>0.0</td>\n","      <td>[0.17910747230000001, 0.1800464094, 0.02464219...</td>\n","      <td>0.990210</td>\n","    </tr>\n","    <tr>\n","      <th>84</th>\n","      <td>MiniBatchOptimizer</td>\n","      <td>2</td>\n","      <td>0.0</td>\n","      <td>[0.0524176471, 0.083157666, 0.064069055, 0.023...</td>\n","      <td>0.989715</td>\n","    </tr>\n","    <tr>\n","      <th>96</th>\n","      <td>MiniBatchOptimizer</td>\n","      <td>3</td>\n","      <td>0.0</td>\n","      <td>[0.0651606768, 0.2377728969, 0.0287860315, 0.0...</td>\n","      <td>0.988627</td>\n","    </tr>\n","    <tr>\n","      <th>36</th>\n","      <td>NesterovOptimizer</td>\n","      <td>1</td>\n","      <td>0.0</td>\n","      <td>[0.0453112423, 0.0331727266, 0.0055757975, 0.0...</td>\n","      <td>0.990446</td>\n","    </tr>\n","    <tr>\n","      <th>48</th>\n","      <td>NesterovOptimizer</td>\n","      <td>2</td>\n","      <td>0.0</td>\n","      <td>[0.07178882510000001, 0.0065097441, 0.14699059...</td>\n","      <td>0.991640</td>\n","    </tr>\n","    <tr>\n","      <th>60</th>\n","      <td>NesterovOptimizer</td>\n","      <td>3</td>\n","      <td>0.0</td>\n","      <td>[0.0048656156, 0.3748389781, 0.095572389700000...</td>\n","      <td>0.991839</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["             optimizer  n  epsilon  \\\n","0        AdamOptimizer  1      0.0   \n","12       AdamOptimizer  2      0.0   \n","24       AdamOptimizer  3      0.0   \n","72  MiniBatchOptimizer  1      0.0   \n","84  MiniBatchOptimizer  2      0.0   \n","96  MiniBatchOptimizer  3      0.0   \n","36   NesterovOptimizer  1      0.0   \n","48   NesterovOptimizer  2      0.0   \n","60   NesterovOptimizer  3      0.0   \n","\n","                                                 loss       acc  \n","0   [0.0018492619000000001, 0.0349977985, 0.105498...  0.989916  \n","12  [8.23563e-05, 0.0751273111, 0.127101779, 0.025...  0.989317  \n","24  [0.000659264, 0.0679881126, 0.2566815317, 0.01...  0.989217  \n","72  [0.17910747230000001, 0.1800464094, 0.02464219...  0.990210  \n","84  [0.0524176471, 0.083157666, 0.064069055, 0.023...  0.989715  \n","96  [0.0651606768, 0.2377728969, 0.0287860315, 0.0...  0.988627  \n","36  [0.0453112423, 0.0331727266, 0.0055757975, 0.0...  0.990446  \n","48  [0.07178882510000001, 0.0065097441, 0.14699059...  0.991640  \n","60  [0.0048656156, 0.3748389781, 0.095572389700000...  0.991839  "]},"metadata":{"tags":[]},"execution_count":49}]},{"cell_type":"code","metadata":{"id":"burning-dylan","outputId":"891c9410-b68e-415f-c302-b6535f4b0427"},"source":["df_robust"],"id":"burning-dylan","execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>optimizer</th>\n","      <th>n</th>\n","      <th>epsilon</th>\n","      <th>loss</th>\n","      <th>acc</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>AdamOptimizer</td>\n","      <td>1</td>\n","      <td>0.00</td>\n","      <td>[0.0018492619000000001, 0.0349977985, 0.105498...</td>\n","      <td>0.989916</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>AdamOptimizer</td>\n","      <td>2</td>\n","      <td>0.00</td>\n","      <td>[8.23563e-05, 0.0751273111, 0.127101779, 0.025...</td>\n","      <td>0.989317</td>\n","    </tr>\n","    <tr>\n","      <th>24</th>\n","      <td>AdamOptimizer</td>\n","      <td>3</td>\n","      <td>0.00</td>\n","      <td>[0.000659264, 0.0679881126, 0.2566815317, 0.01...</td>\n","      <td>0.989217</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>AdamOptimizer</td>\n","      <td>1</td>\n","      <td>0.05</td>\n","      <td>[0.0018492619000000001, 0.0349977985, 0.105498...</td>\n","      <td>0.988618</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>AdamOptimizer</td>\n","      <td>2</td>\n","      <td>0.05</td>\n","      <td>[8.23563e-05, 0.0751273111, 0.127101779, 0.025...</td>\n","      <td>0.987620</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>58</th>\n","      <td>NesterovOptimizer</td>\n","      <td>2</td>\n","      <td>0.50</td>\n","      <td>[0.07178882510000001, 0.0065097441, 0.14699059...</td>\n","      <td>0.883758</td>\n","    </tr>\n","    <tr>\n","      <th>70</th>\n","      <td>NesterovOptimizer</td>\n","      <td>3</td>\n","      <td>0.50</td>\n","      <td>[0.0048656156, 0.3748389781, 0.095572389700000...</td>\n","      <td>0.902966</td>\n","    </tr>\n","    <tr>\n","      <th>47</th>\n","      <td>NesterovOptimizer</td>\n","      <td>1</td>\n","      <td>0.55</td>\n","      <td>[0.0453112423, 0.0331727266, 0.0055757975, 0.0...</td>\n","      <td>0.848527</td>\n","    </tr>\n","    <tr>\n","      <th>59</th>\n","      <td>NesterovOptimizer</td>\n","      <td>2</td>\n","      <td>0.55</td>\n","      <td>[0.07178882510000001, 0.0065097441, 0.14699059...</td>\n","      <td>0.839471</td>\n","    </tr>\n","    <tr>\n","      <th>71</th>\n","      <td>NesterovOptimizer</td>\n","      <td>3</td>\n","      <td>0.55</td>\n","      <td>[0.0048656156, 0.3748389781, 0.095572389700000...</td>\n","      <td>0.857584</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>108 rows  5 columns</p>\n","</div>"],"text/plain":["            optimizer  n  epsilon  \\\n","0       AdamOptimizer  1     0.00   \n","12      AdamOptimizer  2     0.00   \n","24      AdamOptimizer  3     0.00   \n","1       AdamOptimizer  1     0.05   \n","13      AdamOptimizer  2     0.05   \n","..                ... ..      ...   \n","58  NesterovOptimizer  2     0.50   \n","70  NesterovOptimizer  3     0.50   \n","47  NesterovOptimizer  1     0.55   \n","59  NesterovOptimizer  2     0.55   \n","71  NesterovOptimizer  3     0.55   \n","\n","                                                 loss       acc  \n","0   [0.0018492619000000001, 0.0349977985, 0.105498...  0.989916  \n","12  [8.23563e-05, 0.0751273111, 0.127101779, 0.025...  0.989317  \n","24  [0.000659264, 0.0679881126, 0.2566815317, 0.01...  0.989217  \n","1   [0.0018492619000000001, 0.0349977985, 0.105498...  0.988618  \n","13  [8.23563e-05, 0.0751273111, 0.127101779, 0.025...  0.987620  \n","..                                                ...       ...  \n","58  [0.07178882510000001, 0.0065097441, 0.14699059...  0.883758  \n","70  [0.0048656156, 0.3748389781, 0.095572389700000...  0.902966  \n","47  [0.0453112423, 0.0331727266, 0.0055757975, 0.0...  0.848527  \n","59  [0.07178882510000001, 0.0065097441, 0.14699059...  0.839471  \n","71  [0.0048656156, 0.3748389781, 0.095572389700000...  0.857584  \n","\n","[108 rows x 5 columns]"]},"metadata":{"tags":[]},"execution_count":37}]}]}